{"id": "2504.10639", "pdf": "https://arxiv.org/pdf/2504.10639", "abs": "https://arxiv.org/abs/2504.10639", "authors": ["Sanchita Ghosh", "Tanushree Roy"], "title": "Secure Estimation of Battery Voltage Under Sensor Attacks: A Self-Learning Koopman Approach", "categories": ["eess.SY", "cs.SY"], "comment": "10 pages, 5 figures", "summary": "Cloud-based battery management system (BMS) requires accurate terminal\nvoltage measurement data to ensure optimal and safe charging of Lithium-ion\nbatteries. Unfortunately, an adversary can corrupt the battery terminal voltage\ndata as it passes from the local-BMS to the cloud-BMS through the communication\nnetwork, with the objective of under- or over-charging the battery. To ensure\naccurate terminal voltage data under such malicious sensor attacks, this paper\ninvestigates a Koopman-based secure terminal voltage estimation scheme using a\ntwo-stage error-compensated self-learning feedback. During the first stage of\nerror correction, the potential Koopman prediction error is estimated to\ncompensate for the error accumulation due to the linear approximation of\nKoopman operator. The second stage of error compensation aims to recover the\nerror amassing from the higher-order dynamics of the Lithium-ion batteries\nmissed by the self-learning strategy. Specifically, we have proposed two\ndifferent methods for this second stage error compensation. First, an\ninterpretable empirical correction strategy has been obtained using the open\ncircuit voltage to state-of-charge mapping for the battery. Second, a Gaussian\nprocess regression-based data-driven method has been explored. Finally, we\ndemonstrate the efficacy of the proposed secure estimator using both empirical\nand data-driven corrections.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eKoopman\u7684\u5b89\u5168\u7ec8\u7aef\u7535\u538b\u4f30\u8ba1\u65b9\u6848\uff0c\u4f7f\u7528\u4e24\u9636\u6bb5\u9519\u8bef\u8865\u507f\u6765\u5e94\u5bf9\u4e91BMS\u4e2d\u7684\u6076\u610f\u4f20\u611f\u5668\u653b\u51fb\u3002", "motivation": "\u4e3a\u4e86\u5728\u6076\u610f\u653b\u51fb\u4e0b\u786e\u4fdd\u7535\u6c60\u7ec8\u7aef\u7535\u538b\u6570\u636e\u7684\u51c6\u786e\u6027\uff0c\u9632\u6b62\u7535\u6c60\u8fc7\u5145\u6216\u6b20\u5145\u3002", "method": "\u91c7\u7528Koopman\u8fd0\u7b97\u7b26\u7684\u7ebf\u6027\u903c\u8fd1\uff0c\u5e76\u901a\u8fc7\u4e24\u9636\u6bb5\u9519\u8bef\u8865\u507f\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f30\u8ba1\u5e76\u8865\u507fKoopman\u9884\u6d4b\u9519\u8bef\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u7ecf\u9a8c\u4fee\u6b63\uff08\u5982\u5f00\u8def\u7535\u538b\u5230\u8377\u6001\u6620\u5c04\uff09\u6216Gaussian\u8fc7\u7a0b\u56de\u5f52\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u4f7f\u7528\u7ecf\u9a8c\u548c\u6570\u636e\u9a71\u52a8\u4fee\u6b63\u7684\u5b89\u5168\u4f30\u8ba1\u5668\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6848\u80fd\u591f\u6709\u6548\u6062\u590d\u88ab\u653b\u51fb\u7684\u7535\u538b\u6570\u636e\uff0c\u786e\u4fddBMS\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2504.10658", "pdf": "https://arxiv.org/pdf/2504.10658", "abs": "https://arxiv.org/abs/2504.10658", "authors": ["Sanchita Ghosh", "Tanushree Roy"], "title": "Transfer Learning Assisted XgBoost For Adaptable Cyberattack Detection In Battery Packs", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "9 pages, 5 figures", "summary": "Optimal charging of electric vehicle (EVs) depends heavily on reliable sensor\nmeasurements from the battery pack to the cloud-controller of the smart\ncharging station. However, an adversary could corrupt the voltage sensor data\nduring transmission, potentially causing local to wide-scale disruptions.\nTherefore, it is essential to detect sensor cyberattacks in real-time to ensure\nsecure EV charging, and the developed algorithms must be readily adaptable to\nvariations, including pack configurations. To tackle these challenges, we\npropose adaptable fine-tuning of an XgBoost-based cell-level model using\nlimited pack-level data to use for voltage prediction and residual generation.\nWe used battery cell and pack data from high-fidelity charging experiments in\nPyBaMM and `liionpack' package to train and test the detection algorithm. The\nalgorithm's performance has been evaluated for two large-format battery packs\nunder sensor swapping and replay attacks. The simulation results also highlight\nthe adaptability and efficacy of our proposed detection algorithm.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u53ef\u9002\u5e94XgBoost\u6a21\u578b\u68c0\u6d4b\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u4e2d\u4f20\u611f\u5668\u7f51\u7edc\u653b\u51fb\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7531\u4e8e\u5bf9\u624b\u53ef\u80fd\u7be1\u6539\u7535\u538b\u4f20\u611f\u5668\u6570\u636e\u5bfc\u81f4\u5145\u7535\u4e2d\u65ad\uff0c\u56e0\u6b64\u9700\u8981\u5b9e\u65f6\u68c0\u6d4b\u653b\u51fb\u4ee5\u786e\u4fdd\u5145\u7535\u5b89\u5168\uff0c\u5e76\u9002\u5e94\u4e0d\u540c\u7535\u6c60\u914d\u7f6e\u3002", "method": "\u63d0\u51fa\u5bf9XgBoost-based\u7684\u7535\u6c60\u5355\u5143\u7ea7\u6a21\u578b\u8fdb\u884c\u53ef\u9002\u5e94\u5fae\u8c03\uff0c\u4f7f\u7528\u6709\u9650\u7684\u7535\u6c60\u7ec4\u7ea7\u6570\u636e\u8fdb\u884c\u7535\u538b\u9884\u6d4b\u548c\u6b8b\u5dee\u751f\u6210\uff0c\u5e76\u5229\u7528PyBaMM\u548cliionpack\u8f6f\u4ef6\u5305\u7684\u5b9e\u9a8c\u6570\u636e\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002", "result": "\u7b97\u6cd5\u5728\u4f20\u611f\u5668\u4ea4\u6362\u548c\u91cd\u653e\u653b\u51fb\u4e0b\uff0c\u5bf9\u4e24\u4e2a\u5927\u5bb9\u91cf\u7535\u6c60\u7ec4\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u6a21\u62df\u7ed3\u679c\u7a81\u51fa\u4e86\u5176\u53ef\u9002\u5e94\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u68c0\u6d4b\u7b97\u6cd5\u5728\u5b9e\u65f6\u786e\u4fdd\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u5b89\u5168\u65b9\u9762\u662f\u6709\u6548\u7684\uff0c\u4e14\u5177\u6709\u826f\u597d\u7684\u9002\u5e94\u6027\u3002"}}
{"id": "2504.10691", "pdf": "https://arxiv.org/pdf/2504.10691", "abs": "https://arxiv.org/abs/2504.10691", "authors": ["Ali Nazari", "Ali Olfat"], "title": "Spectrum Sharing in STAR-RIS-assisted UAV with NOMA for Cognitive Radio Networks", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "As an emerging technology, the simultaneous transmitting and reflecting\nreconfigurable intelligent surface (STAR-RIS) can improve the spectrum\nefficiency (SE) of primary users (PUs) and secondary users (SUs) in cognitive\nradio (CR) networks by mitigating the interference of the incident signals. The\nSTAR-RIS-assisted unmanned aerial vehicle (UAV) can fully cover the dynamic\nenvironment through high mobility and fast deployment. According to the dynamic\nair-to-ground channels, the STAR-RIS-assisted UAV may face a challenge\nconfiguring their elements' coefficients (i.e., reflecting and transmitting the\namplitude and phases). Hence, to meet the requirements of dynamic channel\ndetermination with the SE approach, this paper proposes the sum rate\nmaximization of both PUs and SUs through non-orthogonal multiple access in CR\nnetwork to jointly optimize the trajectory and transmission-reflection\nbeamforming design of the STAR-RIS-assisted UAV, and power allocation. Since\nthe non-convex joint optimization problem includes coupled optimization\nvariables, we develop an alternative optimization algorithm. Simulation results\nstudy the impact of: 1) the significant parameters, 2) the performance of\ndifferent intelligence surface modes and STAR-RIS operating protocols, 3) the\njoint trajectory and beamforming design with fixed and mobile users, and 4)\nSTAR-RIS capabilities such as mitigating the interference, and how variations\nin the roles of elements dynamically.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSTAR-RIS\u8f85\u52a9UAV\u7684\u8ba4\u77e5\u65e0\u7ebf\u7535\u7f51\u7edc\u4f18\u5316\u65b9\u6848\uff0c\u4ee5\u63d0\u9ad8\u9891\u8c31\u6548\u7387\u548c\u7f13\u89e3\u5e72\u6270\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u8ba4\u77e5\u65e0\u7ebf\u7535\u7f51\u7edc\u4e2d\u52a8\u6001\u4fe1\u9053\u6311\u6218\uff0c\u5e76\u901a\u8fc7STAR-RIS\u548cUAV\u6280\u672f\u6539\u5584\u4e3b\u7528\u6237\u548c\u6b21\u7528\u6237\u9891\u8c31\u6548\u7387\u3002", "method": "\u63d0\u51fa\u901a\u8fc7\u975e\u6b63\u4ea4\u591a\u5740\u63a5\u5165\u6700\u5927\u5316\u603b\u901f\u7387\uff0c\u8054\u5408\u4f18\u5316UAV\u8f68\u8ff9\u3001\u4f20\u8f93-\u53cd\u5c04\u6ce2\u675f\u5f62\u6210\u548c\u529f\u7387\u5206\u914d\uff0c\u5e76\u5f00\u53d1\u4e86\u66ff\u4ee3\u4f18\u5316\u7b97\u6cd5\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u7814\u7a76\u4e86\u91cd\u8981\u53c2\u6570\u7684\u5f71\u54cd\u3001\u4e0d\u540c\u667a\u80fd\u8868\u9762\u6a21\u5f0f\u6027\u80fd\u3001\u8054\u5408\u8f68\u8ff9\u548c\u6ce2\u675f\u5f62\u6210\u8bbe\u8ba1\uff0c\u4ee5\u53caSTAR-RIS\u5728\u7f13\u89e3\u5e72\u6270\u65b9\u9762\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5730\u63d0\u5347\u4e86\u9891\u8c31\u6548\u7387\uff0c\u5e76\u5c55\u793a\u4e86STAR-RIS\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u4f18\u52bf\u3002"}}
{"id": "2504.10709", "pdf": "https://arxiv.org/pdf/2504.10709", "abs": "https://arxiv.org/abs/2504.10709", "authors": ["Chi-Bach Pham", "Homayoun Hamedmoghadam Rafati", "Robert Noel Shorten"], "title": "Vehicle Dynamics Control for Simultaneous Optimization of Tire Emissions and Performance in EVs", "categories": ["eess.SY", "cs.SY"], "comment": "25 pages, 12 figures", "summary": "In recent years, Electric Vehicles (EVs) have seen widespread public\nadoption. While EVs produce zero tailpipe emissions, they contribute to an\nincrease in another type of vehicular emission: tire emissions.\nBattery-operated EVs are generally heavier than their combustion-engine\ncounterparts and require greater acceleration forces, which their high-torque\nelectric motors provide. This combination of increased weight and traction\nforces leads to higher tire emissions, which possess various adverse health and\nenvironmental effects. Here, we propose a control solution with promising\nresults in mitigating tire wear in all-wheel-drive EVs. The idea is to utilize\ndifferent tire profiles on each drive axis: a low-wear, low-traction axis and a\nhigh-wear, high-traction axis. Derived from detailed mathematical analyses, we\npropose a simple control scheme to counteract the performance difference from\nusing the low-traction tires. The proposed control mechanism then distributes\ntorque optimally between the two axes, maximizing usage from the low-wear axis\nand simultaneously maintaining stability and performance by leveraging\nhigh-traction tires. Through detailed numerical simulations, we demonstrate\nthat the developed model significantly reduces tire emissions and maintains\nvehicle drivability and performance.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u63a7\u5236\u65b9\u6848\uff0c\u901a\u8fc7\u4f7f\u7528\u4e0d\u540c\u8f6e\u80ce\u914d\u7f6e\u6587\u4ef6\u548c\u4f18\u5316\u626d\u77e9\u5206\u914d\uff0c\u51cf\u5c11\u7535\u52a8\u6c7d\u8f66\u8f6e\u80ce\u6392\u653e\uff0c\u6a21\u62df\u7ed3\u679c\u663e\u793a\u6709\u6548\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u91cd\u91cf\u589e\u52a0\u548c\u7275\u5f15\u529b\u5bfc\u81f4\u8f6e\u80ce\u6392\u653e\u4e0a\u5347\uff0c\u5bf9\u5065\u5eb7\u548c\u73af\u5883\u6709\u5bb3\u3002", "method": "\u63d0\u51fa\u63a7\u5236\u65b9\u6848\uff0c\u5229\u7528\u4f4e\u78e8\u635f\u4f4e\u7275\u5f15\u529b\u548c\u9ad8\u78e8\u635f\u9ad8\u7275\u5f15\u529b\u8f6e\u80ce\uff0c\u5e76\u4f18\u5316\u626d\u77e9\u5206\u5e03\u3002", "result": "\u6570\u503c\u6a21\u62df\u663e\u793a\u663e\u8457\u51cf\u5c11\u8f6e\u80ce\u6392\u653e\uff0c\u540c\u65f6\u4fdd\u6301\u8f66\u8f86\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u51cf\u8f7b\u8f6e\u80ce\u78e8\u635f\u5e76\u7ef4\u6301\u7a33\u5b9a\u6027\u3002"}}
{"id": "2504.10519", "pdf": "https://arxiv.org/pdf/2504.10519", "abs": "https://arxiv.org/abs/2504.10519", "authors": ["Yuhang Yao", "Haixin Wang", "Yibo Chen", "Jiawen Wang", "Min Chang Jordan Ren", "Bosheng Ding", "Salman Avestimehr", "Chaoyang He"], "title": "Toward Super Agent System with Hybrid AI Routers", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "comment": null, "summary": "AI Agents powered by Large Language Models are transforming the world through\nenormous applications. A super agent has the potential to fulfill diverse user\nneeds, such as summarization, coding, and research, by accurately understanding\nuser intent and leveraging the appropriate tools to solve tasks. However, to\nmake such an agent viable for real-world deployment and accessible at scale,\nsignificant optimizations are required to ensure high efficiency and low cost.\nThis paper presents a design of the Super Agent System. Upon receiving a user\nprompt, the system first detects the intent of the user, then routes the\nrequest to specialized task agents with the necessary tools or automatically\ngenerates agentic workflows. In practice, most applications directly serve as\nAI assistants on edge devices such as phones and robots. As different language\nmodels vary in capability and cloud-based models often entail high\ncomputational costs, latency, and privacy concerns, we then explore the hybrid\nmode where the router dynamically selects between local and cloud models based\non task complexity. Finally, we introduce the blueprint of an on-device super\nagent enhanced with cloud. With advances in multi-modality models and edge\nhardware, we envision that most computations can be handled locally, with cloud\ncollaboration only as needed. Such architecture paves the way for super agents\nto be seamlessly integrated into everyday life in the near future.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u8d85\u7ea7\u4ee3\u7406\u7cfb\u7edf\uff0c\u4f7f\u7528\u6df7\u5408\u672c\u5730\u548c\u4e91\u7aef\u6a21\u578b\u6765\u9ad8\u6548\u5904\u7406\u7528\u6237\u4efb\u52a1\u3002", "motivation": "\u4e3a\u4e86\u4f7f\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684AI\u8d85\u7ea7\u4ee3\u7406\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u53ef\u90e8\u7f72\uff0c\u9700\u8981\u4f18\u5316\u6548\u7387\u3001\u964d\u4f4e\u6210\u672c\u5e76\u89e3\u51b3\u9690\u79c1\u95ee\u9898\u3002", "method": "\u7cfb\u7edf\u901a\u8fc7\u68c0\u6d4b\u7528\u6237\u610f\u56fe\u3001\u8def\u7531\u5230\u4e13\u7528\u4ee3\u7406\u6216\u751f\u6210\u5de5\u4f5c\u6d41\uff0c\u5e76\u52a8\u6001\u9009\u62e9\u672c\u5730\u6216\u4e91\u7aef\u6a21\u578b\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u589e\u5f3a\u578b\u672c\u5730\u8bbe\u5907\u7684\u8d85\u7ea7\u4ee3\u7406\u84dd\u56fe\uff0c\u51cf\u5c11\u4e86\u5bf9\u4e91\u7aef\u7684\u4f9d\u8d56\u3002", "conclusion": "\u5c55\u671b\u672a\u6765\uff0c\u8d85\u7ea7\u4ee3\u7406\u5c06\u901a\u8fc7\u672c\u5730\u8ba1\u7b97\u548c\u4e91\u7aef\u534f\u4f5c\u65e0\u7f1d\u878d\u5165\u65e5\u5e38\u751f\u6d3b\u3002"}}
{"id": "2504.10490", "pdf": "https://arxiv.org/pdf/2504.10490", "abs": "https://arxiv.org/abs/2504.10490", "authors": ["Gabriel Bo", "Marc Bernardino", "Justin Gu"], "title": "GPT Meets Graphs and KAN Splines: Testing Novel Frameworks on Multitask Fine-Tuned GPT-2 with LoRA", "categories": ["cs.LG", "cs.CL"], "comment": "10 pages, 11 figures. This submission cites arXiv:2404.19756.\n  Supplementary materials and additional information are available at\n  arXiv:2404.19756", "summary": "We explore the potential of integrating learnable and interpretable\nmodules--specifically Kolmogorov-Arnold Networks (KAN) and graph-based\nrepresentations--within a pre-trained GPT-2 model to enhance multi-task\nlearning accuracy. Motivated by the recent surge in using KAN and graph\nattention (GAT) architectures in chain-of-thought (CoT) models and debates over\ntheir benefits compared to simpler architectures like MLPs, we begin by\nenhancing a standard self-attention transformer using Low-Rank Adaptation\n(LoRA), fine-tuning hyperparameters, and incorporating L2 regularization. This\napproach yields significant improvements. To further boost interpretability and\nricher representations, we develop two variants that attempt to improve the\nstandard KAN and GAT: Graph LoRA and Hybrid-KAN LoRA (Learnable GPT). However,\nsystematic evaluations reveal that neither variant outperforms the optimized\nLoRA-enhanced transformer, which achieves 55.249% accuracy on the SST test set,\n99.18% on the CFIMDB dev set, and 89.9% paraphrase detection test accuracy. On\nsonnet generation, we get a CHRF score of 42.097. These findings highlight that\nefficient parameter adaptation via LoRA remains the most effective strategy for\nour tasks: sentiment analysis, paraphrase detection, and sonnet generation.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c1d\u8bd5\u5c06KAN\u548c\u56fe\u8868\u793a\u6574\u5408\u5230GPT-2\u4e2d\u63d0\u5347\u591a\u4efb\u52a1\u5b66\u4e60\u51c6\u786e\u6027\uff0c\u4f46\u53d1\u73b0LoRA\u4f18\u5316\u65b9\u6cd5\u66f4\u6709\u6548\u3002", "motivation": "\u53d7KAN\u548cGAT\u5728CoT\u6a21\u578b\u5e94\u7528\u589e\u52a0\u4ee5\u53ca\u4e0eMLP\u6bd4\u8f83\u7684\u4e89\u8bae\u542f\u53d1\uff0c\u65e8\u5728\u63d0\u9ad8\u591a\u4efb\u52a1\u5b66\u4e60\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528LoRA\u589e\u5f3atransformer\uff0c\u8fdb\u884c\u8d85\u53c2\u6570\u5fae\u8c03\u548cL2\u6b63\u5219\u5316\uff1b\u5f00\u53d1Graph LoRA\u548cHybrid-KAN LoRA\u53d8\u4f53\uff0c\u5e76\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "LoRA\u589e\u5f3atransformer\u5728SST\u6d4b\u8bd5\u96c6\u51c6\u786e\u738755.249%\uff0cCFIMDB dev\u96c699.18%\uff0c\u91ca\u4e49\u68c0\u6d4b89.9%\uff0c\u5341\u56db\u884c\u8bd7\u751f\u6210CHRF\u5206\u657042.097\uff1b\u53d8\u4f53\u672a\u4f18\u4e8e\u57fa\u51c6\u3002", "conclusion": "\u9ad8\u6548\u53c2\u6570\u9002\u914d\u901a\u8fc7LoRA\u662f\u9488\u5bf9\u60c5\u611f\u5206\u6790\u3001\u91ca\u4e49\u68c0\u6d4b\u548c\u5341\u56db\u884c\u8bd7\u751f\u6210\u7684\u6700\u6709\u6548\u7b56\u7565\u3002"}}
{"id": "2504.10855", "pdf": "https://arxiv.org/pdf/2504.10855", "abs": "https://arxiv.org/abs/2504.10855", "authors": ["Yu Kawano", "Zhiyong Sun"], "title": "Virtual Contraction Approach to Decentralized Adaptive Stabilization of Nonlinear Time-Delayed Networks", "categories": ["eess.SY", "cs.SY", "math.OC"], "comment": null, "summary": "In this paper, we utilize a diagonally dominant structure for the\ndecentralized stabilization of unknown nonlinear time-delayed networks.\nGeneralizing the idea of virtual contraction analysis to time-delayed systems,\nwe demonstrate that nonlinear time-delayed networks can be stabilized by\ndiagonal high-gains if the input matrices possess certain generalized\n(column/row) diagonally dominant properties. To achieve stabilization of\nunknown networks, we further propose a distributed adaptive tuning rule for\neach individual gain function, ensuring that all closed-loop trajectories\nconverge to the origin. The effectiveness of the proposed decentralized\nadaptive control is verified in a case study on epidemic spreading control in\nSIS networks with transmission delays.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528\u5bf9\u89d2\u5360\u4f18\u7ed3\u6784\u7a33\u5b9a\u672a\u77e5\u975e\u7ebf\u6027\u65f6\u5ef6\u7f51\u7edc\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u81ea\u9002\u5e94\u63a7\u5236\uff0c\u5e76\u5728SIS\u7f51\u7edc\u75ab\u60c5\u4f20\u64ad\u63a7\u5236\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u63a8\u5e7f\u865a\u62df\u6536\u7f29\u5206\u6790\u5230\u65f6\u5ef6\u7cfb\u7edf\uff0c\u4ee5\u7a33\u5b9a\u672a\u77e5\u975e\u7ebf\u6027\u65f6\u5ef6\u7f51\u7edc\uff0c\u7279\u522b\u662f\u5904\u7406\u4f20\u8f93\u5ef6\u8fdf\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u8f93\u5165\u77e9\u9635\u7684\u5e7f\u4e49\u5bf9\u89d2\u5360\u4f18\u7279\u6027\uff0c\u901a\u8fc7\u5bf9\u89d2\u9ad8\u589e\u76ca\u548c\u5206\u5e03\u5f0f\u81ea\u9002\u5e94\u8c03\u8c10\u89c4\u5219\u5b9e\u73b0\u7a33\u5b9a\u3002", "result": "\u8bc1\u660e\u4e86\u65f6\u5ef6\u7f51\u7edc\u53ef\u4ee5\u901a\u8fc7\u5bf9\u89d2\u9ad8\u589e\u76ca\u7a33\u5b9a\uff0c\u5e76\u901a\u8fc7SIS\u7f51\u7edc\u75ab\u60c5\u4f20\u64ad\u63a7\u5236\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u53bb\u4e2d\u5fc3\u5316\u81ea\u9002\u5e94\u63a7\u5236\u786e\u4fdd\u95ed\u73af\u8f68\u8ff9\u6536\u655b\u5230\u539f\u70b9\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2504.10527", "pdf": "https://arxiv.org/pdf/2504.10527", "abs": "https://arxiv.org/abs/2504.10527", "authors": ["Leonardo Arrighi", "Ingrid Alves de Moraes", "Marco Zullich", "Michele Simonato", "Douglas Fernandes Barbin", "Sylvio Barbon Junior"], "title": "Explainable Artificial Intelligence techniques for interpretation of food datasets: a review", "categories": ["cs.AI", "cs.CY", "A.1"], "comment": "33 pages, 8 figures, 5 tables", "summary": "Artificial Intelligence (AI) has become essential for analyzing complex data\nand solving highly-challenging tasks. It is being applied across numerous\ndisciplines beyond computer science, including Food Engineering, where there is\na growing demand for accurate and trustworthy predictions to meet stringent\nfood quality standards. However, this requires increasingly complex AI models,\nraising reliability concerns. In response, eXplainable AI (XAI) has emerged to\nprovide insights into AI decision-making, aiding model interpretation by\ndevelopers and users. Nevertheless, XAI remains underutilized in Food\nEngineering, limiting model reliability. For instance, in food quality control,\nAI models using spectral imaging can detect contaminants or assess freshness\nlevels, but their opaque decision-making process hinders adoption. XAI\ntechniques such as SHAP (Shapley Additive Explanations) and Grad-CAM\n(Gradient-weighted Class Activation Mapping) can pinpoint which spectral\nwavelengths or image regions contribute most to a prediction, enhancing\ntransparency and aiding quality control inspectors in verifying AI-generated\nassessments. This survey presents a taxonomy for classifying food quality\nresearch using XAI techniques, organized by data types and explanation methods,\nto guide researchers in choosing suitable approaches. We also highlight trends,\nchallenges, and opportunities to encourage the adoption of XAI in Food\nEngineering.", "AI": {"tldr": "\u8fd9\u7bc7\u8c03\u67e5\u4ecb\u7ecd\u4e86\u5728\u98df\u54c1\u5de5\u7a0b\u4e2d\u4f7f\u7528\u53ef\u89e3\u91caAI\uff08XAI\uff09\u6280\u672f\u7684\u5206\u7c7b\u6cd5\uff0c\u4ee5\u63d0\u9ad8AI\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u900f\u660e\u5ea6\uff0c\u5e76\u6307\u5bfc\u7814\u7a76\u4eba\u5458\u9009\u62e9\u5408\u9002\u7684\u65b9\u6cd5\u3002", "motivation": "AI\u5728\u98df\u54c1\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u590d\u6742\uff0c\u5bfc\u81f4\u53ef\u9760\u6027\u95ee\u9898\uff0c\u800cXAI\u5c1a\u672a\u88ab\u5145\u5206\u5229\u7528\uff0c\u9700\u8981\u63d0\u5347AI\u51b3\u7b56\u7684\u900f\u660e\u5ea6\u4ee5\u6ee1\u8db3\u98df\u54c1\u8d28\u91cf\u6807\u51c6\u3002", "method": "\u5448\u73b0\u4e00\u4e2a\u57fa\u4e8e\u6570\u636e\u7c7b\u578b\u548c\u89e3\u91ca\u65b9\u6cd5\u7684\u5206\u7c7b\u6cd5\uff0c\u7528\u4e8e\u5206\u7c7b\u4f7f\u7528XAI\u6280\u672f\u7684\u98df\u54c1\u8d28\u91cf\u7814\u7a76\u3002", "result": "\u7a81\u51fa\u4e86XAI\u5728\u98df\u54c1\u5de5\u7a0b\u4e2d\u7684\u8d8b\u52bf\u3001\u6311\u6218\u548c\u673a\u4f1a\uff0c\u4ee5\u9f13\u52b1\u5176\u91c7\u7528\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u5206\u7c7b\u6cd5\u548c\u89c1\u89e3\uff0c\u6307\u5bfc\u7814\u7a76\u4eba\u5458\u5e76\u63a8\u52a8XAI\u5728\u98df\u54c1\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2504.10536", "pdf": "https://arxiv.org/pdf/2504.10536", "abs": "https://arxiv.org/abs/2504.10536", "authors": ["Lihong Zhang", "Yue Li"], "title": "Federated Learning with Layer Skipping: Efficient Training of Large Language Models for Healthcare NLP", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Federated learning (FL) enables collaborative model training across\norganizations without sharing raw data, addressing crucial privacy concerns in\nhealthcare natural language processing (NLP). However, training large language\nmodels (LLMs) in federated settings faces significant challenges, including\ncommunication overhead and data heterogeneity. We propose Layer-Skipping\nFederated Learning, where only selected layers of a pre-trained LLM are\nfine-tuned across clients while others remain frozen. Applied to LLaMA 3.2-1B,\nour approach reduces communication costs by approximately 70% while maintaining\nperformance within 2% of centralized training. We evaluate our method on\nclinical NER and classification tasks using i2b2 and MIMIC-III datasets. Our\nexperiments demonstrate that Layer-Skipping FL outperforms competitive\nbaselines, handles non-IID clinical data distributions effectively, and shows\nrobustness when combined with differential privacy. This approach represents a\npractical solution for privacy-preserving collaborative learning in healthcare\nNLP.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u5c42\u8df3\u8dc3\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8e\u533b\u7597NLP\uff0c\u51cf\u5c11\u901a\u4fe1\u5f00\u950070%\uff0c\u6027\u80fd\u63a5\u8fd1\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u5728\u533b\u7597NLP\u4e2d\u7684\u9690\u79c1\u95ee\u9898\uff0c\u4ee5\u53ca\u901a\u4fe1\u5f00\u9500\u548c\u6570\u636e\u5f02\u8d28\u6027\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5c42\u8df3\u8dc3\u8054\u90a6\u5b66\u4e60\uff0c\u4ec5\u5fae\u8c03\u9884\u8bad\u7ec3LLM\uff08\u5982LLaMA 3.2-1B\uff09\u7684\u9009\u5b9a\u5c42\uff0c\u5176\u4ed6\u5c42\u51bb\u7ed3\u3002", "result": "\u901a\u4fe1\u6210\u672c\u51cf\u5c11\u7ea670%\uff0c\u6027\u80fd\u4e0e\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u76f8\u5dee\u4e0d\u52302%\uff0c\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5904\u7406\u975eIID\u6570\u636e\u5e76\u4e0e\u5dee\u5206\u9690\u79c1\u517c\u5bb9\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u533b\u7597NLP\u9690\u79c1\u4fdd\u62a4\u534f\u4f5c\u5b66\u4e60\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.10954", "pdf": "https://arxiv.org/pdf/2504.10954", "abs": "https://arxiv.org/abs/2504.10954", "authors": ["Irene Schimperna", "Lea Bold", "Karl Worthmann"], "title": "Offset-free Nonlinear MPC with Koopman-based Surrogate Models", "categories": ["eess.SY", "cs.SY", "math.OC"], "comment": "10 pages, 3 figures", "summary": "In this paper, we design offset-free nonlinear Model Predictive Control (MPC)\nfor surrogate models based on Extended Dynamic Mode Decomposition (EDMD). The\nmodel used for prediction in MPC is augmented with a disturbance term, that is\nestimated by an observer. If the full information about the equilibrium of the\nreal system is not available, a reference calculator is introduced in the\nalgorithm to compute the MPC state and input references. The control algorithm\nguarantees offset-free tracking of the controlled output under the assumption\nthat the modeling errors are asymptotically constant. The effectiveness of the\nproposed approach is showcased with numerical simulations for two popular\nbenchmark systems: the van-der-Pol oscillator and the four-tanks process.", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u6269\u5c55\u52a8\u6001\u6a21\u5f0f\u5206\u89e3(EDMD)\u7684\u504f\u79fb\u81ea\u7531\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236(MPC)\uff0c\u7528\u4e8e\u4ee3\u7406\u6a21\u578b\uff0c\u786e\u4fdd\u5728\u5efa\u6a21\u8bef\u5dee\u4e0b\u5b9e\u73b0\u8ddf\u8e2a\uff0c\u901a\u8fc7\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u3002", "motivation": "\u52a8\u673a\u662f\u5904\u7406\u5efa\u6a21\u8bef\u5dee\u5e76\u5728\u7cfb\u7edf\u5e73\u8861\u70b9\u4fe1\u606f\u4e0d\u5b8c\u6574\u65f6\u5b9e\u73b0\u504f\u79fb\u81ea\u7531\u8ddf\u8e2a\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528EDMD\u6784\u5efa\u4ee3\u7406\u6a21\u578b\uff0c\u589e\u52a0\u5e72\u6270\u9879\u901a\u8fc7\u89c2\u5bdf\u5668\u4f30\u8ba1\uff0c\u5e76\u5f15\u5165\u53c2\u8003\u8ba1\u7b97\u5668\u8ba1\u7b97MPC\u53c2\u8003\u72b6\u6001\u548c\u8f93\u5165\u3002", "result": "\u7ed3\u679c\u901a\u8fc7van-der-Pol\u632f\u8361\u5668\u548c\u56db\u6c34\u7bb1\u8fc7\u7a0b\u7684\u6570\u503c\u6a21\u62df\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u5728\u5efa\u6a21\u8bef\u5dee\u6e10\u8fdb\u5e38\u6570\u5047\u8bbe\u4e0b\uff0c\u7b97\u6cd5\u4fdd\u8bc1\u4e86\u8f93\u51fa\u8ddf\u8e2a\u65e0\u504f\u79fb\u3002"}}
{"id": "2504.10649", "pdf": "https://arxiv.org/pdf/2504.10649", "abs": "https://arxiv.org/abs/2504.10649", "authors": ["Matthew Zalesak", "Hins Hu", "Samitha Samaranayake"], "title": "Ride-pool Assignment Algorithms: Modern Implementation and Swapping Heuristics", "categories": ["cs.AI", "cs.ET"], "comment": null, "summary": "On-demand ride-pooling has emerged as a popular urban transportation\nsolution, addressing the efficiency limitations of traditional ride-hailing\nservices by grouping multiple riding requests with spatiotemporal proximity\ninto a single vehicle. Although numerous algorithms have been developed for the\nRide-pool Assignment Problem (RAP) -- a core component of ride-pooling systems,\nthere is a lack of open-source implementations, making it difficult to\nbenchmark these algorithms on a common dataset and objective. In this paper, we\npresent the implementation details of a ride-pool simulator that encompasses\nseveral key ride-pool assignment algorithms, along with associated components\nsuch as vehicle routing and rebalancing. We also open-source a highly optimized\nand modular C++ codebase, designed to facilitate the extension of new\nalgorithms and features. Additionally, we introduce a family of swapping-based\nlocal-search heuristics to enhance existing ride-pool assignment algorithms,\nachieving a better balance between performance and computational efficiency.\nExtensive experiments on a large-scale, real-world dataset from Manhattan, NYC\nreveal that while all selected algorithms perform comparably, the newly\nproposed Multi-Round Linear Assignment with Cyclic Exchange (LA-MR-CE)\nalgorithm achieves a state-of-the-art service rate with significantly reduced\ncomputational time. Furthermore, an in-depth analysis suggests that a\nperformance barrier exists for all myopic ride-pool assignment algorithms due\nto the system's capacity bottleneck, and incorporating future information could\nbe key to overcoming this limitation.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f00\u6e90\u4e86\u4e58\u8f66\u6c60\u6a21\u62df\u5668\uff0c\u5f15\u5165\u65b0\u7b97\u6cd5\uff0c\u63d0\u5347\u4e86\u6548\u7387\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u6027\u80fd\u3002", "motivation": "\u7f3a\u4e4f\u5f00\u6e90\u5b9e\u73b0\u5bfc\u81f4\u57fa\u51c6\u6d4b\u8bd5\u56f0\u96be\uff0c\u56e0\u6b64\u5f00\u53d1\u4e86\u5f00\u6e90\u5de5\u5177\u4ee5\u4fbf\u7b97\u6cd5\u6bd4\u8f83\u3002", "method": "\u5b9e\u73b0\u4e86\u4e58\u8f66\u6c60\u6a21\u62df\u5668\uff0c\u5305\u62ec\u8f66\u8f86\u8def\u7531\u548c\u518d\u5e73\u8861\u7ec4\u4ef6\uff0c\u5f15\u5165\u4ea4\u6362-based\u5c40\u90e8\u641c\u7d22\u542f\u53d1\u5f0f\uff0c\u5e76\u63d0\u51faLA-MR-CE\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793aLA-MR-CE\u7b97\u6cd5\u5728\u670d\u52a1\u7387\u548c\u8ba1\u7b97\u65f6\u95f4\u4e0a\u4f18\u8d8a\uff0c\u6240\u6709\u77ed\u89c6\u7b97\u6cd5\u53d7\u5bb9\u91cf\u74f6\u9888\u9650\u5236\u3002", "conclusion": "\u5efa\u8bae\u6574\u5408\u672a\u6765\u4fe1\u606f\u4ee5\u514b\u670d\u6027\u80fd\u74f6\u9888\uff0c\u63d0\u5347\u7b97\u6cd5\u6548\u679c\u3002"}}
{"id": "2504.10551", "pdf": "https://arxiv.org/pdf/2504.10551", "abs": "https://arxiv.org/abs/2504.10551", "authors": ["Lili Zhao", "Qi Liu", "Wei Chen", "Liyi Chen", "Ruijun Sun", "Min Hou", "Yang Wang", "Shijin Wang"], "title": "MiMu: Mitigating Multiple Shortcut Learning Behavior of Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Empirical Risk Minimization (ERM) models often rely on spurious correlations\nbetween features and labels during the learning process, leading to shortcut\nlearning behavior that undermines robustness generalization performance.\nCurrent research mainly targets identifying or mitigating a single shortcut;\nhowever, in real-world scenarios, cues within the data are diverse and unknown.\nIn empirical studies, we reveal that the models rely to varying extents on\ndifferent shortcuts. Compared to weak shortcuts, models depend more heavily on\nstrong shortcuts, resulting in their poor generalization ability. To address\nthese challenges, we propose MiMu, a novel method integrated with\nTransformer-based ERMs designed to Mitigate Multiple shortcut learning\nbehavior, which incorporates self-calibration strategy and self-improvement\nstrategy. In the source model, we preliminarily propose the self-calibration\nstrategy to prevent the model from relying on shortcuts and make overconfident\npredictions. Then, we further design self-improvement strategy in target model\nto reduce the reliance on multiple shortcuts. The random mask strategy involves\nrandomly masking partial attention positions to diversify the focus of target\nmodel other than concentrating on a fixed region. Meanwhile, the adaptive\nattention alignment module facilitates the alignment of attention weights to\nthe calibrated source model, without the need for post-hoc attention maps or\nsupervision. Finally, extensive experiments conducted on Natural Language\nProcessing (NLP) and Computer Vision (CV) demonstrate the effectiveness of MiMu\nin improving robustness generalization abilities.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faMiMu\u65b9\u6cd5\uff0c\u7f13\u89e3Empirical Risk Minimization (ERM)\u6a21\u578b\u7684\u591a\u91cd\u6377\u5f84\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u9ad8\u9c81\u68d2\u6027\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "ERM\u6a21\u578b\u4f9d\u8d56\u865a\u5047\u76f8\u5173\u6027\u5bfc\u81f4\u6377\u5f84\u5b66\u4e60\uff0c\u73b0\u6709\u65b9\u6cd5\u4ec5\u9488\u5bf9\u5355\u4e00\u6377\u5f84\uff0c\u800c\u73b0\u5b9e\u4e2d\u6377\u5f84\u591a\u6837\u4e14\u672a\u77e5\uff0c\u6a21\u578b\u5bf9\u5f3a\u6377\u5f84\u8fc7\u5ea6\u4f9d\u8d56\u5f71\u54cd\u6cdb\u5316\u3002", "method": "\u63d0\u51faMiMu\u65b9\u6cd5\uff0c\u5305\u62ec\u81ea\u6821\u51c6\u7b56\u7565\uff08\u9632\u6b62\u4f9d\u8d56\u6377\u5f84\uff09\u548c\u81ea\u63d0\u5347\u7b56\u7565\uff08\u968f\u673a\u63a9\u7801\u53ca\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u5bf9\u9f50\uff09\u3002", "result": "\u5b9e\u9a8c\u5728NLP\u548cCV\u9886\u57df\u663e\u793aMiMu\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MiMu\u901a\u8fc7\u51cf\u8f7b\u591a\u91cd\u6377\u5f84\u5b66\u4e60\u884c\u4e3a\uff0c\u663e\u8457\u6539\u5584\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2504.10960", "pdf": "https://arxiv.org/pdf/2504.10960", "abs": "https://arxiv.org/abs/2504.10960", "authors": ["Evagoras Makridis", "Themistoklis Charalambous"], "title": "A Linear Push-Pull Average Consensus Algorithm for Delay-Prone Networks", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "In this paper, we address the average consensus problem of multi-agent\nsystems for possibly unbalanced and delay-prone networks with directional\ninformation flow. We propose a linear distributed algorithm (referred to as\nRPPAC) that handles asynchronous updates and time-varying heterogeneous\ninformation delays. Our proposed distributed algorithm utilizes a\nsurplus-consensus mechanism and information regarding the number of incoming\nand outgoing links to guarantee state averaging, despite the imbalanced and\ndelayed information flow in directional networks. The convergence of the RPPAC\nalgorithm is examined using key properties of the backward product of\ntime-varying matrices that correspond to different snapshots of the directional\naugmented network.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRPPAC\u7684\u7ebf\u6027\u5206\u5e03\u5f0f\u7b97\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u53ef\u80fd\u4e0d\u5e73\u8861\u548c\u6709\u5ef6\u8fdf\u7684\u65b9\u5411\u7f51\u7edc\u7684\u5e73\u5747\u5171\u8bc6\u95ee\u9898\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u65b9\u5411\u7f51\u7edc\u4e2d\u4e0d\u5e73\u8861\u548c\u5ef6\u8fdf\u95ee\u9898\u4e0b\u7684\u5e73\u5747\u5171\u8bc6\u6311\u6218\u3002", "method": "\u65b9\u6cd5\u662f\u63d0\u51faRPPAC\u7b97\u6cd5\uff0c\u5229\u7528\u5269\u4f59\u5171\u8bc6\u673a\u5236\u548c\u94fe\u8def\u4fe1\u606f\uff0c\u5904\u7406\u5f02\u6b65\u66f4\u65b0\u548c\u65f6\u53d8\u5ef6\u8fdf\uff0c\u901a\u8fc7\u65f6\u53d8\u77e9\u9635\u7684\u540e\u5411\u4e58\u79ef\u5206\u6790\u6536\u655b\u6027\u3002", "result": "\u7ed3\u679c\u662f\u7b97\u6cd5\u4fdd\u8bc1\u4e86\u72b6\u6001\u5e73\u5747\uff0c\u5c3d\u7ba1\u5b58\u5728\u4e0d\u5e73\u8861\u548c\u5ef6\u8fdf\u3002", "conclusion": "\u7ed3\u8bba\u662fRPPAC\u7b97\u6cd5\u5728\u65b9\u5411\u7f51\u7edc\u4e2d\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u5e73\u5747\u5171\u8bc6\u3002"}}
{"id": "2504.10831", "pdf": "https://arxiv.org/pdf/2504.10831", "abs": "https://arxiv.org/abs/2504.10831", "authors": ["Hyojun Ahn", "Seungcheol Oh", "Gyu Seon Kim", "Soyi Jung", "Soohyun Park", "Joongheon Kim"], "title": "Hallucination-Aware Generative Pretrained Transformer for Cooperative Aerial Mobility Control", "categories": ["cs.AI", "cs.RO", "68T05"], "comment": null, "summary": "This paper proposes SafeGPT, a two-tiered framework that integrates\ngenerative pretrained transformers (GPTs) with reinforcement learning (RL) for\nefficient and reliable unmanned aerial vehicle (UAV) last-mile deliveries. In\nthe proposed design, a Global GPT module assigns high-level tasks such as\nsector allocation, while an On-Device GPT manages real-time local route\nplanning. An RL-based safety filter monitors each GPT decision and overrides\nunsafe actions that could lead to battery depletion or duplicate visits,\neffectively mitigating hallucinations. Furthermore, a dual replay buffer\nmechanism helps both the GPT modules and the RL agent refine their strategies\nover time. Simulation results demonstrate that SafeGPT achieves higher delivery\nsuccess rates compared to a GPT-only baseline, while substantially reducing\nbattery consumption and travel distance. These findings validate the efficacy\nof combining GPT-based semantic reasoning with formal safety guarantees,\ncontributing a viable solution for robust and energy-efficient UAV logistics.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faSafeGPT\u6846\u67b6\uff0c\u7ed3\u5408GPT\u548cRL\u63d0\u5347UAV\u6700\u540e\u4e00\u6bb5\u4ea4\u4ed8\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u9ad8\u6548\u53ef\u9760\u7684\u65e0\u4eba\u673a(UAV)\u6700\u540e\u4e00\u6bb5\u4ea4\u4ed8\uff0c\u89e3\u51b3GPT\u53ef\u80fd\u4ea7\u751f\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "method": "SafeGPT\u91c7\u7528\u4e24\u5c42\u7ed3\u6784\uff1aGlobal GPT\u5206\u914d\u9ad8\u6c34\u5e73\u4efb\u52a1\uff0cOn-Device GPT\u5904\u7406\u5b9e\u65f6\u8def\u7ebf\u89c4\u5212\uff1bRL\u5b89\u5168\u8fc7\u6ee4\u5668\u76d1\u63a7\u5e76\u8986\u76d6\u4e0d\u5b89\u5168\u51b3\u7b56\uff1b\u53cc\u91cd\u56de\u653e\u7f13\u51b2\u533a\u4f18\u5316\u7b56\u7565\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0cSafeGPT\u6bd4GPT-only\u57fa\u51c6\u6709\u66f4\u9ad8\u4ea4\u4ed8\u6210\u529f\u7387\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u7535\u6c60\u6d88\u8017\u548c\u65c5\u884c\u8ddd\u79bb\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u7ed3\u5408GPT\u8bed\u4e49\u63a8\u7406\u4e0e\u6b63\u5f0f\u5b89\u5168\u4fdd\u8bc1\u7684\u6709\u6548\u6027\uff0c\u4e3a\u9c81\u68d2\u8282\u80fd\u7684UAV\u7269\u6d41\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.10552", "pdf": "https://arxiv.org/pdf/2504.10552", "abs": "https://arxiv.org/abs/2504.10552", "authors": ["Arash Torabi Goodarzi", "Roman Kochnev", "Waleed Khalid", "Furui Qin", "Tolgay Atinc Uzun", "Yashkumar Sanjaybhai Dhameliya", "Yash Kanubhai Kathiriya", "Zofia Antonina Bentyn", "Dmitry Ignatov", "Radu Timofte"], "title": "LEMUR Neural Network Dataset: Towards Seamless AutoML", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DL"], "comment": null, "summary": "Neural networks are fundamental in artificial intelligence, driving progress\nin computer vision and natural language processing. High-quality datasets are\ncrucial for their development, and there is growing interest in datasets\ncomposed of neural networks themselves to support benchmarking, automated\nmachine learning (AutoML), and model analysis. We introduce LEMUR, an open\nsource dataset of neural network models with well-structured code for diverse\narchitectures across tasks such as object detection, image classification,\nsegmentation, and natural language processing. LEMUR is primarily designed to\nenable fine-tuning of large language models (LLMs) for AutoML tasks, providing\na rich source of structured model representations and associated performance\ndata. Leveraging Python and PyTorch, LEMUR enables seamless extension to new\ndatasets and models while maintaining consistency. It integrates an\nOptuna-powered framework for evaluation, hyperparameter optimization,\nstatistical analysis, and graphical insights. LEMUR provides an extension that\nenables models to run efficiently on edge devices, facilitating deployment in\nresource-constrained environments. Providing tools for model evaluation,\npreprocessing, and database management, LEMUR supports researchers and\npractitioners in developing, testing, and analyzing neural networks.\nAdditionally, it offers an API that delivers comprehensive information about\nneural network models and their complete performance statistics with a single\nrequest, which can be used in experiments with code-generating large language\nmodels. The LEMUR will be released as an open source project under the MIT\nlicense upon acceptance of the paper.", "AI": {"tldr": "LEMUR \u662f\u4e00\u4e2a\u5f00\u6e90\u6570\u636e\u96c6\uff0c\u5305\u542b\u5404\u79cd\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4ee3\u7801\uff0c\u7528\u4e8e AutoML \u548c\u6a21\u578b\u5206\u6790\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u8868\u793a\u548c\u6027\u80fd\u6570\u636e\u3002", "motivation": "\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u5bf9\u795e\u7ecf\u7f51\u7edc\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u9700\u652f\u6301\u57fa\u51c6\u6d4b\u8bd5\u3001AutoML \u548c\u6a21\u578b\u5206\u6790\u3002", "method": "\u5f15\u5165 LEMUR\uff0c\u4f7f\u7528 Python \u548c PyTorch \u6784\u5efa\uff0c\u96c6\u6210 Optuna \u6846\u67b6\u8fdb\u884c\u8bc4\u4f30\u3001\u4f18\u5316\u548c\u7edf\u8ba1\u5206\u6790\u3002", "result": "\u542f\u7528 LLM \u5fae\u8c03\u3001\u63d0\u4f9b\u8bc4\u4f30\u5de5\u5177\u3001API \u548c\u8fb9\u8bbe\u5907\u90e8\u7f72\uff0c\u652f\u6301\u6a21\u578b\u5f00\u53d1\u548c\u6027\u80fd\u7edf\u8ba1\u3002", "conclusion": "LEMUR \u5c06\u5f00\u6e90\u53d1\u5e03\uff0c\u5e2e\u52a9\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u9ad8\u6548\u5f00\u53d1\u3001\u6d4b\u8bd5\u548c\u5206\u6790\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002"}}
{"id": "2504.10964", "pdf": "https://arxiv.org/pdf/2504.10964", "abs": "https://arxiv.org/abs/2504.10964", "authors": ["Evagoras Makridis", "Gabriele Oliva", "Kasagatta Ramesh Narahari", "Mohammadreza Doostmohammadian", "Usman A. Khan", "Themistoklis Charalambous"], "title": "Distributed Optimization with Gradient Tracking over Heterogeneous Delay-Prone Directed Networks", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "In this paper, we address the distributed optimization problem over\nunidirectional networks with possibly time-invariant heterogeneous bounded\ntransmission delays. In particular, we propose a modified version of the\nAccelerated Distributed Directed OPTimization (ADD-OPT) algorithm, herein\ncalled Robustified ADD-OPT (R-ADD-OPT), which is able to solve the distributed\noptimization problem, even when the communication links suffer from\nheterogeneous but bounded transmission delays. We show that if the gradient\nstep-size of the R-ADD-OPT algorithm is within a certain range, which also\ndepends on the maximum time delay in the network, then the nodes are guaranteed\nto converge to the optimal solution of the distributed optimization problem.\nThe range of the gradient step-size that guarantees convergence can be computed\na priori based on the maximum time delay in the network.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faR-ADD-OPT\u7b97\u6cd5\uff0c\u5904\u7406\u5355\u5411\u7f51\u7edc\u4e2d\u5f02\u8d28\u6709\u754c\u5ef6\u8fdf\u7684\u5206\u5e03\u5f0f\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u4fdd\u8bc1\u9002\u5f53\u6b65\u957f\u4e0b\u6536\u655b\u5230\u6700\u4f18\u89e3\u3002", "motivation": "\u89e3\u51b3\u5355\u5411\u7f51\u7edc\u4e2d\u53ef\u80fd\u5b58\u5728\u5f02\u8d28\u4f46\u6709\u754c\u4f20\u8f93\u5ef6\u8fdf\u7684\u5206\u5e03\u5f0f\u4f18\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51faRobustified ADD-OPT (R-ADD-OPT)\u7b97\u6cd5\u7684\u4fee\u6539\u7248\u672c\uff0c\u4ee5\u9002\u5e94\u4f20\u8f93\u5ef6\u8fdf\u3002", "result": "\u68af\u5ea6\u6b65\u957f\u5728\u7279\u5b9a\u8303\u56f4\u5185\uff08\u53d6\u51b3\u4e8e\u6700\u5927\u5ef6\u8fdf\uff09\u53ef\u4fdd\u8bc1\u8282\u70b9\u6536\u655b\u5230\u6700\u4f18\u89e3\uff0c\u4e14\u8303\u56f4\u53ef\u9884\u5148\u8ba1\u7b97\u3002", "conclusion": "R-ADD-OPT\u7b97\u6cd5\u5728\u6709\u5ef6\u8fdf\u7f51\u7edc\u4e2d\u5b9e\u73b0\u5206\u5e03\u5f0f\u4f18\u5316\u7684\u53ef\u9760\u6536\u655b\u3002"}}
{"id": "2504.10865", "pdf": "https://arxiv.org/pdf/2504.10865", "abs": "https://arxiv.org/abs/2504.10865", "authors": ["Han-Dong Lim", "Donghwan Lee"], "title": "Understanding the theoretical properties of projected Bellman equation, linear Q-learning, and approximate value iteration", "categories": ["cs.AI", "cs.LG"], "comment": "Initial submission", "summary": "In this paper, we study the theoretical properties of the projected Bellman\nequation (PBE) and two algorithms to solve this equation: linear Q-learning and\napproximate value iteration (AVI). We consider two sufficient conditions for\nthe existence of a solution to PBE : strictly negatively row dominating\ndiagonal (SNRDD) assumption and a condition motivated by the convergence of\nAVI. The SNRDD assumption also ensures the convergence of linear Q-learning,\nand its relationship with the convergence of AVI is examined. Lastly, several\ninteresting observations on the solution of PBE are provided when using\n$\\epsilon$-greedy policy.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u6295\u5f71Bellman\u65b9\u7a0b\u7684\u7406\u8bba\u5c5e\u6027\u3001\u7ebf\u6027Q\u5b66\u4e60\u548c\u8fd1\u4f3c\u503c\u8fed\u4ee3\u7b97\u6cd5\uff0c\u63a2\u8ba8\u89e3\u7684\u5b58\u5728\u6027\u548c\u6536\u655b\u6761\u4ef6\u3002", "motivation": "\u52a8\u673a\u662f\u5206\u6790\u6295\u5f71Bellman\u65b9\u7a0b\u89e3\u7684\u5b58\u5728\u4ee5\u53ca\u7b97\u6cd5\u6536\u655b\u7684\u5145\u5206\u6761\u4ef6\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u4e25\u683c\u8d1f\u884c\u4e3b\u5bfc\u5bf9\u89d2\u5047\u8bbe\u548cAVI\u6536\u655b\u6761\u4ef6\uff0c\u68c0\u67e5\u7ebf\u6027Q\u5b66\u4e60\u7684\u6536\u655b\uff0c\u5e76\u89c2\u5bdf\u03b5-\u8d2a\u5a6a\u7b56\u7565\u4e0b\u7684\u89e3\u3002", "result": "\u7ed3\u679c\u663e\u793aSNRDD\u5047\u8bbe\u786e\u4fdd\u7ebf\u6027Q\u5b66\u4e60\u7684\u6536\u655b\uff0c\u5e76\u63a2\u8ba8\u5176\u4e0eAVI\u6536\u655b\u7684\u5173\u7cfb\uff0c\u63d0\u4f9b\u76f8\u5173\u89c2\u5bdf\u3002", "conclusion": "\u7ed3\u8bba\u662f\u5bf9\u6295\u5f71Bellman\u65b9\u7a0b\u7406\u8bba\u6027\u8d28\u7684\u6df1\u5165\u7406\u89e3\u548c\u7b97\u6cd5\u6539\u8fdb\u7684\u542f\u793a\u3002"}}
{"id": "2504.10555", "pdf": "https://arxiv.org/pdf/2504.10555", "abs": "https://arxiv.org/abs/2504.10555", "authors": ["Marco Salm\u00e8", "Lorenzo Tronchin", "Rosa Sicilia", "Paolo Soda", "Valerio Guarrasi"], "title": "Beyond the Generative Learning Trilemma: Generative Model Assessment in Data Scarcity Domains", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Data scarcity remains a critical bottleneck impeding technological\nadvancements across various domains, including but not limited to medicine and\nprecision agriculture. To address this challenge, we explore the potential of\nDeep Generative Models (DGMs) in producing synthetic data that satisfies the\nGenerative Learning Trilemma: fidelity, diversity, and sampling efficiency.\nHowever, recognizing that these criteria alone are insufficient for practical\napplications, we extend the trilemma to include utility, robustness, and\nprivacy, factors crucial for ensuring the applicability of DGMs in real-world\nscenarios. Evaluating these metrics becomes particularly challenging in\ndata-scarce environments, as DGMs traditionally rely on large datasets to\nperform optimally. This limitation is especially pronounced in domains like\nmedicine and precision agriculture, where ensuring acceptable model performance\nunder data constraints is vital. To address these challenges, we assess the\nGenerative Learning Trilemma in data-scarcity settings using state-of-the-art\nevaluation metrics, comparing three prominent DGMs: Variational Autoencoders\n(VAEs), Generative Adversarial Networks (GANs), and Diffusion Models (DMs).\nFurthermore, we propose a comprehensive framework to assess utility,\nrobustness, and privacy in synthetic data generated by DGMs. Our findings\ndemonstrate varying strengths among DGMs, with each model exhibiting unique\nadvantages based on the application context. This study broadens the scope of\nthe Generative Learning Trilemma, aligning it with real-world demands and\nproviding actionable guidance for selecting DGMs tailored to specific\napplications.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u5728\u6570\u636e\u7a00\u7f3a\u73af\u5883\u4e0b\u7684\u5e94\u7528\uff0c\u6269\u5c55\u751f\u6210\u5b66\u4e60\u4e09\u96be\u56f0\u5883\u5e76\u8bc4\u4f30VAE\u3001GAN\u548cDM\u7684\u6027\u80fd\u3002", "motivation": "\u6570\u636e\u7a00\u7f3a\u963b\u788d\u4e86\u533b\u5b66\u548c\u7cbe\u51c6\u519c\u4e1a\u7b49\u9886\u57df\u7684\u6280\u672f\u8fdb\u6b65\uff0c\u9700\u8981\u5408\u6210\u6570\u636e\u89e3\u51b3\u751f\u6210\u5b66\u4e60\u4e09\u96be\u56f0\u5883\u7684\u9650\u5236\u3002", "method": "\u8bc4\u4f30VAE\u3001GAN\u548cDM\u5728\u4fdd\u771f\u5ea6\u3001\u591a\u6837\u6027\u548c\u91c7\u6837\u6548\u7387\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u6846\u67b6\u8bc4\u4f30\u5408\u6210\u6570\u636e\u7684\u5b9e\u7528\u6027\u3001\u9c81\u68d2\u6027\u548c\u9690\u79c1\u6027\u3002", "result": "\u4e0d\u540cDGM\u6a21\u578b\u663e\u793a\u51fa\u5e94\u7528\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u72ec\u7279\u4f18\u52bf\u3002", "conclusion": "\u6269\u5c55\u751f\u6210\u5b66\u4e60\u4e09\u96be\u56f0\u5883\uff0c\u63d0\u4f9b\u9009\u62e9DGM\u6a21\u578b\u7684\u6307\u5bfc\uff0c\u4ee5\u9002\u5e94\u771f\u5b9e\u4e16\u754c\u9700\u6c42\u3002"}}
{"id": "2504.11097", "pdf": "https://arxiv.org/pdf/2504.11097", "abs": "https://arxiv.org/abs/2504.11097", "authors": ["Maximilian B\u00f6hle", "Bernhard Schick", "Steffen M\u00fcller"], "title": "Steering Feedback in Dynamic Driving Simulators: Road-Induced and Non-Road-Induced Harshness", "categories": ["eess.SY", "cs.SY"], "comment": "11 pages, 5 figures, 5 tables, submitted to the IEEE Transactions on\n  Intelligent Vehicles. arXiv admin note: substantial text overlap with\n  arXiv:2403.17800", "summary": "Steering feedback plays a substantial role in the validity of driving\nsimulators for the virtual development of modern vehicles. Established\nobjective steering characteristics typically assess the feedback behavior in\nthe frequency range of up to 30 Hz while factors such as steering wheel and\nvehicle body vibrations at higher frequencies are mainly approached as comfort\nissues. This work investigates the influence of steering wheel and vehicle body\nexcitations in the frequency range between 30 and 100 Hz on the subjective\nevaluation of steering feedback in a dynamic driving simulator. A controlled\nsubject study with 42 participants was performed to compare a reference vehicle\nwith an electrical power steering system to four variants of its virtual\nrepresentation on a dynamic driving simulator. The effects of road-induced\nexcitations were investigated by comparing a semi-empirical and a physics-based\ntire model, while the influence of non-road-induced excitations was\ninvestigated by implementing engine and wheel orders. The simulator variants\nwere evaluated in comparison to the reference vehicle during closed-loop\ndriving on a country road in a single-blind within-subjects design. The\nsubjective evaluation focused on the perception of road feedback compared to\nthe reference vehicle. The statistical analysis of subjective results shows\nthat there is a strong effect of non-road-induced steering and vehicle body\nexcitations, while the effect of road-induced excitations is considerably less\npronounced.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u4e8630-100 Hz\u9891\u7387\u8303\u56f4\u5185\u8f6c\u5411\u8f6e\u548c\u8f66\u8eab\u6fc0\u52b1\u5bf9\u52a8\u6001\u9a7e\u9a76\u6a21\u62df\u5668\u4e3b\u89c2\u8f6c\u5411\u53cd\u9988\u7684\u5f71\u54cd\uff0c\u901a\u8fc742\u540d\u53c2\u4e0e\u8005\u7684\u5bf9\u7167\u7814\u7a76\uff0c\u53d1\u73b0\u975e\u9053\u8def\u8bf1\u53d1\u6fc0\u52b1\u5f71\u54cd\u663e\u8457\uff0c\u800c\u9053\u8def\u8bf1\u53d1\u6fc0\u52b1\u5f71\u54cd\u8f83\u5c0f\u3002", "motivation": "\u52a8\u673a\u662f\u63a2\u8ba8\u66f4\u9ad8\u9891\u7387\uff0830-100 Hz\uff09\u8f6c\u5411\u53cd\u9988\u5bf9\u4e3b\u89c2\u8bc4\u4f30\u7684\u5f71\u54cd\uff0c\u56e0\u4e3a\u4f20\u7edf\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4f4e\u4e8e30 Hz\u7684\u9891\u7387\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u52a8\u6001\u9a7e\u9a76\u6a21\u62df\u5668\u8fdb\u884c\u5355\u76f2\u5185\u90e8\u53d7\u8bd5\u8005\u8bbe\u8ba1\u7684\u7814\u7a76\uff0c\u6bd4\u8f83\u53c2\u8003\u8f66\u8f86\u548c\u56db\u79cd\u6a21\u62df\u5668\u53d8\u4f53\uff0c\u91c7\u7528\u534a\u7ecf\u9a8c\u548c\u57fa\u4e8e\u7269\u7406\u7684\u8f6e\u80ce\u6a21\u578b\uff0c\u5e76\u6dfb\u52a0\u53d1\u52a8\u673a\u548c\u8f66\u8f6e\u9636\u6b21\u6fc0\u52b1\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u975e\u9053\u8def\u8bf1\u53d1\u6fc0\u52b1\u5bf9\u4e3b\u89c2\u8f6c\u5411\u53cd\u9988\u6709\u5f3a\u70c8\u5f71\u54cd\uff0c\u800c\u9053\u8def\u8bf1\u53d1\u6fc0\u52b1\u7684\u5f71\u54cd\u8f83\u4e0d\u663e\u8457\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u975e\u9053\u8def\u8bf1\u53d1\u6fc0\u52b1\u5728\u4e3b\u89c2\u8bc4\u4f30\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5efa\u8bae\u5728\u9a7e\u9a76\u6a21\u62df\u5668\u5f00\u53d1\u4e2d\u4f18\u5148\u8003\u8651\u8fd9\u4e9b\u56e0\u7d20\u3002"}}
{"id": "2504.10893", "pdf": "https://arxiv.org/pdf/2504.10893", "abs": "https://arxiv.org/abs/2504.10893", "authors": ["Yize Zhang", "Tianshu Wang", "Sirui Chen", "Kun Wang", "Xingyu Zeng", "Hongyu Lin", "Xianpei Han", "Le Sun", "Chaochao Lu"], "title": "ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search", "categories": ["cs.AI", "cs.CL"], "comment": "Project homepage: https://opencausalab.github.io/ARise", "summary": "Large language models (LLMs) have demonstrated impressive capabilities and\nare receiving increasing attention to enhance their reasoning through scaling\ntest--time compute. However, their application in open--ended,\nknowledge--intensive, complex reasoning scenarios is still limited.\nReasoning--oriented methods struggle to generalize to open--ended scenarios due\nto implicit assumptions of complete world knowledge. Meanwhile,\nknowledge--augmented reasoning (KAR) methods fail to address two core\nchallenges: 1) error propagation, where errors in early steps cascade through\nthe chain, and 2) verification bottleneck, where the explore--exploit tradeoff\narises in multi--branch decision processes. To overcome these limitations, we\nintroduce ARise, a novel framework that integrates risk assessment of\nintermediate reasoning states with dynamic retrieval--augmented generation\n(RAG) within a Monte Carlo tree search paradigm. This approach enables\neffective construction and optimization of reasoning plans across multiple\nmaintained hypothesis branches. Experimental results show that ARise\nsignificantly outperforms the state--of--the--art KAR methods by up to 23.10%,\nand the latest RAG-equipped large reasoning models by up to 25.37%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faARise\u6846\u67b6\uff0c\u901a\u8fc7\u98ce\u9669\u8bc4\u4f30\u3001\u52a8\u6001RAG\u548cMonte Carlo\u6811\u641c\u7d22\u4f18\u5316LLMs\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "LLMs\u5728\u5f00\u653e\u5f0f\u77e5\u8bc6\u5bc6\u96c6\u63a8\u7406\u4e2d\u53d7\u9650\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u6cdb\u5316\u95ee\u9898\u3001\u9519\u8bef\u4f20\u64ad\u548c\u9a8c\u8bc1\u74f6\u9888\u3002", "method": "ARise\u6846\u67b6\u6574\u5408\u4e2d\u95f4\u72b6\u6001\u98ce\u9669\u8bc4\u4f30\u3001\u52a8\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548cMonte Carlo\u6811\u641c\u7d22\u8303\u5f0f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aARise\u6bd4\u6700\u5148\u8fdbKAR\u65b9\u6cd5\u63d0\u534723.10%\uff0c\u6bd4RAG\u589e\u5f3a\u6a21\u578b\u63d0\u534725.37%\u3002", "conclusion": "ARise\u6846\u67b6\u6709\u6548\u89e3\u51b3\u63a8\u7406\u5c40\u9650\u6027\uff0c\u4f18\u5316\u591a\u5206\u652f\u5047\u8bbe\u63a8\u7406\u8ba1\u5212\u3002"}}
{"id": "2504.10556", "pdf": "https://arxiv.org/pdf/2504.10556", "abs": "https://arxiv.org/abs/2504.10556", "authors": ["Lucas Heublein", "Simon Kocher", "Tobias Feigl", "Alexander R\u00fcgamer", "Christopher Mutschler", "Felix Ott"], "title": "VAE-based Feature Disentanglement for Data Augmentation and Compression in Generalized GNSS Interference Classification", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "94-05, 82-11", "E.0; I.2.0; I.5.4; I.5.1"], "comment": "7 pages, 9 figures", "summary": "Distributed learning and Edge AI necessitate efficient data processing,\nlow-latency communication, decentralized model training, and stringent data\nprivacy to facilitate real-time intelligence on edge devices while reducing\ndependency on centralized infrastructure and ensuring high model performance.\nIn the context of global navigation satellite system (GNSS) applications, the\nprimary objective is to accurately monitor and classify interferences that\ndegrade system performance in distributed environments, thereby enhancing\nsituational awareness. To achieve this, machine learning (ML) models can be\ndeployed on low-resource devices, ensuring minimal communication latency and\npreserving data privacy. The key challenge is to compress ML models while\nmaintaining high classification accuracy. In this paper, we propose variational\nautoencoders (VAEs) for disentanglement to extract essential latent features\nthat enable accurate classification of interferences. We demonstrate that the\ndisentanglement approach can be leveraged for both data compression and data\naugmentation by interpolating the lower-dimensional latent representations of\nsignal power. To validate our approach, we evaluate three VAE variants -\nvanilla, factorized, and conditional generative - on four distinct datasets,\nincluding two collected in controlled indoor environments and two real-world\nhighway datasets. Additionally, we conduct extensive hyperparameter searches to\noptimize performance. Our proposed VAE achieves a data compression rate ranging\nfrom 512 to 8,192 and achieves an accuracy up to 99.92%.", "AI": {"tldr": "\u672c\u8bba\u6587\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u5b9e\u73b0GNSS\u5e72\u6270\u5206\u7c7b\u7684\u6a21\u578b\u538b\u7f29\u548c\u6570\u636e\u589e\u5f3a\uff0c\u8fbe\u5230\u9ad8\u8fbe99.92%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u5206\u5e03\u5f0f\u5b66\u4e60\u548cEdge AI\u9700\u8981\u9ad8\u6548\u6570\u636e\u5904\u7406\u3001\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u3001\u53bb\u4e2d\u5fc3\u5316\u8bad\u7ec3\u548c\u6570\u636e\u9690\u79c1\uff1b\u5728GNSS\u5e94\u7528\u4e2d\uff0c\u9700\u51c6\u786e\u76d1\u63a7\u548c\u5206\u7c7b\u5e72\u6270\u4ee5\u63d0\u5347 situational awareness\uff0c\u6311\u6218\u662f\u538b\u7f29ML\u6a21\u578b\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faVAE\u7684disentanglement\u65b9\u6cd5\u63d0\u53d6latent features\uff0c\u7528\u4e8e\u5e72\u6270\u5206\u7c7b\uff1b\u5305\u62ecvanilla\u3001factorized\u548cconditional generative\u4e09\u79cd\u53d8\u4f53\uff1b\u7528\u4e8e\u6570\u636e\u538b\u7f29\u548c\u589e\u5f3a\uff0c\u901a\u8fc7latent\u8868\u793a\u63d2\u503c\uff1b\u8bc4\u4f30\u56db\u4e2a\u6570\u636e\u96c6\uff0c\u5e76\u8fdb\u884c\u8d85\u53c2\u6570\u4f18\u5316\u3002", "result": "\u6570\u636e\u538b\u7f29\u7387\u4ece512\u52308192\uff1b\u51c6\u786e\u7387\u9ad8\u8fbe99.92%\u3002", "conclusion": "VAE\u65b9\u6cd5\u6709\u6548\u5b9e\u73b0\u4e86\u9ad8\u538b\u7f29\u7387\u548c\u9ad8\u51c6\u786e\u7387\u7684\u5e72\u6270\u5206\u7c7b\uff0c\u8bc1\u660e\u4e86\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2504.11125", "pdf": "https://arxiv.org/pdf/2504.11125", "abs": "https://arxiv.org/abs/2504.11125", "authors": ["Dieter Teichrib", "Moritz Schulze Darup"], "title": "A mixed-integer framework for analyzing neural network-based controllers for piecewise affine systems with bounded disturbances", "categories": ["eess.SY", "cs.SY", "math.OC"], "comment": "8 pages, 3 figures, to be published in the proceedings of the 23rd\n  European Control Conference (2025)", "summary": "We present a method for representing the closed-loop dynamics of piecewise\naffine (PWA) systems with bounded additive disturbances and neural\nnetwork-based controllers as mixed-integer (MI) linear constraints. We show\nthat such representations enable the computation of robustly positively\ninvariant (RPI) sets for the specified system class by solving MI linear\nprograms. These RPI sets can subsequently be used to certify stability and\nconstraint satisfaction. Furthermore, the approach allows to handle non-linear\nsystems based on suitable PWA approximations and corresponding error bounds,\nwhich can be interpreted as the bounded disturbances from above.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df7\u5408\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u8868\u793a\u5206\u6bb5\u4eff\u5c04\u7cfb\u7edf\u53ca\u5176\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u5668\u7684\u95ed\u73af\u52a8\u529b\u5b66\uff0c\u5e76\u901a\u8fc7\u6c42\u89e3\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u8ba1\u7b97\u9c81\u68d2\u6b63\u4e0d\u53d8\u96c6\uff0c\u4ee5\u9a8c\u8bc1\u7a33\u5b9a\u6027\u548c\u7ea6\u675f\u6ee1\u8db3\u3002", "motivation": "\u4e3a\u4e86\u5904\u7406\u5e26\u6709\u8fb9\u754c\u6270\u52a8\u548c\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u5668\u7684\u5206\u6bb5\u4eff\u5c04\u7cfb\u7edf\uff0c\u5b9e\u73b0\u9c81\u68d2\u7a33\u5b9a\u6027\u548c\u7ea6\u675f\u6ee1\u8db3\u7684\u8ba4\u8bc1\u3002", "method": "\u5c06\u7cfb\u7edf\u52a8\u529b\u5b66\u8868\u793a\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u7ea6\u675f\uff0c\u5e76\u901a\u8fc7\u6c42\u89e3\u6df7\u5408\u6574\u6570\u7ebf\u6027\u7a0b\u5e8f\u8ba1\u7b97\u9c81\u68d2\u6b63\u4e0d\u53d8\u96c6\u3002", "result": "\u80fd\u591f\u8ba1\u7b97\u9c81\u68d2\u6b63\u4e0d\u53d8\u96c6\uff0c\u8ba4\u8bc1\u7a33\u5b9a\u6027\u548c\u7ea6\u675f\u6ee1\u8db3\uff0c\u5e76\u901a\u8fc7\u5206\u6bb5\u4eff\u5c04\u903c\u8fd1\u5904\u7406\u975e\u7ebf\u6027\u7cfb\u7edf\u53ca\u5176\u8bef\u5dee\u8fb9\u754c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6307\u5b9a\u7cfb\u7edf\u7c7b\u63d0\u4f9b\u4e86\u8ba1\u7b97\u9c81\u68d2\u6b63\u4e0d\u53d8\u96c6\u7684\u6846\u67b6\uff0c\u4ece\u800c\u786e\u4fdd\u7a33\u5b9a\u6027\u548c\u7ea6\u675f\u6ee1\u8db3\u3002"}}
{"id": "2504.11075", "pdf": "https://arxiv.org/pdf/2504.11075", "abs": "https://arxiv.org/abs/2504.11075", "authors": ["Dongmin Kim", "Hoshinori Kanazawa", "Naoto Yoshida", "Yasuo Kuniyoshi"], "title": "Emergence of Goal-Directed Behaviors via Active Inference with Self-Prior", "categories": ["cs.AI", "68T05, 68T40, 68T42", "I.2.0; I.2.6; I.2.9"], "comment": "20 pages, Code is available at\n  https://github.com/kim135797531/self-prior", "summary": "Infants often exhibit goal-directed behaviors, such as reaching for a sensory\nstimulus, even when no external reward criterion is provided. These\nintrinsically motivated behaviors facilitate spontaneous exploration and\nlearning of the body and environment during early developmental stages.\nAlthough computational modeling can offer insight into the mechanisms\nunderlying such behaviors, many existing studies on intrinsic motivation focus\nprimarily on how exploration contributes to acquiring external rewards. In this\npaper, we propose a novel density model for an agent's own multimodal sensory\nexperiences, called the \"self-prior,\" and investigate whether it can\nautonomously induce goal-directed behavior. Integrated within an active\ninference framework based on the free energy principle, the self-prior\ngenerates behavioral references purely from an intrinsic process that minimizes\nmismatches between average past sensory experiences and current observations.\nThis mechanism is also analogous to the acquisition and utilization of a body\nschema through continuous interaction with the environment. We examine this\napproach in a simulated environment and confirm that the agent spontaneously\nreaches toward a tactile stimulus. Our study implements intrinsically motivated\nbehavior shaped by the agent's own sensory experiences, demonstrating the\nspontaneous emergence of intentional behavior during early development.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa'self-prior'\u5bc6\u5ea6\u6a21\u578b\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u8fc7\u53bb\u548c\u5f53\u524d\u611f\u5b98\u4f53\u9a8c\u5dee\u5f02\uff0c\u8bf1\u5bfc\u4ee3\u7406\u5185\u5728\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\uff1b\u5728\u6a21\u62df\u73af\u5883\u4e2d\uff0c\u4ee3\u7406\u81ea\u53d1\u4f38\u624b\u89e6\u78b0\u89e6\u89c9\u523a\u6fc0\uff0c\u5c55\u793a\u4e86\u5185\u5728\u52a8\u673a\u884c\u4e3a\u7684\u6d8c\u73b0\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u63a2\u7d22\u5982\u4f55\u83b7\u5f97\u5916\u90e8\u5956\u52b1\uff0c\u672c\u8bba\u6587\u63a2\u8ba8\u7eaf\u5185\u5728\u8fc7\u7a0b\u5982\u4f55\u9a71\u52a8\u65e0\u5916\u90e8\u5956\u52b1\u7684 spontaneous \u63a2\u7d22\u548c\u5b66\u4e60\u3002", "method": "\u63d0\u51fa'self-prior'\u591a\u6a21\u6001\u611f\u5b98\u4f53\u9a8c\u5bc6\u5ea6\u6a21\u578b\uff0c\u5e76\u6574\u5408\u5230\u57fa\u4e8e\u81ea\u7531\u80fd\u91cf\u539f\u7406\u7684\u4e3b\u52a8\u63a8\u7406\u6846\u67b6\u4e2d\uff1b\u5728\u6a21\u62df\u73af\u5883\u4e2d\u6d4b\u8bd5\u4ee3\u7406\u884c\u4e3a\u3002", "result": "\u4ee3\u7406\u81ea\u53d1\u5730\u4f38\u624b\u89e6\u78b0\u89e6\u89c9\u523a\u6fc0\uff0c\u8bc1\u5b9e\u4e86\u5185\u5728\u52a8\u673a\u673a\u5236\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5c55\u793a\u4e86\u4ee3\u7406\u901a\u8fc7\u81ea\u8eab\u611f\u5b98\u4f53\u9a8c\u5851\u9020\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\uff0c\u7c7b\u4f3c\u4e8e\u5a74\u513f\u65e9\u671f\u53d1\u5c55\u7684 intentional \u884c\u4e3a\u6d8c\u73b0\u3002"}}
{"id": "2504.10559", "pdf": "https://arxiv.org/pdf/2504.10559", "abs": "https://arxiv.org/abs/2504.10559", "authors": ["Keyu Duan", "Zichen Liu", "Xin Mao", "Tianyu Pang", "Changyu Chen", "Qiguang Chen", "Michael Qizhe Shieh", "Longxu Dou"], "title": "Efficient Process Reward Model Training via Active Learning", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 4 figures", "summary": "Process Reward Models (PRMs) provide step-level supervision to large language\nmodels (LLMs), but scaling up training data annotation remains challenging for\nboth humans and LLMs. To address this limitation, we propose an active learning\napproach, ActPRM, which proactively selects the most uncertain samples for\ntraining, substantially reducing labeling costs. During training, we use the\nPRM to estimate uncertainty after the forward pass, retaining only highly\nuncertain data. A capable yet costly reasoning model then labels this data.\nThen we compute the loss with respect to the labels and update the PRM's\nweights. We compare ActPRM vs. vanilla fine-tuning, on a pool-based active\nlearning setting, demonstrating that ActPRM reduces 50% annotation, but\nachieving the comparable or even better performance. Beyond annotation\nefficiency, we further advance the actively trained PRM by filtering over 1M+\nmath reasoning trajectories with ActPRM, retaining 60% of the data. A\nsubsequent training on this selected dataset yields a new state-of-the-art\n(SOTA) PRM on ProcessBench (75.0%) and PRMBench (65.5%) compared with same\nsized models.", "AI": {"tldr": "ActPRM \u662f\u4e00\u79cd\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u51cf\u5c11 50% \u7684\u6807\u6ce8\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u6027\u80fd\uff0c\u5e76\u5728\u7279\u5b9a\u57fa\u51c6\u4e0a\u8fbe\u5230 SOTA\u3002", "motivation": "\u8bad\u7ec3\u6570\u636e\u6807\u6ce8\u7684\u89c4\u6a21\u5316\u5bf9\u4eba\u7c7b\u548c LLM \u90fd\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u6b64\u63d0\u51fa ActPRM \u6765\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5 ActPRM\uff0c\u9009\u62e9\u4e0d\u786e\u5b9a\u6027\u6700\u9ad8\u7684\u6837\u672c\uff0c\u4f7f\u7528 PRM \u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\uff0c\u7531\u9ad8\u6210\u672c\u7684\u63a8\u7406\u6a21\u578b\u6807\u6ce8\u6570\u636e\uff0c\u7136\u540e\u8ba1\u7b97\u635f\u5931\u5e76\u66f4\u65b0 PRM \u7684\u6743\u91cd\u3002", "result": "\u51cf\u5c11 50% \u7684\u6807\u6ce8\u6210\u672c\uff0c\u540c\u65f6\u8fbe\u5230\u76f8\u5f53\u6216\u66f4\u597d\u7684\u6027\u80fd\uff1b\u901a\u8fc7\u8fc7\u6ee4\u8d85\u8fc7 100 \u4e07\u7684\u6570\u5b66\u63a8\u7406\u8f68\u8ff9\uff0c\u4fdd\u7559 60% \u7684\u6570\u636e\uff0c\u5728 ProcessBench (75.0%) \u548c PRMBench (65.5%) \u4e0a\u8fbe\u5230\u65b0\u7684 SOTA\u3002", "conclusion": "ActPRM \u5728\u51cf\u5c11\u6807\u6ce8\u6210\u672c\u548c\u63d0\u9ad8\u6027\u80fd\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5b9e\u73b0\u4e86\u65b0\u7684\u72b6\u6001-of-the-art \u7ed3\u679c\u3002"}}
{"id": "2504.11261", "pdf": "https://arxiv.org/pdf/2504.11261", "abs": "https://arxiv.org/abs/2504.11261", "authors": ["Hannes Petrenz", "Johannes K\u00f6hler", "Francesco Borrelli"], "title": "Robust MPC for Uncertain Linear Systems -- Combining Model Adaptation and Iterative Learning", "categories": ["eess.SY", "cs.SY", "math.OC"], "comment": "Github link to the example:\n  https://github.com/HannesPetrenz/RALMPC_Linear_Uncertain_Systems", "summary": "This paper presents a robust adaptive learning Model Predictive Control (MPC)\nframework for linear systems with parametric uncertainties and additive\ndisturbances performing iterative tasks. The approach iteratively refines the\nparameter estimates using set membership estimation. Performance enhancement\nover iterations is achieved by learning the terminal cost from data. Safety is\nenforced using a terminal set, which is also learned iteratively. The proposed\nmethod guarantees recursive feasibility, constraint satisfaction, and a robust\nbound on the closed-loop cost. Numerical simulations on a mass-spring-damper\nsystem demonstrate improved computational efficiency and control performance\ncompared to an existing robust adaptive MPC approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u81ea\u9002\u5e94\u5b66\u4e60MPC\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u7ebf\u6027\u7cfb\u7edf\u4e2d\u7684\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u548c\u6270\u52a8\uff0c\u901a\u8fc7\u8fed\u4ee3\u5b66\u4e60\u63d0\u5347\u6027\u80fd\u548c\u5b89\u5168\u6027\uff0c\u4eff\u771f\u7ed3\u679c\u663e\u793a\u6539\u8fdb\u3002", "motivation": "\u9488\u5bf9\u7ebf\u6027\u7cfb\u7edf\u5728\u8fed\u4ee3\u4efb\u52a1\u4e2d\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u548c\u52a0\u6027\u6270\u52a8\u7684\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u63a7\u5236\u6027\u80fd\u548c\u786e\u4fdd\u5b89\u5168\u6027\u3002", "method": "\u4f7f\u7528\u96c6\u5408\u6210\u5458\u4f30\u8ba1\u8fed\u4ee3\u6539\u8fdb\u53c2\u6570\u4f30\u8ba1\uff0c\u4ece\u6570\u636e\u5b66\u4e60\u7ec8\u7aef\u6210\u672c\u548c\u7ec8\u7aef\u96c6\uff0c\u786e\u4fdd\u9012\u5f52\u53ef\u884c\u6027\u548c\u7ea6\u675f\u6ee1\u8db3\u3002", "result": "\u4fdd\u8bc1\u9012\u5f52\u53ef\u884c\u6027\u3001\u7ea6\u675f\u6ee1\u8db3\u548c\u95ed\u73af\u6210\u672c\u9c81\u68d2\u754c\u9650\uff1b\u4eff\u771f\u663e\u793a\u8ba1\u7b97\u6548\u7387\u548c\u63a7\u5236\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u63a7\u5236\u6027\u80fd\u548c\u6548\u7387\uff0c\u9002\u7528\u4e8e\u7c7b\u4f3c\u7cfb\u7edf\u3002"}}
{"id": "2504.11159", "pdf": "https://arxiv.org/pdf/2504.11159", "abs": "https://arxiv.org/abs/2504.11159", "authors": ["Annemarie Jutte", "Faizan Ahmed", "Jeroen Linssen", "Maurice van Keulen"], "title": "C-SHAP for time series: An approach to high-level temporal explanations", "categories": ["cs.AI"], "comment": "10 pages, 6 figures", "summary": "Time series are ubiquitous in domains such as energy forecasting, healthcare,\nand industry. Using AI systems, some tasks within these domains can be\nefficiently handled. Explainable AI (XAI) aims to increase the reliability of\nAI solutions by explaining model reasoning. For time series, many XAI methods\nprovide point- or sequence-based attribution maps. These methods explain model\nreasoning in terms of low-level patterns. However, they do not capture\nhigh-level patterns that may also influence model reasoning. We propose a\nconcept-based method to provide explanations in terms of these high-level\npatterns. In this paper, we present C-SHAP for time series, an approach which\ndetermines the contribution of concepts to a model outcome. We provide a\ngeneral definition of C-SHAP and present an example implementation using time\nseries decomposition. Additionally, we demonstrate the effectiveness of the\nmethodology through a use case from the energy domain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faC-SHAP\u65b9\u6cd5\uff0c\u7528\u4e8e\u57fa\u4e8e\u6982\u5ff5\u89e3\u91ca\u65f6\u95f4\u5e8f\u5217AI\u6a21\u578b\uff0c\u63d0\u4f9b\u9ad8\u7ea7\u6a21\u5f0f\u89e3\u91ca\u3002", "motivation": "\u73b0\u6709XAI\u65b9\u6cd5\u4ec5\u89e3\u91ca\u4f4e\u7ea7\u6a21\u5f0f\uff0c\u5ffd\u7565\u9ad8\u6c34\u5e73\u6a21\u5f0f\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u6982\u5ff5-based\u65b9\u6cd5\u63d0\u5347AI\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51faC-SHAP\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4f5c\u4e3a\u793a\u4f8b\u5b9e\u73b0\u3002", "result": "\u901a\u8fc7\u80fd\u6e90\u9886\u57df\u7528\u4f8b\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u6027\u3002", "conclusion": "C-SHAP\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217AI\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u6355\u6349\u9ad8\u6c34\u5e73\u6a21\u5f0f\u3002"}}
{"id": "2504.10561", "pdf": "https://arxiv.org/pdf/2504.10561", "abs": "https://arxiv.org/abs/2504.10561", "authors": ["Runqing Wu", "Fei Ye", "Rongyao Hu", "Guoxi Huang"], "title": "Self-Controlled Dynamic Expansion Model for Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 3 figures, 6 tables, Continual Learning, Cross-Domain\n  Continual Learning, Mixture Model", "summary": "Continual Learning (CL) epitomizes an advanced training paradigm wherein\nprior data samples remain inaccessible during the acquisition of new tasks.\nNumerous investigations have delved into leveraging a pre-trained Vision\nTransformer (ViT) to enhance model efficacy in continual learning. Nonetheless,\nthese approaches typically utilize a singular, static backbone, which\ninadequately adapts to novel tasks, particularly when engaging with diverse\ndata domains, due to a substantial number of inactive parameters. This paper\naddresses this limitation by introducing an innovative Self-Controlled Dynamic\nExpansion Model (SCDEM), which orchestrates multiple distinct trainable\npre-trained ViT backbones to furnish diverse and semantically enriched\nrepresentations. Specifically, by employing the multi-backbone architecture as\na shared module, the proposed SCDEM dynamically generates a new expert with\nminimal parameters to accommodate a new task. A novel Collaborative\nOptimization Mechanism (COM) is introduced to synergistically optimize multiple\nbackbones by harnessing prediction signals from historical experts, thereby\nfacilitating new task learning without erasing previously acquired knowledge.\nAdditionally, a novel Feature Distribution Consistency (FDC) approach is\nproposed to align semantic similarity between previously and currently learned\nrepresentations through an optimal transport distance-based mechanism,\neffectively mitigating negative knowledge transfer effects. Furthermore, to\nalleviate over-regularization challenges, this paper presents a novel Dynamic\nLayer-Wise Feature Attention Mechanism (DLWFAM) to autonomously determine the\npenalization intensity on each trainable representation layer. An extensive\nseries of experiments have been conducted to evaluate the proposed\nmethodology's efficacy, with empirical results corroborating that the approach\nattains state-of-the-art performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u81ea\u63a7\u52a8\u6001\u6269\u5c55\u6a21\u578b\uff08SCDEM\uff09\u6765\u63d0\u5347\u6301\u7eed\u5b66\u4e60\u6027\u80fd\uff0c\u901a\u8fc7\u591a\u9aa8\u5e72\u7f51\u52a8\u6001\u9002\u5e94\u65b0\u4efb\u52a1\uff0c\u5e76\u5f15\u5165\u4f18\u5316\u673a\u5236\u5b9e\u73b0\u77e5\u8bc6\u4fdd\u7559\u3002", "motivation": "\u73b0\u6709\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u4f7f\u7528\u9759\u6001Vision Transformer\u9aa8\u5e72\u7f51\uff0c\u65e0\u6cd5\u6709\u6548\u9002\u5e94\u65b0\u4efb\u52a1\u548c\u6570\u636e\u57df\uff0c\u5bfc\u81f4\u53c2\u6570\u5229\u7528\u4e0d\u8db3\u3002", "method": "\u5f15\u5165SCDEM\u6a21\u578b\uff0c\u4f7f\u7528\u591aViT\u9aa8\u5e72\u7f51\u52a8\u6001\u751f\u6210\u65b0\u4e13\u5bb6\uff0c\u7ed3\u5408\u534f\u4f5c\u4f18\u5316\u673a\u5236\uff08COM\uff09\u3001\u7279\u5f81\u5206\u5e03\u4e00\u81f4\u6027\uff08FDC\uff09\u53ca\u52a8\u6001\u5c42\u7ea7\u7279\u5f81\u6ce8\u610f\u529b\u673a\u5236\uff08DLWFAM\uff09\u6765\u4f18\u5316\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u57fa\u51c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5730\u89e3\u51b3\u4e86\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u9002\u5e94\u6027\u548c\u77e5\u8bc6\u4fdd\u7559\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2504.11285", "pdf": "https://arxiv.org/pdf/2504.11285", "abs": "https://arxiv.org/abs/2504.11285", "authors": ["Hazem Abdel-Khalek", "Eddy Jalbout", "Caspar Schau\u00df", "Benjamin Pfluger"], "title": "Balancing hydrogen delivery in national energy systems: impact of the temporal flexibility of hydrogen delivery on export prices", "categories": ["eess.SY", "cs.SY"], "comment": "6 pages, 3 figures, 2 tables", "summary": "Hydrogen is expected to play a key role in the energy transition. Analyses\nexploring the price of hydrogen usually calculate average or marginal\nproduction costs regardless of the time of delivery. A key factor that affects\nthe price of hydrogen is the balancing costs, which we define as the expense of\nensuring a steady schedule of hydrogen delivery. We explore the effect of\ndelivering hydrogen to the export ports at different schedules, ranging from\nfully flexible to moderately stable with a daily and weekly buffer, to fully\nstable. We quantify the rise in hydrogen price with strict balancing constraint\nin three countries: Brazil, Morocco and Turkey, and three export volumes: 10,\n50 and 200 TWh. The price difference between the flexible and stable schedules\nwas found to reach a maximum of 36% in Brazil, 47% in Morocco and 18% in Turkey\nacross the different export volumes.", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u7814\u7a76\u5e73\u8861\u6210\u672c\u5982\u4f55\u5f71\u54cd\u6c22\u6c14\u4ef7\u683c\uff0c\u9488\u5bf9\u4e0d\u540c\u4ea4\u4ed8\u65f6\u95f4\u8868\uff0c\u5728\u5df4\u897f\u3001\u6469\u6d1b\u54e5\u548c\u571f\u8033\u5176\u53d1\u73b0\u4ef7\u683c\u4e0a\u6da8\u6700\u9ad8\u53ef\u8fbe47%\u3002", "motivation": "\u6c22\u6c14\u5728\u80fd\u6e90\u8f6c\u578b\u4e2d\u626e\u6f14\u5173\u952e\u89d2\u8272\uff0c\u73b0\u6709\u7684\u5206\u6790\u901a\u5e38\u5ffd\u7565\u4ea4\u4ed8\u65f6\u95f4\uff0c\u56e0\u6b64\u9700\u8981\u91cf\u5316\u5e73\u8861\u6210\u672c\u5bf9\u4ef7\u683c\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u4ece\u5b8c\u5168\u7075\u6d3b\u5230\u5b8c\u5168\u7a33\u5b9a\u7684\u6c22\u6c14\u4ea4\u4ed8\u65f6\u95f4\u8868\uff0c\u5728\u5df4\u897f\u3001\u6469\u6d1b\u54e5\u548c\u571f\u8033\u5176\u4e09\u4e2a\u56fd\u5bb6\uff0c\u4ee5\u53ca10\u300150\u548c200 TWh\u4e09\u79cd\u51fa\u53e3\u91cf\u4e0b\u8ba1\u7b97\u4ef7\u683c\u5dee\u5f02\u3002", "result": "\u4ef7\u683c\u5dee\u5f02\u5728\u5df4\u897f\u6700\u9ad8\u8fbe36%\uff0c\u6469\u6d1b\u54e547%\uff0c\u571f\u8033\u517618%\uff0c\u8de8\u4e0d\u540c\u51fa\u53e3\u91cf\u3002", "conclusion": "\u66f4\u4e25\u683c\u7684\u5e73\u8861\u7ea6\u675f\u663e\u8457\u589e\u52a0\u6c22\u6c14\u4ef7\u683c\uff0c\u5f3a\u8c03\u5728\u80fd\u6e90\u8f6c\u578b\u5206\u6790\u4e2d\u5fc5\u987b\u8003\u8651\u4ea4\u4ed8\u65f6\u95f4\u8868\u3002"}}
{"id": "2504.11190", "pdf": "https://arxiv.org/pdf/2504.11190", "abs": "https://arxiv.org/abs/2504.11190", "authors": ["Anna Sofia Lippolis", "Andrea Giovanni Nuzzolese", "Aldo Gangemi"], "title": "Enhancing multimodal analogical reasoning with Logic Augmented Generation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances in Large Language Models have demonstrated their capabilities\nacross a variety of tasks. However, automatically extracting implicit knowledge\nfrom natural language remains a significant challenge, as machines lack active\nexperience with the physical world. Given this scenario, semantic knowledge\ngraphs can serve as conceptual spaces that guide the automated text generation\nreasoning process to achieve more efficient and explainable results. In this\npaper, we apply a logic-augmented generation (LAG) framework that leverages the\nexplicit representation of a text through a semantic knowledge graph and\napplies it in combination with prompt heuristics to elicit implicit analogical\nconnections. This method generates extended knowledge graph triples\nrepresenting implicit meaning, enabling systems to reason on unlabeled\nmultimodal data regardless of the domain. We validate our work through three\nmetaphor detection and understanding tasks across four datasets, as they\nrequire deep analogical reasoning capabilities. The results show that this\nintegrated approach surpasses current baselines, performs better than humans in\nunderstanding visual metaphors, and enables more explainable reasoning\nprocesses, though still has inherent limitations in metaphor understanding,\nespecially for domain-specific metaphors. Furthermore, we propose a thorough\nerror analysis, discussing issues with metaphorical annotations and current\nevaluation methods.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u903b\u8f91\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u4f7f\u7528\u8bed\u4e49\u77e5\u8bc6\u56fe\u6765\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9690\u55bb\u68c0\u6d4b\u548c\u7406\u89e3\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u4ece\u81ea\u7136\u8bed\u8a00\u4e2d\u63d0\u53d6\u9690\u542b\u77e5\u8bc6\uff0c\u56e0\u6b64\u4f7f\u7528\u8bed\u4e49\u77e5\u8bc6\u56fe\u4f5c\u4e3a\u6982\u5ff5\u7a7a\u95f4\u6765\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5e94\u7528\u903b\u8f91\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u8bed\u4e49\u77e5\u8bc6\u56fe\u548c\u63d0\u793a\u542f\u53d1\u5f0f\uff0c\u751f\u6210\u9690\u542b\u7684\u7c7b\u6bd4\u8fde\u63a5\uff0c\u5e76\u7528\u4e8e\u9690\u55bb\u68c0\u6d4b\u4efb\u52a1\u3002", "result": "\u65b9\u6cd5\u8d85\u8d8a\u57fa\u7ebf\uff0c\u5728\u89c6\u89c9\u9690\u55bb\u7406\u89e3\u4e0a\u4f18\u4e8e\u4eba\u7c7b\uff0c\u4f46\u5bf9\u9886\u57df\u7279\u5b9a\u9690\u55bb\u6709\u5c40\u9650\uff0c\u5e76\u8fdb\u884c\u4e86\u9519\u8bef\u5206\u6790\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u63a8\u7406\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4f46\u4ecd\u5b58\u5728\u6311\u6218\uff0c\u5efa\u8bae\u6539\u8fdb\u9690\u55bb\u6ce8\u91ca\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2504.10612", "pdf": "https://arxiv.org/pdf/2504.10612", "abs": "https://arxiv.org/abs/2504.10612", "authors": ["Michal Balcerak", "Tamaz Amiranashvili", "Suprosanna Shit", "Antonio Terpin", "Sebastian Kaltenbach", "Petros Koumoutsakos", "Bjoern Menze"], "title": "Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Generative models often map noise to data by matching flows or scores, but\nthese approaches become cumbersome for incorporating partial observations or\nadditional priors. Inspired by recent advances in Wasserstein gradient flows,\nwe propose Energy Matching, a framework that unifies flow-based approaches with\nthe flexibility of energy-based models (EBMs). Far from the data manifold,\nsamples move along curl-free, optimal transport paths from noise to data. As\nthey approach the data manifold, an entropic energy term guides the system into\na Boltzmann equilibrium distribution, explicitly capturing the underlying\nlikelihood structure of the data. We parameterize this dynamic with a single\ntime-independent scalar field, which serves as both a powerful generator and a\nflexible prior for effective regularization of inverse problems. Our method\nsubstantially outperforms existing EBMs on CIFAR-10 generation (FID 3.97\ncompared to 8.61), while retaining the simulation-free training of\ntransport-based approaches away from the data manifold. Additionally, we\nexploit the flexibility of our method and introduce an interaction energy for\ndiverse mode exploration. Our approach focuses on learning a static scalar\npotential energy -- without time conditioning, auxiliary generators, or\nadditional networks -- marking a significant departure from recent EBM methods.\nWe believe this simplified framework significantly advances EBM capabilities\nand paves the way for their broader adoption in generative modeling across\ndiverse domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEnergy Matching\u6846\u67b6\uff0c\u7edf\u4e00\u6d41\u65b9\u6cd5\u548c\u80fd\u91cf\u6a21\u578b\uff0c\u63d0\u9ad8\u751f\u6210\u6027\u80fd\uff0c\u5728CIFAR-10\u4e0aFID\u8fbe3.97\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u5904\u7406\u90e8\u5206\u89c2\u5bdf\u6216\u989d\u5916\u5148\u9a8c\u65f6\u590d\u6742\uff0c\u53d7\u5230Wasserstein\u68af\u5ea6\u6d41\u8fdb\u5c55\u542f\u53d1\uff0c\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faEnergy Matching\u6846\u67b6\uff0c\u4f7f\u7528\u5355\u4e00\u65f6\u95f4\u65e0\u5173\u6807\u91cf\u573a\uff0c\u7ed3\u5408\u6d41\u65b9\u6cd5\u548c\u80fd\u91cf\u6a21\u578b\u7075\u6d3b\u6027\uff0c\u65e0\u9700\u65f6\u95f4\u6761\u4ef6\u6216\u989d\u5916\u7f51\u7edc\u3002", "result": "\u5728CIFAR-10\u751f\u6210\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709EBM\uff08FID 3.97 vs 8.61\uff09\uff0c\u4fdd\u7559\u65e0\u6a21\u62df\u8bad\u7ec3\uff0c\u5e76\u5f15\u5165\u4ea4\u4e92\u80fd\u91cf\u652f\u6301\u591a\u6837\u6a21\u5f0f\u63a2\u7d22\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6807\u5fd7\u7740EBM\u7684\u91cd\u5927\u521b\u65b0\uff0c\u7b80\u5316\u6846\u67b6\uff0c\u63d0\u5347\u80fd\u529b\uff0c\u4fc3\u8fdb\u5728\u5404\u79cd\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2504.11319", "pdf": "https://arxiv.org/pdf/2504.11319", "abs": "https://arxiv.org/abs/2504.11319", "authors": ["Yiqing Zhou", "Karsten Naert", "Dirk Nuyens"], "title": "Sensitivity Analysis of State Space Models for Scrap Composition Estimation in EAF and BOF", "categories": ["eess.SY", "cs.SY", "93C41, 90B30, 80A19, 93E11, 93C10"], "comment": null, "summary": "This study develops and analyzes linear and nonlinear state space models for\nestimating the elemental composition of scrap steel used in steelmaking, with\napplications to Electric Arc Furnace (EAF) and Basic Oxygen Furnace (BOF)\nprocesses. The models incorporate mass balance equations and are fitted using a\nmodified Kalman filter for linear cases and the Unscented Kalman Filter (UKF)\nfor nonlinear cases. Using Cu and Cr as representative elements, we assess the\nsensitivity of model predictions to measurement noise in key process variables,\nincluding steel mass, steel composition, scrap input mass, slag mass, and iron\noxide fraction in slag. Results show that the models are robust to moderate\nnoise levels in most variables, particularly when errors are below $10\\%$.\nHowever, accuracy significantly deteriorates with noise in slag mass\nestimation. These findings highlight the practical feasibility and limitations\nof applying state space models for real-time scrap composition estimation in\nindustrial settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u7ebf\u6027\u4e0e\u975e\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u4f30\u8ba1\u70bc\u94a2\u4e2d\u5e9f\u94a2\u5143\u7d20\u7ec4\u6210\uff0c\u5e76\u8bc4\u4f30\u5bf9\u6d4b\u91cf\u566a\u58f0\u7684\u654f\u611f\u6027\u3002", "motivation": "\u52a8\u673a\u662f\u63d0\u9ad8\u7535\u5f27\u7089\u548c\u78b1\u6027\u6c27\u6c14\u7089\u4e2d\u5e9f\u94a2\u6210\u5206\u4f30\u8ba1\u7684\u51c6\u786e\u6027\uff0c\u4ee5\u652f\u6301\u5de5\u4e1a\u5e94\u7528\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u8d28\u91cf\u5e73\u8861\u65b9\u7a0b\u548c\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff08\u7ebf\u6027\u7528\u4fee\u6539\u7248\uff0c\u975e\u7ebf\u6027\u7528UKF\uff09\uff0c\u4ee5Cu\u548cCr\u5143\u7d20\u6d4b\u8bd5\u566a\u58f0\u654f\u611f\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6a21\u578b\u5bf9\u5927\u591a\u6570\u53d8\u91cf\u566a\u58f0\u9c81\u68d2\uff0c\u4f46\u5bf9\u7089\u6e23\u8d28\u91cf\u566a\u58f0\u654f\u611f\u3002", "conclusion": "\u7ed3\u8bba\u7a81\u51fa\u4e86\u8be5\u6a21\u578b\u5728\u5b9e\u65f6\u4f30\u8ba1\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u9650\u5236\u3002"}}
{"id": "2504.11200", "pdf": "https://arxiv.org/pdf/2504.11200", "abs": "https://arxiv.org/abs/2504.11200", "authors": ["Irene Celino", "Mario Scrocca", "Agnese Chiatti"], "title": "Mutual Understanding between People and Systems via Neurosymbolic AI and Knowledge Graphs", "categories": ["cs.AI"], "comment": "26 pages, 13 figures, 1 table; pre-print version of book chapter", "summary": "This chapter investigates the concept of mutual understanding between humans\nand systems, positing that Neuro-symbolic Artificial Intelligence (NeSy AI)\nmethods can significantly enhance this mutual understanding by leveraging\nexplicit symbolic knowledge representations with data-driven learning models.\nWe start by introducing three critical dimensions to characterize mutual\nunderstanding: sharing knowledge, exchanging knowledge, and governing\nknowledge. Sharing knowledge involves aligning the conceptual models of\ndifferent agents to enable a shared understanding of the domain of interest.\nExchanging knowledge relates to ensuring the effective and accurate\ncommunication between agents. Governing knowledge concerns establishing rules\nand processes to regulate the interaction between agents. Then, we present\nseveral different use case scenarios that demonstrate the application of NeSy\nAI and Knowledge Graphs to aid meaningful exchanges between human, artificial,\nand robotic agents. These scenarios highlight both the potential and the\nchallenges of combining top-down symbolic reasoning with bottom-up neural\nlearning, guiding the discussion of the coverage provided by current solutions\nalong the dimensions of sharing, exchanging, and governing knowledge.\nConcurrently, this analysis facilitates the identification of gaps and less\ndeveloped aspects in mutual understanding to address in future research.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u795e\u7ecf\u7b26\u53f7\u4eba\u5de5\u667a\u80fd\uff08NeSy AI\uff09\u5982\u4f55\u901a\u8fc7\u7ed3\u5408\u7b26\u53f7\u77e5\u8bc6\u548c\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u6765\u63d0\u5347\u4eba\u7c7b\u4e0e\u7cfb\u7edf\u4e4b\u95f4\u7684\u76f8\u4e92\u7406\u89e3\uff0c\u6db5\u76d6\u77e5\u8bc6\u5206\u4eab\u3001\u4ea4\u6362\u548c\u6cbb\u7406\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u5206\u6790\u8bc6\u522b\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u8bba\u6587\u7684\u52a8\u673a\u662f\u5f3a\u8c03NeSy AI\u5728\u4fc3\u8fdb\u4eba\u7c7b\u4e0e\u7cfb\u7edf\u76f8\u4e92\u7406\u89e3\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u901a\u8fc7\u5b9a\u4e49\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\u6765\u8868\u5f81\u548c\u6539\u8fdb\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5f15\u5165\u77e5\u8bc6\u5206\u4eab\u3001\u4ea4\u6362\u548c\u6cbb\u7406\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u5448\u73b0NeSy AI\u548c\u77e5\u8bc6\u56fe\u8c31\u7684\u5e94\u7528\u6848\u4f8b\uff0c\u5e76\u5206\u6790\u8fd9\u4e9b\u65b9\u6cd5\u5728\u4e0d\u540c\u7ef4\u5ea6\u7684\u8986\u76d6\u60c5\u51b5\u3002", "result": "\u7ed3\u679c\u7a81\u51fa\u4e86NeSy AI\u7684\u6f5c\u529b\u4e0e\u6311\u6218\uff0c\u5e76\u8bc6\u522b\u4e86\u672a\u6765\u7814\u7a76\u4e2d\u76f8\u4e92\u7406\u89e3\u7684\u7a7a\u767d\u548c\u4e0d\u8db3\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u8fd9\u79cd\u5206\u6790\u6709\u52a9\u4e8e\u6307\u5bfc\u672a\u6765\u7814\u7a76\uff0c\u89e3\u51b3\u5f53\u524d\u65b9\u6cd5\u5728\u76f8\u4e92\u7406\u89e3\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2504.10677", "pdf": "https://arxiv.org/pdf/2504.10677", "abs": "https://arxiv.org/abs/2504.10677", "authors": ["Muhammad Al-Zafar Khan", "Jamal Al-Karaki"], "title": "Achieving Optimal Tissue Repair Through MARL with Reward Shaping and Curriculum Learning", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": "14 pages, 4 figures, submitted to the 10th International Conference\n  on Information and Communication Technology for Intelligent Systems (ICTIS)", "summary": "In this paper, we present a multi-agent reinforcement learning (MARL)\nframework for optimizing tissue repair processes using engineered biological\nagents. Our approach integrates: (1) stochastic reaction-diffusion systems\nmodeling molecular signaling, (2) neural-like electrochemical communication\nwith Hebbian plasticity, and (3) a biologically informed reward function\ncombining chemical gradient tracking, neural synchronization, and robust\npenalties. A curriculum learning scheme guides the agent through progressively\ncomplex repair scenarios. In silico experiments demonstrate emergent repair\nstrategies, including dynamic secretion control and spatial coordination.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u4f7f\u7528\u5de5\u7a0b\u751f\u7269\u4ee3\u7406\u7684\u7ec4\u7ec7\u4fee\u590d\u8fc7\u7a0b\u3002", "motivation": "\u4e3a\u4e86\u4f18\u5316\u7ec4\u7ec7\u4fee\u590d\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u751f\u7269\u533b\u5b66\u5e94\u7528\u4e2d\u7684\u6548\u7387\u548c\u6548\u679c\u3002", "method": "\u6574\u5408\u4e86\u968f\u673a\u53cd\u5e94-\u6269\u6563\u7cfb\u7edf\u3001\u795e\u7ecf\u6837\u7535\u5316\u5b66\u901a\u4fe1\uff08\u5305\u62ecHebbian\u53ef\u5851\u6027\uff09\u3001\u751f\u7269\u5b66\u4fe1\u606f\u5956\u52b1\u51fd\u6570\uff08\u7ed3\u5408\u5316\u5b66\u68af\u5ea6\u8ddf\u8e2a\u3001\u795e\u7ecf\u540c\u6b65\u548c\u9c81\u68d2\u60e9\u7f5a\uff09\u3001\u4ee5\u53ca\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6848\u3002", "result": "\u901a\u8fc7in silico\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u7d27\u6025\u4fee\u590d\u7b56\u7565\uff0c\u5305\u62ec\u52a8\u6001\u5206\u6ccc\u63a7\u5236\u548c\u7a7a\u95f4\u534f\u8c03\u3002", "conclusion": "\u8be5\u6846\u67b6\u8bc1\u660e\u4e86\u5728\u7ec4\u7ec7\u4fee\u590d\u4e2d\u7684\u6709\u6548\u6027\uff0c\u7a81\u663e\u4e86\u7d27\u6025\u884c\u4e3a\u548c\u4f18\u5316\u6f5c\u529b\u3002"}}
{"id": "2504.11355", "pdf": "https://arxiv.org/pdf/2504.11355", "abs": "https://arxiv.org/abs/2504.11355", "authors": ["Alberto Castillo", "Elliot Pryor", "Anas El Fathi", "Boris Kovatchev", "Marc Breton"], "title": "Neural Networks for on-chip Model Predictive Control: a Method to Build Optimized Training Datasets and its application to Type-1 Diabetes", "categories": ["eess.SY", "cs.AI", "cs.SY"], "comment": null, "summary": "Training Neural Networks (NNs) to behave as Model Predictive Control (MPC)\nalgorithms is an effective way to implement them in constrained embedded\ndevices. By collecting large amounts of input-output data, where inputs\nrepresent system states and outputs are MPC-generated control actions, NNs can\nbe trained to replicate MPC behavior at a fraction of the computational cost.\nHowever, although the composition of the training data critically influences\nthe final NN accuracy, methods for systematically optimizing it remain\nunderexplored. In this paper, we introduce the concept of Optimally-Sampled\nDatasets (OSDs) as ideal training sets and present an efficient algorithm for\ngenerating them. An OSD is a parametrized subset of all the available data that\n(i) preserves existing MPC information up to a certain numerical resolution,\n(ii) avoids duplicate or near-duplicate states, and (iii) becomes saturated or\ncomplete. We demonstrate the effectiveness of OSDs by training NNs to replicate\nthe University of Virginia's MPC algorithm for automated insulin delivery in\nType-1 Diabetes, achieving a four-fold improvement in final accuracy. Notably,\ntwo OSD-trained NNs received regulatory clearance for clinical testing as the\nfirst NN-based control algorithm for direct human insulin dosing. This\nmethodology opens new pathways for implementing advanced optimizations on\nresource-constrained embedded platforms, potentially revolutionizing how\ncomplex algorithms are deployed.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4f18\u5316\u91c7\u6837\u6570\u636e\u96c6\uff08OSDs\uff09\u6765\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6a21\u4eff\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\uff0c\u5728\u8ba1\u7b97\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9ad8\u6548\u63a7\u5236\uff0c\u5e76\u901a\u8fc7\u80f0\u5c9b\u7d20\u9012\u9001\u5e94\u7528\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u52a8\u673a\u662f\u867d\u7136\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u4ee5\u66f4\u4f4e\u8ba1\u7b97\u6210\u672c\u590d\u5236MPC\u7b97\u6cd5\uff0c\u4f46\u8bad\u7ec3\u6570\u636e\u7684\u7ec4\u6210\u5bf9\u51c6\u786e\u6027\u81f3\u5173\u91cd\u8981\uff0c\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u65b9\u6cd5\u662f\u5f15\u5165OSDs\uff0c\u8fd9\u662f\u4e00\u4e2a\u53c2\u6570\u5316\u7684\u6570\u636e\u5b50\u96c6\uff0c\u80fd\u591f\u4fdd\u7559MPC\u4fe1\u606f\u3001\u907f\u514d\u91cd\u590d\u72b6\u6001\u5e76\u5b9e\u73b0\u9971\u548c\uff0c\u5e76\u63d0\u4f9b\u9ad8\u6548\u751f\u6210\u7b97\u6cd5\u3002", "result": "\u7ed3\u679c\u662f\u901a\u8fc7\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u590d\u5236\u7279\u5b9aMPC\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u6027\u7684\u56db\u500d\u6539\u8fdb\uff0c\u5e76\u6709\u57fa\u4e8eOSDs\u7684\u795e\u7ecf\u7f51\u7edc\u83b7\u5f97\u4e34\u5e8a\u6d4b\u8bd5\u76d1\u7ba1\u6279\u51c6\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u5728\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u90e8\u7f72\u590d\u6742\u7b97\u6cd5\u6253\u5f00\u65b0\u9014\u5f84\uff0c\u53ef\u80fd\u5f7b\u5e95\u6539\u53d8\u4f18\u5316\u5b9e\u73b0\u65b9\u5f0f\u3002"}}
{"id": "2504.11239", "pdf": "https://arxiv.org/pdf/2504.11239", "abs": "https://arxiv.org/abs/2504.11239", "authors": ["Chang Yang", "Ruiyu Wang", "Junzhe Jiang", "Qi Jiang", "Qinggang Zhang", "Yanchen Deng", "Shuxin Li", "Shuyue Hu", "Bo Li", "Florian T. Pokorny", "Xiao Huang", "Xinrun Wang"], "title": "Nondeterministic Polynomial-time Problem Challenge: An Ever-Scaling Reasoning Benchmark for LLMs", "categories": ["cs.AI", "cs.CL"], "comment": "Preliminary work, 10 pages for main text", "summary": "Reasoning is the fundamental capability of large language models (LLMs). Due\nto the rapid progress of LLMs, there are two main issues of current benchmarks:\ni) these benchmarks can be crushed in a short time (less than 1 year), and ii)\nthese benchmarks may be easily hacked. To handle these issues, we propose the\never-scalingness for building the benchmarks which are uncrushable, unhackable,\nauto-verifiable and general. This paper presents Nondeterministic\nPolynomial-time Problem Challenge (NPPC), an ever-scaling reasoning benchmark\nfor LLMs. Specifically, the NPPC has three main modules: i) npgym, which\nprovides a unified interface of 25 well-known NP-complete problems and can\ngenerate any number of instances with any levels of complexities, ii) npsolver:\nwhich provides a unified interface to evaluate the problem instances with both\nonline and offline models via APIs and local deployments, respectively, and\niii) npeval: which provides the comprehensive and ready-to-use tools to analyze\nthe performances of LLMs over different problems, the number of tokens, the aha\nmoments, the reasoning errors and the solution errors. Extensive experiments\nover widely-used LLMs demonstrate: i) NPPC can successfully decrease the\nperformances of advanced LLMs' performances to below 10%, demonstrating that\nNPPC is uncrushable, ii) DeepSeek-R1, Claude-3.7-Sonnet, and o1/o3-mini are the\nmost powerful LLMs, where DeepSeek-R1 outperforms Claude-3.7-Sonnet and\no1/o3-mini in most NP-complete problems considered, and iii) the numbers of\ntokens, aha moments in the advanced LLMs, e.g., Claude-3.7-Sonnet and\nDeepSeek-R1, are observed first to increase and then decrease when the problem\ninstances become more and more difficult. We believe that NPPC is the first\never-scaling reasoning benchmark, serving as the uncrushable and unhackable\ntestbed for LLMs toward artificial general intelligence (AGI).", "AI": {"tldr": "\u672c\u6587\u63d0\u51faNPPC\uff0c\u4e00\u4e2a\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6c38\u7eed\u6269\u5c55\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8eNP\u5b8c\u5168\u95ee\u9898\uff0c\u65e8\u5728\u4e0d\u53ef\u51fb\u6e83\u3001\u4e0d\u53ef\u9ed1\u5ba2\u653b\u51fb\u3001\u81ea\u52a8\u53ef\u9a8c\u8bc1\u548c\u901a\u7528\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5bb9\u6613\u88ab\u5feb\u901f\u51fb\u6e83\u548c\u9ed1\u5ba2\u653b\u51fb\uff0c\u56e0\u6b64\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u6c38\u7eed\u6269\u5c55\u3001\u4e0d\u53ef\u51fb\u6e83\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u63d0\u51faNPPC\u6846\u67b6\uff0c\u5305\u62ecnpgym\uff08\u751f\u6210NP\u5b8c\u5168\u95ee\u9898\u5b9e\u4f8b\uff09\u3001npsolver\uff08\u8bc4\u4f30LLMs\u6027\u80fd\uff09\u548cnpeval\uff08\u5206\u6790\u6027\u80fd\u6307\u6807\uff09\u4e09\u4e2a\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u663e\u793aNPPC\u5c06\u9ad8\u7ea7LLMs\u6027\u80fd\u964d\u81f310%\u4ee5\u4e0b\uff0cDeepSeek-R1\u8868\u73b0\u6700\u4f73\uff0c\u5e76\u89c2\u5bdf\u5230\u4ee4\u724c\u6570\u548c\u987f\u609f\u65f6\u523b\u968f\u96be\u5ea6\u53d8\u5316\u7684\u6a21\u5f0f\u3002", "conclusion": "NPPC\u662f\u9996\u4e2a\u6c38\u7eed\u6269\u5c55\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53ef\u4f5c\u4e3aAGI\u53d1\u5c55\u7684\u4e0d\u53ef\u51fb\u6e83\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2504.10694", "pdf": "https://arxiv.org/pdf/2504.10694", "abs": "https://arxiv.org/abs/2504.10694", "authors": ["Kristina Nikoli\u0107", "Luze Sun", "Jie Zhang", "Florian Tram\u00e8r"], "title": "The Jailbreak Tax: How Useful are Your Jailbreak Outputs?", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Jailbreak attacks bypass the guardrails of large language models to produce\nharmful outputs. In this paper, we ask whether the model outputs produced by\nexisting jailbreaks are actually useful. For example, when jailbreaking a model\nto give instructions for building a bomb, does the jailbreak yield good\ninstructions? Since the utility of most unsafe answers (e.g., bomb\ninstructions) is hard to evaluate rigorously, we build new jailbreak evaluation\nsets with known ground truth answers, by aligning models to refuse questions\nrelated to benign and easy-to-evaluate topics (e.g., biology or math). Our\nevaluation of eight representative jailbreaks across five utility benchmarks\nreveals a consistent drop in model utility in jailbroken responses, which we\nterm the jailbreak tax. For example, while all jailbreaks we tested bypass\nguardrails in models aligned to refuse to answer math, this comes at the\nexpense of a drop of up to 92% in accuracy. Overall, our work proposes the\njailbreak tax as a new important metric in AI safety, and introduces benchmarks\nto evaluate existing and future jailbreaks. We make the benchmark available at\nhttps://github.com/ethz-spylab/jailbreak-tax", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8bc4\u4f30\u4e86\u8d8a\u72f1\u653b\u51fb\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6548\u7528\uff0c\u5f15\u5165\u4e86'\u8d8a\u72f1\u7a0e'\u6982\u5ff5\uff0c\u5f3a\u8c03\u653b\u51fb\u6210\u529f\u53ef\u80fd\u5bfc\u81f4\u8f93\u51fa\u8d28\u91cf\u4e0b\u964d\u3002", "motivation": "\u8d28\u7591\u73b0\u6709\u8d8a\u72f1\u653b\u51fb\u7684\u8f93\u51fa\u662f\u5426\u771f\u6b63\u6709\u7528\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u80fd\u4ea7\u751f\u6709\u5bb3\u4f46\u4f4e\u6548\u7528\u7684\u54cd\u5e94\u3002", "method": "\u6784\u5efa\u65b0\u8bc4\u4f30\u96c6\uff0c\u901a\u8fc7\u8ba9\u6a21\u578b\u62d2\u7edd\u826f\u6027\u4e3b\u9898\uff08\u5982\u751f\u7269\u6216\u6570\u5b66\uff09\u7684\u95ee\u9898\uff0c\u5e76\u8bc4\u4f30\u516b\u79cd\u4ee3\u8868\u6027\u8d8a\u72f1\u653b\u51fb\u5728\u4e94\u4e2a\u6548\u7528\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u8d8a\u72f1\u54cd\u5e94\u4e2d\u6a21\u578b\u6548\u7528\u4e00\u81f4\u4e0b\u964d\uff0c\u79f0\u4e3a\u8d8a\u72f1\u7a0e\uff0c\u4f8b\u5982\u6570\u5b66\u51c6\u786e\u7387\u4e0b\u964d\u9ad8\u8fbe92%\u3002", "conclusion": "\u63d0\u51fa\u8d8a\u72f1\u7a0e\u4f5c\u4e3aAI\u5b89\u5168\u65b0\u6307\u6807\uff0c\u5e76\u63d0\u4f9b\u57fa\u51c6\uff0c\u53d1\u5e03\u5728https://github.com/ethz-spylab/jailbreak-tax\u3002"}}
{"id": "2504.11374", "pdf": "https://arxiv.org/pdf/2504.11374", "abs": "https://arxiv.org/abs/2504.11374", "authors": ["Yongkang Huo", "Fuvio Forni", "Rodolphe Sepulchre"], "title": "A Winner-Takes-All Mechanism for Event Generation", "categories": ["eess.SY", "cs.AI", "cs.SY"], "comment": null, "summary": "We present a novel framework for central pattern generator design that\nleverages the intrinsic rebound excitability of neurons in combination with\nwinner-takes-all computation. Our approach unifies decision-making and rhythmic\npattern generation within a simple yet powerful network architecture that\nemploys all-to-all inhibitory connections enhanced by designable excitatory\ninteractions. This design offers significant advantages regarding ease of\nimplementation, adaptability, and robustness. We demonstrate its efficacy\nthrough a ring oscillator model, which exhibits adaptive phase and frequency\nmodulation, making the framework particularly promising for applications in\nneuromorphic systems and robotics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u4e2d\u5fc3\u6a21\u5f0f\u53d1\u751f\u5668\u8bbe\u8ba1\uff0c\u7ed3\u5408\u795e\u7ecf\u5143\u53cd\u5f39\u5174\u594b\u6027\u548c\u8d62\u8005\u901a\u5403\u8ba1\u7b97\uff0c\u7edf\u4e00\u51b3\u7b56\u548c\u8282\u5f8b\u6a21\u5f0f\u751f\u6210\u3002", "motivation": "\u52a8\u673a\u662f\u5f00\u53d1\u4e00\u4e2a\u7b80\u5355\u3001\u5f3a\u5927\u4e14\u9c81\u68d2\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u4ee5\u7edf\u4e00\u51b3\u7b56\u548c\u8282\u5f8b\u6a21\u5f0f\u751f\u6210\uff0c\u89e3\u51b3\u76f8\u5173\u9886\u57df\u7684\u6311\u6218\u3002", "method": "\u65b9\u6cd5\u4f7f\u7528\u5168\u4e92\u6291\u8fde\u63a5\u5e76\u589e\u5f3a\u53ef\u8bbe\u8ba1\u5174\u594b\u4ea4\u4e92\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u7ed3\u5408\u795e\u7ecf\u5143\u7684\u5185\u5728\u53cd\u5f39\u5174\u594b\u6027\u548c\u8d62\u8005\u901a\u5403\u8ba1\u7b97\u3002", "result": "\u7ed3\u679c\u901a\u8fc7\u73af\u5f62\u632f\u8361\u5668\u6a21\u578b\u5c55\u793a\u4e86\u81ea\u9002\u5e94\u76f8\u4f4d\u548c\u9891\u7387\u8c03\u5236\uff0c\u8bc1\u660e\u4e86\u6846\u67b6\u5728\u6613\u5b9e\u73b0\u3001\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8be5\u6846\u67b6\u5bf9\u795e\u7ecf\u5f62\u6001\u7cfb\u7edf\u548c\u673a\u5668\u4eba\u5e94\u7528\u5177\u6709\u91cd\u8981\u524d\u666f\u3002"}}
{"id": "2504.11243", "pdf": "https://arxiv.org/pdf/2504.11243", "abs": "https://arxiv.org/abs/2504.11243", "authors": ["Balahari Vignesh Balu", "Florian Geissler", "Francesco Carella", "Joao-Vitor Zacchi", "Josef Jiru", "Nuria Mata", "Reinhard Stolle"], "title": "Towards Automated Safety Requirements Derivation Using Agent-based RAG", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "9 pages, 3 figures", "summary": "We study the automated derivation of safety requirements in a self-driving\nvehicle use case, leveraging LLMs in combination with agent-based\nretrieval-augmented generation. Conventional approaches that utilise\npre-trained LLMs to assist in safety analyses typically lack domain-specific\nknowledge. Existing RAG approaches address this issue, yet their performance\ndeteriorates when handling complex queries and it becomes increasingly harder\nto retrieve the most relevant information. This is particularly relevant for\nsafety-relevant applications. In this paper, we propose the use of agent-based\nRAG to derive safety requirements and show that the retrieved information is\nmore relevant to the queries. We implement an agent-based approach on a\ndocument pool of automotive standards and the Apollo case study, as a\nrepresentative example of an automated driving perception system. Our solution\nis tested on a data set of safety requirement questions and answers, extracted\nfrom the Apollo data. Evaluating a set of selected RAG metrics, we present and\ndiscuss advantages of a agent-based approach compared to default RAG methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u4ee3\u7406-based RAG\u7ed3\u5408LLM\u81ea\u52a8\u63a8\u5bfc\u81ea\u9a7e\u8f66\u5b89\u5168\u8981\u6c42\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u590d\u6742\u67e5\u8be2\u4e2d\u7684\u76f8\u5173\u6027\u95ee\u9898\uff0c\u5e76\u5728Apollo\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edfLLM\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\uff0c\u73b0\u6709RAG\u5728\u5904\u7406\u5b89\u5168\u76f8\u5173\u590d\u6742\u67e5\u8be2\u65f6\u6027\u80fd\u4e0b\u964d\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u4ee3\u7406-based RAG\u63d0\u5347\u4fe1\u606f\u68c0\u7d22\u76f8\u5173\u6027\u3002", "method": "\u63d0\u51fa\u4ee3\u7406-based RAG\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8e\u6c7d\u8f66\u6807\u51c6\u548cApollo\u6848\u4f8b\uff0c\u4f7f\u7528\u4eceApollo\u6570\u636e\u63d0\u53d6\u7684\u5b89\u5168\u8981\u6c42\u95ee\u9898\u96c6\u8fdb\u884c\u5b9e\u73b0\u3002", "result": "\u901a\u8fc7RAG\u6307\u6807\u8bc4\u4f30\uff0c\u4ee3\u7406-based \u65b9\u6cd5\u6bd4\u9ed8\u8ba4RAG\u68c0\u7d22\u4fe1\u606f\u66f4\u76f8\u5173\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u4f18\u52bf\u3002", "conclusion": "\u4ee3\u7406-based RAG\u5728\u81ea\u9a7e\u8f66\u5b89\u5168\u8981\u6c42\u63a8\u5bfc\u4e2d\u66f4\u6709\u6548\uff0c\u63d0\u4f9b\u66f4\u597d\u7684\u6027\u80fd\u548c\u76f8\u5173\u6027\u3002"}}
{"id": "2504.10720", "pdf": "https://arxiv.org/pdf/2504.10720", "abs": "https://arxiv.org/abs/2504.10720", "authors": ["Kamaljyoti Nath", "Khemraj Shukla", "Victor C. Tsai", "Umair bin Waheed", "Christian Huber", "Omer Alpak", "Chuen-Song Chen", "Ligang Lu", "Amik St-Cyr"], "title": "Leveraging Deep Operator Networks (DeepONet) for Acoustic Full Waveform Inversion (FWI)", "categories": ["cs.LG"], "comment": null, "summary": "Full Waveform Inversion (FWI) is an important geophysical technique\nconsidered in subsurface property prediction. It solves the inverse problem of\npredicting high-resolution Earth interior models from seismic data. Traditional\nFWI methods are computationally demanding. Inverse problems in geophysics often\nface challenges of non-uniqueness due to limited data, as data are often\ncollected only on the surface. In this study, we introduce a novel methodology\nthat leverages Deep Operator Networks (DeepONet) to attempt to improve both the\nefficiency and accuracy of FWI. The proposed DeepONet methodology inverts\nseismic waveforms for the subsurface velocity field. This approach is able to\ncapture some key features of the subsurface velocity field. We have shown that\nthe architecture can be applied to noisy seismic data with an accuracy that is\nbetter than some other machine learning methods. We also test our proposed\nmethod with out-of-distribution prediction for different velocity models. The\nproposed DeepONet shows comparable and better accuracy in some velocity models\nthan some other machine learning methods. To improve the FWI workflow, we\npropose using the DeepONet output as a starting model for conventional FWI and\nthat it may improve FWI performance. While we have only shown that DeepONet\nfacilitates faster convergence than starting with a homogeneous velocity field,\nit may have some benefits compared to other approaches to constructing starting\nmodels. This integration of DeepONet into FWI may accelerate the inversion\nprocess and may also enhance its robustness and reliability.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528Deep Operator Networks (DeepONet)\u6539\u8fdbFull Waveform Inversion (FWI)\uff0c\u4ee5\u63d0\u5347\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edfFWI\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u4e14\u9006\u95ee\u9898\u56e0\u6570\u636e\u6709\u9650\u53ef\u80fd\u975e\u552f\u4e00\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u63d0\u51faDeepONet\u53cd\u6f14\u5730\u9707\u6ce2\u5f62\u83b7\u53d6\u5730\u4e0b\u901f\u5ea6\u573a\uff0c\u5305\u62ec\u5904\u7406\u566a\u58f0\u6570\u636e\u3001\u51fa\u5206\u5e03\u9884\u6d4b\uff0c\u5e76\u4f5c\u4e3a\u4f20\u7edfFWI\u8d77\u59cb\u6a21\u578b\u3002", "result": "DeepONet\u6355\u83b7\u5173\u952e\u7279\u5f81\uff0c\u5728\u566a\u58f0\u6570\u636e\u548c\u67d0\u4e9b\u901f\u5ea6\u6a21\u578b\u4e2d\u51c6\u786e\u6027\u4f18\u4e8e\u5176\u4ed6\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u52a0\u901fFWI\u6536\u655b\u3002", "conclusion": "\u6574\u5408DeepONet\u53ef\u52a0\u901fFWI\u8fc7\u7a0b\uff0c\u5e76\u63d0\u9ad8\u5176\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2504.11446", "pdf": "https://arxiv.org/pdf/2504.11446", "abs": "https://arxiv.org/abs/2504.11446", "authors": ["Federico Porcari", "Donatello Materassi", "Simone Formentin"], "title": "eXplainable AI for data driven control: an inverse optimal control approach", "categories": ["eess.SY", "cs.SY"], "comment": "Submitted to CDC 2025", "summary": "Understanding the behavior of black-box data-driven controllers is a key\nchallenge in modern control design. In this work, we propose an eXplainable AI\n(XAI) methodology based on Inverse Optimal Control (IOC) to obtain local\nexplanations for the behavior of a controller operating around a given region.\nSpecifically, we extract the weights assigned to tracking errors and control\neffort in the implicit cost function that a black-box controller is optimizing,\noffering a more transparent and interpretable representation of the\ncontroller's underlying objectives. This approach presents connections with\nwell-established XAI techniques, such as Local Interpretable Model-agnostic\nExplanations (LIME) since it is still based on a local approximation of the\ncontrol policy. However, rather being limited to a standard sensitivity\nanalysis, the explanation provided by our method relies on the solution of an\ninverse Linear Quadratic (LQ) problem, offering a structured and more\ncontrol-relevant perspective. Numerical examples demonstrate that the inferred\ncost function consistently provides a deeper understanding of the controller's\ndecision-making process, shedding light on otherwise counterintuitive or\nunexpected phenomena.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faXAI\u65b9\u6cd5\u57fa\u4e8e\u9006\u6700\u4f18\u63a7\u5236\uff0c\u89e3\u91ca\u9ed1\u7bb1\u63a7\u5236\u5668\u7684\u884c\u4e3a\uff0c\u901a\u8fc7\u63d0\u53d6\u6210\u672c\u51fd\u6570\u6743\u91cd\u63d0\u4f9b\u672c\u5730\u900f\u660e\u89e3\u91ca\uff0c\u4e0eLIME\u76f8\u5173\u8054\u3002", "motivation": "\u7406\u89e3\u9ed1\u7bb1\u6570\u636e\u9a71\u52a8\u63a7\u5236\u5668\u7684\u884c\u4e3a\u662f\u73b0\u4ee3\u63a7\u5236\u8bbe\u8ba1\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u4f7f\u7528Inverse Optimal Control (IOC)\u65b9\u6cd5\uff0c\u6c42\u89e3\u9006Linear Quadratic (LQ)\u95ee\u9898\uff0c\u63d0\u53d6\u8ddf\u8e2a\u8bef\u5dee\u548c\u63a7\u5236\u52aa\u529b\u7684\u6743\u91cd\u3002", "result": "\u6570\u503c\u4f8b\u5b50\u663e\u793a\uff0c\u63a8\u65ad\u7684\u6210\u672c\u51fd\u6570\u80fd\u66f4\u6df1\u5165\u7406\u89e3\u63a7\u5236\u5668\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u63ed\u793a\u53cd\u76f4\u89c9\u73b0\u8c61\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u7ed3\u6784\u5316\u3001\u63a7\u5236\u76f8\u5173\u7684\u89e3\u91ca\uff0c\u5e2e\u52a9\u9610\u660e\u9ed1\u7bb1\u63a7\u5236\u5668\u7684\u6f5c\u5728\u76ee\u6807\u3002"}}
{"id": "2504.11301", "pdf": "https://arxiv.org/pdf/2504.11301", "abs": "https://arxiv.org/abs/2504.11301", "authors": ["Yangyang Zhuang", "Wenjia Jiang", "Jiayu Zhang", "Ze Yang", "Joey Tianyi Zhou", "Chi Zhang"], "title": "Learning to Be A Doctor: Searching for Effective Medical Agent Architectures", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Model (LLM)-based agents have demonstrated strong capabilities\nacross a wide range of tasks, and their application in the medical domain holds\nparticular promise due to the demand for high generalizability and reliance on\ninterdisciplinary knowledge. However, existing medical agent systems often rely\non static, manually crafted workflows that lack the flexibility to accommodate\ndiverse diagnostic requirements and adapt to emerging clinical scenarios.\nMotivated by the success of automated machine learning (AutoML), this paper\nintroduces a novel framework for the automated design of medical agent\narchitectures. Specifically, we define a hierarchical and expressive agent\nsearch space that enables dynamic workflow adaptation through structured\nmodifications at the node, structural, and framework levels. Our framework\nconceptualizes medical agents as graph-based architectures composed of diverse,\nfunctional node types and supports iterative self-improvement guided by\ndiagnostic feedback. Experimental results on skin disease diagnosis tasks\ndemonstrate that the proposed method effectively evolves workflow structures\nand significantly enhances diagnostic accuracy over time. This work represents\nthe first fully automated framework for medical agent architecture design and\noffers a scalable, adaptable foundation for deploying intelligent agents in\nreal-world clinical environments.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u8bbe\u8ba1\u533b\u7597\u4ee3\u7406\u67b6\u6784\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u901a\u8fc7\u5206\u5c42\u641c\u7d22\u7a7a\u95f4\u5b9e\u73b0\u52a8\u6001\u9002\u5e94\u548c\u8bca\u65ad\u51c6\u786e\u6027\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u533b\u7597\u4ee3\u7406\u7cfb\u7edf\u4f9d\u8d56\u9759\u6001\u5de5\u4f5c\u6d41\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\uff1b\u53d7AutoML\u6210\u529f\u542f\u53d1\uff0c\u9700\u8981\u81ea\u52a8\u8bbe\u8ba1\u4ee5\u9002\u5e94\u591a\u6837\u5316\u8bca\u65ad\u9700\u6c42\u3002", "method": "\u5b9a\u4e49\u5206\u5c42\u4ee3\u7406\u641c\u7d22\u7a7a\u95f4\uff0c\u5c06\u533b\u7597\u4ee3\u7406\u89c6\u4e3a\u57fa\u4e8e\u56fe\u7684\u67b6\u6784\uff0c\u652f\u6301\u8282\u70b9\u3001\u7ed3\u6784\u548c\u6846\u67b6\u7ea7\u4fee\u6539\uff0c\u4ee5\u53ca\u8bca\u65ad\u53cd\u9988\u5f15\u5bfc\u7684\u8fed\u4ee3\u81ea\u6539\u8fdb\u3002", "result": "\u5728\u76ae\u80a4\u75c5\u8bca\u65ad\u4efb\u52a1\u7684\u5b9e\u9a8c\u4e2d\uff0c\u65b9\u6cd5\u6709\u6548\u6f14\u5316\u5de5\u4f5c\u6d41\u7ed3\u6784\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u3002", "conclusion": "\u8fd9\u662f\u7b2c\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u533b\u7597\u4ee3\u7406\u67b6\u6784\u8bbe\u8ba1\u6846\u67b6\uff0c\u4e3a\u5728\u771f\u5b9e\u4e34\u5e8a\u73af\u5883\u4e2d\u90e8\u7f72\u667a\u80fd\u4ee3\u7406\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2504.10735", "pdf": "https://arxiv.org/pdf/2504.10735", "abs": "https://arxiv.org/abs/2504.10735", "authors": ["Timur Carstensen", "Neeratyoy Mallik", "Frank Hutter", "Martin Rapp"], "title": "Frozen Layers: Memory-efficient Many-fidelity Hyperparameter Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As model sizes grow, finding efficient and cost-effective hyperparameter\noptimization (HPO) methods becomes increasingly crucial for deep learning\npipelines. While multi-fidelity HPO (MF-HPO) trades off computational resources\nrequired for DL training with lower fidelity estimations, existing fidelity\nsources often fail under lower compute and memory constraints. We propose a\nnovel fidelity source: the number of layers that are trained or frozen during\ntraining. For deep networks, this approach offers significant compute and\nmemory savings while preserving rank correlations between hyperparameters at\nlow fidelities compared to full model training. We demonstrate this in our\nempirical evaluation across ResNets and Transformers and additionally analyze\nthe utility of frozen layers as a fidelity in using GPU resources as a fidelity\nin HPO, and for a combined MF-HPO with other fidelity sources. This\ncontribution opens new applications for MF-HPO with hardware resources as a\nfidelity and creates opportunities for improved algorithms navigating joint\nfidelity spaces.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u4fdd\u771f\u5ea6\u8d85\u53c2\u6570\u4f18\u5316\uff08MF-HPO\uff09\u65b9\u6cd5\uff0c\u4f7f\u7528\u8bad\u7ec3\u6216\u51bb\u7ed3\u5c42\u6570\u4f5c\u4e3a\u4fdd\u771f\u5ea6\u6765\u6e90\uff0c\u4ee5\u8282\u7701\u8ba1\u7b97\u8d44\u6e90\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u6a21\u578b\u89c4\u6a21\u589e\u957f\uff0c\u9ad8\u6548\u7684\u8d85\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709\u7684\u4fdd\u771f\u5ea6\u6765\u6e90\u5728\u4f4e\u8ba1\u7b97\u8d44\u6e90\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u5c06\u8bad\u7ec3\u6216\u51bb\u7ed3\u5c42\u6570\u4f5c\u4e3a\u4fdd\u771f\u5ea6\u6765\u6e90\uff0c\u901a\u8fc7\u51bb\u7ed3\u90e8\u5206\u5c42\u51cf\u5c11\u8ba1\u7b97\u548c\u5185\u5b58\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u8d85\u53c2\u6570\u7684\u76f8\u5173\u6027\u3002", "result": "\u5728ResNets\u548cTransformers\u4e0a\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\u4e86\u826f\u597d\u76f8\u5173\u6027\uff0c\u5e76\u5206\u6790\u4e86\u4e0e\u5176\u4ed6\u4fdd\u771f\u5ea6\u6765\u6e90\u7ed3\u5408\u7684\u6548\u7528\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4f7f\u7528\u786c\u4ef6\u8d44\u6e90\u4f5c\u4e3a\u4fdd\u771f\u5ea6\u7684MF-HPO\u6253\u5f00\u65b0\u5e94\u7528\uff0c\u5e76\u4e3a\u6539\u8fdb\u8054\u5408\u4fdd\u771f\u5ea6\u7a7a\u95f4\u7684\u7b97\u6cd5\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002"}}
{"id": "2504.10497", "pdf": "https://arxiv.org/pdf/2504.10497", "abs": "https://arxiv.org/abs/2504.10497", "authors": ["Sunyi Liu", "Mengzhe Geng", "Rebecca Hart"], "title": "Exploring Generative AI Techniques in Government: A Case Study", "categories": ["cs.IR", "cs.AI", "cs.HC", "cs.MA", "cs.SY", "eess.SY"], "comment": "In submission to IEEE Intelligent Systems", "summary": "The swift progress of Generative Artificial intelligence (GenAI), notably\nLarge Language Models (LLMs), is reshaping the digital landscape. Recognizing\nthis transformative potential, the National Research Council of Canada (NRC)\nlaunched a pilot initiative to explore the integration of GenAI techniques into\nits daily operation for performance excellence, where 22 projects were launched\nin May 2024. Within these projects, this paper presents the development of the\nintelligent agent Pubbie as a case study, targeting the automation of\nperformance measurement, data management and insight reporting at the NRC.\nCutting-edge techniques are explored, including LLM orchestration and semantic\nembedding via RoBERTa, while strategic fine-tuning and few-shot learning\napproaches are incorporated to infuse domain knowledge at an affordable cost.\nThe user-friendly interface of Pubbie allows general government users to input\nqueries in natural language and easily upload or download files with a simple\nbutton click, greatly reducing manual efforts and accessibility barriers.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u52a0\u62ff\u5927\u56fd\u5bb6\u7814\u7a76\u59d4\u5458\u4f1a (NRC) \u5f00\u53d1\u7684\u667a\u80fd\u4ee3\u7406 Pubbie\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6027\u80fd\u6d4b\u91cf\u3001\u6570\u636e\u7ba1\u7406\u548c\u62a5\u544a\uff0c\u91c7\u7528\u751f\u6210\u5f0f AI \u6280\u672f\u51cf\u5c11\u624b\u52a8\u5de5\u4f5c\u3002", "motivation": "\u8ba4\u8bc6\u5230\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u5feb\u901f\u53d1\u5c55\u548c\u53d8\u9769\u6f5c\u529b\uff0cNRC \u542f\u52a8\u8bd5\u70b9\u9879\u76ee\uff0c\u4ee5\u63a2\u7d22\u5c06\u5176\u6574\u5408\u5230\u65e5\u5e38\u64cd\u4f5c\u4e2d\u63d0\u5347\u6027\u80fd\u3002", "method": "\u4f7f\u7528 LLM \u7f16\u6392\u3001RoBERTa \u8bed\u4e49\u5d4c\u5165\u3001\u6218\u7565\u5fae\u8c03\u548c\u5c11\u6837\u672c\u5b66\u4e60\u7b49\u6280\u672f\uff0c\u8bbe\u8ba1\u7528\u6237\u53cb\u597d\u7684\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u63a5\u53e3\uff0c\u652f\u6301\u6587\u4ef6\u4e0a\u4f20/\u4e0b\u8f7d\u3002", "result": "Pubbie \u51cf\u5c11\u4e86\u624b\u52a8\u52aa\u529b\u548c\u53ef\u8bbf\u95ee\u6027\u969c\u788d\uff0c\u63d0\u9ad8\u4e86\u6570\u636e\u7ba1\u7406\u548c\u62a5\u544a\u7684\u6548\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u751f\u6210\u5f0f AI \u5728\u7ec4\u7ec7\u6027\u80fd\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u4e3a\u7c7b\u4f3c\u96c6\u6210\u63d0\u4f9b\u53ef\u884c\u6848\u4f8b\u3002"}}
{"id": "2504.11354", "pdf": "https://arxiv.org/pdf/2504.11354", "abs": "https://arxiv.org/abs/2504.11354", "authors": ["Haiming Wang", "Mert Unsal", "Xiaohan Lin", "Mantas Baksys", "Junqi Liu", "Marco Dos Santos", "Flood Sung", "Marina Vinyes", "Zhenzhe Ying", "Zekai Zhu", "Jianqiao Lu", "Hugues de Saxc\u00e9", "Bolton Bailey", "Chendong Song", "Chenjun Xiao", "Dehao Zhang", "Ebony Zhang", "Frederick Pu", "Han Zhu", "Jiawei Liu", "Jonas Bayer", "Julien Michel", "Longhui Yu", "L\u00e9o Dreyfus-Schmidt", "Lewis Tunstall", "Luigi Pagani", "Moreira Machado", "Pauline Bourigault", "Ran Wang", "Stanislas Polu", "Thibaut Barroyer", "Wen-Ding Li", "Yazhe Niu", "Yann Fleureau", "Yangyang Hu", "Zhouliang Yu", "Zihan Wang", "Zhilin Yang", "Zhengying Liu", "Jia Li"], "title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning", "categories": ["cs.AI"], "comment": "22 pages", "summary": "We introduce Kimina-Prover Preview, a large language model that pioneers a\nnovel reasoning-driven exploration paradigm for formal theorem proving, as\nshowcased in this preview release. Trained with a large-scale reinforcement\nlearning pipeline from Qwen2.5-72B, Kimina-Prover demonstrates strong\nperformance in Lean 4 proof generation by employing a structured reasoning\npattern we term \\textit{formal reasoning pattern}. This approach allows the\nmodel to emulate human problem-solving strategies in Lean, iteratively\ngenerating and refining proof steps. Kimina-Prover sets a new state-of-the-art\non the miniF2F benchmark, reaching 80.7% with pass@8192. Beyond improved\nbenchmark performance, our work yields several key insights: (1) Kimina-Prover\nexhibits high sample efficiency, delivering strong results even with minimal\nsampling (pass@1) and scaling effectively with computational budget, stemming\nfrom its unique reasoning pattern and RL training; (2) we demonstrate clear\nperformance scaling with model size, a trend previously unobserved for neural\ntheorem provers in formal mathematics; (3) the learned reasoning style,\ndistinct from traditional search algorithms, shows potential to bridge the gap\nbetween formal verification and informal mathematical intuition. We open source\ndistilled versions with 1.5B and 7B parameters of Kimina-Prover", "AI": {"tldr": "Kimina-Prover \u662f\u4e00\u4e2a\u65b0\u578b\u63a8\u7406\u9a71\u52a8\u7684\u6b63\u5f0f\u5b9a\u7406\u8bc1\u660e\u6a21\u578b\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5728 Lean 4 \u8bc1\u660e\u751f\u6210\u4e2d\u8fbe\u5230 miniF2F \u57fa\u51c6 80.7% pass@8192 \u7684\u65b0\u7eaa\u5f55\uff0c\u5e76\u5f00\u6e90\u7cbe\u7b80\u7248\u672c\u3002", "motivation": "\u521b\u65b0\u63a8\u7406\u8303\u5f0f\uff0c\u6a21\u62df\u4eba\u7c7b\u95ee\u9898\u89e3\u51b3\u7b56\u7565\uff0c\u6865\u63a5\u6b63\u5f0f\u9a8c\u8bc1\u4e0e\u975e\u6b63\u5f0f\u6570\u5b66\u76f4\u89c9\u7684\u5dee\u8ddd\u3002", "method": "\u91c7\u7528\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u7ba1\u9053\u4ece Qwen2.5-72B \u8bad\u7ec3\uff0c\u4f7f\u7528 '\u6b63\u5f0f\u63a8\u7406\u6a21\u5f0f' \u8fed\u4ee3\u751f\u6210\u548c\u5b8c\u5584\u8bc1\u660e\u6b65\u9aa4\u3002", "result": "\u5728 miniF2F \u57fa\u51c6\u4e0a\u8fbe\u5230 80.7% pass@8192 \u7684\u65b0\u72b6\u6001-of-the-art\uff0c\u9ad8\u6837\u672c\u6548\u7387\u3001\u6a21\u578b\u5927\u5c0f\u6027\u80fd scaling\uff0c\u4ee5\u53ca\u72ec\u7279\u63a8\u7406\u98ce\u683c\u3002", "conclusion": "\u5c55\u793a\u4e86\u6837\u672c\u6548\u7387\u3001\u6027\u80fd scaling \u7684\u4f18\u52bf\uff0c\u5e76\u6709\u6f5c\u529b\u5f25\u5408\u6b63\u5f0f\u9a8c\u8bc1\u4e0e\u6570\u5b66\u76f4\u89c9\u7684\u5dee\u8ddd\uff1b\u5f00\u6e90 1.5B \u548c 7B \u53c2\u6570\u7248\u672c\u3002"}}
{"id": "2504.10752", "pdf": "https://arxiv.org/pdf/2504.10752", "abs": "https://arxiv.org/abs/2504.10752", "authors": ["Neil Mehta", "Ines Goncalves", "Alberto Montagna", "Mathis Fleury", "Gustavo Caetano", "Ines Esteves", "Athanasios Vourvopoulos", "Pulkit Grover", "Patricia Figueiredo"], "title": "Time-varying EEG spectral power predicts evoked and spontaneous fMRI motor brain activity", "categories": ["cs.LG", "q-bio.NC"], "comment": null, "summary": "Simultaneous EEG-fMRI recordings are increasingly used to investigate brain\nactivity by leveraging the complementary high spatial and high temporal\nresolution of fMRI and EEG signals respectively. It remains unclear, however,\nto what degree these two imaging modalities capture shared information about\nneural activity. Here, we investigate whether it is possible to predict both\ntask-evoked and spontaneous fMRI signals of motor brain networks from EEG\ntime-varying spectral power using interpretable models trained for individual\nsubjects with Sparse Group Lasso regularization. Critically, we test the\ntrained models on data acquired from each subject on a different day and obtain\nstatistical validation by comparison with appropriate null models as well as\nthe conventional EEG sensorimotor rhythm. We find significant prediction\nresults in most subjects, although less frequently for resting-state compared\nto task-based conditions. Furthermore, we interpret the model learned\nparameters to understand representations of EEG-fMRI coupling in terms of\npredictive EEG channels, frequencies, and haemodynamic delays. In conclusion,\nour work provides evidence of the ability to predict fMRI motor brain activity\nfrom EEG recordings alone across different days, in both task-evoked and\nspontaneous conditions, with statistical significance in individual subjects.\nThese results present great potential for translation to EEG neurofeedback\napplications.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u8bc1\u660eEEG\u53ef\u4ee5\u9884\u6d4bfMRI\u8fd0\u52a8\u8111\u7f51\u7edc\u4fe1\u53f7\uff0c\u5728\u4efb\u52a1\u548c\u81ea\u53d1\u6761\u4ef6\u4e0b\u8de8\u4e0d\u540c\u5929\u6709\u7edf\u8ba1\u5b66\u610f\u4e49\uff0c\u5e76\u6709\u795e\u7ecf\u53cd\u9988\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u63a2\u8ba8EEG\u548cfMRI\u662f\u5426\u6355\u6349\u5171\u4eab\u795e\u7ecf\u6d3b\u52a8\u4fe1\u606f\uff0c\u7279\u522b\u662f\u9884\u6d4bfMRI\u4fe1\u53f7\u7684\u7a0b\u5ea6\u3002", "method": "\u4f7f\u7528Sparse Group Lasso\u6b63\u5219\u5316\u7684\u53ef\u89e3\u91ca\u6a21\u578b\uff0c\u9488\u5bf9\u4e2a\u4f53\u53d7\u8bd5\u8005\u8bad\u7ec3\uff0c\u5e76\u5728\u4e0d\u540c\u5929\u6d4b\u8bd5\uff0c\u4e0e\u7a7a\u6a21\u578b\u548c\u4f20\u7edfEEG\u4f20\u611f\u5668\u8fd0\u52a8\u8282\u5f8b\u6bd4\u8f83\u3002", "result": "\u5728\u5927\u591a\u6570\u53d7\u8bd5\u8005\u4e2d\u83b7\u5f97\u663e\u8457\u9884\u6d4b\uff0c\u4efb\u52a1\u6761\u4ef6\u4e0b\u66f4\u9891\u7e41\uff0c\u89e3\u91ca\u4e86EEG\u901a\u9053\u3001\u9891\u7387\u548c\u8840\u6d41\u52a8\u529b\u5b66\u5ef6\u8fdf\u3002", "conclusion": "\u8bc1\u660eEEG\u53ef\u8de8\u4e0d\u540c\u5929\u9884\u6d4bfMRI\u6d3b\u52a8\uff0c\u5177\u6709\u4e2a\u4f53\u7edf\u8ba1\u5b66\u610f\u4e49\uff0c\u5e76\u4e3aEEG\u795e\u7ecf\u53cd\u9988\u5e94\u7528\u63d0\u4f9b\u6f5c\u529b\u3002"}}
{"id": "2504.10699", "pdf": "https://arxiv.org/pdf/2504.10699", "abs": "https://arxiv.org/abs/2504.10699", "authors": ["Nan Wang", "Ricardo G. Sanfelice"], "title": "HyRRT-Connect: Bidirectional Motion Planning for Hybrid Dynamical Systems", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "59 pages, 9 figures, submitted to IJRR. arXiv admin note: substantial\n  text overlap with arXiv:2403.18413; text overlap with arXiv:2406.01802", "summary": "This paper proposes a bidirectional rapidly-exploring random trees (RRT)\nalgorithm to solve the motion planning problem for hybrid systems. The proposed\nalgorithm, called HyRRT-Connect, propagates in both forward and backward\ndirections in hybrid time until an overlap between the forward and backward\npropagation results is detected. Then, HyRRT-Connect constructs a motion plan\nthrough the reversal and concatenation of functions defined on hybrid time\ndomains, ensuring that the motion plan satisfies the given hybrid dynamics. To\naddress the potential discontinuity along the flow caused by tolerating some\ndistance between the forward and backward partial motion plans, we reconstruct\nthe backward partial motion plan by a forward-in-hybrid-time simulation from\nthe final state of the forward partial motion plan. effectively eliminating the\ndiscontinuity. The proposed algorithm is applied to an actuated bouncing ball\nsystem and a walking robot example to highlight its computational improvement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHyRRT-Connect\u7b97\u6cd5\uff0c\u7528\u4e8e\u6df7\u5408\u7cfb\u7edf\u7684\u8fd0\u52a8\u89c4\u5212\uff0c\u901a\u8fc7\u53cc\u5411\u4f20\u64ad\u63d0\u9ad8\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u9a8c\u8bc1\u3002", "motivation": "\u89e3\u51b3\u6df7\u5408\u7cfb\u7edf\u8fd0\u52a8\u89c4\u5212\u95ee\u9898\uff0c\u7279\u522b\u662f\u5904\u7406\u6df7\u5408\u52a8\u529b\u5b66\u4e2d\u7684\u4e0d\u8fde\u7eed\u6027\u548c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u63d0\u51faHyRRT-Connect\u7b97\u6cd5\uff0c\u5728\u6df7\u5408\u65f6\u95f4\u5185\u53cc\u5411\u4f20\u64ad\u68c0\u6d4b\u91cd\u53e0\uff0c\u6784\u5efa\u8fd0\u52a8\u89c4\u5212\uff0c\u5e76\u901a\u8fc7\u524d\u5411\u6a21\u62df\u91cd\u5efa\u540e\u5411\u90e8\u5206\u6d88\u9664\u4e0d\u8fde\u7eed\u6027\u3002", "result": "\u5e94\u7528\u4e8e\u5e26\u9a71\u52a8\u7684\u5f39\u8df3\u7403\u7cfb\u7edf\u548c\u6b65\u884c\u673a\u5668\u4eba\u793a\u4f8b\uff0c\u5c55\u793a\u4e86\u8ba1\u7b97\u6548\u7387\u7684\u663e\u8457\u63d0\u5347\u3002", "conclusion": "HyRRT-Connect\u7b97\u6cd5\u6709\u6548\u5730\u89e3\u51b3\u4e86\u6df7\u5408\u7cfb\u7edf\u8fd0\u52a8\u89c4\u5212\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u9ad8\u4e86\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2504.11419", "pdf": "https://arxiv.org/pdf/2504.11419", "abs": "https://arxiv.org/abs/2504.11419", "authors": ["Li Jin", "Liu Jia"], "title": "Embodied World Models Emerge from Navigational Task in Open-Ended Environments", "categories": ["cs.AI", "cs.NE"], "comment": "Research on explainable meta-reinforcement learning AI", "summary": "Understanding how artificial systems can develop spatial awareness and\nreasoning has long been a challenge in AI research. Traditional models often\nrely on passive observation, but embodied cognition theory suggests that deeper\nunderstanding emerges from active interaction with the environment. This study\ninvestigates whether neural networks can autonomously internalize spatial\nconcepts through interaction, focusing on planar navigation tasks. Using Gated\nRecurrent Units (GRUs) combined with Meta-Reinforcement Learning (Meta-RL), we\nshow that agents can learn to encode spatial properties like direction,\ndistance, and obstacle avoidance. We introduce Hybrid Dynamical Systems (HDS)\nto model the agent-environment interaction as a closed dynamical system,\nrevealing stable limit cycles that correspond to optimal navigation strategies.\nRidge Representation allows us to map navigation paths into a fixed-dimensional\nbehavioral space, enabling comparison with neural states. Canonical Correlation\nAnalysis (CCA) confirms strong alignment between these representations,\nsuggesting that the agent's neural states actively encode spatial knowledge.\nIntervention experiments further show that specific neural dimensions are\ncausally linked to navigation performance. This work provides an approach to\nbridging the gap between action and perception in AI, offering new insights\ninto building adaptive, interpretable models that can generalize across complex\nenvironments. The causal validation of neural representations also opens new\navenues for understanding and controlling the internal mechanisms of AI\nsystems, pushing the boundaries of how machines learn and reason in dynamic,\nreal-world scenarios.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5143\u5f3a\u5316\u5b66\u4e60\u548c\u795e\u7ecf\u7f51\u7edc\uff0c\u5c55\u793a\u4e86AI\u4ee3\u7406\u5982\u4f55\u901a\u8fc7\u4e3b\u52a8\u4e92\u52a8\u5b66\u4e60\u7a7a\u95f4\u610f\u8bc6\uff0c\u5e76\u901a\u8fc7\u56e0\u679c\u9a8c\u8bc1\u786e\u8ba4\u795e\u7ecf\u8868\u793a\u7684\u6709\u6548\u6027\u3002", "motivation": "AI\u7814\u7a76\u4e2d\uff0c\u7a7a\u95f4\u610f\u8bc6\u548c\u63a8\u7406\u53d1\u5c55\u957f\u671f\u9762\u4e34\u6311\u6218\uff0c\u4f20\u7edf\u6a21\u578b\u4f9d\u8d56\u88ab\u52a8\u89c2\u5bdf\uff0c\u800c\u5177\u8eab\u8ba4\u77e5\u7406\u8bba\u5f3a\u8c03\u4e3b\u52a8\u4e92\u52a8\u7684\u91cd\u8981\u6027\u3002", "method": "\u4f7f\u7528\u95e8\u63a7\u5faa\u73af\u5355\u5143(GRU)\u7ed3\u5408\u5143\u5f3a\u5316\u5b66\u4e60(Meta-RL)\uff0c\u5f15\u5165\u6df7\u5408\u52a8\u529b\u7cfb\u7edf(HDS)\u5efa\u6a21\u4ea4\u4e92\uff0c\u810a\u8868\u793a\u6620\u5c04\u8def\u5f84\uff0c\u89c4\u8303\u76f8\u5173\u5206\u6790(CCA)\u786e\u8ba4\u5bf9\u9f50\uff0c\u5e76\u8fdb\u884c\u5e72\u9884\u5b9e\u9a8c\u3002", "result": "\u4ee3\u7406\u5b66\u4f1a\u7f16\u7801\u65b9\u5411\u3001\u8ddd\u79bb\u548c\u969c\u788d\u907f\u514d\uff0c\u663e\u793a\u7a33\u5b9a\u6781\u9650\u73af\uff0cCCA\u786e\u8ba4\u795e\u7ecf\u72b6\u6001\u4e0e\u884c\u4e3a\u7a7a\u95f4\u5f3a\u5bf9\u9f50\uff0c\u5e72\u9884\u5b9e\u9a8c\u8bc1\u5b9e\u7279\u5b9a\u795e\u7ecf\u7ef4\u5ea6\u4e0e\u5bfc\u822a\u6027\u80fd\u7684\u56e0\u679c\u8054\u7cfb\u3002", "conclusion": "\u6865\u63a5\u884c\u52a8\u4e0e\u611f\u77e5\u7684\u9e3f\u6c9f\uff0c\u63d0\u4f9b\u6784\u5efa\u9002\u5e94\u6027\u3001\u53ef\u89e3\u91caAI\u6a21\u578b\u7684\u6d1e\u89c1\uff0c\u5e76\u4e3a\u7406\u89e3\u548c\u63a7\u5236AI\u5185\u90e8\u673a\u5236\u5f00\u8f9f\u65b0\u9014\u5f84\u3002"}}
{"id": "2504.10754", "pdf": "https://arxiv.org/pdf/2504.10754", "abs": "https://arxiv.org/abs/2504.10754", "authors": ["Arjun Subramonian", "Elvis Dohmatob"], "title": "auto-fpt: Automating Free Probability Theory Calculations for Machine Learning Theory", "categories": ["cs.LG", "cs.MS"], "comment": "Work in progress", "summary": "A large part of modern machine learning theory often involves computing the\nhigh-dimensional expected trace of a rational expression of large rectangular\nrandom matrices. To symbolically compute such quantities using free probability\ntheory, we introduce auto-fpt, a lightweight Python and SymPy-based tool that\ncan automatically produce a reduced system of fixed-point equations which can\nbe solved for the quantities of interest, and effectively constitutes a theory.\nWe overview the algorithmic ideas underlying auto-fpt and its applications to\nvarious interesting problems, such as the high-dimensional error of linearized\nfeed-forward neural networks, recovering well-known results. We hope that\nauto-fpt streamlines the majority of calculations involved in high-dimensional\nanalysis, while helping the machine learning community reproduce known and\nuncover new phenomena.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f15\u5165auto-fpt\u5de5\u5177\uff0c\u4f7f\u7528\u81ea\u7531\u6982\u7387\u7406\u8bba\u81ea\u52a8\u8ba1\u7b97\u9ad8\u7ef4\u968f\u673a\u77e9\u9635\u671f\u671b\u8ff9\uff0c\u7b80\u5316\u673a\u5668\u5b66\u4e60\u8ba1\u7b97\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u7406\u8bba\u4e2d\u9ad8\u7ef4\u8ba1\u7b97\u590d\u6742\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u7b80\u5316\u7b26\u53f7\u8ba1\u7b97\u3002", "method": "\u5f00\u53d1\u57fa\u4e8ePython\u548cSymPy\u7684auto-fpt\u5de5\u5177\uff0c\u81ea\u52a8\u751f\u6210\u5e76\u6c42\u89e3\u56fa\u5b9a\u70b9\u65b9\u7a0b\u7cfb\u7edf\u3002", "result": "\u5e94\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u9ad8\u7ef4\u8bef\u5dee\u5206\u6790\uff0c\u590d\u73b0\u5df2\u77e5\u7ed3\u679c\u3002", "conclusion": "\u5e0c\u671bauto-fpt\u7b80\u5316\u9ad8\u7ef4\u5206\u6790\uff0c\u5e2e\u52a9\u673a\u5668\u5b66\u4e60\u793e\u533a\u590d\u73b0\u548c\u53d1\u73b0\u65b0\u73b0\u8c61\u3002"}}
{"id": "2504.10767", "pdf": "https://arxiv.org/pdf/2504.10767", "abs": "https://arxiv.org/abs/2504.10767", "authors": ["Faiyaz Elahi Mullick", "Supriyo Bandyopadhyay", "Rob Baxter", "Tony J. Ragucci", "Avik W. Ghosh"], "title": "Adaptive Synaptogenesis Implemented on a Nanomagnetic Platform", "categories": ["cond-mat.dis-nn", "cs.NE", "cs.SY", "eess.SY"], "comment": null, "summary": "The human brain functions very differently from artificial neural networks\n(ANN) and possesses unique features that are absent in ANN. An important one\namong them is \"adaptive synaptogenesis\" that modifies synaptic weights when\nneeded to avoid catastrophic forgetting and promote lifelong learning. The key\naspect of this algorithm is supervised Hebbian learning, where weight\nmodifications in the neocortex driven by temporal coincidence are further\naccepted or vetoed by an added control mechanism from the hippocampus during\nthe training cycle, to make distant synaptic connections highly sparse and\nstrategic. In this work, we discuss various algorithmic aspects of adaptive\nsynaptogenesis tailored to edge computing, demonstrate its function using\nsimulations, and design nanomagnetic hardware accelerators for specific\nfunctions of synaptogenesis.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4eba\u7c7b\u5927\u8111\u7684adaptive synaptogenesis\u7b97\u6cd5\uff0c\u7528\u4e8eAI\u907f\u514d\u9057\u5fd8\u548c\u4fc3\u8fdb\u7ec8\u8eab\u5b66\u4e60\uff0c\u901a\u8fc7\u6a21\u62df\u548c\u786c\u4ef6\u5b9e\u73b0\u3002", "motivation": "\u4eba\u7c7b\u5927\u8111\u4e0e\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4e0d\u540c\uff0c\u5177\u6709adaptive synaptogenesis\uff0c\u80fd\u52a8\u6001\u8c03\u6574\u7a81\u89e6\u4ee5\u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\u548c\u652f\u6301\u7ec8\u8eab\u5b66\u4e60\u3002", "method": "\u91c7\u7528supervised Hebbian\u5b66\u4e60\u548c\u6d77\u9a6c\u4f53\u63a7\u5236\u673a\u5236\uff0c\u901a\u8fc7\u6a21\u62df\u6f14\u793a\u548c\u8bbe\u8ba1\u7eb3\u7c73\u78c1\u786c\u4ef6\u52a0\u901f\u5668\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u529f\u80fd\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9488\u5bf9\u8fb9\u7f18\u8ba1\u7b97\u7684\u786c\u4ef6\u52a0\u901f\u5668\u3002", "conclusion": "adaptive synaptogenesis\u7b97\u6cd5\u53ef\u63d0\u5347AI\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u573a\u666f\u3002"}}
{"id": "1906.05682", "pdf": "https://arxiv.org/pdf/1906.05682", "abs": "https://arxiv.org/abs/1906.05682", "authors": ["Suraj Tripathi", "Abhay Kumar", "Abhiram Ramesh", "Chirag Singh", "Promod Yenigalla"], "title": "Focal Loss based Residual Convolutional Neural Network for Speech Emotion Recognition", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD", "stat.ML"], "comment": "Accepted in CICLing 2019", "summary": "This paper proposes a Residual Convolutional Neural Network (ResNet) based on\nspeech features and trained under Focal Loss to recognize emotion in speech.\nSpeech features such as Spectrogram and Mel-frequency Cepstral Coefficients\n(MFCCs) have shown the ability to characterize emotion better than just plain\ntext. Further Focal Loss, first used in One-Stage Object Detectors, has shown\nthe ability to focus the training process more towards hard-examples and\ndown-weight the loss assigned to well-classified examples, thus preventing the\nmodel from being overwhelmed by easily classifiable examples.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4f7f\u7528ResNet\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\u8bed\u97f3\u7279\u5f81\u548cFocal Loss\u6765\u8bc6\u522b\u8bed\u97f3\u60c5\u611f\u3002", "motivation": "\u8bed\u97f3\u7279\u5f81\u5982Spectrogram\u548cMFCCs\u6bd4\u7eaf\u6587\u672c\u66f4\u80fd\u8868\u5f81\u60c5\u611f\uff0cFocal Loss\u5e2e\u52a9\u8bad\u7ec3\u5173\u6ce8\u96be\u4f8b\u3002", "method": "\u57fa\u4e8eResNet\u6784\u5efa\u6a21\u578b\uff0c\u4f7f\u7528\u8bed\u97f3\u7279\u5f81\u548cFocal Loss\u8bad\u7ec3\u3002", "result": "\u6539\u8fdb\u4e86\u60c5\u611f\u8bc6\u522b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5bf9\u96be\u4f8b\u7684\u5904\u7406\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u63d0\u5347\u4e86\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2504.10766", "pdf": "https://arxiv.org/pdf/2504.10766", "abs": "https://arxiv.org/abs/2504.10766", "authors": ["Ming Li", "Yanhong Li", "Ziyue Li", "Tianyi Zhou"], "title": "How Instruction and Reasoning Data shape Post-Training: Data Quality through the Lens of Layer-wise Gradients", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "As the post-training of large language models (LLMs) advances from\ninstruction-following to complex reasoning tasks, understanding how different\ndata affect finetuning dynamics remains largely unexplored. In this paper, we\npresent a spectral analysis of layer-wise gradients induced by low/high-quality\ninstruction and reasoning data for LLM post-training. Our analysis reveals that\nwidely-studied metrics for data evaluation, e.g., IFD, InsTag, Difficulty, and\nReward, can be explained and unified by spectral properties computed from\ngradients' singular value decomposition (SVD). Specifically, higher-quality\ndata are usually associated with lower nuclear norms and higher effective\nranks. Notably, effective rank exhibits better robustness and resolution than\nnuclear norm in capturing subtle quality differences. For example, reasoning\ndata achieves substantially higher effective ranks than instruction data,\nimplying richer gradient structures on more complex tasks. Our experiments also\nhighlight that models within the same family share similar gradient patterns\nregardless of their sizes, whereas different model families diverge\nsignificantly. Providing a unified view on the effects of data quality across\ninstruction and reasoning data, this work illuminates the interplay between\ndata quality and training stability, shedding novel insights into developing\nbetter data exploration strategies for post-training.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u68af\u5ea6\u8c31\u5206\u6790\u7edf\u4e00\u6570\u636e\u8d28\u91cf\u6307\u6807\uff0c\u4e3aLLM\u540e\u8bad\u7ec3\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002", "motivation": "\u63a2\u7d22\u4e0d\u540c\u6570\u636e\u8d28\u91cf\u5bf9LLM\u5fae\u8c03\u52a8\u6001\u7684\u5f71\u54cd\uff0c\u56e0\u4e3a\u6b64\u9886\u57df\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u5c42\u7ea7\u68af\u5ea6\u7684\u5947\u5f02\u503c\u5206\u89e3(SVD)\u8fdb\u884c\u8c31\u5206\u6790\uff0c\u8bc4\u4f30\u6307\u4ee4\u548c\u63a8\u7406\u6570\u636e\u7684\u8d28\u91cf\u3002", "result": "\u9ad8\u8d28\u91cf\u6570\u636e\u5177\u6709\u8f83\u4f4e\u6838\u8303\u6570\u548c\u8f83\u9ad8\u6709\u6548\u79e9\uff1b\u6709\u6548\u79e9\u66f4\u80fd\u6355\u6349\u5fae\u5999\u5dee\u5f02\uff1b\u540c\u4e00\u6a21\u578b\u5bb6\u65cf\u68af\u5ea6\u6a21\u5f0f\u76f8\u4f3c\uff0c\u4e0d\u540c\u5bb6\u65cf\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u63d0\u4f9b\u6570\u636e\u8d28\u91cf\u5f71\u54cd\u7684\u7edf\u4e00\u89c6\u89d2\uff0c\u5e2e\u52a9\u5f00\u53d1\u66f4\u597d\u7684\u6570\u636e\u63a2\u7d22\u7b56\u7565\u3002"}}
{"id": "2504.10962", "pdf": "https://arxiv.org/pdf/2504.10962", "abs": "https://arxiv.org/abs/2504.10962", "authors": ["Edvin Martin Andrejev", "Amith Manoharan", "Karl-Eerik Unt", "Arun Kumar Singh"], "title": "$\u03c0$-MPPI: A Projection-based Model Predictive Path Integral Scheme for Smooth Optimal Control of Fixed-Wing Aerial Vehicles", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "8 pages, 4 figures, submitted to IEEE RA-L", "summary": "Model Predictive Path Integral (MPPI) is a popular sampling-based Model\nPredictive Control (MPC) algorithm for nonlinear systems. It optimizes\ntrajectories by sampling control sequences and averaging them. However, a key\nissue with MPPI is the non-smoothness of the optimal control sequence, leading\nto oscillations in systems like fixed-wing aerial vehicles (FWVs). Existing\nsolutions use post-hoc smoothing, which fails to bound control derivatives.\nThis paper introduces a new approach: we add a projection filter $\\pi$ to\nminimally correct control samples, ensuring bounds on control magnitude and\nhigher-order derivatives. The filtered samples are then averaged using MPPI,\nleading to our $\\pi$-MPPI approach. We minimize computational overhead by using\na neural accelerated custom optimizer for the projection filter. $\\pi$-MPPI\noffers a simple way to achieve arbitrary smoothness in control sequences. While\nwe focus on FWVs, this projection filter can be integrated into any MPPI\npipeline. Applied to FWVs, $\\pi$-MPPI is easier to tune than the baseline,\nresulting in smoother, more robust performance.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u03c0-MPPI\u65b9\u6cd5\uff0c\u901a\u8fc7\u6dfb\u52a0\u6295\u5f71\u8fc7\u6ee4\u5668\u6539\u5584MPPI\u7b97\u6cd5\u7684\u63a7\u5236\u5e73\u6ed1\u6027\uff0c\u9002\u7528\u4e8e\u56fa\u5b9a\u7ffc\u98de\u884c\u5668\u3002", "motivation": "\u89e3\u51b3MPPI\u7b97\u6cd5\u4e2d\u63a7\u5236\u5e8f\u5217\u4e0d\u5e73\u6ed1\u5bfc\u81f4\u7cfb\u7edf\u632f\u8361\u7684\u95ee\u9898\uff0c\u73b0\u6709\u540e\u5904\u7406\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u7ea6\u675f\u63a7\u5236\u5bfc\u6570\u3002", "method": "\u5f15\u5165\u6295\u5f71\u8fc7\u6ee4\u5668\u03c0\u5bf9\u63a7\u5236\u6837\u672c\u8fdb\u884c\u6700\u5c0f\u4fee\u6b63\uff0c\u786e\u4fdd\u63a7\u5236\u5e45\u5ea6\u548c\u5bfc\u6570\u8fb9\u754c\uff0c\u5e76\u4f7f\u7528\u795e\u7ecf\u52a0\u901f\u4f18\u5316\u5668\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u03c0-MPPI\u5728\u56fa\u5b9a\u7ffc\u98de\u884c\u5668\u4e0a\u8c03\u4f18\u66f4\u5bb9\u6613\uff0c\u83b7\u5f97\u66f4\u5e73\u6ed1\u548c\u9c81\u68d2\u7684\u6027\u80fd\u3002", "conclusion": "\u03c0-MPPI\u63d0\u4f9b\u7b80\u5355\u5b9e\u73b0\u4efb\u610f\u5e73\u6ed1\u5ea6\u63a7\u5236\u5e8f\u5217\u7684\u65b9\u6cd5\uff0c\u53ef\u6574\u5408\u5230\u4efb\u4f55MPPI\u7ba1\u9053\u4e2d\u3002"}}
{"id": "1908.08652", "pdf": "https://arxiv.org/pdf/1908.08652", "abs": "https://arxiv.org/abs/1908.08652", "authors": ["Abhay Kumar", "Nishant Jain", "Suraj Tripathi", "Chirag Singh", "Kamal Krishna"], "title": "MTCNET: Multi-task Learning Paradigm for Crowd Count Estimation", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "5 pages, 3 figures, Accepted in IEEE AVSS 2019", "summary": "We propose a Multi-Task Learning (MTL) paradigm based deep neural network\narchitecture, called MTCNet (Multi-Task Crowd Network) for crowd density and\ncount estimation. Crowd count estimation is challenging due to the non-uniform\nscale variations and the arbitrary perspective of an individual image. The\nproposed model has two related tasks, with Crowd Density Estimation as the main\ntask and Crowd-Count Group Classification as the auxiliary task. The auxiliary\ntask helps in capturing the relevant scale-related information to improve the\nperformance of the main task. The main task model comprises two blocks: VGG-16\nfront-end for feature extraction and a dilated Convolutional Neural Network for\ndensity map generation. The auxiliary task model shares the same front-end as\nthe main task, followed by a CNN classifier. Our proposed network achieves 5.8%\nand 14.9% lower Mean Absolute Error (MAE) than the state-of-the-art methods on\nShanghaiTech dataset without using any data augmentation. Our model also\noutperforms with 10.5% lower MAE on UCF_CC_50 dataset.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u4efb\u52a1\u5b66\u4e60\u7f51\u7edcMTCNet\uff0c\u7528\u4e8e\u4eba\u7fa4\u5bc6\u5ea6\u548c\u8ba1\u6570\u4f30\u8ba1\uff0c\u901a\u8fc7\u8f85\u52a9\u4efb\u52a1\u63d0\u5347\u4e86\u4e3b\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u4eba\u7fa4\u8ba1\u6570\u4f30\u8ba1\u9762\u4e34\u975e\u5747\u5300\u5c3a\u5ea6\u53d8\u5316\u548c\u4efb\u610f\u89c6\u89d2\u7684\u6311\u6218\uff0c\u56e0\u6b64\u4f7f\u7528\u591a\u4efb\u52a1\u5b66\u4e60\u6765\u6355\u6349\u76f8\u5173\u5c3a\u5ea6\u4fe1\u606f\u3002", "method": "\u6a21\u578b\u5305\u62ec\u4e3b\u4efb\u52a1\uff08\u4f7f\u7528VGG-16\u63d0\u53d6\u7279\u5f81\u548c\u6269\u5f20CNN\u751f\u6210\u5bc6\u5ea6\u56fe\uff09\u548c\u8f85\u52a9\u4efb\u52a1\uff08\u5171\u4eab\u524d\u7aef\u7684CNN\u5206\u7c7b\u5668\uff09\u3002", "result": "\u5728ShanghaiTech\u6570\u636e\u96c6\u4e0a\uff0cMAE\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u4f4e5.8%\u548c14.9%\uff08\u65e0\u6570\u636e\u589e\u5f3a\uff09\uff0c\u5728UCF_CC_50\u6570\u636e\u96c6\u4e0a\u4f4e10.5%\u3002", "conclusion": "\u8bc1\u660e\u4e86\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\u5728\u4eba\u7fa4\u8ba1\u6570\u4e2d\u7684\u6709\u6548\u6027\uff0c\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2504.10770", "pdf": "https://arxiv.org/pdf/2504.10770", "abs": "https://arxiv.org/abs/2504.10770", "authors": ["Donglin Zhan", "Haoting Zhang", "Rhonda Righter", "Zeyu Zheng", "James Anderson"], "title": "Collaborative Bayesian Optimization via Wasserstein Barycenters", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Motivated by the growing need for black-box optimization and data privacy, we\nintroduce a collaborative Bayesian optimization (BO) framework that addresses\nboth of these challenges. In this framework agents work collaboratively to\noptimize a function they only have oracle access to. In order to mitigate\nagainst communication and privacy constraints, agents are not allowed to share\ntheir data but can share their Gaussian process (GP) surrogate models. To\nenable collaboration under these constraints, we construct a central model to\napproximate the objective function by leveraging the concept of Wasserstein\nbarycenters of GPs. This central model integrates the shared models without\naccessing the underlying data. A key aspect of our approach is a collaborative\nacquisition function that balances exploration and exploitation, allowing for\nthe optimization of decision variables collaboratively in each iteration. We\nprove that our proposed algorithm is asymptotically consistent and that its\nimplementation via Monte Carlo methods is numerically accurate. Through\nnumerical experiments, we demonstrate that our approach outperforms other\nbaseline collaborative frameworks and is competitive with centralized\napproaches that do not consider data privacy.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u534f\u4f5c\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u9ed1\u7bb1\u4f18\u5316\u548c\u6570\u636e\u9690\u79c1\u95ee\u9898\uff0c\u4ee3\u7406\u5171\u4eabGP\u6a21\u578b\u4f7f\u7528Wasserstein\u91cd\u5fc3\uff0c\u8bc1\u660e\u6709\u6548\u6027\u3002", "motivation": "\u7531\u4e8e\u9ed1\u7bb1\u4f18\u5316\u548c\u6570\u636e\u9690\u79c1\u9700\u6c42\u589e\u957f\u3002", "method": "\u5f15\u5165\u534f\u4f5cBO\u6846\u67b6\uff0c\u4ee3\u7406\u5171\u4eabGP\u6a21\u578b\u4e0d\u5171\u4eab\u6570\u636e\uff0c\u6784\u5efaWasserstein\u91cd\u5fc3\u4e2d\u5fc3\u6a21\u578b\u548c\u534f\u4f5c\u83b7\u53d6\u51fd\u6570\u3002", "result": "\u8bc1\u660e\u7b97\u6cd5\u6e10\u8fdb\u4e00\u81f4\u548c\u6570\u503c\u51c6\u786e\uff0c\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u6846\u67b6\uff0c\u4e0e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u7ade\u4e89\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u9690\u79c1\u7ea6\u675f\u4e0b\u5b9e\u73b0\u9ad8\u6548\u534f\u4f5c\u4f18\u5316\u3002"}}
{"id": "2504.11045", "pdf": "https://arxiv.org/pdf/2504.11045", "abs": "https://arxiv.org/abs/2504.11045", "authors": ["Shreenabh Agrawal", "Manan Tayal", "Aditya Singh", "Shishir Kolathaya"], "title": "Neural Control Barrier Functions from Physics Informed Neural Networks", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "8 pages, 5 figures", "summary": "As autonomous systems become increasingly prevalent in daily life, ensuring\ntheir safety is paramount. Control Barrier Functions (CBFs) have emerged as an\neffective tool for guaranteeing safety; however, manually designing them for\nspecific applications remains a significant challenge. With the advent of deep\nlearning techniques, recent research has explored synthesizing CBFs using\nneural networks-commonly referred to as neural CBFs. This paper introduces a\nnovel class of neural CBFs that leverages a physics-inspired neural network\nframework by incorporating Zubov's Partial Differential Equation (PDE) within\nthe context of safety. This approach provides a scalable methodology for\nsynthesizing neural CBFs applicable to high-dimensional systems. Furthermore,\nby utilizing reciprocal CBFs instead of zeroing CBFs, the proposed framework\nallows for the specification of flexible, user-defined safe regions. To\nvalidate the effectiveness of the approach, we present case studies on three\ndifferent systems: an inverted pendulum, autonomous ground navigation, and\naerial navigation in obstacle-laden environments.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eZubov PDE\u7684\u795e\u7ecf\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u65b9\u6cd5\uff0c\u63d0\u9ad8\u81ea\u4e3b\u7cfb\u7edf\u5b89\u5168\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b\u7cfb\u7edf\u666e\u53ca\uff0c\u786e\u4fdd\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edfCBFs\u8bbe\u8ba1\u56f0\u96be\uff0c\u6df1\u5ea6\u5b66\u4e60\u88ab\u7528\u4e8e\u5408\u6210\u795e\u7ecfCBFs\u3002", "method": "\u5f15\u5165\u7269\u7406\u542f\u53d1\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u7ed3\u5408Zubov PDE\u548c\u4e92\u60e0CBFs\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u7cfb\u7edf\uff0c\u901a\u8fc7\u5012\u7acb\u6446\u3001\u5730\u9762\u548c\u7a7a\u4e2d\u5bfc\u822a\u6848\u4f8b\u9a8c\u8bc1\u3002", "result": "\u65b9\u6cd5\u53ef\u6269\u5c55\uff0c\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u4e86\u5176\u5728\u4e0d\u540c\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u795e\u7ecfCBFs\u5408\u6210\u65b9\u6cd5\uff0c\u63d0\u5347\u81ea\u4e3b\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u80fd\u3002"}}
{"id": "2504.09861", "pdf": "https://arxiv.org/pdf/2504.09861", "abs": "https://arxiv.org/abs/2504.09861", "authors": ["Luyao Zhang"], "title": "EthosGPT: Mapping Human Value Diversity to Advance Sustainable Development Goals (SDGs)", "categories": ["cs.CY", "cs.AI", "cs.HC", "econ.GN", "q-fin.EC", "stat.AP"], "comment": null, "summary": "Large language models (LLMs) are transforming global decision-making and\nsocietal systems by processing diverse data at unprecedented scales. However,\ntheir potential to homogenize human values poses critical risks, similar to\nbiodiversity loss undermining ecological resilience. Rooted in the ancient\nGreek concept of ethos, meaning both individual character and the shared moral\nfabric of communities, EthosGPT draws on a tradition that spans from\nAristotle's virtue ethics to Adam Smith's moral sentiments as the ethical\nfoundation of economic cooperation. These traditions underscore the vital role\nof value diversity in fostering social trust, institutional legitimacy, and\nlong-term prosperity. EthosGPT addresses the challenge of value homogenization\nby introducing an open-source framework for mapping and evaluating LLMs within\na global scale of human values. Using international survey data on cultural\nindices, prompt-based assessments, and comparative statistical analyses,\nEthosGPT reveals both the adaptability and biases of LLMs across regions and\ncultures. It offers actionable insights for developing inclusive LLMs, such as\ndiversifying training data and preserving endangered cultural heritage to\nensure representation in AI systems. These contributions align with the United\nNations Sustainable Development Goals (SDGs), especially SDG 10 (Reduced\nInequalities), SDG 11.4 (Cultural Heritage Preservation), and SDG 16 (Peace,\nJustice and Strong Institutions). Through interdisciplinary collaboration,\nEthosGPT promotes AI systems that are both technically robust and ethically\ninclusive, advancing value plurality as a cornerstone for sustainable and\nequitable futures.", "AI": {"tldr": "EthosGPT\u662f\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u901a\u8fc7\u6620\u5c04\u548c\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5168\u7403\u4eba\u7c7b\u4ef7\u503c\u89c2\u4e2d\u7684\u8868\u73b0\uff0c\u5e94\u5bf9LLM\u5bfc\u81f4\u4ef7\u503c\u540c\u8d28\u5316\u7684\u98ce\u9669\uff0c\u4fc3\u8fdb\u4ef7\u503c\u591a\u6837\u6027\u3002", "motivation": "\u8bba\u6587\u52a8\u673a\u662f\u89e3\u51b3LLM\u53ef\u80fd\u4f7f\u4eba\u7c7b\u4ef7\u503c\u89c2\u540c\u8d28\u5316\u7684\u98ce\u9669\uff0c\u7c7b\u4f3c\u4e8e\u751f\u7269\u591a\u6837\u6027\u4e27\u5931\u5bf9\u751f\u6001\u97e7\u6027\u7684\u5a01\u80c1\uff0c\u5f3a\u8c03\u4ef7\u503c\u591a\u6837\u6027\u5bf9\u793e\u4f1a\u4fe1\u4efb\u3001\u673a\u6784\u5408\u6cd5\u6027\u548c\u957f\u671f\u7e41\u8363\u7684\u91cd\u8981\u6027\uff0c\u5e76\u501f\u9274\u53e4\u5e0c\u814a\u4ee5\u592a\u6982\u5ff5\u548c\u8054\u5408\u56fd\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u3002", "method": "\u4f7f\u7528\u56fd\u9645\u8c03\u67e5\u6570\u636e\u3001\u57fa\u4e8e\u63d0\u793a\u7684\u8bc4\u4f30\u548c\u6bd4\u8f83\u7edf\u8ba1\u5206\u6790\u6765\u6620\u5c04\u548c\u8bc4\u4f30LLM\u5728\u4e0d\u540c\u5730\u533a\u548c\u6587\u5316\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u63ed\u793aLLM\u7684\u9002\u5e94\u6027\u548c\u504f\u5dee\uff0c\u63d0\u4f9b\u884c\u52a8\u6d1e\u89c1\uff0c\u5982\u591a\u6837\u5316\u8bad\u7ec3\u6570\u636e\u548c\u4fdd\u62a4\u6fd2\u5371\u6587\u5316\u9057\u4ea7\uff0c\u4ee5\u786e\u4fddAI\u7cfb\u7edf\u7684\u4ee3\u8868\u6027\u3002", "conclusion": "\u901a\u8fc7\u8de8\u5b66\u79d1\u5408\u4f5c\uff0c\u4fc3\u8fdb\u6280\u672f\u7a33\u5065\u548c\u4f26\u7406\u5305\u5bb9\u7684AI\u7cfb\u7edf\uff0c\u63a8\u8fdb\u4ef7\u503c\u591a\u5143\u6027\uff0c\u4ee5\u5b9e\u73b0\u53ef\u6301\u7eed\u548c\u516c\u5e73\u7684\u672a\u6765\uff0c\u5e76\u4e0e\u8054\u5408\u56fd\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\uff08\u5982\u51cf\u5c11\u4e0d\u5e73\u7b49\u3001\u6587\u5316\u9057\u4ea7\u4fdd\u62a4\u4e0e\u548c\u5e73\u6b63\u4e49\uff09\u4fdd\u6301\u4e00\u81f4\u3002"}}
{"id": "2504.10777", "pdf": "https://arxiv.org/pdf/2504.10777", "abs": "https://arxiv.org/abs/2504.10777", "authors": ["Manu Bhat", "Jonghyun Park", "Jianke Yang", "Nima Dehmamy", "Robin Walters", "Rose Yu"], "title": "AtlasD: Automatic Local Symmetry Discovery", "categories": ["cs.LG"], "comment": null, "summary": "Existing symmetry discovery methods predominantly focus on global\ntransformations across the entire system or space, but they fail to consider\nthe symmetries in local neighborhoods. This may result in the reported symmetry\ngroup being a misrepresentation of the true symmetry. In this paper, we\nformalize the notion of local symmetry as atlas equivariance. Our proposed\npipeline, automatic local symmetry discovery (AtlasD), recovers the local\nsymmetries of a function by training local predictor networks and then learning\na Lie group basis to which the predictors are equivariant. We demonstrate\nAtlasD is capable of discovering local symmetry groups with multiple connected\ncomponents in top-quark tagging and partial differential equation experiments.\nThe discovered local symmetry is shown to be a useful inductive bias that\nimproves the performance of downstream tasks in climate segmentation and vision\ntasks.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faAtlasD\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d1\u73b0\u5c40\u90e8\u5bf9\u79f0\u6027\u6765\u6539\u8fdb\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u5c40\u90e8\u90bb\u57df\u5bf9\u79f0\u6027\uff0c\u5bfc\u81f4\u5bf9\u79f0\u7fa4 misrepresentation\u3002", "method": "\u5f62\u5f0f\u5316\u5c40\u90e8\u5bf9\u79f0\u6027\u4e3a\u56fe\u96c6\u7b49\u53d8\u6027\uff0c\u8bad\u7ec3\u5c40\u90e8\u9884\u6d4b\u7f51\u7edc\u5e76\u5b66\u4e60Lie\u7fa4\u57fa\u3002", "result": "\u5728top-quark tagging\u548cPDE\u5b9e\u9a8c\u4e2d\u53d1\u73b0\u591a\u8fde\u901a\u5206\u91cf\u5c40\u90e8\u5bf9\u79f0\u7fa4\uff0c\u63d0\u5347\u6c14\u5019\u5206\u5272\u548c\u89c6\u89c9\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u5c40\u90e8\u5bf9\u79f0\u6027\u4f5c\u4e3a\u5f52\u7eb3\u504f\u5dee\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u4e0b\u6e38\u4efb\u52a1\u6548\u679c\u3002"}}
{"id": "2504.11064", "pdf": "https://arxiv.org/pdf/2504.11064", "abs": "https://arxiv.org/abs/2504.11064", "authors": ["Bo Ma", "Yi Ji", "Liyong Fang"], "title": "A Multi-UAV Formation Obstacle Avoidance Method Combined Improved Simulated Annealing and Adaptive Artificial Potential Field", "categories": ["cs.MA", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "The traditional Artificial Potential Field (APF) method exhibits limitations\nin its force distribution: excessive attraction when UAVs are far from the\ntarget may cause collisions with obstacles, while insufficient attraction near\nthe goal often results in failure to reach the target. Furthermore, APF is\nhighly susceptible to local minima, compromising motion reliability in complex\nenvironments. To address these challenges, this paper presents a novel hybrid\nobstacle avoidance algorithm-Deflected Simulated Annealing-Adaptive Artificial\nPotential Field (DSA-AAPF)-which combines an improved simulated annealing\nmechanism with an enhanced APF model. The proposed approach integrates a\nLeader-Follower distributed formation strategy with the APF framework, where\nthe resultant force formulation is redefined to smooth UAV trajectories. An\nadaptive gravitational gain function is introduced to dynamically adjust UAV\nvelocity based on environmental context, and a fast-converging controller\nensures accurate and efficient convergence to the target. Moreover, a\ndirectional deflection mechanism is embedded within the simulated annealing\nprocess, enabling UAVs to escape local minima caused by semi-enclosed obstacles\nthrough continuous rotational motion. The simulation results, covering\nformation reconfiguration, complex obstacle avoidance, and entrapment escape,\ndemonstrate the feasibility, robustness, and superiority of the proposed\nDSA-AAPF algorithm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDSA-AAPF\u7b97\u6cd5\uff0c\u6539\u8fdb\u4f20\u7edfAPF\u65b9\u6cd5\uff0c\u89e3\u51b3UAV\u969c\u788d\u907f\u514d\u4e2d\u7684\u5438\u5f15\u529b\u548c\u5c40\u90e8\u6781\u5c0f\u503c\u95ee\u9898\uff0c\u6a21\u62df\u7ed3\u679c\u663e\u793a\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edfAPF\u65b9\u6cd5\u5b58\u5728\u5438\u5f15\u529b\u5206\u5e03\u4e0d\u5f53\u548c\u6613\u9677\u5c40\u90e8\u6781\u5c0f\u503c\u7684\u5c40\u9650\u6027\uff0c\u5bfc\u81f4UAV\u5728\u590d\u6742\u73af\u5883\u4e2d\u53ef\u80fd\u78b0\u649e\u969c\u788d\u6216\u65e0\u6cd5\u8fbe\u6807\u3002", "method": "\u63d0\u51faDSA-AAPF\u7b97\u6cd5\uff0c\u7ed3\u5408\u6539\u8fdb\u6a21\u62df\u9000\u706b\u548c\u589e\u5f3aAPF\uff0c\u878d\u5165\u9886\u5bfc\u8005-\u8ddf\u968f\u8005\u7b56\u7565\u3001\u81ea\u9002\u5e94\u91cd\u529b\u589e\u76ca\u548c\u65b9\u5411\u504f\u8f6c\u673a\u5236\uff0c\u4ee5\u5e73\u6ed1\u8f68\u8ff9\u548c\u9003\u79bb\u5c40\u90e8\u6781\u5c0f\u503c\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8bc1\u660eDSA-AAPF\u5728\u7f16\u961f\u91cd\u6784\u3001\u590d\u6742\u969c\u788d\u907f\u514d\u548c\u9003\u79bb\u9677\u9631\u4e2d\u7684\u53ef\u884c\u6027\u3001\u7a33\u5065\u6027\u548c\u4f18\u8d8a\u6027\u3002", "conclusion": "DSA-AAPF\u7b97\u6cd5\u6709\u6548\u63d0\u5347UAV\u969c\u788d\u907f\u514d\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u7f3a\u9677\u3002"}}
{"id": "2504.10489", "pdf": "https://arxiv.org/pdf/2504.10489", "abs": "https://arxiv.org/abs/2504.10489", "authors": ["Vikranth Udandarao", "Noel Abraham Tiju", "Muthuraj Vairamuthu", "Harsh Mistry", "Dhruv Kumar"], "title": "Roamify: Designing and Evaluating an LLM Based Google Chrome Extension for Personalised Itinerary Planning", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": "for code implementation, check\n  https://github.com/Roamify-Research/Roamify", "summary": "In this paper, we present Roamify, an Artificial Intelligence powered travel\nassistant that aims to ease the process of travel planning. We have tested and\nused multiple Large Language Models like Llama and T5 to generate personalised\nitineraries per user preferences. Results from user surveys highlight the\npreference for AI powered mediums over existing methods to help in travel\nplanning across all user age groups. These results firmly validate the\npotential need of such a travel assistant. We highlight the two primary design\nconsiderations for travel assistance: D1) incorporating a web-scraping method\nto gather up-to-date news articles about destinations from various blog\nsources, which significantly improves our itinerary suggestions, and D2)\nutilising user preferences to create customised travel experiences along with a\nrecommendation system which changes the itinerary according to the user needs.\nOur findings suggest that Roamify has the potential to improve and simplify how\nusers across multiple age groups plan their travel experiences.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Roamify\uff0c\u4e00\u4e2aAI\u9a71\u52a8\u7684\u65c5\u884c\u52a9\u624b\uff0c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e2a\u6027\u5316\u884c\u7a0b\uff0c\u7528\u6237\u8c03\u67e5\u663e\u793aAI\u65b9\u6cd5\u66f4\u53d7\u6b22\u8fce\uff0c\u5e76\u5f3a\u8c03\u8bbe\u8ba1\u8003\u8651\u3002", "motivation": "\u7b80\u5316\u65c5\u884c\u89c4\u5212\u8fc7\u7a0b\uff0c\u7528\u6237\u8c03\u67e5\u663e\u793a\u6240\u6709\u5e74\u9f84\u7ec4\u66f4\u504f\u597dAI\u8f85\u52a9\uff0c\u9a8c\u8bc1\u4e86\u6b64\u7c7b\u52a9\u624b\u7684\u5fc5\u8981\u6027\u3002", "method": "\u4f7f\u7528Llama\u548cT5\u7b49\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u884c\u7a0b\uff0c\u7ed3\u5408\u7f51\u7edc\u722c\u866b\u83b7\u53d6\u5b9e\u65f6\u76ee\u7684\u5730\u4fe1\u606f\uff0c\u5e76\u57fa\u4e8e\u7528\u6237\u504f\u597d\u8c03\u6574\u63a8\u8350\u7cfb\u7edf\u3002", "result": "\u7528\u6237\u8c03\u67e5\u7ed3\u679c\u663e\u793aAI\u65b9\u6cd5\u66f4\u53d7\u6b22\u8fce\uff0c\u9a8c\u8bc1\u4e86\u65c5\u884c\u52a9\u624b\u7684\u6f5c\u5728\u9700\u6c42\u3002", "conclusion": "Roamify\u53ef\u6539\u5584\u5e76\u7b80\u5316\u4e0d\u540c\u5e74\u9f84\u7ec4\u7684\u65c5\u884c\u89c4\u5212\u4f53\u9a8c\u3002"}}
{"id": "2504.10807", "pdf": "https://arxiv.org/pdf/2504.10807", "abs": "https://arxiv.org/abs/2504.10807", "authors": ["Huseyin Tuna Erdinc", "Yunlin Zeng", "Abhinav Prakash Gahlot", "Felix J. Herrmann"], "title": "Power-scaled Bayesian Inference with Score-based Generative mModels", "categories": ["cs.LG", "cs.CV", "physics.geo-ph"], "comment": "8 pages, 4 figures", "summary": "We propose a score-based generative algorithm for sampling from power-scaled\npriors and likelihoods within the Bayesian inference framework. Our algorithm\nenables flexible control over prior-likelihood influence without requiring\nretraining for different power-scaling configurations. Specifically, we focus\non synthesizing seismic velocity models conditioned on imaged seismic. Our\nmethod enables sensitivity analysis by sampling from intermediate power\nposteriors, allowing us to assess the relative influence of the prior and\nlikelihood on samples of the posterior distribution. Through a comprehensive\nset of experiments, we evaluate the effects of varying the power parameter in\ndifferent settings: applying it solely to the prior, to the likelihood of a\nBayesian formulation, and to both simultaneously. The results show that\nincreasing the power of the likelihood up to a certain threshold improves the\nfidelity of posterior samples to the conditioning data (e.g., seismic images),\nwhile decreasing the prior power promotes greater structural diversity among\nsamples. Moreover, we find that moderate scaling of the likelihood leads to a\nreduced shot data residual, confirming its utility in posterior refinement.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u57fa\u4e8e\u5f97\u5206\u7684\u751f\u6210\u7b97\u6cd5\uff0c\u7528\u4e8e\u8d1d\u53f6\u65af\u63a8\u7406\u4e2d\u5e42\u7f29\u653e\u5148\u9a8c\u548c\u4f3c\u7136\u7684\u91c7\u6837\uff0c\u5e94\u7528\u4e8e\u5730\u9707\u901f\u5ea6\u6a21\u578b\u5408\u6210\u3002", "motivation": "\u52a8\u673a\u662f\u5b9e\u73b0\u5bf9\u5148\u9a8c\u548c\u4f3c\u7136\u5f71\u54cd\u7684\u7075\u6d3b\u63a7\u5236\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u5e76\u901a\u8fc7\u654f\u611f\u6027\u5206\u6790\u8bc4\u4f30\u5176\u5bf9\u540e\u9a8c\u5206\u5e03\u7684\u5f71\u54cd\u3002", "method": "\u65b9\u6cd5\u4f7f\u7528\u57fa\u4e8e\u5f97\u5206\u7684\u751f\u6210\u7b97\u6cd5\uff0c\u4ece\u4e2d\u95f4\u5e42\u540e\u9a8c\u4e2d\u91c7\u6837\uff0c\u4e13\u6ce8\u4e8e\u6761\u4ef6\u5730\u9707\u56fe\u50cf\u7684\u5730\u9707\u901f\u5ea6\u6a21\u578b\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u589e\u52a0\u4f3c\u7136\u5e42\u63d0\u9ad8\u6837\u672c\u6570\u636e\u4fdd\u771f\u5ea6\uff0c\u51cf\u5c11\u5148\u9a8c\u5e42\u589e\u52a0\u7ed3\u6784\u591a\u6837\u6027\uff1b\u9002\u5ea6\u4f3c\u7136\u7f29\u653e\u964d\u4f4e\u5c04\u51fb\u6570\u636e\u6b8b\u5dee\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u8be5\u7b97\u6cd5\u5728\u540e\u9a8c\u7ec6\u5316\u548c\u654f\u611f\u6027\u5206\u6790\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2504.11372", "pdf": "https://arxiv.org/pdf/2504.11372", "abs": "https://arxiv.org/abs/2504.11372", "authors": ["Zhengbing He", "Jorge Laval", "Yu Han", "Ryosuke Nishi", "Cathy Wu"], "title": "A Review of Traffic Wave Suppression Strategies: Variable Speed Limit vs. Jam-Absorption Driving", "categories": ["physics.soc-ph", "cs.SY", "eess.SY", "stat.AP"], "comment": null, "summary": "The main form of freeway traffic congestion is the familiar stop-and-go wave,\ncharacterized by wide moving jams that propagate indefinitely upstream provided\nenough traffic demand. They cause severe, long-lasting adverse effects, such as\nreduced traffic efficiency, increased driving risks, and higher vehicle\nemissions. This underscores the crucial importance of artificial intervention\nin the propagation of stop-and-go waves. Over the past two decades, two\nprominent strategies for stop-and-go wave suppression have emerged: variable\nspeed limit (VSL) and jam-absorption driving (JAD). Although they share similar\nresearch motivations, objectives, and theoretical foundations, the development\nof these strategies has remained relatively disconnected. To synthesize\nfragmented advances and drive the field forward, this paper first provides a\ncomprehensive review of the achievements in the stop-and-go wave\nsuppression-oriented VSL and JAD, respectively. It then focuses on bridging the\ntwo areas and identifying research opportunities from the following\nperspectives: fundamental diagrams, traffic dynamics modeling, traffic state\nestimation and prediction, stochasticity, scenarios for strategy validation,\nand field tests and practical deployment. We expect that through this review,\none area can effectively address its limitations by identifying and leveraging\nthe strengths of the other, thus promoting the overall research goal of freeway\nstop-and-go wave suppression.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u56de\u987e\u4e86\u53ef\u53d8\u9650\u901f\uff08VSL\uff09\u548c\u62e5\u5835\u5438\u6536\u9a7e\u9a76\uff08JAD\uff09\u5728\u6291\u5236\u9ad8\u901f\u516c\u8def\u505c\u8f66-\u542f\u52a8\u6ce2\u65b9\u9762\u7684\u8fdb\u5c55\uff0c\u6865\u63a5\u4e86\u8fd9\u4e24\u4e2a\u9886\u57df\uff0c\u5e76\u6307\u51fa\u4e86\u7814\u7a76\u673a\u4f1a\u3002", "motivation": "\u505c\u8f66-\u542f\u52a8\u6ce2\u5bfc\u81f4\u4ea4\u901a\u6548\u7387\u964d\u4f4e\u3001\u9a7e\u9a76\u98ce\u9669\u589e\u52a0\u548c\u8f66\u8f86\u6392\u653e\u5347\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u4eba\u5de5\u5e72\u9884\u3002\u8bba\u6587\u65e8\u5728\u7efc\u5408VSL\u548cJAD\u7684\u788e\u7247\u5316\u8fdb\u5c55\u3002", "method": "\u8bba\u6587\u9996\u5148\u5168\u9762\u56de\u987eVSL\u548cJAD\u7684\u6210\u5c31\uff0c\u7136\u540e\u4ece\u57fa\u7840\u56fe\u3001\u4ea4\u901a\u52a8\u6001\u5efa\u6a21\u3001\u4ea4\u901a\u72b6\u6001\u4f30\u8ba1\u548c\u9884\u6d4b\u3001\u968f\u673a\u6027\u3001\u7b56\u7565\u9a8c\u8bc1\u573a\u666f\u4ee5\u53ca\u73b0\u573a\u6d4b\u8bd5\u548c\u5b9e\u9645\u90e8\u7f72\u7b49\u89d2\u5ea6\u6865\u63a5\u4e24\u4e2a\u9886\u57df\u5e76\u8bc6\u522b\u7814\u7a76\u673a\u4f1a\u3002", "result": "\u901a\u8fc7\u56de\u987e\u548c\u6865\u63a5\uff0c\u8bba\u6587\u4fc3\u8fdb\u4e86VSL\u548cJAD\u4e4b\u95f4\u7684\u4e92\u8865\uff0c\u63a8\u8fdb\u4e86\u9ad8\u901f\u516c\u8def\u505c\u8f66-\u542f\u52a8\u6ce2\u6291\u5236\u7684\u6574\u4f53\u7814\u7a76\u76ee\u6807\u3002", "conclusion": "\u671f\u671b\u901a\u8fc7\u8fd9\u79cd\u6865\u63a5\uff0c\u4e00\u4e2a\u9886\u57df\u53ef\u4ee5\u5229\u7528\u53e6\u4e00\u4e2a\u9886\u57df\u7684\u4f18\u52bf\u6765\u514b\u670d\u5176\u5c40\u9650\u6027\uff0c\u4ece\u800c\u63a8\u52a8\u505c\u8f66-\u542f\u52a8\u6ce2\u6291\u5236\u7684\u8fdb\u6b65\u3002"}}
{"id": "2504.10496", "pdf": "https://arxiv.org/pdf/2504.10496", "abs": "https://arxiv.org/abs/2504.10496", "authors": ["Ning Li", "Jingran Zhang", "Justin Cui"], "title": "ArxivBench: Can LLMs Assist Researchers in Conducting Research?", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable effectiveness in\ncompleting various tasks such as reasoning, translation, and question\nanswering. However the issue of factual incorrect content in LLM-generated\nresponses remains a persistent challenge. In this study, we evaluate both\nproprietary and open-source LLMs on their ability to respond with relevant\nresearch papers and accurate links to articles hosted on the arXiv platform,\nbased on high level prompts. To facilitate this evaluation, we introduce\narXivBench, a benchmark specifically designed to assess LLM performance across\neight major subject categories on arXiv and five subfields within computer\nscience, one of the most popular categories among them. Our findings reveal a\nconcerning accuracy of LLM-generated responses depending on the subject, with\nsome subjects experiencing significantly lower accuracy than others. Notably,\nClaude-3.5-Sonnet exhibits a substantial advantage in generating both relevant\nand accurate responses. And interestingly, most LLMs achieve a much higher\naccuracy in the Artificial Intelligence sub-field than other sub-fields. This\nbenchmark provides a standardized tool for evaluating the reliability of\nLLM-generated scientific responses, promoting more dependable use of LLMs in\nacademic and research environments. Our code is open-sourced at\nhttps://github.com/arxivBenchLLM/arXivBench and our dataset is available on\nhuggingface at https://huggingface.co/datasets/arXivBenchLLM/arXivBench.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210arXiv\u76f8\u5173\u8bba\u6587\u548c\u94fe\u63a5\u7684\u51c6\u786e\u6027\uff0c\u5f15\u5165arXivBench\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u89e3\u51b3LLMs\u751f\u6210\u4e8b\u5b9e\u9519\u8bef\u5185\u5bb9\u7684\u6311\u6218\uff0c\u63d0\u5347\u5728\u5b66\u672f\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528arXivBench\u57fa\u51c6\u6d4b\u8bd5\u5404\u79cdLLMs\u5728\u516b\u4e2aarXiv\u4e3b\u9898\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u4e94\u4e2a\u5b50\u9886\u57df\u7684\u6027\u80fd\u3002", "result": "\u51c6\u786e\u6027\u56e0\u4e3b\u9898\u800c\u5f02\uff0cClaude-3.5-Sonnet\u8868\u73b0\u6700\u4f73\uff0c\u4eba\u5de5\u667a\u80fd\u5b50\u9886\u57df\u51c6\u786e\u6027\u8f83\u9ad8\u3002", "conclusion": "\u63d0\u4f9b\u6807\u51c6\u5316\u5de5\u5177\uff0c\u4fc3\u8fdbLLM\u5728\u7814\u7a76\u4e2d\u7684\u53ef\u9760\u4f7f\u7528\uff0c\u5e76\u5f00\u6e90\u4ee3\u7801\u548c\u6570\u636e\u96c6\u3002"}}
{"id": "2504.10817", "pdf": "https://arxiv.org/pdf/2504.10817", "abs": "https://arxiv.org/abs/2504.10817", "authors": ["Penghao Wang", "Qian Chen", "Teng Zhang", "Yingwei Zhang", "Wang Lu", "Yiqiang Chen"], "title": "FHBench: Towards Efficient and Personalized Federated Learning for Multimodal Healthcare", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated Learning (FL) has emerged as an effective solution for\nmulti-institutional collaborations without sharing patient data, offering a\nrange of methods tailored for diverse applications. However, real-world medical\ndatasets are often multimodal, and computational resources are limited, posing\nsignificant challenges for existing FL approaches. Recognizing these\nlimitations, we developed the Federated Healthcare Benchmark(FHBench), a\nbenchmark specifically designed from datasets derived from real-world\nhealthcare applications. FHBench encompasses critical diagnostic tasks across\ndomains such as the nervous, cardiovascular, and respiratory systems and\ngeneral pathology, providing comprehensive support for multimodal healthcare\nevaluations and filling a significant gap in existing benchmarks. Building on\nFHBench, we introduced Efficient Personalized Federated Learning with Adaptive\nLoRA(EPFL), a personalized FL framework that demonstrates superior efficiency\nand effectiveness across various healthcare modalities. Our results highlight\nthe robustness of FHBench as a benchmarking tool and the potential of EPFL as\nan innovative approach to advancing healthcare-focused FL, addressing key\nlimitations of existing methods.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86Federated Healthcare Benchmark (FHBench)\uff0c\u4e00\u4e2a\u9488\u5bf9\u771f\u5b9e\u533b\u7597\u5e94\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5f15\u5165\u4e86Efficient Personalized Federated Learning with Adaptive LoRA (EPFL)\uff0c\u4ee5\u63d0\u5347\u8054\u90a6\u5b66\u4e60\u5728\u533b\u7597\u9886\u57df\u7684\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u591a\u4e3a\u591a\u6a21\u6001\uff0c\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\uff0c\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u586b\u8865\u57fa\u51c6\u6d4b\u8bd5\u7684\u7a7a\u767d\u3002", "method": "\u5f00\u53d1\u4e86FHBench\uff0c\u6db5\u76d6\u795e\u7ecf\u3001\u5fc3\u8840\u7ba1\u3001\u547c\u5438\u7cfb\u7edf\u548c\u4e00\u822c\u75c5\u7406\u9886\u57df\u7684\u8bca\u65ad\u4efb\u52a1\uff0c\u5e76\u5f15\u5165EPFL\u6846\u67b6\uff0c\u4f7f\u7528Adaptive LoRA\u5b9e\u73b0\u9ad8\u6548\u7684\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u3002", "result": "\u7ed3\u679c\u663e\u793aFHBench\u4f5c\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u7684\u7a33\u5065\u6027\uff0c\u4ee5\u53caEPFL\u5728\u5404\u79cd\u533b\u7597\u6a21\u5f0f\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "EPFL\u6846\u67b6\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63a8\u52a8\u4e86\u533b\u7597\u9886\u57df\u8054\u90a6\u5b66\u4e60\u7684\u521b\u65b0\u53d1\u5c55\u3002"}}
{"id": "2504.11421", "pdf": "https://arxiv.org/pdf/2504.11421", "abs": "https://arxiv.org/abs/2504.11421", "authors": ["Mahdi Hasanzadeh", "Kasem Khalil", "Cynthia Sturton", "Ahmad Patooghy"], "title": "HeatSense: Intelligent Thermal Anomaly Detection for Securing NoC-Enabled MPSoCs", "categories": ["cs.AR", "cs.SY", "eess.SY"], "comment": "14 pages,", "summary": "Multi-Processor System-on-Chips (MPSoCs) are highly vulnerable to thermal\nattacks that manipulate dynamic thermal management systems. To counter this, we\npropose an adaptive real-time monitoring mechanism that detects abnormal\nthermal patterns in chip tiles. Our design space exploration helped identify\nkey thermal features for an efficient anomaly detection module to be\nimplemented at routers of network-enabled MPSoCs. To minimize hardware\noverhead, we employ weighted moving average (WMA) calculations and bit-shift\noperations, ensuring a lightweight yet effective implementation. By defining a\nspectrum of abnormal behaviors, our system successfully detects and mitigates\nmalicious temperature fluctuations, reducing severe cases from 3.00{\\deg}C to\n1.9{\\deg}C. The anomaly detection module achieves up to 82% of accuracy in\ndetecting thermal attacks, which is only 10-15% less than top-performing\nmachine learning (ML) models like Random Forest. However, our approach reduces\nhardware usage by up to 75% for logic resources and 100% for specialized\nresources, making it significantly more efficient than ML-based solutions. This\nmethod provides a practical, low-cost solution for resource-constrained\nenvironments, ensuring resilience against thermal attacks while maintaining\nsystem performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u591a\u5904\u7406\u5668\u7247\u4e0a\u7cfb\u7edf\uff08MPSoC\uff09\u70ed\u653b\u51fb\u76d1\u6d4b\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u5f02\u5e38\u68c0\u6d4b\u548c\u4f4e\u786c\u4ef6\u5f00\u9500\u3002", "motivation": "MPSoC\u6613\u53d7\u70ed\u653b\u51fb\u5f71\u54cd\uff0c\u9700\u8981\u5bf9\u6297\u52a8\u6001\u70ed\u7ba1\u7406\u7cfb\u7edf\u7684\u64cd\u7eb5\uff0c\u4ee5\u63d0\u5347\u7cfb\u7edf\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u81ea\u9002\u5e94\u5b9e\u65f6\u76d1\u6d4b\u673a\u5236\uff0c\u901a\u8fc7\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u548c\u4f4d\u79fb\u64cd\u4f5c\uff0c\u5728\u7f51\u7edc\u8def\u7531\u5668\u4e2d\u5b9e\u73b0\u5f02\u5e38\u68c0\u6d4b\u6a21\u5757\uff0c\u5e76\u8fdb\u884c\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u3002", "result": "\u5c06\u6e29\u5ea6\u6ce2\u52a8\u4ece3.00\u00b0C\u964d\u4f4e\u52301.9\u00b0C\uff0c\u5f02\u5e38\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe82%\uff0c\u786c\u4ef6\u4f7f\u7528\u51cf\u5c11\u9ad8\u8fbe75%\u3002", "conclusion": "\u63d0\u4f9b\u5b9e\u7528\u3001\u4f4e\u6210\u672c\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\uff0c\u786e\u4fdd\u62b5\u6297\u70ed\u653b\u51fb\u5e76\u7ef4\u6301\u6027\u80fd\u3002"}}
{"id": "2504.10833", "pdf": "https://arxiv.org/pdf/2504.10833", "abs": "https://arxiv.org/abs/2504.10833", "authors": ["Shubham Kumar", "Dwip Dalal", "Narendra Ahuja"], "title": "Towards Spatially-Aware and Optimally Faithful Concept-Based Explanations", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Post-hoc, unsupervised concept-based explanation methods (U-CBEMs) are a\npromising tool for generating semantic explanations of the decision-making\nprocesses in deep neural networks, having applications in both model\nimprovement and understanding. It is vital that the explanation is accurate, or\nfaithful, to the model, yet we identify several limitations of prior\nfaithfulness metrics that inhibit an accurate evaluation; most notably, prior\nmetrics involve only the set of concepts present, ignoring how they may be\nspatially distributed. We address these limitations with Surrogate Faithfulness\n(SF), an evaluation method that introduces a spatially-aware surrogate and two\nnovel faithfulness metrics. Using SF, we produce Optimally Faithful (OF)\nexplanations, where concepts are found that maximize faithfulness. Our\nexperiments show that (1) adding spatial-awareness to prior U-CBEMs increases\nfaithfulness in all cases; (2) OF produces significantly more faithful\nexplanations than prior U-CBEMs (30% or higher improvement in error); (3) OF's\nlearned concepts generalize well to out-of-domain data and are more robust to\nadversarial examples, where prior U-CBEMs struggle.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165\u4e86Surrogate Faithfulness (SF)\u65b9\u6cd5\uff0c\u4ee5\u6539\u8fdb\u65e0\u76d1\u7763\u6982\u5ff5\u89e3\u91ca\u65b9\u6cd5\u7684\u5fe0\u5b9e\u5ea6\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7Optimally Faithful (OF)\u89e3\u91ca\u5c55\u793a\u4e86\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u5fe0\u5b9e\u5ea6\u6307\u6807\u5ffd\u7565\u4e86\u6982\u5ff5\u7684\u7a7a\u95f4\u5206\u5e03\uff0c\u5bfc\u81f4\u89e3\u91ca\u4e0d\u51c6\u786e\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u7cbe\u786e\u7684\u8bc4\u4ef7\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSF\u65b9\u6cd5\uff0c\u5305\u62ec\u7a7a\u95f4\u611f\u77e5\u4ee3\u7406\u548c\u4e24\u4e2a\u65b0\u5fe0\u5b9e\u5ea6\u6307\u6807\uff0c\u5e76\u5f00\u53d1OF\u89e3\u91ca\u6765\u6700\u5927\u5316\u5fe0\u5b9e\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6dfb\u52a0\u7a7a\u95f4\u611f\u77e5\u63d0\u9ad8\u4e86\u5fe0\u5b9e\u5ea6\uff1bOF\u89e3\u91ca\u7684\u9519\u8bef\u7387\u964d\u4f4e\u4e8630%\u4ee5\u4e0a\uff1bOF\u6982\u5ff5\u5728\u57df\u5916\u6570\u636e\u4e0a\u6cdb\u5316\u826f\u597d\uff0c\u5e76\u5bf9\u5bf9\u6297\u6837\u672c\u66f4\u9c81\u68d2\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u89e3\u91ca\u7684\u5fe0\u5b9e\u5ea6\u3001\u6cdb\u5316\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2504.10498", "pdf": "https://arxiv.org/pdf/2504.10498", "abs": "https://arxiv.org/abs/2504.10498", "authors": ["Jianling Lu", "Mingqi Lv"], "title": "CCSK:Cognitive Convection of Self-Knowledge Based Retrieval Augmentation for Large Language Models", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "The performance of large language models (LLMs) in Q&A task increased\nsubstantially through Retrieval-Augmented Generation (RAG) which brings in\nexternal knowledge. However, the main difficulty lies in balancing the inherent\nself-knowledge of LLMs with external information retrieval (IR). The current\nthreshold-based methods apply one-dimensional static mechanisms with single\ncriterion. As a result, their IR decisions might be irrelevant to the LLMs'\nresponse under difficult queries. To alleviate this problem, we propose\nCognitive Convection of Self-Knowledge (CCSK). Different from traditional\nmethods that maintain single fixed IR activation criteria, CCSK implements a\ndynamic joint decision process via a Siamese Network module and a Response\nQuality Model. The Siamese Network calculates the cosine similarity between the\ncurrent query and the historical queries. The Response Quality Model evaluates\nthe responses of LLMs through LightGBM. The final decision of the CCSK is\nderived from the outputs of the two modules, as well as text features fused\nusing a multi-head attention mechanism. Extensive experiments on real-world\ndatasets show that CCSK significantly enhances the model's effectiveness in\ninformation retrieval.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faCCSK\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u5e73\u8861\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6709\u77e5\u8bc6\u548c\u5916\u90e8\u68c0\u7d22\uff0c\u6539\u5584Q&A\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u9608\u503c-based\u65b9\u6cd5\u9759\u6001\u5355\u4e00\uff0c\u96be\u4ee5\u5e73\u8861LLM\u81ea\u6709\u77e5\u8bc6\u4e0e\u5916\u90e8IR\uff0c\u5bfc\u81f4\u67e5\u8be2\u56f0\u96be\u65f6IR\u51b3\u7b56\u53ef\u80fd\u65e0\u5173\u3002", "method": "\u63d0\u51faCCSK\uff0c\u4f7f\u7528Siamese Network\u8ba1\u7b97\u67e5\u8be2\u5386\u53f2\u76f8\u4f3c\u6027\uff0cResponse Quality Model\u57fa\u4e8eLightGBM\u8bc4\u4f30\u54cd\u5e94\uff0c\u5e76\u901a\u8fc7\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u7279\u5f81\u8fdb\u884c\u52a8\u6001\u8054\u5408\u51b3\u7b56\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u663e\u793a\uff0cCCSK\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u4fe1\u606f\u68c0\u7d22\u6709\u6548\u6027\u3002", "conclusion": "CCSK\u901a\u8fc7\u52a8\u6001\u673a\u5236\u7f13\u89e3\u4e86IR\u51b3\u7b56\u65e0\u5173\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u63d0\u5347LLM Q&A\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2504.10850", "pdf": "https://arxiv.org/pdf/2504.10850", "abs": "https://arxiv.org/abs/2504.10850", "authors": ["Meiqi Liu", "Zhuoqun Huang", "Yue Xing"], "title": "How to Enhance Downstream Adversarial Robustness (almost) without Touching the Pre-Trained Foundation Model?", "categories": ["cs.LG", "cs.CR"], "comment": "22 pages, 2 figures, 12 tables. Include 10 pages of appendices", "summary": "With the rise of powerful foundation models, a pre-training-fine-tuning\nparadigm becomes increasingly popular these days: A foundation model is\npre-trained using a huge amount of data from various sources, and then the\ndownstream users only need to fine-tune and adapt it to specific downstream\ntasks. However, due to the high computation complexity of adversarial training,\nit is not feasible to fine-tune the foundation model to improve its robustness\non the downstream task. Observing the above challenge, we want to improve the\ndownstream robustness without updating/accessing the weights in the foundation\nmodel. Inspired from existing literature in robustness inheritance (Kim et al.,\n2020), through theoretical investigation, we identify a close relationship\nbetween robust contrastive learning with the adversarial robustness of\nsupervised learning. To further validate and utilize this theoretical insight,\nwe design a simple-yet-effective robust auto-encoder as a data pre-processing\nmethod before feeding the data into the foundation model. The proposed approach\nhas zero access to the foundation model when training the robust auto-encoder.\nExtensive experiments demonstrate the effectiveness of the proposed method in\nimproving the robustness of downstream tasks, verifying the connection between\nthe feature robustness (implied by small adversarial contrastive loss) and the\nrobustness of the downstream task.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bbf\u95ee\u57fa\u7840\u6a21\u578b\u6743\u91cd\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3\u9c81\u68d2\u81ea\u7f16\u7801\u5668\u4f5c\u4e3a\u6570\u636e\u9884\u5904\u7406\uff0c\u63d0\u9ad8\u4e0b\u6e38\u4efb\u52a1\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "motivation": "\u52a8\u673a\uff1a\u5bf9\u6297\u8bad\u7ec3\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u65e0\u6cd5\u5bf9\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u4e0d\u66f4\u65b0\u6a21\u578b\u6743\u91cd\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u7684\u9c81\u68d2\u6027\u3002", "method": "\u65b9\u6cd5\uff1a\u57fa\u4e8e\u7406\u8bba\u5206\u6790\uff0c\u8bbe\u8ba1\u9c81\u68d2\u81ea\u7f16\u7801\u5668\u4f5c\u4e3a\u6570\u636e\u9884\u5904\u7406\u5de5\u5177\uff0c\u8bad\u7ec3\u65f6\u4e0d\u8bbf\u95ee\u57fa\u7840\u6a21\u578b\u3002", "result": "\u7ed3\u679c\uff1a\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u9c81\u68d2\u6027\uff0c\u5e76\u9a8c\u8bc1\u7279\u5f81\u9c81\u68d2\u6027\u4e0e\u4e0b\u6e38\u9c81\u68d2\u6027\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "conclusion": "\u7ed3\u8bba\uff1a\u8be5\u65b9\u6cd5\u7b80\u5355\u6709\u6548\uff0c\u8bc1\u5b9e\u4e86\u7406\u8bba\u6d1e\u89c1\u3002"}}
{"id": "2504.10500", "pdf": "https://arxiv.org/pdf/2504.10500", "abs": "https://arxiv.org/abs/2504.10500", "authors": ["Eya Mhedhbi", "Youssef Mourchid", "Alice Othmani"], "title": "Leveraging Auto-Distillation and Generative Self-Supervised Learning in Residual Graph Transformers for Enhanced Recommender Systems", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper introduces a cutting-edge method for enhancing recommender systems\nthrough the integration of generative self-supervised learning (SSL) with a\nResidual Graph Transformer. Our approach emphasizes the importance of superior\ndata enhancement through the use of pertinent pretext tasks, automated through\nrationale-aware SSL to distill clear ways of how users and items interact. The\nResidual Graph Transformer incorporates a topology-aware transformer for global\ncontext and employs residual connections to improve graph representation\nlearning. Additionally, an auto-distillation process refines self-supervised\nsignals to uncover consistent collaborative rationales. Experimental\nevaluations on multiple datasets demonstrate that our approach consistently\noutperforms baseline methods.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u751f\u6210\u5f0f\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u6b8b\u5dee\u56fe\u53d8\u6362\u5668\u7684\u521b\u65b0\u65b9\u6cd5\u6765\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4e3a\u4e86\u901a\u8fc7\u66f4\u597d\u7684\u6570\u636e\u589e\u5f3a\u548c\u7528\u6237\u7269\u54c1\u4ea4\u4e92\u5b66\u4e60\u6765\u6539\u8fdb\u63a8\u8350\u7cfb\u7edf\u3002", "method": "\u6574\u5408\u751f\u6210\u5f0f\u81ea\u76d1\u7763\u5b66\u4e60\u4e0e\u6b8b\u5dee\u56fe\u53d8\u6362\u5668\uff0c\u4f7f\u7528\u7406\u6027aware SSL\u8fdb\u884c\u81ea\u52a8\u5316\u9884\u8bad\u7ec3\u4efb\u52a1\uff0c\u7ed3\u5408\u62d3\u6251aware \u53d8\u6362\u5668\u548c\u6b8b\u5dee\u8fde\u63a5\u8fdb\u884c\u56fe\u8868\u793a\u5b66\u4e60\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u84b8\u998f\u8fc7\u7a0b\u63d0\u70bc\u81ea\u76d1\u7763\u4fe1\u53f7\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u4e2d\uff0c\u8be5\u65b9\u6cd5 consistently \u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u81ea\u76d1\u7763\u5b66\u4e60\u5728\u8be5\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.10851", "pdf": "https://arxiv.org/pdf/2504.10851", "abs": "https://arxiv.org/abs/2504.10851", "authors": ["Ruochen Jin", "Boning Tong", "Shu Yang", "Bojian Hou", "Li Shen"], "title": "ICAFS: Inter-Client-Aware Feature Selection for Vertical Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Vertical federated learning (VFL) enables a paradigm for vertically\npartitioned data across clients to collaboratively train machine learning\nmodels. Feature selection (FS) plays a crucial role in Vertical Federated\nLearning (VFL) due to the unique nature that data are distributed across\nmultiple clients. In VFL, different clients possess distinct subsets of\nfeatures for overlapping data samples, making the process of identifying and\nselecting the most relevant features a complex yet essential task. Previous FS\nefforts have primarily revolved around intra-client feature selection,\noverlooking vital feature interaction across clients, leading to subpar model\noutcomes. We introduce ICAFS, a novel multi-stage ensemble approach for\neffective FS in VFL by considering inter-client interactions. By employing\nconditional feature synthesis alongside multiple learnable feature selectors,\nICAFS facilitates ensemble FS over these selectors using synthetic embeddings.\nThis method bypasses the limitations of private gradient sharing and allows for\nmodel training using real data with refined embeddings. Experiments on multiple\nreal-world datasets demonstrate that ICAFS surpasses current state-of-the-art\nmethods in prediction accuracy.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165ICAFS\uff0c\u4e00\u79cd\u65b0\u7684\u5782\u76f4\u8054\u90a6\u5b66\u4e60\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u5ba2\u6237\u7aef\u95f4\u4ea4\u4e92\uff0c\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5ba2\u6237\u7aef\u5185\u90e8\uff0c\u5ffd\u7565\u4e86\u5ba2\u6237\u7aef\u95f4\u7279\u5f81\u4ea4\u4e92\uff0c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51faICAFS\u591a\u9636\u6bb5\u96c6\u6210\u65b9\u6cd5\uff0c\u4f7f\u7528\u6761\u4ef6\u7279\u5f81\u5408\u6210\u548c\u53ef\u5b66\u4e60\u7279\u5f81\u9009\u62e9\u5668\uff0c\u901a\u8fc7\u5408\u6210\u5d4c\u5165\u8fdb\u884c\u96c6\u6210\u7279\u5f81\u9009\u62e9\uff0c\u7ed5\u8fc7\u79c1\u6709\u68af\u5ea6\u5171\u4eab\u9650\u5236\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cICAFS\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u8d85\u8fc7\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "ICAFS\u901a\u8fc7\u8003\u8651\u5ba2\u6237\u7aef\u95f4\u4ea4\u4e92\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5782\u76f4\u8054\u90a6\u5b66\u4e60\u7279\u5f81\u9009\u62e9\u65b9\u6848\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2504.10508", "pdf": "https://arxiv.org/pdf/2504.10508", "abs": "https://arxiv.org/abs/2504.10508", "authors": ["Jo\u00e3o Alberto de Oliveira Lima"], "title": "Poly-Vector Retrieval: Reference and Content Embeddings for Legal Documents", "categories": ["cs.IR", "cs.AI", "I.2.8"], "comment": "39 pages, 5 figures", "summary": "Retrieval-Augmented Generation (RAG) has emerged as an effective paradigm for\ngenerating contextually accurate answers by integrating Large Language Models\n(LLMs) with retrieval mechanisms. However, in legal contexts, users frequently\nreference norms by their labels or nicknames (e.g., Article 5 of the\nConstitution or Consumer Defense Code (CDC)), rather than by their content,\nposing challenges for traditional RAG approaches that rely solely on semantic\nembeddings of text. Furthermore, legal texts themselves heavily rely on\nexplicit cross-references (e.g., \"pursuant to Article 34\") that function as\npointers. Both scenarios pose challenges for traditional RAG approaches that\nrely solely on semantic embeddings of text, often failing to retrieve the\nnecessary referenced content. This paper introduces Poly-Vector Retrieval, a\nmethod assigning multiple distinct embeddings to each legal provision: one\nembedding captures the content (the full text), another captures the label (the\nidentifier or proper name), and optionally additional embeddings capture\nalternative denominations. Inspired by Frege's distinction between Sense and\nReference, this poly-vector retrieval approach treats labels, identifiers and\nreference markers as rigid designators and content embeddings as carriers of\nsemantic substance. Experiments on the Brazilian Federal Constitution\ndemonstrate that Poly-Vector Retrieval significantly improves retrieval\naccuracy for label-centric queries and potential to resolve internal and\nexternal cross-references, without compromising performance on purely semantic\nqueries. The study discusses philosophical and practical implications of\nexplicitly separating reference from content in vector embeddings and proposes\nfuture research directions for applying this approach to broader legal datasets\nand other domains characterized by explicit reference identifiers.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faPoly-Vector Retrieval\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3a\u6cd5\u5f8b\u6761\u6b3e\u5206\u914d\u591a\u4e2a\u5d4c\u5165\u5411\u91cf\u6765\u63d0\u5347RAG\u5728\u5904\u7406\u6807\u7b7e\u548c\u4ea4\u53c9\u5f15\u7528\u65f6\u7684\u6027\u80fd\u3002", "motivation": "\u6cd5\u5f8b\u9886\u57df\u7684RAG\u7cfb\u7edf\u96be\u4ee5\u5904\u7406\u7528\u6237\u57fa\u4e8e\u6807\u7b7e\u7684\u67e5\u8be2\u548c\u6587\u672c\u4e2d\u7684\u663e\u5f0f\u4ea4\u53c9\u5f15\u7528\u3002", "method": "Poly-Vector Retrieval\u65b9\u6cd5\uff0c\u4e3a\u6bcf\u4e2a\u6cd5\u5f8b\u6761\u6b3e\u521b\u5efa\u591a\u4e2a\u5d4c\u5165\uff1a\u4e00\u4e2a\u6355\u6349\u5185\u5bb9\uff0c\u4e00\u4e2a\u6355\u6349\u6807\u7b7e\uff0c\u5e76\u53ef\u9009\u5730\u6355\u6349\u5176\u4ed6\u540d\u79f0\u3002", "result": "\u5728\u5df4\u897f\u8054\u90a6\u5baa\u6cd5\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6807\u7b7e\u5bfc\u5411\u67e5\u8be2\u7684\u68c0\u7d22\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4e0d\u5f71\u54cd\u7eaf\u8bed\u4e49\u67e5\u8be2\u7684\u6027\u80fd\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u5206\u79bb\u5f15\u7528\u548c\u5185\u5bb9\u7684\u54f2\u5b66\u53ca\u5b9e\u9645\u542b\u4e49\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u6570\u636e\u96c6\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.10900", "pdf": "https://arxiv.org/pdf/2504.10900", "abs": "https://arxiv.org/abs/2504.10900", "authors": ["Peiliang Gong", "Emadeldeen Eldele", "Min Wu", "Zhenghua Chen", "Xiaoli Li", "Daoqiang Zhang"], "title": "Bridging Distribution Gaps in Time Series Foundation Model Pretraining with Prototype-Guided Normalization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Foundation models have achieved remarkable success across diverse\nmachine-learning domains through large-scale pretraining on large, diverse\ndatasets. However, pretraining on such datasets introduces significant\nchallenges due to substantial mismatches in data distributions, a problem\nparticularly pronounced with time series data. In this paper, we tackle this\nissue by proposing a domain-aware adaptive normalization strategy within the\nTransformer architecture. Specifically, we replace the traditional LayerNorm\nwith a prototype-guided dynamic normalization mechanism (ProtoNorm), where\nlearned prototypes encapsulate distinct data distributions, and\nsample-to-prototype affinity determines the appropriate normalization layer.\nThis mechanism effectively captures the heterogeneity of time series\ncharacteristics, aligning pretrained representations with downstream tasks.\nThrough comprehensive empirical evaluation, we demonstrate that our method\nsignificantly outperforms conventional pretraining techniques across both\nclassification and forecasting tasks, while effectively mitigating the adverse\neffects of distribution shifts during pretraining. Incorporating ProtoNorm is\nas simple as replacing a single line of code. Extensive experiments on diverse\nreal-world time series benchmarks validate the robustness and generalizability\nof our approach, advancing the development of more versatile time series\nfoundation models.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faProtoNorm\u673a\u5236\uff0c\u6539\u8fdbTransformer\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u8bad\u7ec3\u4e2d\u7684\u89c4\u8303\u5316\u7b56\u7565\uff0c\u89e3\u51b3\u6570\u636e\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\u3002", "motivation": "\u9884\u8bad\u7ec3\u5927\u578b\u6570\u636e\u96c6\u65f6\uff0c\u6570\u636e\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\u5728\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u5c24\u4e3a\u4e25\u91cd\uff0c\u9700\u8981\u9002\u5e94\u6027\u5f3a\u7684\u89c4\u8303\u5316\u65b9\u6cd5\u3002", "method": "\u5728Transformer\u4e2d\u7528\u539f\u578b\u5f15\u5bfc\u7684\u52a8\u6001\u89c4\u8303\u5316(ProtoNorm)\u66ff\u6362LayerNorm\uff0c\u901a\u8fc7\u6837\u672c\u4e0e\u539f\u578b\u7684\u4eb2\u548c\u5ea6\u9009\u62e9\u89c4\u8303\u5316\u5c42\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5206\u7c7b\u548c\u9884\u6d4b\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6280\u672f\uff0c\u5e76\u7f13\u89e3\u5206\u5e03\u504f\u79fb\uff0c\u5728\u771f\u5b9e\u57fa\u51c6\u4e0a\u8bc1\u660e\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4fc3\u8fdb\u4e86\u66f4\u901a\u7528\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u53d1\u5c55\u3002"}}
{"id": "2504.10509", "pdf": "https://arxiv.org/pdf/2504.10509", "abs": "https://arxiv.org/abs/2504.10509", "authors": ["Jakub Podolak", "Leon Peric", "Mina Janicijevic", "Roxana Petcu"], "title": "Beyond Reproducibility: Advancing Zero-shot LLM Reranking Efficiency with Setwise Insertion", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "This study presents a comprehensive reproducibility and extension analysis of\nthe Setwise prompting methodology for zero-shot ranking with Large Language\nModels (LLMs), as proposed by Zhuang et al. We evaluate its effectiveness and\nefficiency compared to traditional Pointwise, Pairwise, and Listwise approaches\nin document ranking tasks. Our reproduction confirms the findings of Zhuang et\nal., highlighting the trade-offs between computational efficiency and ranking\neffectiveness in Setwise methods. Building on these insights, we introduce\nSetwise Insertion, a novel approach that leverages the initial document ranking\nas prior knowledge, reducing unnecessary comparisons and uncertainty by\nfocusing on candidates more likely to improve the ranking results. Experimental\nresults across multiple LLM architectures (Flan-T5, Vicuna, and Llama) show\nthat Setwise Insertion yields a 31% reduction in query time, a 23% reduction in\nmodel inferences, and a slight improvement in reranking effectiveness compared\nto the original Setwise method. These findings highlight the practical\nadvantage of incorporating prior ranking knowledge into Setwise prompting for\nefficient and accurate zero-shot document reranking.", "AI": {"tldr": "\u672c\u7814\u7a76\u518d\u73b0\u5e76\u6269\u5c55Setwise\u63d0\u793a\u65b9\u6cd5\uff0c\u7528\u4e8eLLM\u7684\u96f6\u6837\u672c\u6392\u540d\uff0c\u5f15\u5165Setwise Insertion\u4ee5\u63d0\u9ad8\u6548\u7387\uff0c\u5b9e\u9a8c\u663e\u793a\u67e5\u8be2\u65f6\u95f4\u51cf\u5c1131%\u3001\u6a21\u578b\u63a8\u7406\u51cf\u5c1123%\uff0c\u5e76\u7565\u5fae\u63d0\u5347\u6548\u679c\u3002", "motivation": "\u52a8\u673a\u662f\u9a8c\u8bc1Setwise\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u65b0\u65b9\u6cd5\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u4ee5\u5e73\u8861\u6027\u80fd\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u518d\u73b0\u539fSetwise\u65b9\u6cd5\u3001\u63d0\u51faSetwise Insertion\uff08\u5229\u7528\u521d\u59cb\u6392\u540d\u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\uff09\u3001\u5e76\u5728Flan-T5\u3001Vicuna\u548cLlama\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u7ed3\u679c\u663e\u793aSetwise Insertion\u6bd4\u539f\u65b9\u6cd5\u67e5\u8be2\u65f6\u95f4\u51cf\u5c1131%\u3001\u6a21\u578b\u63a8\u7406\u51cf\u5c1123%\uff0c\u5e76\u7565\u5fae\u63d0\u9ad8\u4e86\u91cd\u65b0\u6392\u540d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u878d\u5165\u5148\u9a8c\u6392\u540d\u77e5\u8bc6\u80fd\u63d0\u5347Setwise\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\uff0c\u4f7f\u96f6\u6837\u672c\u6587\u6863\u6392\u540d\u66f4\u9ad8\u6548\u51c6\u786e\u3002"}}
{"id": "2504.10902", "pdf": "https://arxiv.org/pdf/2504.10902", "abs": "https://arxiv.org/abs/2504.10902", "authors": ["Rui Dai", "Sile Hu", "Xu Shen", "Yonggang Zhang", "Xinmei Tian", "Jieping Ye"], "title": "Leveraging Submodule Linearity Enhances Task Arithmetic Performance in LLMs", "categories": ["cs.LG"], "comment": "Accepted by ICLR 2025", "summary": "Task arithmetic is a straightforward yet highly effective strategy for model\nmerging, enabling the resultant model to exhibit multi-task capabilities.\nRecent research indicates that models demonstrating linearity enhance the\nperformance of task arithmetic. In contrast to existing methods that rely on\nthe global linearization of the model, we argue that this linearity already\nexists within the model's submodules. In particular, we present a statistical\nanalysis and show that submodules (e.g., layers, self-attentions, and MLPs)\nexhibit significantly higher linearity than the overall model. Based on these\nfindings, we propose an innovative model merging strategy that independently\nmerges these submodules. Especially, we derive a closed-form solution for\noptimal merging weights grounded in the linear properties of these submodules.\nExperimental results demonstrate that our method consistently outperforms the\nstandard task arithmetic approach and other established baselines across\ndifferent model scales and various tasks. This result highlights the benefits\nof leveraging the linearity of submodules and provides a new perspective for\nexploring solutions for effective and practical multi-task model merging.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u57fa\u4e8e\u5b50\u6a21\u5757\u7ebf\u6027\u6027\u7684\u6a21\u578b\u5408\u5e76\u7b56\u7565\uff0c\u63d0\u5347\u591a\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u4f5c\u8005\u8ba4\u4e3a\u5b50\u6a21\u5757\u7ebf\u6027\u6027\u9ad8\u4e8e\u6574\u4f53\u6a21\u578b\uff0c\u56e0\u6b64\u5f00\u53d1\u72ec\u7acb\u5408\u5e76\u65b9\u6cd5\u3002", "method": "\u72ec\u7acb\u5408\u5e76\u5b50\u6a21\u5757\uff08\u5982\u5c42\u3001self-attention\u548cMLP\uff09\uff0c\u5e76\u63a8\u5bfc\u6700\u4f18\u5408\u5e76\u6743\u91cd\u7684\u95ed\u5f0f\u89e3\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u4f18\u4e8e\u6807\u51c6\u4efb\u52a1\u7b97\u672f\u548c\u5176\u4ed6\u57fa\u51c6\uff0c\u5728\u4e0d\u540c\u89c4\u6a21\u548c\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u5f3a\u8c03\u5229\u7528\u5b50\u6a21\u5757\u7ebf\u6027\u6027\u7684\u4f18\u52bf\uff0c\u4e3a\u591a\u4efb\u52a1\u6a21\u578b\u5408\u5e76\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002"}}
{"id": "2504.10512", "pdf": "https://arxiv.org/pdf/2504.10512", "abs": "https://arxiv.org/abs/2504.10512", "authors": ["Minh-Anh Nguyen", "Dung D. Le"], "title": "JEPA4Rec: Learning Effective Language Representations for Sequential Recommendation via Joint Embedding Predictive Architecture", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Language representation learning has emerged as a promising approach for\nsequential recommendation, thanks to its ability to learn generalizable\nrepresentations. However, despite its advantages, this approach still struggles\nwith data sparsity and a limited understanding of common-sense user\npreferences. To address these limitations, we propose $\\textbf{JEPA4Rec}$, a\nframework that combines $\\textbf{J}$oint $\\textbf{E}$mbedding\n$\\textbf{P}$redictive $\\textbf{A}$rchitecture with language modeling of item\ntextual descriptions. JEPA4Rec captures semantically rich and transferable\nrepresentations, improving recommendation performance and reducing reliance on\nlarge-scale pre-training data. Specifically, JEPA4Rec represents items as text\nsentences by flattening descriptive information such as $\\textit{title,\ncategory}$, and other attributes. To encode these sentences, we employ a\nbidirectional Transformer encoder with modified embedding layers tailored for\ncapturing item information in recommendation datasets. We apply masking to text\nsentences and use them to predict the representations of the unmasked\nsentences, helping the model learn generalizable item embeddings. To further\nimprove recommendation performance and language understanding, we employ a\ntwo-stage training strategy incorporating self-supervised learning losses.\nExperiments on six real-world datasets demonstrate that JEPA4Rec consistently\noutperforms state-of-the-art methods, particularly in cross-domain,\ncross-platform, and low-resource scenarios.", "AI": {"tldr": "\u63d0\u51faJEPA4Rec\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u8054\u5408\u5d4c\u5165\u9884\u6d4b\u67b6\u6784\u548c\u8bed\u8a00\u5efa\u6a21\uff0c\u63d0\u9ad8\u5e8f\u5217\u63a8\u8350\u6027\u80fd\uff0c\u89e3\u51b3\u6570\u636e\u7a00\u758f\u548c\u5e38\u8bc6\u504f\u597d\u95ee\u9898\u3002", "motivation": "\u8bed\u8a00\u8868\u793a\u5b66\u4e60\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u867d\u6709\u4f18\u52bf\uff0c\u4f46\u9762\u4e34\u6570\u636e\u7a00\u758f\u548c\u5bf9\u7528\u6237\u5e38\u8bc6\u504f\u597d\u7684\u6709\u9650\u7406\u89e3\u3002", "method": "JEPA4Rec\u5c06\u9879\u76ee\u8868\u793a\u4e3a\u6587\u672c\u53e5\u5b50\uff0c\u4f7f\u7528\u53cc\u5411Transformer\u7f16\u7801\u5668\u3001\u63a9\u7801\u9884\u6d4b\u7b56\u7565\uff0c\u5e76\u91c7\u7528\u4e24\u9636\u6bb5\u81ea\u76d1\u7763\u5b66\u4e60\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cJEPA4Rec\u5728\u8de8\u57df\u3001\u8de8\u5e73\u53f0\u548c\u4f4e\u8d44\u6e90\u573a\u666f\u4e2d\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u5347\u63a8\u8350\u6027\u80fd\uff0c\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6570\u636e\u7684\u4f9d\u8d56\u3002"}}
{"id": "2504.10917", "pdf": "https://arxiv.org/pdf/2504.10917", "abs": "https://arxiv.org/abs/2504.10917", "authors": ["Jialin Chen", "Haolan Zuo", "Haoyu Peter Wang", "Siqi Miao", "Pan Li", "Rex Ying"], "title": "Towards A Universal Graph Structural Encoder", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancements in large-scale pre-training have shown the potential to\nlearn generalizable representations for downstream tasks. In the graph domain,\nhowever, capturing and transferring structural information across different\ngraph domains remains challenging, primarily due to the inherent differences in\ntopological patterns across various contexts. Additionally, most existing\nmodels struggle to capture the complexity of rich graph structures, leading to\ninadequate exploration of the embedding space. To address these challenges, we\npropose GFSE, a universal graph structural encoder designed to capture\ntransferable structural patterns across diverse domains such as molecular\ngraphs, social networks, and citation networks. GFSE is the first cross-domain\ngraph structural encoder pre-trained with multiple self-supervised learning\nobjectives. Built on a Graph Transformer, GFSE incorporates attention\nmechanisms informed by graph inductive bias, enabling it to encode intricate\nmulti-level and fine-grained topological features. The pre-trained GFSE\nproduces generic and theoretically expressive positional and structural\nencoding for graphs, which can be seamlessly integrated with various downstream\ngraph feature encoders, including graph neural networks for vectorized features\nand Large Language Models for text-attributed graphs. Comprehensive experiments\non synthetic and real-world datasets demonstrate GFSE's capability to\nsignificantly enhance the model's performance while requiring substantially\nless task-specific fine-tuning. Notably, GFSE achieves state-of-the-art\nperformance in 81.6% evaluated cases, spanning diverse graph models and\ndatasets, highlighting its potential as a powerful and versatile encoder for\ngraph-structured data.", "AI": {"tldr": "GFSE \u662f\u4e00\u79cd\u901a\u7528\u56fe\u7ed3\u6784\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u63d0\u5347\u8de8\u57df\u56fe\u8868\u793a\u5b66\u4e60\u6027\u80fd\uff0c\u5e76\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u6355\u83b7\u548c\u8f6c\u79fb\u4e0d\u540c\u56fe\u57df\u7684\u7ed3\u6784\u4fe1\u606f\uff0c\u4e14\u65e0\u6cd5\u6709\u6548\u5904\u7406\u590d\u6742\u62d3\u6251\u3002", "method": "\u63d0\u51fa GFSE\uff0c\u4f7f\u7528\u57fa\u4e8e\u56fe Transformer \u7684\u6ce8\u610f\u529b\u673a\u5236\u548c\u591a\u81ea\u76d1\u7763\u5b66\u4e60\u76ee\u6807\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u53ef\u4e0e\u4e0b\u6e38\u6a21\u578b\u65e0\u7f1d\u6574\u5408\u3002", "result": "\u5b9e\u9a8c\u663e\u793a GFSE \u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5728 81.6% \u7684\u8bc4\u4f30\u6848\u4f8b\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5e76\u51cf\u5c11\u5fae\u8c03\u9700\u6c42\u3002", "conclusion": "GFSE \u4f5c\u4e3a\u5f3a\u5927\u901a\u7528\u7684\u56fe\u7ed3\u6784\u7f16\u7801\u5668\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u4e8e\u56fe\u7ed3\u6784\u6570\u636e\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.10514", "pdf": "https://arxiv.org/pdf/2504.10514", "abs": "https://arxiv.org/abs/2504.10514", "authors": ["Yijun Liang", "Ming Li", "Chenrui Fan", "Ziyue Li", "Dang Nguyen", "Kwesi Cobbina", "Shweta Bhardwaj", "Jiuhai Chen", "Fuxiao Liu", "Tianyi Zhou"], "title": "ColorBench: Can VLMs See and Understand the Colorful World? A Comprehensive Benchmark for Color Perception, Reasoning, and Robustness", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "33 pages, including references and appendix. Code is available at\n  https://github.com/tianyi-lab/ColorBench", "summary": "Color plays an important role in human perception and usually provides\ncritical clues in visual reasoning. However, it is unclear whether and how\nvision-language models (VLMs) can perceive, understand, and leverage color as\nhumans. This paper introduces ColorBench, an innovative benchmark meticulously\ncrafted to assess the capabilities of VLMs in color understanding, including\ncolor perception, reasoning, and robustness. By curating a suite of diverse\ntest scenarios, with grounding in real applications, ColorBench evaluates how\nthese models perceive colors, infer meanings from color-based cues, and\nmaintain consistent performance under varying color transformations. Through an\nextensive evaluation of 32 VLMs with varying language models and vision\nencoders, our paper reveals some undiscovered findings: (i) The scaling law\n(larger models are better) still holds on ColorBench, while the language model\nplays a more important role than the vision encoder. (ii) However, the\nperformance gaps across models are relatively small, indicating that color\nunderstanding has been largely neglected by existing VLMs. (iii) CoT reasoning\nimproves color understanding accuracies and robustness, though they are\nvision-centric tasks. (iv) Color clues are indeed leveraged by VLMs on\nColorBench but they can also mislead models in some tasks. These findings\nhighlight the critical limitations of current VLMs and underscore the need to\nenhance color comprehension. Our ColorBenchcan serve as a foundational tool for\nadvancing the study of human-level color understanding of multimodal AI.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165ColorBench\u57fa\u51c6\u6765\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u7684\u989c\u8272\u7406\u89e3\u80fd\u529b\uff0c\u5e76\u63ed\u793a\u4e86\u5173\u952e\u53d1\u73b0\u3002", "motivation": "\u63a2\u8ba8VLMs\u662f\u5426\u548c\u5982\u4f55\u50cf\u4eba\u7c7b\u4e00\u6837\u611f\u77e5\u548c\u5229\u7528\u989c\u8272\uff0c\u56e0\u4e3a\u989c\u8272\u5728\u89c6\u89c9\u63a8\u7406\u4e2d\u5f88\u91cd\u8981\u3002", "method": "\u5f15\u5165ColorBench\uff0c\u8fd9\u662f\u4e00\u4e2a\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u57fa\u51c6\uff0c\u5305\u542b\u5404\u79cd\u6d4b\u8bd5\u573a\u666f\uff0c\u7528\u4e8e\u8bc4\u4f30VLMs\u7684\u989c\u8272\u611f\u77e5\u3001\u63a8\u7406\u548c\u9c81\u68d2\u6027\u3002", "result": "\u8bc4\u4f3032\u4e2aVLMs\u540e\u53d1\u73b0\uff1a\u7f29\u653e\u5b9a\u5f8b\u6210\u7acb\uff0c\u8bed\u8a00\u6a21\u578b\u6bd4\u89c6\u89c9\u7f16\u7801\u5668\u66f4\u91cd\u8981\uff1b\u6027\u80fd\u5dee\u8ddd\u5c0f\uff0c\u8868\u660e\u989c\u8272\u7406\u89e3\u88ab\u5ffd\u7565\uff1bCoT\u63a8\u7406\u6539\u5584\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff1b\u989c\u8272\u7ebf\u7d22\u53ef\u80fd\u8bef\u5bfc\u6a21\u578b\u3002", "conclusion": "\u5f53\u524dVLMs\u5728\u989c\u8272\u7406\u89e3\u65b9\u9762\u6709\u5c40\u9650\u6027\uff0c\u9700\u8981\u6539\u8fdb\uff0cColorBench\u53ef\u4f5c\u4e3a\u63a8\u8fdb\u591a\u6a21\u6001AI\u7814\u7a76\u7684\u57fa\u7840\u5de5\u5177\u3002"}}
{"id": "2504.10923", "pdf": "https://arxiv.org/pdf/2504.10923", "abs": "https://arxiv.org/abs/2504.10923", "authors": ["Mingyi Zhu", "Zhaoxin Li", "Qiao Lin", "Li Ding"], "title": "Fast-Powerformer: A Memory-Efficient Transformer for Accurate Mid-Term Wind Power Forecasting", "categories": ["cs.LG", "eess.SP"], "comment": "Mingyi Zhu is the first author. Li Ding is the corresponding author", "summary": "Wind power forecasting (WPF), as a significant research topic within\nrenewable energy, plays a crucial role in enhancing the security, stability,\nand economic operation of power grids. However, due to the high stochasticity\nof meteorological factors (e.g., wind speed) and significant fluctuations in\nwind power output, mid-term wind power forecasting faces a dual challenge of\nmaintaining high accuracy and computational efficiency. To address these\nissues, this paper proposes an efficient and lightweight mid-term wind power\nforecasting model, termed Fast-Powerformer. The proposed model is built upon\nthe Reformer architecture, incorporating structural enhancements such as a\nlightweight Long Short-Term Memory (LSTM) embedding module, an input\ntransposition mechanism, and a Frequency Enhanced Channel Attention Mechanism\n(FECAM). These improvements enable the model to strengthen temporal feature\nextraction, optimize dependency modeling across variables, significantly reduce\ncomputational complexity, and enhance sensitivity to periodic patterns and\ndominant frequency components. Experimental results conducted on multiple\nreal-world wind farm datasets demonstrate that the proposed Fast-Powerformer\nachieves superior prediction accuracy and operational efficiency compared to\nmainstream forecasting approaches. Furthermore, the model exhibits fast\ninference speed and low memory consumption, highlighting its considerable\npractical value for real-world deployment scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFast-Powerformer\u6a21\u578b\uff0c\u7528\u4e8e\u4e2d\u671f\u98ce\u529b\u53d1\u7535\u9884\u6d4b\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u98ce\u529b\u53d1\u7535\u9884\u6d4b\u9762\u4e34\u6c14\u8c61\u968f\u673a\u6027\u548c\u8f93\u51fa\u6ce2\u52a8\u5e26\u6765\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u6311\u6218\u3002", "method": "\u57fa\u4e8eReformer\u67b6\u6784\uff0c\u6dfb\u52a0\u8f7b\u91cf\u7ea7LSTM\u5d4c\u5165\u3001\u8f93\u5165\u8f6c\u7f6e\u548cFECAM\u673a\u5236\uff0c\u4ee5\u589e\u5f3a\u7279\u5f81\u63d0\u53d6\u548c\u51cf\u5c11\u590d\u6742\u5ea6\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7cbe\u5ea6\u548c\u6548\u7387\u4f18\u4e8e\u4e3b\u6d41\u65b9\u6cd5\uff0c\u5e76\u5177\u6709\u5feb\u901f\u63a8\u7406\u548c\u4f4e\u5185\u5b58\u6d88\u8017\u3002", "conclusion": "\u6a21\u578b\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u5177\u6709\u9ad8\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2504.10521", "pdf": "https://arxiv.org/pdf/2504.10521", "abs": "https://arxiv.org/abs/2504.10521", "authors": ["Pardis Moradbeiki", "Mohammad Ali Zare Chahooki"], "title": "Integrating Emotion Distribution Networks and Textual Message Analysis for X User Emotional State Classification", "categories": ["cs.SI", "cs.AI", "cs.LG"], "comment": null, "summary": "As the popularity and reach of social networks continue to surge, a vast\nreservoir of opinions and sentiments across various subjects inundates these\nplatforms. Among these, X social network (formerly Twitter) stands as a\njuggernaut, boasting approximately 420 million active users. Extracting users'\nemotional and mental states from their expressed opinions on social media has\nbecome a common pursuit. While past methodologies predominantly focused on the\ntextual content of messages to analyze user sentiment, the interactive nature\nof these platforms suggests a deeper complexity. This study employs hybrid\nmethodologies, integrating textual analysis, profile examination, follower\nanalysis, and emotion dissemination patterns. Initially, user interactions are\nleveraged to refine emotion classification within messages, encompassing\nexchanges where users respond to each other. Introducing the concept of a\ncommunication tree, a model is extracted to map these interactions.\nSubsequently, users' bios and interests from this tree are juxtaposed with\nmessage text to enrich analysis. Finally, influential figures are identified\namong users' followers in the communication tree, categorized into different\ntopics to gauge interests. The study highlights that traditional sentiment\nanalysis methodologies, focusing solely on textual content, are inadequate in\ndiscerning sentiment towards significant events, notably the presidential\nelection. Comparative analysis with conventional methods reveals a substantial\nimprovement in accuracy with the incorporation of emotion distribution patterns\nand user profiles. The proposed approach yields a 12% increase in accuracy with\nemotion distribution patterns and a 15% increase when considering user\nprofiles, underscoring its efficacy in capturing nuanced sentiment dynamics.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6574\u5408\u6587\u672c\u5206\u6790\u3001\u7528\u6237\u4e92\u52a8\u548c\u4e2a\u4eba\u8d44\u6599\uff0c\u63d0\u9ad8\u793e\u4ea4\u5a92\u4f53\u60c5\u611f\u5206\u6790\u51c6\u786e\u7387\uff0c\u5c24\u5176\u9488\u5bf9\u91cd\u5927\u4e8b\u4ef6\u3002", "motivation": "\u793e\u4ea4\u7f51\u7edc\u7528\u6237\u4f17\u591a\uff0c\u4f20\u7edf\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u6587\u672c\u5185\u5bb9\uff0c\u65e0\u6cd5\u6709\u6548\u6355\u6349\u590d\u6742\u4e92\u52a8\u548c\u4e8b\u4ef6\u76f8\u5173\u60c5\u611f\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u5305\u62ec\u6587\u672c\u5206\u6790\u3001\u901a\u4fe1\u6811\u6a21\u578b\u6620\u5c04\u4e92\u52a8\u3001\u7528\u6237\u4e2a\u4eba\u8d44\u6599\u548c\u5173\u6ce8\u8005\u5206\u6790\u3002", "result": "\u4e0e\u4f20\u7edf\u65b9\u6cd5\u6bd4\u8f83\uff0c\u60c5\u611f\u5206\u5e03\u6a21\u5f0f\u63d0\u9ad8\u51c6\u786e\u738712%\uff0c\u7528\u6237\u8d44\u6599\u63d0\u9ad815%\u3002", "conclusion": "\u8bc1\u660e\u6574\u5408\u591a\u6e90\u6570\u636e\u80fd\u66f4\u597d\u5730\u6355\u6349\u7ec6\u5fae\u60c5\u611f\u52a8\u6001\uff0c\u4f20\u7edf\u65b9\u6cd5\u4e0d\u8db3\u4ee5\u5904\u7406\u91cd\u5927\u4e8b\u4ef6\u5206\u6790\u3002"}}
{"id": "2504.10925", "pdf": "https://arxiv.org/pdf/2504.10925", "abs": "https://arxiv.org/abs/2504.10925", "authors": ["Ayan Chatterjee", "Barbara Ikica", "Babak Ravandi", "John Palowitch"], "title": "Transfer Learning for Temporal Link Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 7 figures", "summary": "Link prediction on graphs has applications spanning from recommender systems\nto drug discovery. Temporal link prediction (TLP) refers to predicting future\nlinks in a temporally evolving graph and adds additional complexity related to\nthe dynamic nature of graphs. State-of-the-art TLP models incorporate memory\nmodules alongside graph neural networks to learn both the temporal mechanisms\nof incoming nodes and the evolving graph topology. However, memory modules only\nstore information about nodes seen at train time, and hence such models cannot\nbe directly transferred to entirely new graphs at test time and deployment. In\nthis work, we study a new transfer learning task for temporal link prediction,\nand develop transfer-effective methods for memory-laden models. Specifically,\nmotivated by work showing the informativeness of structural signals for the TLP\ntask, we augment a structural mapping module to the existing TLP model\narchitectures, which learns a mapping from graph structural (topological)\nfeatures to memory embeddings. Our work paves the way for a memory-free\nfoundation model for TLP.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u4e86\u65f6\u95f4\u94fe\u63a5\u9884\u6d4b\u7684\u8f6c\u79fb\u5b66\u4e60\u4efb\u52a1\uff0c\u901a\u8fc7\u6dfb\u52a0\u7ed3\u6784\u6620\u5c04\u6a21\u5757\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u8f6c\u79fb\u5230\u65b0\u56fe\u4e0a\uff0c\u5e76\u4e3a\u65e0\u8bb0\u5fc6\u57fa\u7840\u6a21\u578b\u94fa\u5e73\u9053\u8def\u3002", "motivation": "\u73b0\u6709TLP\u6a21\u578b\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8e\u65b0\u56fe\uff0c\u56e0\u4e3a\u8bb0\u5fc6\u6a21\u5757\u53ea\u5b58\u50a8\u8bad\u7ec3\u65f6\u7684\u8282\u70b9\u4fe1\u606f\uff0c\u4e14\u7ed3\u6784\u4fe1\u53f7\u5bf9\u4efb\u52a1\u5177\u6709\u91cd\u8981\u6027\u3002", "method": "\u5728\u73b0\u6709TLP\u6a21\u578b\u67b6\u6784\u4e2d\u6dfb\u52a0\u7ed3\u6784\u6620\u5c04\u6a21\u5757\uff0c\u5b66\u4e60\u4ece\u56fe\u7ed3\u6784\u7279\u5f81\u5230\u8bb0\u5fc6\u5d4c\u5165\u7684\u6620\u5c04\u3002", "result": "\u5f00\u53d1\u4e86\u8f6c\u79fb\u6709\u6548\u7684\u8bb0\u5fc6\u8d1f\u8f7d\u6a21\u578b\uff0c\u4e3a\u65f6\u95f4\u94fe\u63a5\u9884\u6d4b\u7684\u65e0\u8bb0\u5fc6\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63a8\u52a8\u4e86TLP\u4efb\u52a1\u4e2d\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2504.10639", "pdf": "https://arxiv.org/pdf/2504.10639", "abs": "https://arxiv.org/abs/2504.10639", "authors": ["Sanchita Ghosh", "Tanushree Roy"], "title": "Secure Estimation of Battery Voltage Under Sensor Attacks: A Self-Learning Koopman Approach", "categories": ["eess.SY", "cs.SY"], "comment": "10 pages, 5 figures", "summary": "Cloud-based battery management system (BMS) requires accurate terminal\nvoltage measurement data to ensure optimal and safe charging of Lithium-ion\nbatteries. Unfortunately, an adversary can corrupt the battery terminal voltage\ndata as it passes from the local-BMS to the cloud-BMS through the communication\nnetwork, with the objective of under- or over-charging the battery. To ensure\naccurate terminal voltage data under such malicious sensor attacks, this paper\ninvestigates a Koopman-based secure terminal voltage estimation scheme using a\ntwo-stage error-compensated self-learning feedback. During the first stage of\nerror correction, the potential Koopman prediction error is estimated to\ncompensate for the error accumulation due to the linear approximation of\nKoopman operator. The second stage of error compensation aims to recover the\nerror amassing from the higher-order dynamics of the Lithium-ion batteries\nmissed by the self-learning strategy. Specifically, we have proposed two\ndifferent methods for this second stage error compensation. First, an\ninterpretable empirical correction strategy has been obtained using the open\ncircuit voltage to state-of-charge mapping for the battery. Second, a Gaussian\nprocess regression-based data-driven method has been explored. Finally, we\ndemonstrate the efficacy of the proposed secure estimator using both empirical\nand data-driven corrections.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eKoopman\u7684secure terminal voltage estimation\u65b9\u6848\uff0c\u7528\u4e8ecloud-based BMS\uff0c\u4ee5\u5bf9\u6297\u6076\u610f\u4f20\u611f\u5668\u653b\u51fb\uff0c\u786e\u4fdd\u7535\u6c60\u5145\u7535\u5b89\u5168\u3002", "motivation": "\u52a8\u673a\u662f\u9632\u6b62adversary\u7be1\u6539\u7535\u6c60\u7ec8\u7aef\u7535\u538b\u6570\u636e\uff0c\u5bfc\u81f4\u7535\u6c60\u5145\u7535\u4e0d\u5f53\uff0c\u4ece\u800c\u786e\u4fdd\u6570\u636e\u51c6\u786e\u6027\u3002", "method": "\u65b9\u6cd5\u5305\u62ecKoopman-based secure estimation\uff0c\u4f7f\u7528\u4e24\u9636\u6bb5\u9519\u8bef\u8865\u507f\uff1a\u7b2c\u4e00\u9636\u6bb5\u8865\u507fKoopman\u9884\u6d4b\u9519\u8bef\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u7ecf\u9a8c\u4fee\u6b63\u6216Gaussian process regression\u3002", "result": "\u7ed3\u679c\u5c55\u793a\u4e86\u4f7f\u7528\u7ecf\u9a8c\u548c\u6570\u636e\u9a71\u52a8\u4fee\u6b63\u7684\u65b9\u6848\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7ed3\u8bba\u662f\u6240\u63d0\u51fa\u7684secure estimator\u5728\u5bf9\u6297\u653b\u51fb\u65f6\u6709\u6548\u3002"}}
{"id": "2504.10658", "pdf": "https://arxiv.org/pdf/2504.10658", "abs": "https://arxiv.org/abs/2504.10658", "authors": ["Sanchita Ghosh", "Tanushree Roy"], "title": "Transfer Learning Assisted XgBoost For Adaptable Cyberattack Detection In Battery Packs", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "9 pages, 5 figures", "summary": "Optimal charging of electric vehicle (EVs) depends heavily on reliable sensor\nmeasurements from the battery pack to the cloud-controller of the smart\ncharging station. However, an adversary could corrupt the voltage sensor data\nduring transmission, potentially causing local to wide-scale disruptions.\nTherefore, it is essential to detect sensor cyberattacks in real-time to ensure\nsecure EV charging, and the developed algorithms must be readily adaptable to\nvariations, including pack configurations. To tackle these challenges, we\npropose adaptable fine-tuning of an XgBoost-based cell-level model using\nlimited pack-level data to use for voltage prediction and residual generation.\nWe used battery cell and pack data from high-fidelity charging experiments in\nPyBaMM and `liionpack' package to train and test the detection algorithm. The\nalgorithm's performance has been evaluated for two large-format battery packs\nunder sensor swapping and replay attacks. The simulation results also highlight\nthe adaptability and efficacy of our proposed detection algorithm.", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eXgBoost\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u6709\u9650\u7684\u6570\u636e\u5fae\u8c03\u6765\u68c0\u6d4b\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u4e2d\u7684\u4f20\u611f\u5668\u7f51\u7edc\u653b\u51fb\uff0c\u5e76\u5728\u6a21\u62df\u4e2d\u663e\u793a\u51fa\u826f\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u68c0\u6d4b\u548c\u7f13\u89e3\u53ef\u80fd\u7834\u574f\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u7684\u4f20\u611f\u5668\u7f51\u7edc\u653b\u51fb\uff0c\u786e\u4fdd\u5b9e\u65f6\u5b89\u5168\u5e76\u9002\u5e94\u4e0d\u540c\u7684\u7535\u6c60\u914d\u7f6e\u3002", "method": "\u63d0\u51fa\u901a\u8fc7\u4f7f\u7528PyBaMM\u548cliionpack\u5305\u7684pack-level\u6570\u636e\u5bf9XgBoost-based cell-level\u6a21\u578b\u8fdb\u884c\u53ef\u9002\u5e94\u5fae\u8c03\uff0c\u7528\u4e8e\u7535\u538b\u9884\u6d4b\u548c\u6b8b\u5dee\u751f\u6210\u3002", "result": "\u7b97\u6cd5\u5728\u4e24\u4e2a\u5927\u5bb9\u91cf\u7535\u6c60\u7ec4\u4e0a\u9488\u5bf9\u4f20\u611f\u5668\u4ea4\u6362\u548c\u91cd\u653e\u653b\u51fb\u7684\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7a81\u663e\u5176\u9002\u5e94\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u68c0\u6d4b\u7b97\u6cd5\u5728\u786e\u4fdd\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u5b89\u5168\u65b9\u9762\u6709\u6548\u4e14\u53ef\u9002\u5e94\u3002"}}
{"id": "2504.10691", "pdf": "https://arxiv.org/pdf/2504.10691", "abs": "https://arxiv.org/abs/2504.10691", "authors": ["Ali Nazari", "Ali Olfat"], "title": "Spectrum Sharing in STAR-RIS-assisted UAV with NOMA for Cognitive Radio Networks", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "As an emerging technology, the simultaneous transmitting and reflecting\nreconfigurable intelligent surface (STAR-RIS) can improve the spectrum\nefficiency (SE) of primary users (PUs) and secondary users (SUs) in cognitive\nradio (CR) networks by mitigating the interference of the incident signals. The\nSTAR-RIS-assisted unmanned aerial vehicle (UAV) can fully cover the dynamic\nenvironment through high mobility and fast deployment. According to the dynamic\nair-to-ground channels, the STAR-RIS-assisted UAV may face a challenge\nconfiguring their elements' coefficients (i.e., reflecting and transmitting the\namplitude and phases). Hence, to meet the requirements of dynamic channel\ndetermination with the SE approach, this paper proposes the sum rate\nmaximization of both PUs and SUs through non-orthogonal multiple access in CR\nnetwork to jointly optimize the trajectory and transmission-reflection\nbeamforming design of the STAR-RIS-assisted UAV, and power allocation. Since\nthe non-convex joint optimization problem includes coupled optimization\nvariables, we develop an alternative optimization algorithm. Simulation results\nstudy the impact of: 1) the significant parameters, 2) the performance of\ndifferent intelligence surface modes and STAR-RIS operating protocols, 3) the\njoint trajectory and beamforming design with fixed and mobile users, and 4)\nSTAR-RIS capabilities such as mitigating the interference, and how variations\nin the roles of elements dynamically.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSTAR-RIS\u8f85\u52a9UAV\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u4ee5\u6700\u5927\u5316\u8ba4\u77e5\u65e0\u7ebf\u7535\u7f51\u7edc\u4e2d\u4e3b\u7528\u6237\u548c\u6b21\u8981\u7528\u6237\u7684\u603b\u901f\u7387\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u9891\u8c31\u6548\u7387\uff0c\u7f13\u89e3\u5e72\u6270\uff0c\u5e76\u9002\u5e94\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6311\u6218\u3002", "method": "\u901a\u8fc7\u8054\u5408\u4f18\u5316UAV\u8f68\u8ff9\u3001\u4f20\u8f93-\u53cd\u5c04\u6ce2\u675f\u5f62\u6210\u548c\u529f\u7387\u5206\u914d\uff0c\u4f7f\u7528\u66ff\u4ee3\u4f18\u5316\u7b97\u6cd5\u89e3\u51b3\u975e\u51f8\u4f18\u5316\u95ee\u9898\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u5206\u6790\u4e86\u5173\u952e\u53c2\u6570\u7684\u5f71\u54cd\u3001\u4e0d\u540c\u667a\u80fd\u8868\u9762\u6a21\u5f0f\u548c\u534f\u8bae\u7684\u6027\u80fd\u3001\u8f68\u8ff9\u8bbe\u8ba1\u4ee5\u53caSTAR-RIS\u7684\u5e72\u6270\u7f13\u89e3\u80fd\u529b\u3002", "conclusion": "STAR-RIS\u80fd\u591f\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u5e76\u5728\u52a8\u6001\u73af\u5883\u4e2d\u52a8\u6001\u8c03\u6574\u5143\u7d20\u89d2\u8272\u3002"}}
{"id": "2504.10709", "pdf": "https://arxiv.org/pdf/2504.10709", "abs": "https://arxiv.org/abs/2504.10709", "authors": ["Chi-Bach Pham", "Homayoun Hamedmoghadam Rafati", "Robert Noel Shorten"], "title": "Vehicle Dynamics Control for Simultaneous Optimization of Tire Emissions and Performance in EVs", "categories": ["eess.SY", "cs.SY"], "comment": "25 pages, 12 figures", "summary": "In recent years, Electric Vehicles (EVs) have seen widespread public\nadoption. While EVs produce zero tailpipe emissions, they contribute to an\nincrease in another type of vehicular emission: tire emissions.\nBattery-operated EVs are generally heavier than their combustion-engine\ncounterparts and require greater acceleration forces, which their high-torque\nelectric motors provide. This combination of increased weight and traction\nforces leads to higher tire emissions, which possess various adverse health and\nenvironmental effects. Here, we propose a control solution with promising\nresults in mitigating tire wear in all-wheel-drive EVs. The idea is to utilize\ndifferent tire profiles on each drive axis: a low-wear, low-traction axis and a\nhigh-wear, high-traction axis. Derived from detailed mathematical analyses, we\npropose a simple control scheme to counteract the performance difference from\nusing the low-traction tires. The proposed control mechanism then distributes\ntorque optimally between the two axes, maximizing usage from the low-wear axis\nand simultaneously maintaining stability and performance by leveraging\nhigh-traction tires. Through detailed numerical simulations, we demonstrate\nthat the developed model significantly reduces tire emissions and maintains\nvehicle drivability and performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u63a7\u5236\u65b9\u6848\uff0c\u4f7f\u7528\u4e0d\u540c\u8f6e\u80ce\u914d\u7f6e\u51cf\u5c11\u7535\u52a8\u6c7d\u8f66\u8f6e\u80ce\u6392\u653e\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u91cd\u91cf\u589e\u52a0\u548c\u7275\u5f15\u529b\u5bfc\u81f4\u8f6e\u80ce\u6392\u653e\u4e0a\u5347\uff0c\u5bf9\u5065\u5eb7\u548c\u73af\u5883\u6709\u5bb3\uff0c\u9700\u8981\u51cf\u8f7b\u8f6e\u80ce\u78e8\u635f\u3002", "method": "\u91c7\u7528\u4f4e\u78e8\u635f\u4f4e\u7275\u5f15\u529b\u548c\u9ad8\u78e8\u635f\u9ad8\u7275\u5f15\u529b\u8f6e\u80ce\u7ec4\u5408\uff0c\u5e76\u4f18\u5316\u626d\u77e9\u5206\u5e03\u63a7\u5236\u65b9\u6848\u3002", "result": "\u6570\u503c\u6a21\u62df\u663e\u793a\uff0c\u8be5\u6a21\u578b\u663e\u8457\u964d\u4f4e\u8f6e\u80ce\u6392\u653e\uff0c\u540c\u65f6\u7ef4\u6301\u8f66\u8f86\u53ef\u9a7e\u9a76\u6027\u548c\u6027\u80fd\u3002", "conclusion": "\u8be5\u63a7\u5236\u673a\u5236\u6709\u6548\u51cf\u5c11\u8f6e\u80ce\u6392\u653e\uff0c\u5e76\u4fdd\u6301\u8f66\u8f86\u7a33\u5b9a\u6027\u548c\u6027\u80fd\uff0c\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2504.10519", "pdf": "https://arxiv.org/pdf/2504.10519", "abs": "https://arxiv.org/abs/2504.10519", "authors": ["Yuhang Yao", "Haixin Wang", "Yibo Chen", "Jiawen Wang", "Min Chang Jordan Ren", "Bosheng Ding", "Salman Avestimehr", "Chaoyang He"], "title": "Toward Super Agent System with Hybrid AI Routers", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "comment": null, "summary": "AI Agents powered by Large Language Models are transforming the world through\nenormous applications. A super agent has the potential to fulfill diverse user\nneeds, such as summarization, coding, and research, by accurately understanding\nuser intent and leveraging the appropriate tools to solve tasks. However, to\nmake such an agent viable for real-world deployment and accessible at scale,\nsignificant optimizations are required to ensure high efficiency and low cost.\nThis paper presents a design of the Super Agent System. Upon receiving a user\nprompt, the system first detects the intent of the user, then routes the\nrequest to specialized task agents with the necessary tools or automatically\ngenerates agentic workflows. In practice, most applications directly serve as\nAI assistants on edge devices such as phones and robots. As different language\nmodels vary in capability and cloud-based models often entail high\ncomputational costs, latency, and privacy concerns, we then explore the hybrid\nmode where the router dynamically selects between local and cloud models based\non task complexity. Finally, we introduce the blueprint of an on-device super\nagent enhanced with cloud. With advances in multi-modality models and edge\nhardware, we envision that most computations can be handled locally, with cloud\ncollaboration only as needed. Such architecture paves the way for super agents\nto be seamlessly integrated into everyday life in the near future.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u8d85\u7ea7\u4ee3\u7406\u7cfb\u7edf\u7684\u8bbe\u8ba1\uff0c\u65e8\u5728\u901a\u8fc7\u610f\u56fe\u68c0\u6d4b\u3001\u4efb\u52a1\u8def\u7531\u548c\u6df7\u5408\u8ba1\u7b97\u6a21\u5f0f\u5b9e\u73b0\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684AI\u5e94\u7528\u3002", "motivation": "AI\u4ee3\u7406\u9700\u8981\u4f18\u5316\u4ee5\u5b9e\u73b0\u5927\u89c4\u6a21\u90e8\u7f72\uff0c\u89e3\u51b3\u6548\u7387\u3001\u6210\u672c\u548c\u9690\u79c1\u95ee\u9898\u3002", "method": "\u7cfb\u7edf\u68c0\u6d4b\u7528\u6237\u610f\u56fe\uff0c\u8def\u7531\u8bf7\u6c42\u5230\u4e13\u7528\u4ee3\u7406\u6216\u751f\u6210\u5de5\u4f5c\u6d41\uff0c\u5e76\u52a8\u6001\u9009\u62e9\u672c\u5730\u6216\u4e91\u7aef\u6a21\u578b\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u4e91\u7aef\u7684\u672c\u5730\u8d85\u7ea7\u4ee3\u7406\u84dd\u56fe\u3002", "conclusion": "\u5c55\u671b\u8d85\u7ea7\u4ee3\u7406\u901a\u8fc7\u6280\u672f\u8fdb\u6b65\u65e0\u7f1d\u878d\u5165\u65e5\u5e38\u751f\u6d3b\u3002"}}
{"id": "2504.10490", "pdf": "https://arxiv.org/pdf/2504.10490", "abs": "https://arxiv.org/abs/2504.10490", "authors": ["Gabriel Bo", "Marc Bernardino", "Justin Gu"], "title": "GPT Meets Graphs and KAN Splines: Testing Novel Frameworks on Multitask Fine-Tuned GPT-2 with LoRA", "categories": ["cs.LG", "cs.CL"], "comment": "10 pages, 11 figures. This submission cites arXiv:2404.19756.\n  Supplementary materials and additional information are available at\n  arXiv:2404.19756", "summary": "We explore the potential of integrating learnable and interpretable\nmodules--specifically Kolmogorov-Arnold Networks (KAN) and graph-based\nrepresentations--within a pre-trained GPT-2 model to enhance multi-task\nlearning accuracy. Motivated by the recent surge in using KAN and graph\nattention (GAT) architectures in chain-of-thought (CoT) models and debates over\ntheir benefits compared to simpler architectures like MLPs, we begin by\nenhancing a standard self-attention transformer using Low-Rank Adaptation\n(LoRA), fine-tuning hyperparameters, and incorporating L2 regularization. This\napproach yields significant improvements. To further boost interpretability and\nricher representations, we develop two variants that attempt to improve the\nstandard KAN and GAT: Graph LoRA and Hybrid-KAN LoRA (Learnable GPT). However,\nsystematic evaluations reveal that neither variant outperforms the optimized\nLoRA-enhanced transformer, which achieves 55.249% accuracy on the SST test set,\n99.18% on the CFIMDB dev set, and 89.9% paraphrase detection test accuracy. On\nsonnet generation, we get a CHRF score of 42.097. These findings highlight that\nefficient parameter adaptation via LoRA remains the most effective strategy for\nour tasks: sentiment analysis, paraphrase detection, and sonnet generation.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u5c06KAN\u548c\u56fe\u8868\u793a\u6574\u5408\u5230GPT-2\u4e2d\u4ee5\u63d0\u5347\u591a\u4efb\u52a1\u5b66\u4e60\u51c6\u786e\u6027\uff0c\u4f46\u53d1\u73b0\u4f18\u5316LoRA\u65b9\u6cd5\u66f4\u6709\u6548\u3002", "motivation": "\u53d7KAN\u548cGAT\u5728CoT\u6a21\u578b\u4e2d\u5e94\u7528\u7684 surge \u4ee5\u53ca\u4e0eMLP\u6bd4\u8f83\u7684\u8fa9\u8bba\u9a71\u52a8\uff0c\u65e8\u5728\u63d0\u5347\u591a\u4efb\u52a1\u5b66\u4e60\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528LoRA\u589e\u5f3a\u81ea\u6ce8\u610f\u529btransformer\uff0c\u8fdb\u884c\u8d85\u53c2\u6570\u5fae\u8c03\u548cL2\u6b63\u5219\u5316\uff1b\u5f00\u53d1Graph LoRA\u548cHybrid-KAN LoRA\u53d8\u4f53\u3002", "result": "\u4f18\u5316LoRA transformer\u5728SST\u4e0a55.249%\u51c6\u786e\u7387\uff0cCFIMDB\u4e0a99.18%\uff0c\u91ca\u4e49\u68c0\u6d4b\u4e0a89.9%\uff0c\u5341\u56db\u884c\u8bd7\u751f\u6210CHRF\u5f97\u5206\u4e3a42.097\uff1b\u53d8\u4f53\u672a\u4f18\u4e8e\u57fa\u51c6\u3002", "conclusion": "LoRA\u7684efficient\u53c2\u6570\u9002\u914d\u662f\u9488\u5bf9\u60c5\u611f\u5206\u6790\u3001\u91ca\u4e49\u68c0\u6d4b\u548c\u5341\u56db\u884c\u8bd7\u751f\u6210\u7684\u6700\u6709\u6548\u7b56\u7565\u3002"}}
{"id": "2504.10855", "pdf": "https://arxiv.org/pdf/2504.10855", "abs": "https://arxiv.org/abs/2504.10855", "authors": ["Yu Kawano", "Zhiyong Sun"], "title": "Virtual Contraction Approach to Decentralized Adaptive Stabilization of Nonlinear Time-Delayed Networks", "categories": ["eess.SY", "cs.SY", "math.OC"], "comment": null, "summary": "In this paper, we utilize a diagonally dominant structure for the\ndecentralized stabilization of unknown nonlinear time-delayed networks.\nGeneralizing the idea of virtual contraction analysis to time-delayed systems,\nwe demonstrate that nonlinear time-delayed networks can be stabilized by\ndiagonal high-gains if the input matrices possess certain generalized\n(column/row) diagonally dominant properties. To achieve stabilization of\nunknown networks, we further propose a distributed adaptive tuning rule for\neach individual gain function, ensuring that all closed-loop trajectories\nconverge to the origin. The effectiveness of the proposed decentralized\nadaptive control is verified in a case study on epidemic spreading control in\nSIS networks with transmission delays.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u5bf9\u89d2\u5360\u4f18\u7ed3\u6784\u5b9e\u73b0\u672a\u77e5\u975e\u7ebf\u6027\u65f6\u5ef6\u7f51\u7edc\u7684\u53bb\u4e2d\u5fc3\u5316\u7a33\u5b9a\u5316\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u63a7\u5236\u548c\u75ab\u60c5\u4f20\u64ad\u6848\u4f8b\u9a8c\u8bc1\u3002", "motivation": "\u9488\u5bf9\u672a\u77e5\u975e\u7ebf\u6027\u65f6\u5ef6\u7f51\u7edc\u7a33\u5b9a\u5316\u7684\u9700\u6c42\uff0c\u63a8\u5e7f\u865a\u62df\u6536\u7f29\u5206\u6790\u65b9\u6cd5\u4ee5\u5904\u7406\u65f6\u5ef6\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5bf9\u89d2\u9ad8\u589e\u76ca\u548c\u5177\u6709\u5e7f\u4e49\u5bf9\u89d2\u5360\u4f18\u5c5e\u6027\u7684\u8f93\u5165\u77e9\u9635\uff0c\u4ee5\u53ca\u5206\u5e03\u5f0f\u81ea\u9002\u5e94\u8c03\u8c10\u89c4\u5219\u6765\u7a33\u5b9a\u7f51\u7edc\u3002", "result": "\u5b9e\u73b0\u4e86\u7f51\u7edc\u7a33\u5b9a\u5316\uff0c\u6240\u6709\u95ed\u73af\u8f68\u8ff9\u6536\u655b\u5230\u539f\u70b9\uff0c\u5e76\u5728SIS\u7f51\u7edc\u75ab\u60c5\u4f20\u64ad\u63a7\u5236\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u6709\u6548\u3002", "conclusion": "\u63d0\u51fa\u7684\u53bb\u4e2d\u5fc3\u5316\u81ea\u9002\u5e94\u63a7\u5236\u65b9\u6cd5\u5bf9\u65f6\u5ef6\u7f51\u7edc\u7a33\u5b9a\u5316\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2504.10527", "pdf": "https://arxiv.org/pdf/2504.10527", "abs": "https://arxiv.org/abs/2504.10527", "authors": ["Leonardo Arrighi", "Ingrid Alves de Moraes", "Marco Zullich", "Michele Simonato", "Douglas Fernandes Barbin", "Sylvio Barbon Junior"], "title": "Explainable Artificial Intelligence techniques for interpretation of food datasets: a review", "categories": ["cs.AI", "cs.CY", "A.1"], "comment": "33 pages, 8 figures, 5 tables", "summary": "Artificial Intelligence (AI) has become essential for analyzing complex data\nand solving highly-challenging tasks. It is being applied across numerous\ndisciplines beyond computer science, including Food Engineering, where there is\na growing demand for accurate and trustworthy predictions to meet stringent\nfood quality standards. However, this requires increasingly complex AI models,\nraising reliability concerns. In response, eXplainable AI (XAI) has emerged to\nprovide insights into AI decision-making, aiding model interpretation by\ndevelopers and users. Nevertheless, XAI remains underutilized in Food\nEngineering, limiting model reliability. For instance, in food quality control,\nAI models using spectral imaging can detect contaminants or assess freshness\nlevels, but their opaque decision-making process hinders adoption. XAI\ntechniques such as SHAP (Shapley Additive Explanations) and Grad-CAM\n(Gradient-weighted Class Activation Mapping) can pinpoint which spectral\nwavelengths or image regions contribute most to a prediction, enhancing\ntransparency and aiding quality control inspectors in verifying AI-generated\nassessments. This survey presents a taxonomy for classifying food quality\nresearch using XAI techniques, organized by data types and explanation methods,\nto guide researchers in choosing suitable approaches. We also highlight trends,\nchallenges, and opportunities to encourage the adoption of XAI in Food\nEngineering.", "AI": {"tldr": "\u8fd9\u7bc7\u8c03\u67e5\u901a\u8fc7\u5206\u7c7b\u6cd5\u7ec4\u7ec7XAI\u5728\u98df\u54c1\u8d28\u91cf\u7814\u7a76\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u8ba8\u8bba\u8d8b\u52bf\u3001\u6311\u6218\u548c\u673a\u4f1a\u3002", "motivation": "AI\u6a21\u578b\u5728\u98df\u54c1\u5de5\u7a0b\u4e2d\u590d\u6742\u6027\u589e\u52a0\uff0c\u53ef\u9760\u6027\u62c5\u5fe7\u7a81\u51fa\uff0cXAI\u4f7f\u7528\u4e0d\u8db3\uff0c\u9700\u8981\u63d0\u5347\u900f\u660e\u5ea6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6570\u636e\u7c7b\u578b\u548c\u89e3\u91ca\u65b9\u6cd5\u7684\u5206\u7c7b\u6cd5\uff0c\u7528\u4e8e\u6307\u5bfc\u7814\u7a76\u4eba\u5458\u9009\u62e9XAI\u65b9\u6cd5\u3002", "result": "\u7a81\u51fa\u4e86XAI\u5728\u98df\u54c1\u5de5\u7a0b\u4e2d\u7684\u8d8b\u52bf\u3001\u6311\u6218\u548c\u673a\u4f1a\uff0c\u4ee5\u4fc3\u8fdb\u5176\u91c7\u7528\u3002", "conclusion": "\u9f13\u52b1\u5728\u98df\u54c1\u5de5\u7a0b\u4e2d\u91c7\u7528XAI\uff0c\u901a\u8fc7\u5206\u7c7b\u6cd5\u548c\u8ba8\u8bba\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2504.10536", "pdf": "https://arxiv.org/pdf/2504.10536", "abs": "https://arxiv.org/abs/2504.10536", "authors": ["Lihong Zhang", "Yue Li"], "title": "Federated Learning with Layer Skipping: Efficient Training of Large Language Models for Healthcare NLP", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Federated learning (FL) enables collaborative model training across\norganizations without sharing raw data, addressing crucial privacy concerns in\nhealthcare natural language processing (NLP). However, training large language\nmodels (LLMs) in federated settings faces significant challenges, including\ncommunication overhead and data heterogeneity. We propose Layer-Skipping\nFederated Learning, where only selected layers of a pre-trained LLM are\nfine-tuned across clients while others remain frozen. Applied to LLaMA 3.2-1B,\nour approach reduces communication costs by approximately 70% while maintaining\nperformance within 2% of centralized training. We evaluate our method on\nclinical NER and classification tasks using i2b2 and MIMIC-III datasets. Our\nexperiments demonstrate that Layer-Skipping FL outperforms competitive\nbaselines, handles non-IID clinical data distributions effectively, and shows\nrobustness when combined with differential privacy. This approach represents a\npractical solution for privacy-preserving collaborative learning in healthcare\nNLP.", "AI": {"tldr": "\u63d0\u51faLayer-Skipping Federated Learning\u65b9\u6cd5\uff0c\u51cf\u5c11\u8054\u90a6\u5b66\u4e60\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u901a\u4fe1\u5f00\u9500\uff0c\u540c\u65f6\u5728\u533b\u7597NLP\u4efb\u52a1\u4e2d\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u53ef\u89e3\u51b3\u533b\u7597NLP\u4e2d\u7684\u9690\u79c1\u95ee\u9898\uff0c\u4f46\u9762\u4e34\u901a\u4fe1\u5f00\u9500\u548c\u6570\u636e\u5f02\u8d28\u6027\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4ec5\u5fae\u8c03\u9884\u8bad\u7ec3LLM\u9009\u5b9a\u5c42\u7684Layer-Skipping FL\u65b9\u6cd5\uff0c\u4f7f\u7528LLaMA 3.2-1B\u6a21\u578b\uff0c\u5728i2b2\u548cMIMIC-III\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e34\u5e8a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u5206\u7c7b\u4efb\u52a1\u3002", "result": "\u51cf\u5c11\u7ea670%\u901a\u4fe1\u6210\u672c\uff0c\u6027\u80fd\u4ec5\u6bd4\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u4f4e2%\uff0c\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5904\u7406\u975eIID\u6570\u636e\u5e76\u4e0e\u5dee\u5206\u9690\u79c1\u517c\u5bb9\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u662f\u533b\u7597NLP\u4e2d\u9690\u79c1\u4fdd\u62a4\u534f\u4f5c\u5b66\u4e60\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.10954", "pdf": "https://arxiv.org/pdf/2504.10954", "abs": "https://arxiv.org/abs/2504.10954", "authors": ["Irene Schimperna", "Lea Bold", "Karl Worthmann"], "title": "Offset-free Nonlinear MPC with Koopman-based Surrogate Models", "categories": ["eess.SY", "cs.SY", "math.OC"], "comment": "10 pages, 3 figures", "summary": "In this paper, we design offset-free nonlinear Model Predictive Control (MPC)\nfor surrogate models based on Extended Dynamic Mode Decomposition (EDMD). The\nmodel used for prediction in MPC is augmented with a disturbance term, that is\nestimated by an observer. If the full information about the equilibrium of the\nreal system is not available, a reference calculator is introduced in the\nalgorithm to compute the MPC state and input references. The control algorithm\nguarantees offset-free tracking of the controlled output under the assumption\nthat the modeling errors are asymptotically constant. The effectiveness of the\nproposed approach is showcased with numerical simulations for two popular\nbenchmark systems: the van-der-Pol oscillator and the four-tanks process.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u4e86\u57fa\u4e8eEDMD\u7684\u4ee3\u7406\u6a21\u578b\u7684\u504f\u79fb\u81ea\u7531\u975e\u7ebf\u6027MPC\uff0c\u901a\u8fc7\u5e72\u6270\u4f30\u8ba1\u548c\u53c2\u8003\u8ba1\u7b97\u4fdd\u8bc1\u8ddf\u8e2a\u7cbe\u5ea6\uff0c\u5e76\u5728\u57fa\u51c6\u7cfb\u7edf\u4e2d\u9a8c\u8bc1\u3002", "motivation": "\u5904\u7406MPC\u5efa\u6a21\u8bef\u5dee\uff0c\u786e\u4fdd\u5728\u5e73\u8861\u4fe1\u606f\u672a\u77e5\u65f6\u5b9e\u73b0\u504f\u79fb\u81ea\u7531\u8ddf\u8e2a\u3002", "method": "\u4f7f\u7528EDMD\u6784\u5efa\u4ee3\u7406\u6a21\u578b\uff0c\u6dfb\u52a0\u5e72\u6270\u9879\u7531\u89c2\u5bdf\u5668\u4f30\u8ba1\uff1b\u5f15\u5165\u53c2\u8003\u8ba1\u7b97\u5668\u8ba1\u7b97MPC\u53c2\u8003\u72b6\u6001\u548c\u8f93\u5165\u3002", "result": "\u7b97\u6cd5\u5728\u5efa\u6a21\u8bef\u5dee\u6052\u5b9a\u65f6\u4fdd\u8bc1\u504f\u79fb\u81ea\u7531\u8ddf\u8e2a\uff1b\u901a\u8fc7van-der-Pol\u632f\u8361\u5668\u548c\u56db\u6c34\u7bb1\u8fc7\u7a0b\u7684\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u5904\u7406\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2504.10649", "pdf": "https://arxiv.org/pdf/2504.10649", "abs": "https://arxiv.org/abs/2504.10649", "authors": ["Matthew Zalesak", "Hins Hu", "Samitha Samaranayake"], "title": "Ride-pool Assignment Algorithms: Modern Implementation and Swapping Heuristics", "categories": ["cs.AI", "cs.ET"], "comment": null, "summary": "On-demand ride-pooling has emerged as a popular urban transportation\nsolution, addressing the efficiency limitations of traditional ride-hailing\nservices by grouping multiple riding requests with spatiotemporal proximity\ninto a single vehicle. Although numerous algorithms have been developed for the\nRide-pool Assignment Problem (RAP) -- a core component of ride-pooling systems,\nthere is a lack of open-source implementations, making it difficult to\nbenchmark these algorithms on a common dataset and objective. In this paper, we\npresent the implementation details of a ride-pool simulator that encompasses\nseveral key ride-pool assignment algorithms, along with associated components\nsuch as vehicle routing and rebalancing. We also open-source a highly optimized\nand modular C++ codebase, designed to facilitate the extension of new\nalgorithms and features. Additionally, we introduce a family of swapping-based\nlocal-search heuristics to enhance existing ride-pool assignment algorithms,\nachieving a better balance between performance and computational efficiency.\nExtensive experiments on a large-scale, real-world dataset from Manhattan, NYC\nreveal that while all selected algorithms perform comparably, the newly\nproposed Multi-Round Linear Assignment with Cyclic Exchange (LA-MR-CE)\nalgorithm achieves a state-of-the-art service rate with significantly reduced\ncomputational time. Furthermore, an in-depth analysis suggests that a\nperformance barrier exists for all myopic ride-pool assignment algorithms due\nto the system's capacity bottleneck, and incorporating future information could\nbe key to overcoming this limitation.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u5f00\u6e90\u4e58\u8f66\u6c60\u6a21\u62df\u5668\uff0c\u5b9e\u73b0\u4e86\u5173\u952e\u7b97\u6cd5\uff0c\u5e76\u63d0\u51fa\u9ad8\u6548\u65b0\u7b97\u6cd5LA-MR-CE\u3002", "motivation": "\u7f3a\u4e4f\u4e58\u8f66\u6c60\u5206\u914d\u7b97\u6cd5\u5f00\u6e90\u5b9e\u73b0\uff0c\u96be\u4ee5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u5b9e\u73b0C++\u57fa\u4e8e\u6a21\u62df\u5668\uff0c\u5305\u62ec\u8f66\u8f86\u8def\u7531\u3001\u518d\u5e73\u8861\u548c\u4ea4\u6362\u5f0f\u5c40\u90e8\u641c\u7d22\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4ee5\u53caLA-MR-CE\u7b97\u6cd5\u3002", "result": "\u66fc\u54c8\u987f\u6570\u636e\u96c6\u5b9e\u9a8c\u663e\u793aLA-MR-CE\u7b97\u6cd5\u670d\u52a1\u7387\u9ad8\u3001\u8ba1\u7b97\u65f6\u95f4\u77ed\uff1b\u6240\u6709\u77ed\u89c6\u7b97\u6cd5\u5b58\u5728\u5bb9\u91cf\u74f6\u9888\u3002", "conclusion": "\u514b\u670d\u6027\u80fd\u9650\u5236\u9700\u7eb3\u5165\u672a\u6765\u4fe1\u606f\u3002"}}
{"id": "2504.10551", "pdf": "https://arxiv.org/pdf/2504.10551", "abs": "https://arxiv.org/abs/2504.10551", "authors": ["Lili Zhao", "Qi Liu", "Wei Chen", "Liyi Chen", "Ruijun Sun", "Min Hou", "Yang Wang", "Shijin Wang"], "title": "MiMu: Mitigating Multiple Shortcut Learning Behavior of Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Empirical Risk Minimization (ERM) models often rely on spurious correlations\nbetween features and labels during the learning process, leading to shortcut\nlearning behavior that undermines robustness generalization performance.\nCurrent research mainly targets identifying or mitigating a single shortcut;\nhowever, in real-world scenarios, cues within the data are diverse and unknown.\nIn empirical studies, we reveal that the models rely to varying extents on\ndifferent shortcuts. Compared to weak shortcuts, models depend more heavily on\nstrong shortcuts, resulting in their poor generalization ability. To address\nthese challenges, we propose MiMu, a novel method integrated with\nTransformer-based ERMs designed to Mitigate Multiple shortcut learning\nbehavior, which incorporates self-calibration strategy and self-improvement\nstrategy. In the source model, we preliminarily propose the self-calibration\nstrategy to prevent the model from relying on shortcuts and make overconfident\npredictions. Then, we further design self-improvement strategy in target model\nto reduce the reliance on multiple shortcuts. The random mask strategy involves\nrandomly masking partial attention positions to diversify the focus of target\nmodel other than concentrating on a fixed region. Meanwhile, the adaptive\nattention alignment module facilitates the alignment of attention weights to\nthe calibrated source model, without the need for post-hoc attention maps or\nsupervision. Finally, extensive experiments conducted on Natural Language\nProcessing (NLP) and Computer Vision (CV) demonstrate the effectiveness of MiMu\nin improving robustness generalization abilities.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faMiMu\u65b9\u6cd5\uff0c\u7528\u4e8e\u7f13\u89e3\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\uff08ERM\uff09\u6a21\u578b\u4e2d\u7684\u591a\u79cd\u6377\u5f84\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u9ad8\u9c81\u68d2\u6027\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "ERM\u6a21\u578b\u5e38\u4f9d\u8d56\u865a\u5047\u76f8\u5173\u6027\u548c\u6377\u5f84\u5b66\u4e60\uff0c\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u5dee\uff1b\u771f\u5b9e\u6570\u636e\u4e2d\u5b58\u5728\u591a\u79cd\u672a\u77e5\u6377\u5f84\uff0c\u6a21\u578b\u66f4\u4f9d\u8d56\u5f3a\u6377\u5f84\u3002", "method": "\u63d0\u51faMiMu\u65b9\u6cd5\uff0c\u6574\u5408Transformer-based ERM\uff0c\u5305\u62ec\u6e90\u6a21\u578b\u7684\u81ea\u6821\u51c6\u7b56\u7565\u548c\u76ee\u6807\u6a21\u578b\u7684\u81ea\u63d0\u5347\u7b56\u7565\uff08\u5982\u968f\u673a\u63a9\u7801\u548c\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u5bf9\u9f50\u6a21\u5757\uff09\u3002", "result": "\u5728NLP\u548cCV\u9886\u57df\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cMiMu\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MiMu\u6210\u529f\u7f13\u89e3\u4e86\u591a\u4e2a\u6377\u5f84\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2504.10960", "pdf": "https://arxiv.org/pdf/2504.10960", "abs": "https://arxiv.org/abs/2504.10960", "authors": ["Evagoras Makridis", "Themistoklis Charalambous"], "title": "A Linear Push-Pull Average Consensus Algorithm for Delay-Prone Networks", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "In this paper, we address the average consensus problem of multi-agent\nsystems for possibly unbalanced and delay-prone networks with directional\ninformation flow. We propose a linear distributed algorithm (referred to as\nRPPAC) that handles asynchronous updates and time-varying heterogeneous\ninformation delays. Our proposed distributed algorithm utilizes a\nsurplus-consensus mechanism and information regarding the number of incoming\nand outgoing links to guarantee state averaging, despite the imbalanced and\ndelayed information flow in directional networks. The convergence of the RPPAC\nalgorithm is examined using key properties of the backward product of\ntime-varying matrices that correspond to different snapshots of the directional\naugmented network.", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u63d0\u51faRPPAC\u7b97\u6cd5\uff0c\u89e3\u51b3\u591a\u4ee3\u7406\u7cfb\u7edf\u5728\u4e0d\u5e73\u8861\u548c\u5ef6\u8fdf\u7f51\u7edc\u4e2d\u7684\u5e73\u5747\u5171\u8bc6\u95ee\u9898\u3002", "motivation": "\u9488\u5bf9\u591a\u4ee3\u7406\u7cfb\u7edf\u5728\u53ef\u80fd\u4e0d\u5e73\u8861\u3001\u6613\u53d7\u5ef6\u8fdf\u7684\u5b9a\u5411\u7f51\u7edc\u4e2d\u5e73\u5747\u5171\u8bc6\u95ee\u9898\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u7ebf\u6027\u5206\u5e03\u5f0fRPPAC\u7b97\u6cd5\uff0c\u5229\u7528\u5269\u4f59\u5171\u8bc6\u673a\u5236\u548c\u94fe\u8def\u4fe1\u606f\uff0c\u5904\u7406\u5f02\u6b65\u66f4\u65b0\u548c\u65f6\u53d8\u5ef6\u8fdf\u3002", "result": "\u7b97\u6cd5\u4fdd\u8bc1\u72b6\u6001\u5e73\u5747\uff0c\u5e76\u901a\u8fc7\u65f6\u53d8\u77e9\u9635\u540e\u5411\u4e58\u79ef\u5206\u6790\u6536\u655b\u6027\u3002", "conclusion": "RPPAC\u7b97\u6cd5\u5728\u5b9a\u5411\u7f51\u7edc\u4e2d\u5b9e\u73b0\u5e73\u5747\u5171\u8bc6\uff0c\u5c3d\u7ba1\u4fe1\u606f\u6d41\u4e0d\u5e73\u8861\u548c\u6709\u5ef6\u8fdf\u3002"}}
{"id": "2504.10831", "pdf": "https://arxiv.org/pdf/2504.10831", "abs": "https://arxiv.org/abs/2504.10831", "authors": ["Hyojun Ahn", "Seungcheol Oh", "Gyu Seon Kim", "Soyi Jung", "Soohyun Park", "Joongheon Kim"], "title": "Hallucination-Aware Generative Pretrained Transformer for Cooperative Aerial Mobility Control", "categories": ["cs.AI", "cs.RO", "68T05"], "comment": null, "summary": "This paper proposes SafeGPT, a two-tiered framework that integrates\ngenerative pretrained transformers (GPTs) with reinforcement learning (RL) for\nefficient and reliable unmanned aerial vehicle (UAV) last-mile deliveries. In\nthe proposed design, a Global GPT module assigns high-level tasks such as\nsector allocation, while an On-Device GPT manages real-time local route\nplanning. An RL-based safety filter monitors each GPT decision and overrides\nunsafe actions that could lead to battery depletion or duplicate visits,\neffectively mitigating hallucinations. Furthermore, a dual replay buffer\nmechanism helps both the GPT modules and the RL agent refine their strategies\nover time. Simulation results demonstrate that SafeGPT achieves higher delivery\nsuccess rates compared to a GPT-only baseline, while substantially reducing\nbattery consumption and travel distance. These findings validate the efficacy\nof combining GPT-based semantic reasoning with formal safety guarantees,\ncontributing a viable solution for robust and energy-efficient UAV logistics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSafeGPT\u6846\u67b6\uff0c\u5c06GPT\u4e0eRL\u7ed3\u5408\uff0c\u7528\u4e8e\u9ad8\u6548\u53ef\u9760\u7684UAV\u672b\u7aef\u914d\u9001\uff0c\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u6548\u7387\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3UAV\u914d\u9001\u4e2d\u7684\u6548\u7387\u548c\u5b89\u5168\u95ee\u9898\uff0c\u7279\u522b\u662fGPT\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4e24\u5c42GPT\u6846\u67b6\uff08\u5168\u7403GPT\u5206\u914d\u4efb\u52a1\u3001\u8bbe\u5907\u7aefGPT\u5b9e\u65f6\u89c4\u5212\uff09\u3001RL-based\u5b89\u5168\u8fc7\u6ee4\u5668\u548c\u53cc\u91cd\u91cd\u653e\u7f13\u51b2\u673a\u5236\u3002", "result": "\u7ed3\u679c\u663e\u793aSafeGPT\u6bd4GPT-only\u57fa\u7ebf\u6709\u66f4\u9ad8\u914d\u9001\u6210\u529f\u7387\uff0c\u5e76\u51cf\u5c11\u7535\u6c60\u6d88\u8017\u548c\u65c5\u884c\u8ddd\u79bb\u3002", "conclusion": "\u7ed3\u8bba\u9a8c\u8bc1\u4e86GPT\u8bed\u4e49\u63a8\u7406\u4e0e\u5b89\u5168\u4fdd\u8bc1\u7ed3\u5408\u7684\u6709\u6548\u6027\uff0c\u4e3a\u7a33\u5065\u8282\u80fd\u7684UAV\u7269\u6d41\u63d0\u4f9b\u65b9\u6848\u3002"}}
{"id": "2504.10552", "pdf": "https://arxiv.org/pdf/2504.10552", "abs": "https://arxiv.org/abs/2504.10552", "authors": ["Arash Torabi Goodarzi", "Roman Kochnev", "Waleed Khalid", "Furui Qin", "Tolgay Atinc Uzun", "Yashkumar Sanjaybhai Dhameliya", "Yash Kanubhai Kathiriya", "Zofia Antonina Bentyn", "Dmitry Ignatov", "Radu Timofte"], "title": "LEMUR Neural Network Dataset: Towards Seamless AutoML", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DL"], "comment": null, "summary": "Neural networks are fundamental in artificial intelligence, driving progress\nin computer vision and natural language processing. High-quality datasets are\ncrucial for their development, and there is growing interest in datasets\ncomposed of neural networks themselves to support benchmarking, automated\nmachine learning (AutoML), and model analysis. We introduce LEMUR, an open\nsource dataset of neural network models with well-structured code for diverse\narchitectures across tasks such as object detection, image classification,\nsegmentation, and natural language processing. LEMUR is primarily designed to\nenable fine-tuning of large language models (LLMs) for AutoML tasks, providing\na rich source of structured model representations and associated performance\ndata. Leveraging Python and PyTorch, LEMUR enables seamless extension to new\ndatasets and models while maintaining consistency. It integrates an\nOptuna-powered framework for evaluation, hyperparameter optimization,\nstatistical analysis, and graphical insights. LEMUR provides an extension that\nenables models to run efficiently on edge devices, facilitating deployment in\nresource-constrained environments. Providing tools for model evaluation,\npreprocessing, and database management, LEMUR supports researchers and\npractitioners in developing, testing, and analyzing neural networks.\nAdditionally, it offers an API that delivers comprehensive information about\nneural network models and their complete performance statistics with a single\nrequest, which can be used in experiments with code-generating large language\nmodels. The LEMUR will be released as an open source project under the MIT\nlicense upon acceptance of the paper.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86LEMUR\uff0c\u8fd9\u662f\u4e00\u4e2a\u5f00\u6e90\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u652f\u6301AutoML\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u6a21\u578b\u5206\u6790\u3002", "motivation": "\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u5bf9\u795e\u7ecf\u7f51\u7edc\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u7531\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7ec4\u6210\u7684\u7ed3\u6784\u5316\u6570\u636e\u96c6\uff0c\u4ee5\u63a8\u52a8\u57fa\u51c6\u6d4b\u8bd5\u3001AutoML\u548c\u6a21\u578b\u5206\u6790\u3002", "method": "\u4f7f\u7528Python\u548cPyTorch\u6784\u5efaLEMUR\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u4ee3\u7801\u548c\u6027\u80fd\u6570\u636e\uff0c\u96c6\u6210Optuna\u6846\u67b6\u8fdb\u884c\u8bc4\u4f30\u3001\u8d85\u53c2\u6570\u4f18\u5316\u548c\u5206\u6790\uff0c\u5e76\u652f\u6301\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002", "result": "LEMUR\u542f\u7528\u4e86LLM\u7684\u5fae\u8c03\u3001\u63d0\u4f9b\u4e86API\u8bbf\u95ee\u6a21\u578b\u4fe1\u606f\u548c\u6027\u80fd\u7edf\u8ba1\uff0c\u652f\u6301\u7814\u7a76\u4eba\u5458\u5728\u5f00\u53d1\u3001\u6d4b\u8bd5\u548c\u5206\u6790\u795e\u7ecf\u7f51\u7edc\u65f6\u4f7f\u7528\u3002", "conclusion": "LEMUR\u5c06\u4f5c\u4e3aMIT\u8bb8\u53ef\u5f00\u6e90\u9879\u76ee\u53d1\u5e03\uff0c\u5e2e\u52a9\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u9ad8\u6548\u90e8\u7f72\u548c\u5206\u6790\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002"}}
{"id": "2504.10964", "pdf": "https://arxiv.org/pdf/2504.10964", "abs": "https://arxiv.org/abs/2504.10964", "authors": ["Evagoras Makridis", "Gabriele Oliva", "Kasagatta Ramesh Narahari", "Mohammadreza Doostmohammadian", "Usman A. Khan", "Themistoklis Charalambous"], "title": "Distributed Optimization with Gradient Tracking over Heterogeneous Delay-Prone Directed Networks", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "In this paper, we address the distributed optimization problem over\nunidirectional networks with possibly time-invariant heterogeneous bounded\ntransmission delays. In particular, we propose a modified version of the\nAccelerated Distributed Directed OPTimization (ADD-OPT) algorithm, herein\ncalled Robustified ADD-OPT (R-ADD-OPT), which is able to solve the distributed\noptimization problem, even when the communication links suffer from\nheterogeneous but bounded transmission delays. We show that if the gradient\nstep-size of the R-ADD-OPT algorithm is within a certain range, which also\ndepends on the maximum time delay in the network, then the nodes are guaranteed\nto converge to the optimal solution of the distributed optimization problem.\nThe range of the gradient step-size that guarantees convergence can be computed\na priori based on the maximum time delay in the network.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faR-ADD-OPT\u7b97\u6cd5\uff0c\u89e3\u51b3\u5355\u5411\u7f51\u7edc\u4e2d\u5e26\u5f02\u6784\u5ef6\u8fdf\u7684\u5206\u5e03\u5f0f\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u4fdd\u8bc1\u6536\u655b\u3002", "motivation": "\u89e3\u51b3\u5355\u5411\u7f51\u7edc\u4e2d\u5b58\u5728\u5f02\u6784\u4f46\u6709\u754c\u4f20\u8f93\u5ef6\u8fdf\u7684\u5206\u5e03\u5f0f\u4f18\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51faR-ADD-OPT\u7b97\u6cd5\u7684\u4fee\u6539\u7248\uff0c\u4ee5\u5904\u7406\u5f02\u6784\u6709\u754c\u4f20\u8f93\u5ef6\u8fdf\u3002", "result": "\u5728\u7279\u5b9a\u68af\u5ea6\u6b65\u957f\u8303\u56f4\u5185\uff08\u53d6\u51b3\u4e8e\u6700\u5927\u5ef6\u8fdf\uff09\uff0c\u4fdd\u8bc1\u8282\u70b9\u6536\u655b\u5230\u6700\u4f18\u89e3\uff0c\u4e14\u6b65\u957f\u8303\u56f4\u53ef\u9884\u5148\u8ba1\u7b97\u3002", "conclusion": "\u7b97\u6cd5\u5728\u7ed9\u5b9a\u6761\u4ef6\u4e0b\u786e\u4fdd\u6536\u655b\u5230\u5206\u5e03\u5f0f\u4f18\u5316\u95ee\u9898\u7684\u6700\u4f18\u89e3\u3002"}}
{"id": "2504.10865", "pdf": "https://arxiv.org/pdf/2504.10865", "abs": "https://arxiv.org/abs/2504.10865", "authors": ["Han-Dong Lim", "Donghwan Lee"], "title": "Understanding the theoretical properties of projected Bellman equation, linear Q-learning, and approximate value iteration", "categories": ["cs.AI", "cs.LG"], "comment": "Initial submission", "summary": "In this paper, we study the theoretical properties of the projected Bellman\nequation (PBE) and two algorithms to solve this equation: linear Q-learning and\napproximate value iteration (AVI). We consider two sufficient conditions for\nthe existence of a solution to PBE : strictly negatively row dominating\ndiagonal (SNRDD) assumption and a condition motivated by the convergence of\nAVI. The SNRDD assumption also ensures the convergence of linear Q-learning,\nand its relationship with the convergence of AVI is examined. Lastly, several\ninteresting observations on the solution of PBE are provided when using\n$\\epsilon$-greedy policy.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u6295\u5f71Bellman\u65b9\u7a0b\uff08PBE\uff09\u7684\u7406\u8bba\u6027\u8d28\u3001\u89e3\u7684\u5b58\u5728\u6761\u4ef6\uff0c\u4ee5\u53ca\u7ebf\u6027Q\u5b66\u4e60\u548c\u8fd1\u4f3c\u503c\u8fed\u4ee3\uff08AVI\uff09\u7684\u6536\u655b\u3002", "motivation": "\u4e3a\u4e86\u63a2\u7d22PBE\u89e3\u7684\u5b58\u5728\u548c\u7b97\u6cd5\u6536\u655b\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4ee5\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e25\u683c\u8d1f\u884c\u4e3b\u5bfc\u5bf9\u89d2\uff08SNRDD\uff09\u5047\u8bbe\u548cAVI\u6536\u655b\u6761\u4ef6\uff0c\u8003\u5bdf\u7ebf\u6027Q\u5b66\u4e60\u548cAVI\u7b97\u6cd5\u3002", "result": "SNRDD\u5047\u8bbe\u786e\u4fdd\u7ebf\u6027Q\u5b66\u4e60\u7684\u6536\u655b\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u4e0eAVI\u6536\u655b\u7684\u5173\u7cfb\uff1b\u63d0\u4f9b\u4e86\u03b5-\u8d2a\u5a6a\u7b56\u7565\u4e0bPBE\u89e3\u7684\u89c2\u5bdf\u3002", "conclusion": "\u8bba\u6587\u4e3aPBE\u548c\u76f8\u5173\u7b97\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u6d1e\u89c1\uff0c\u6709\u52a9\u4e8e\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u7684\u7b97\u6cd5\u8bbe\u8ba1\u548c\u5e94\u7528\u3002"}}
{"id": "2504.10555", "pdf": "https://arxiv.org/pdf/2504.10555", "abs": "https://arxiv.org/abs/2504.10555", "authors": ["Marco Salm\u00e8", "Lorenzo Tronchin", "Rosa Sicilia", "Paolo Soda", "Valerio Guarrasi"], "title": "Beyond the Generative Learning Trilemma: Generative Model Assessment in Data Scarcity Domains", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Data scarcity remains a critical bottleneck impeding technological\nadvancements across various domains, including but not limited to medicine and\nprecision agriculture. To address this challenge, we explore the potential of\nDeep Generative Models (DGMs) in producing synthetic data that satisfies the\nGenerative Learning Trilemma: fidelity, diversity, and sampling efficiency.\nHowever, recognizing that these criteria alone are insufficient for practical\napplications, we extend the trilemma to include utility, robustness, and\nprivacy, factors crucial for ensuring the applicability of DGMs in real-world\nscenarios. Evaluating these metrics becomes particularly challenging in\ndata-scarce environments, as DGMs traditionally rely on large datasets to\nperform optimally. This limitation is especially pronounced in domains like\nmedicine and precision agriculture, where ensuring acceptable model performance\nunder data constraints is vital. To address these challenges, we assess the\nGenerative Learning Trilemma in data-scarcity settings using state-of-the-art\nevaluation metrics, comparing three prominent DGMs: Variational Autoencoders\n(VAEs), Generative Adversarial Networks (GANs), and Diffusion Models (DMs).\nFurthermore, we propose a comprehensive framework to assess utility,\nrobustness, and privacy in synthetic data generated by DGMs. Our findings\ndemonstrate varying strengths among DGMs, with each model exhibiting unique\nadvantages based on the application context. This study broadens the scope of\nthe Generative Learning Trilemma, aligning it with real-world demands and\nproviding actionable guidance for selecting DGMs tailored to specific\napplications.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u4f7f\u7528\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u6269\u5c55\u8bc4\u4f30\u6807\u51c6\u5e76\u6bd4\u8f83VAE\u3001GAN\u548cDM\u3002", "motivation": "\u6570\u636e\u7a00\u7f3a\u963b\u788d\u4e86\u533b\u5b66\u548c\u7cbe\u51c6\u519c\u4e1a\u7b49\u9886\u57df\u7684\u6280\u672f\u8fdb\u6b65\uff0c\u9700\u8981\u5408\u6210\u6570\u636e\u6ee1\u8db3\u4fdd\u771f\u5ea6\u3001\u591a\u6837\u6027\u3001\u91c7\u6837\u6548\u7387\u3001\u5b9e\u7528\u6027\u3001\u9c81\u68d2\u6027\u548c\u9690\u79c1\u6027\u3002", "method": "\u4f7f\u7528\u6700\u5148\u8fdb\u6307\u6807\u8bc4\u4f30\u751f\u6210\u5b66\u4e60\u4e09\u96be\u56f0\u5883\uff0c\u6bd4\u8f83VAE\u3001GAN\u548cDM\uff0c\u5e76\u63d0\u51fa\u6846\u67b6\u8bc4\u4f30\u5408\u6210\u6570\u636e\u7684\u5b9e\u7528\u6027\u3001\u9c81\u68d2\u6027\u548c\u9690\u79c1\u6027\u3002", "result": "\u53d1\u73b0\u4e0d\u540cDGM\u5728\u5e94\u7528\u4e2d\u5177\u6709\u72ec\u7279\u4f18\u52bf\u3002", "conclusion": "\u6269\u5c55\u4e09\u96be\u56f0\u5883\u4ee5\u9002\u5e94\u73b0\u5b9e\u9700\u6c42\uff0c\u5e76\u4e3a\u9009\u62e9\u5408\u9002\u7684DGM\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2504.11097", "pdf": "https://arxiv.org/pdf/2504.11097", "abs": "https://arxiv.org/abs/2504.11097", "authors": ["Maximilian B\u00f6hle", "Bernhard Schick", "Steffen M\u00fcller"], "title": "Steering Feedback in Dynamic Driving Simulators: Road-Induced and Non-Road-Induced Harshness", "categories": ["eess.SY", "cs.SY"], "comment": "11 pages, 5 figures, 5 tables, submitted to the IEEE Transactions on\n  Intelligent Vehicles. arXiv admin note: substantial text overlap with\n  arXiv:2403.17800", "summary": "Steering feedback plays a substantial role in the validity of driving\nsimulators for the virtual development of modern vehicles. Established\nobjective steering characteristics typically assess the feedback behavior in\nthe frequency range of up to 30 Hz while factors such as steering wheel and\nvehicle body vibrations at higher frequencies are mainly approached as comfort\nissues. This work investigates the influence of steering wheel and vehicle body\nexcitations in the frequency range between 30 and 100 Hz on the subjective\nevaluation of steering feedback in a dynamic driving simulator. A controlled\nsubject study with 42 participants was performed to compare a reference vehicle\nwith an electrical power steering system to four variants of its virtual\nrepresentation on a dynamic driving simulator. The effects of road-induced\nexcitations were investigated by comparing a semi-empirical and a physics-based\ntire model, while the influence of non-road-induced excitations was\ninvestigated by implementing engine and wheel orders. The simulator variants\nwere evaluated in comparison to the reference vehicle during closed-loop\ndriving on a country road in a single-blind within-subjects design. The\nsubjective evaluation focused on the perception of road feedback compared to\nthe reference vehicle. The statistical analysis of subjective results shows\nthat there is a strong effect of non-road-induced steering and vehicle body\nexcitations, while the effect of road-induced excitations is considerably less\npronounced.", "AI": {"tldr": "\u672c\u7814\u7a76\u8003\u5bdf\u4e8630-100 Hz\u9891\u7387\u632f\u52a8\u5bf9\u9a7e\u9a76\u6a21\u62df\u5668\u8f6c\u5411\u53cd\u9988\u4e3b\u89c2\u8bc4\u4ef7\u7684\u5f71\u54cd\uff0c\u7ed3\u679c\u663e\u793a\u975e\u9053\u8def\u8bf1\u53d1\u632f\u52a8\u7684\u5f71\u54cd\u66f4\u5927\u3002", "motivation": "\u8f6c\u5411\u53cd\u9988\u5bf9\u9a7e\u9a76\u6a21\u62df\u5668\u7684\u6709\u6548\u6027\u5f88\u91cd\u8981\uff0c\u4f46\u9ad8\u9891\u632f\u52a8\u5e38\u88ab\u5ffd\u89c6\u6216\u89c6\u4e3a\u8212\u9002\u6027\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u5176\u5bf9\u4e3b\u89c2\u8bc4\u4ef7\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u4e00\u9879\u6d89\u53ca42\u540d\u53c2\u4e0e\u8005\u7684\u63a7\u5236\u6027\u7814\u7a76\uff0c\u6bd4\u8f83\u53c2\u8003\u8f66\u8f86\u4e0e\u52a8\u6001\u9a7e\u9a76\u6a21\u62df\u5668\u7684\u56db\u4e2a\u53d8\u4f53\uff0c\u4f7f\u7528\u534a\u7ecf\u9a8c\u548c\u57fa\u4e8e\u7269\u7406\u7684\u8f6e\u80ce\u6a21\u578b\uff0c\u4ee5\u53ca\u6dfb\u52a0\u53d1\u52a8\u673a\u548c\u8f66\u8f6e\u9636\u6b21\u7684\u975e\u9053\u8def\u8bf1\u53d1\u6fc0\u53d1\uff0c\u91c7\u7528\u5355\u76f2\u5185\u7ec4\u8bbe\u8ba1\u5728\u4e61\u6751\u9053\u8def\u4e0a\u8fdb\u884c\u95ed\u73af\u9a7e\u9a76\u8bc4\u4ef7\u3002", "result": "\u7edf\u8ba1\u5206\u6790\u8868\u660e\uff0c\u975e\u9053\u8def\u8bf1\u53d1\u8f6c\u5411\u548c\u8f66\u8eab\u6fc0\u53d1\u5bf9\u4e3b\u89c2\u8bc4\u4ef7\u6709\u663e\u8457\u5f71\u54cd\uff0c\u800c\u9053\u8def\u8bf1\u53d1\u6fc0\u53d1\u7684\u6548\u679c\u8f83\u5f31\u3002", "conclusion": "\u8fd9\u5f3a\u8c03\u4e86\u5728\u9a7e\u9a76\u6a21\u62df\u5668\u8bbe\u8ba1\u4e2d\uff0c\u5e94\u66f4\u91cd\u89c6\u975e\u9053\u8def\u8bf1\u53d1\u632f\u52a8\u7684\u89d2\u8272\uff0c\u4ee5\u63d0\u9ad8\u6a21\u62df\u7684\u771f\u5b9e\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2504.10893", "pdf": "https://arxiv.org/pdf/2504.10893", "abs": "https://arxiv.org/abs/2504.10893", "authors": ["Yize Zhang", "Tianshu Wang", "Sirui Chen", "Kun Wang", "Xingyu Zeng", "Hongyu Lin", "Xianpei Han", "Le Sun", "Chaochao Lu"], "title": "ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search", "categories": ["cs.AI", "cs.CL"], "comment": "Project homepage: https://opencausalab.github.io/ARise", "summary": "Large language models (LLMs) have demonstrated impressive capabilities and\nare receiving increasing attention to enhance their reasoning through scaling\ntest--time compute. However, their application in open--ended,\nknowledge--intensive, complex reasoning scenarios is still limited.\nReasoning--oriented methods struggle to generalize to open--ended scenarios due\nto implicit assumptions of complete world knowledge. Meanwhile,\nknowledge--augmented reasoning (KAR) methods fail to address two core\nchallenges: 1) error propagation, where errors in early steps cascade through\nthe chain, and 2) verification bottleneck, where the explore--exploit tradeoff\narises in multi--branch decision processes. To overcome these limitations, we\nintroduce ARise, a novel framework that integrates risk assessment of\nintermediate reasoning states with dynamic retrieval--augmented generation\n(RAG) within a Monte Carlo tree search paradigm. This approach enables\neffective construction and optimization of reasoning plans across multiple\nmaintained hypothesis branches. Experimental results show that ARise\nsignificantly outperforms the state--of--the--art KAR methods by up to 23.10%,\nand the latest RAG-equipped large reasoning models by up to 25.37%.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165ARise\u6846\u67b6\uff0c\u901a\u8fc7\u98ce\u9669\u8bc4\u4f30\u548c\u52a8\u6001RAG\u6574\u5408Monte Carlo\u6811\u641c\u7d22\uff0c\u63d0\u5347LLM\u5728\u5f00\u653e\u5f0f\u63a8\u7406\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "LLM\u5728\u5f00\u653e\u5f0f\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u63a8\u7406\u4e2d\u53d7\u9650\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u77e5\u8bc6\u4e0d\u5b8c\u6574\u3001\u9519\u8bef\u4f20\u64ad\u548c\u9a8c\u8bc1\u74f6\u9888\u95ee\u9898\u3002", "method": "\u63d0\u51faARise\u6846\u67b6\uff0c\u7ed3\u5408\u4e2d\u95f4\u72b6\u6001\u98ce\u9669\u8bc4\u4f30\u3001\u52a8\u6001RAG\u548cMonte Carlo\u6811\u641c\u7d22\uff0c\u4f18\u5316\u591a\u5206\u652f\u63a8\u7406\u8ba1\u5212\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cARise\u6bd4\u6700\u5148\u8fdb\u77e5\u8bc6\u589e\u5f3a\u65b9\u6cd5\u63d0\u9ad8\u591a\u8fbe23.10%\uff0c\u6bd4RAG\u589e\u5f3a\u6a21\u578b\u63d0\u9ad8\u591a\u8fbe25.37%\u3002", "conclusion": "ARise\u6709\u6548\u89e3\u51b3\u63a8\u7406\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5177\u6709\u63a8\u5e7f\u6f5c\u529b\u3002"}}
{"id": "2504.10556", "pdf": "https://arxiv.org/pdf/2504.10556", "abs": "https://arxiv.org/abs/2504.10556", "authors": ["Lucas Heublein", "Simon Kocher", "Tobias Feigl", "Alexander R\u00fcgamer", "Christopher Mutschler", "Felix Ott"], "title": "VAE-based Feature Disentanglement for Data Augmentation and Compression in Generalized GNSS Interference Classification", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "94-05, 82-11", "E.0; I.2.0; I.5.4; I.5.1"], "comment": "7 pages, 9 figures", "summary": "Distributed learning and Edge AI necessitate efficient data processing,\nlow-latency communication, decentralized model training, and stringent data\nprivacy to facilitate real-time intelligence on edge devices while reducing\ndependency on centralized infrastructure and ensuring high model performance.\nIn the context of global navigation satellite system (GNSS) applications, the\nprimary objective is to accurately monitor and classify interferences that\ndegrade system performance in distributed environments, thereby enhancing\nsituational awareness. To achieve this, machine learning (ML) models can be\ndeployed on low-resource devices, ensuring minimal communication latency and\npreserving data privacy. The key challenge is to compress ML models while\nmaintaining high classification accuracy. In this paper, we propose variational\nautoencoders (VAEs) for disentanglement to extract essential latent features\nthat enable accurate classification of interferences. We demonstrate that the\ndisentanglement approach can be leveraged for both data compression and data\naugmentation by interpolating the lower-dimensional latent representations of\nsignal power. To validate our approach, we evaluate three VAE variants -\nvanilla, factorized, and conditional generative - on four distinct datasets,\nincluding two collected in controlled indoor environments and two real-world\nhighway datasets. Additionally, we conduct extensive hyperparameter searches to\noptimize performance. Our proposed VAE achieves a data compression rate ranging\nfrom 512 to 8,192 and achieves an accuracy up to 99.92%.", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAEs\uff09\u8fdb\u884c\u7279\u5f81\u89e3\u7f20\u7ed3\uff0c\u4ee5\u538b\u7f29\u548c\u589e\u5f3a\u6570\u636e\uff0c\u7528\u4e8e\u9ad8\u7cbe\u5ea6\u5206\u7c7bGNSS\u5e72\u6270\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u5b66\u4e60\u548cEdge AI\u5728GNSS\u5e94\u7528\u4e2d\u7684\u6311\u6218\uff0c\u5305\u62ec\u9ad8\u6548\u6570\u636e\u5904\u7406\u3001\u4f4e\u5ef6\u8fdf\u3001\u6570\u636e\u9690\u79c1\u548c\u6a21\u578b\u538b\u7f29\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "method": "\u63d0\u51faVAEs\u89e3\u7f20\u7ed3\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u7840\u3001\u56e0\u5b50\u5316\u548c\u6761\u4ef6\u751f\u6210\u53d8\u4f53\uff0c\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5e76\u8fdb\u884c\u8d85\u53c2\u6570\u4f18\u5316\u3002", "result": "\u5b9e\u73b0\u6570\u636e\u538b\u7f29\u7387512\u81f38192\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\u8fbe99.92%\u3002", "conclusion": "VAE\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u5e72\u6270\u5206\u7c7b\u548c\u663e\u8457\u6570\u636e\u538b\u7f29\uff0c\u63d0\u5347\u4e86\u5206\u5e03\u5f0f\u73af\u5883\u4e0b\u7684\u6027\u80fd\u3002"}}
{"id": "2504.11125", "pdf": "https://arxiv.org/pdf/2504.11125", "abs": "https://arxiv.org/abs/2504.11125", "authors": ["Dieter Teichrib", "Moritz Schulze Darup"], "title": "A mixed-integer framework for analyzing neural network-based controllers for piecewise affine systems with bounded disturbances", "categories": ["eess.SY", "cs.SY", "math.OC"], "comment": "8 pages, 3 figures, to be published in the proceedings of the 23rd\n  European Control Conference (2025)", "summary": "We present a method for representing the closed-loop dynamics of piecewise\naffine (PWA) systems with bounded additive disturbances and neural\nnetwork-based controllers as mixed-integer (MI) linear constraints. We show\nthat such representations enable the computation of robustly positively\ninvariant (RPI) sets for the specified system class by solving MI linear\nprograms. These RPI sets can subsequently be used to certify stability and\nconstraint satisfaction. Furthermore, the approach allows to handle non-linear\nsystems based on suitable PWA approximations and corresponding error bounds,\nwhich can be interpreted as the bounded disturbances from above.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\uff0c\u5c06\u5206\u6bb5\u4eff\u5c04\u7cfb\u7edf\u548c\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u5668\u7684\u95ed\u73af\u52a8\u529b\u5b66\u8868\u793a\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u7ea6\u675f\uff0c\u4ece\u800c\u8ba1\u7b97\u9c81\u68d2\u6b63\u4e0d\u53d8\u96c6\uff0c\u4ee5\u8bc1\u660e\u7a33\u5b9a\u6027\u5e76\u6ee1\u8db3\u7ea6\u675f\u3002", "motivation": "\u4e3a\u4e86\u5904\u7406\u5e26\u6709\u8fb9\u754c\u6270\u52a8\u548c\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u5668\u7684\u7cfb\u7edf\uff0c\u8bc1\u660e\u5176\u7a33\u5b9a\u6027\u5e76\u786e\u4fdd\u7ea6\u675f\u6ee1\u8db3\u3002", "method": "\u901a\u8fc7\u5c06\u7cfb\u7edf\u52a8\u529b\u5b66\u8868\u793a\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u7ea6\u675f\uff0c\u5e76\u901a\u8fc7\u6c42\u89e3\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u6765\u8ba1\u7b97\u9c81\u68d2\u6b63\u4e0d\u53d8\u96c6\u3002", "result": "\u6210\u529f\u8ba1\u7b97\u4e86\u9c81\u68d2\u6b63\u4e0d\u53d8\u96c6\uff0c\u80fd\u591f\u8bc1\u660e\u7a33\u5b9a\u6027\u3001\u7ea6\u675f\u6ee1\u8db3\uff0c\u5e76\u901a\u8fc7PWA\u903c\u8fd1\u5904\u7406\u975e\u7ebf\u6027\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u9002\u7528\u4e8e\u6307\u5b9a\u7cfb\u7edf\u7c7b\uff0c\u5e76\u901a\u8fc7\u8bef\u5dee\u8fb9\u754c\u6269\u5c55\u5230\u975e\u7ebf\u6027\u7cfb\u7edf\u3002"}}
{"id": "2504.11075", "pdf": "https://arxiv.org/pdf/2504.11075", "abs": "https://arxiv.org/abs/2504.11075", "authors": ["Dongmin Kim", "Hoshinori Kanazawa", "Naoto Yoshida", "Yasuo Kuniyoshi"], "title": "Emergence of Goal-Directed Behaviors via Active Inference with Self-Prior", "categories": ["cs.AI", "68T05, 68T40, 68T42", "I.2.0; I.2.6; I.2.9"], "comment": "20 pages, Code is available at\n  https://github.com/kim135797531/self-prior", "summary": "Infants often exhibit goal-directed behaviors, such as reaching for a sensory\nstimulus, even when no external reward criterion is provided. These\nintrinsically motivated behaviors facilitate spontaneous exploration and\nlearning of the body and environment during early developmental stages.\nAlthough computational modeling can offer insight into the mechanisms\nunderlying such behaviors, many existing studies on intrinsic motivation focus\nprimarily on how exploration contributes to acquiring external rewards. In this\npaper, we propose a novel density model for an agent's own multimodal sensory\nexperiences, called the \"self-prior,\" and investigate whether it can\nautonomously induce goal-directed behavior. Integrated within an active\ninference framework based on the free energy principle, the self-prior\ngenerates behavioral references purely from an intrinsic process that minimizes\nmismatches between average past sensory experiences and current observations.\nThis mechanism is also analogous to the acquisition and utilization of a body\nschema through continuous interaction with the environment. We examine this\napproach in a simulated environment and confirm that the agent spontaneously\nreaches toward a tactile stimulus. Our study implements intrinsically motivated\nbehavior shaped by the agent's own sensory experiences, demonstrating the\nspontaneous emergence of intentional behavior during early development.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u81ea\u8eab\u611f\u5b98\u7ecf\u9a8c\u7684\u5bc6\u5ea6\u6a21\u578b\uff0c\u8bf1\u5bfc\u81ea\u4e3b\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\uff0c\u6a21\u62df\u5a74\u513f\u65e9\u671f\u53d1\u5c55\u9636\u6bb5\u7684\u81ea\u53d1\u63a2\u7d22\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u591a\u5173\u6ce8\u5916\u90e8\u5956\u52b1\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7eaf\u5185\u5728\u52a8\u673a\u673a\u5236\u7406\u89e3\u5a74\u513f\u81ea\u53d1\u63a2\u7d22\u548c\u5b66\u4e60\u884c\u4e3a\u3002", "method": "\u63d0\u51fa'\u81ea\u5148\u9a8c'\u5bc6\u5ea6\u6a21\u578b\uff0c\u6574\u5408\u5230\u57fa\u4e8e\u81ea\u7531\u80fd\u91cf\u539f\u7406\u7684\u4e3b\u52a8\u63a8\u7406\u6846\u67b6\u4e2d\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u8fc7\u53bb\u4e0e\u5f53\u524d\u611f\u5b98\u7ecf\u9a8c\u7684\u4e0d\u5339\u914d\u751f\u6210\u884c\u4e3a\u53c2\u8003\uff0c\u5e76\u5728\u6a21\u62df\u73af\u5883\u4e2d\u9a8c\u8bc1\u3002", "result": "\u4ee3\u7406\u81ea\u53d1\u5730\u4f38\u624b\u89e6\u78b0\u89e6\u89c9\u523a\u6fc0\uff0c\u5c55\u793a\u4e86\u57fa\u4e8e\u81ea\u8eab\u611f\u5b98\u7684\u5185\u5728\u52a8\u673a\u884c\u4e3a\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\u4e86\u901a\u8fc7\u81ea\u8eab\u611f\u5b98\u7ecf\u9a8c\u53ef\u4ee5\u81ea\u4e3b\u8bf1\u5bfc\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\uff0c\u6a21\u62df\u4e86\u5a74\u513f\u65e9\u671f\u53d1\u5c55\u7684\u610f\u56fe\u884c\u4e3a emerg\u3002"}}
{"id": "2504.10559", "pdf": "https://arxiv.org/pdf/2504.10559", "abs": "https://arxiv.org/abs/2504.10559", "authors": ["Keyu Duan", "Zichen Liu", "Xin Mao", "Tianyu Pang", "Changyu Chen", "Qiguang Chen", "Michael Qizhe Shieh", "Longxu Dou"], "title": "Efficient Process Reward Model Training via Active Learning", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 4 figures", "summary": "Process Reward Models (PRMs) provide step-level supervision to large language\nmodels (LLMs), but scaling up training data annotation remains challenging for\nboth humans and LLMs. To address this limitation, we propose an active learning\napproach, ActPRM, which proactively selects the most uncertain samples for\ntraining, substantially reducing labeling costs. During training, we use the\nPRM to estimate uncertainty after the forward pass, retaining only highly\nuncertain data. A capable yet costly reasoning model then labels this data.\nThen we compute the loss with respect to the labels and update the PRM's\nweights. We compare ActPRM vs. vanilla fine-tuning, on a pool-based active\nlearning setting, demonstrating that ActPRM reduces 50% annotation, but\nachieving the comparable or even better performance. Beyond annotation\nefficiency, we further advance the actively trained PRM by filtering over 1M+\nmath reasoning trajectories with ActPRM, retaining 60% of the data. A\nsubsequent training on this selected dataset yields a new state-of-the-art\n(SOTA) PRM on ProcessBench (75.0%) and PRMBench (65.5%) compared with same\nsized models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faActPRM\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\uff0c\u51cf\u5c11PRMs\u8bad\u7ec3\u6570\u636e\u6807\u6ce8\u6210\u672c50%\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u8fc7\u6ee4\u63d0\u5347\u6027\u80fd\u81f3SOTA\u6c34\u5e73\u3002", "motivation": "\u89e3\u51b3PRMs\u6b65\u7ea7\u76d1\u7763\u8bad\u7ec3\u6570\u636e\u6807\u6ce8\u89c4\u6a21\u5316\u56f0\u96be\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u4eba\u7c7b\u548cLLM\u6807\u6ce8\u6210\u672c\u9ad8\u4e14\u6311\u6218\u6027\u5927\u3002", "method": "\u4f7f\u7528ActPRM\u4f30\u8ba1\u6837\u672c\u4e0d\u786e\u5b9a\u6027\uff0c\u9009\u62e9\u9ad8\u4e0d\u786e\u5b9a\u6570\u636e\uff0c\u7531\u9ad8\u6548\u63a8\u7406\u6a21\u578b\u6807\u6ce8\uff0c\u7136\u540e\u8ba1\u7b97\u635f\u5931\u66f4\u65b0PRM\u6743\u91cd\u3002", "result": "ActPRM\u51cf\u5c1150%\u6807\u6ce8\u91cf\uff0c\u6027\u80fd\u76f8\u5f53\u6216\u66f4\u597d\uff1b\u8fc7\u6ee4100+\u4e07\u6570\u5b66\u8f68\u8ff9\uff0c\u4fdd\u755960%\u6570\u636e\uff0cPRM\u5728ProcessBench\u8fbe75.0%\u3001PRMBench\u8fbe65.5%\u7684\u65b0SOTA\u3002", "conclusion": "ActPRM\u63d0\u9ad8\u4e86\u6807\u6ce8\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684PRMs\u8bad\u7ec3\u3002"}}
{"id": "2504.11261", "pdf": "https://arxiv.org/pdf/2504.11261", "abs": "https://arxiv.org/abs/2504.11261", "authors": ["Hannes Petrenz", "Johannes K\u00f6hler", "Francesco Borrelli"], "title": "Robust MPC for Uncertain Linear Systems -- Combining Model Adaptation and Iterative Learning", "categories": ["eess.SY", "cs.SY", "math.OC"], "comment": "Github link to the example:\n  https://github.com/HannesPetrenz/RALMPC_Linear_Uncertain_Systems", "summary": "This paper presents a robust adaptive learning Model Predictive Control (MPC)\nframework for linear systems with parametric uncertainties and additive\ndisturbances performing iterative tasks. The approach iteratively refines the\nparameter estimates using set membership estimation. Performance enhancement\nover iterations is achieved by learning the terminal cost from data. Safety is\nenforced using a terminal set, which is also learned iteratively. The proposed\nmethod guarantees recursive feasibility, constraint satisfaction, and a robust\nbound on the closed-loop cost. Numerical simulations on a mass-spring-damper\nsystem demonstrate improved computational efficiency and control performance\ncompared to an existing robust adaptive MPC approach.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u81ea\u9002\u5e94\u5b66\u4e60MPC\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u7ebf\u6027\u7cfb\u7edf\u7684\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u548c\u5e72\u6270\uff0c\u901a\u8fc7\u8fed\u4ee3\u5b66\u4e60\u63d0\u9ad8\u6027\u80fd\u548c\u5b89\u5168\u3002", "motivation": "\u52a8\u673a\u662f\u9488\u5bf9\u8fed\u4ee3\u4efb\u52a1\u4e2d\u4e0d\u786e\u5b9a\u6027\u7684\u6311\u6218\uff0c\u63d0\u9ad8\u63a7\u5236\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u65b9\u6cd5\u4f7f\u7528\u96c6\u5408\u6210\u5458\u4f30\u8ba1\u8fed\u4ee3\u6539\u8fdb\u53c2\u6570\u4f30\u8ba1\uff0c\u4ece\u6570\u636e\u5b66\u4e60\u7ec8\u7aef\u6210\u672c\uff0c\u5e76\u8fed\u4ee3\u5b66\u4e60\u7ec8\u7aef\u96c6\u3002", "result": "\u7ed3\u679c\u4fdd\u8bc1\u9012\u5f52\u53ef\u884c\u6027\u3001\u7ea6\u675f\u6ee1\u8db3\u548c\u95ed\u73af\u6210\u672c\u7684\u9c81\u68d2\u754c\uff1b\u6a21\u62df\u663e\u793a\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u597d\u7684\u8ba1\u7b97\u6548\u7387\u548c\u63a7\u5236\u6027\u80fd\u3002", "conclusion": "\u7ed3\u8bba\u662f\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5b89\u5168\u6027\u548c\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u9c81\u68d2\u81ea\u9002\u5e94MPC\u65b9\u6cd5\u3002"}}
{"id": "2504.11159", "pdf": "https://arxiv.org/pdf/2504.11159", "abs": "https://arxiv.org/abs/2504.11159", "authors": ["Annemarie Jutte", "Faizan Ahmed", "Jeroen Linssen", "Maurice van Keulen"], "title": "C-SHAP for time series: An approach to high-level temporal explanations", "categories": ["cs.AI"], "comment": "10 pages, 6 figures", "summary": "Time series are ubiquitous in domains such as energy forecasting, healthcare,\nand industry. Using AI systems, some tasks within these domains can be\nefficiently handled. Explainable AI (XAI) aims to increase the reliability of\nAI solutions by explaining model reasoning. For time series, many XAI methods\nprovide point- or sequence-based attribution maps. These methods explain model\nreasoning in terms of low-level patterns. However, they do not capture\nhigh-level patterns that may also influence model reasoning. We propose a\nconcept-based method to provide explanations in terms of these high-level\npatterns. In this paper, we present C-SHAP for time series, an approach which\ndetermines the contribution of concepts to a model outcome. We provide a\ngeneral definition of C-SHAP and present an example implementation using time\nseries decomposition. Additionally, we demonstrate the effectiveness of the\nmethodology through a use case from the energy domain.", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u63d0\u51faC-SHAP\u65b9\u6cd5\uff0c\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u6982\u5ff5-based XAI\uff0c\u89e3\u91ca\u9ad8\u5c42\u6b21\u6a21\u5f0f\uff0c\u5e76\u5728\u80fd\u6e90\u9886\u57df\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709XAI\u65b9\u6cd5\u4ec5\u5173\u6ce8\u4f4e\u5c42\u6b21\u6a21\u5f0f\uff0c\u5ffd\u7565\u9ad8\u5c42\u6b21\u6a21\u5f0f\u5bf9\u6a21\u578b\u63a8\u7406\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u57fa\u4e8e\u6982\u5ff5\u7684\u89e3\u91ca\u65b9\u6cd5\u3002", "method": "\u63d0\u51faC-SHAP\u65b9\u6cd5\uff0c\u5305\u62ec\u4e00\u822c\u5b9a\u4e49\u548c\u4f7f\u7528\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u7684\u5b9e\u73b0\u793a\u4f8b\u3002", "result": "\u901a\u8fc7\u80fd\u6e90\u9886\u57df\u7684\u7528\u4f8b\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "C-SHAP\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217AI\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4fc3\u8fdb\u4e86AI\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2504.10561", "pdf": "https://arxiv.org/pdf/2504.10561", "abs": "https://arxiv.org/abs/2504.10561", "authors": ["Runqing Wu", "Fei Ye", "Rongyao Hu", "Guoxi Huang"], "title": "Self-Controlled Dynamic Expansion Model for Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 3 figures, 6 tables, Continual Learning, Cross-Domain\n  Continual Learning, Mixture Model", "summary": "Continual Learning (CL) epitomizes an advanced training paradigm wherein\nprior data samples remain inaccessible during the acquisition of new tasks.\nNumerous investigations have delved into leveraging a pre-trained Vision\nTransformer (ViT) to enhance model efficacy in continual learning. Nonetheless,\nthese approaches typically utilize a singular, static backbone, which\ninadequately adapts to novel tasks, particularly when engaging with diverse\ndata domains, due to a substantial number of inactive parameters. This paper\naddresses this limitation by introducing an innovative Self-Controlled Dynamic\nExpansion Model (SCDEM), which orchestrates multiple distinct trainable\npre-trained ViT backbones to furnish diverse and semantically enriched\nrepresentations. Specifically, by employing the multi-backbone architecture as\na shared module, the proposed SCDEM dynamically generates a new expert with\nminimal parameters to accommodate a new task. A novel Collaborative\nOptimization Mechanism (COM) is introduced to synergistically optimize multiple\nbackbones by harnessing prediction signals from historical experts, thereby\nfacilitating new task learning without erasing previously acquired knowledge.\nAdditionally, a novel Feature Distribution Consistency (FDC) approach is\nproposed to align semantic similarity between previously and currently learned\nrepresentations through an optimal transport distance-based mechanism,\neffectively mitigating negative knowledge transfer effects. Furthermore, to\nalleviate over-regularization challenges, this paper presents a novel Dynamic\nLayer-Wise Feature Attention Mechanism (DLWFAM) to autonomously determine the\npenalization intensity on each trainable representation layer. An extensive\nseries of experiments have been conducted to evaluate the proposed\nmethodology's efficacy, with empirical results corroborating that the approach\nattains state-of-the-art performance.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u63a7\u52a8\u6001\u6269\u5c55\u6a21\u578b\uff08SCDEM\uff09\uff0c\u7528\u4e8e\u89c6\u89c9Transformer\u7684\u6301\u7eed\u5b66\u4e60\uff0c\u901a\u8fc7\u591a\u4e2a\u9aa8\u5e72\u7f51\u7edc\u548c\u4f18\u5316\u673a\u5236\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u4e2d\uff0c\u4f7f\u7528\u5355\u4e00\u9759\u6001\u9884\u8bad\u7ec3\u89c6\u89c9Transformer\u9aa8\u5e72\u7f51\u7edc\u65e0\u6cd5\u826f\u597d\u9002\u5e94\u65b0\u4efb\u52a1\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u57df\u591a\u6837\u65f6\uff0c\u5b58\u5728\u8bb8\u591a\u4e0d\u6d3b\u8dc3\u53c2\u6570\u548c\u8d1f\u77e5\u8bc6\u8f6c\u79fb\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5f15\u5165SCDEM\uff0c\u4f7f\u7528\u591a\u4e2a\u53ef\u8bad\u7ec3\u7684ViT\u9aa8\u5e72\u7f51\u7edc\uff1b\u534f\u4f5c\u4f18\u5316\u673a\u5236\uff08COM\uff09\u5229\u7528\u5386\u53f2\u4e13\u5bb6\u9884\u6d4b\u4fe1\u53f7\u4f18\u5316\u5b66\u4e60\uff1b\u7279\u5f81\u5206\u5e03\u4e00\u81f4\u6027\uff08FDC\uff09\u901a\u8fc7\u6700\u4f18\u4f20\u8f93\u8ddd\u79bb\u5bf9\u9f50\u8bed\u4e49\u76f8\u4f3c\u6027\uff1b\u52a8\u6001\u5c42\u7ea7\u7279\u5f81\u6ce8\u610f\u529b\u673a\u5236\uff08DLWFAM\uff09\u81ea\u52a8\u8c03\u6574\u60e9\u7f5a\u5f3a\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u6301\u7eed\u5b66\u4e60\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5730\u7f13\u89e3\u4e86\u8fc7\u5ea6\u6b63\u5219\u5316\u548c\u8d1f\u77e5\u8bc6\u8f6c\u79fb\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u52a8\u6001\u591a\u9aa8\u5e72\u7f51\u7edc\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2504.11285", "pdf": "https://arxiv.org/pdf/2504.11285", "abs": "https://arxiv.org/abs/2504.11285", "authors": ["Hazem Abdel-Khalek", "Eddy Jalbout", "Caspar Schau\u00df", "Benjamin Pfluger"], "title": "Balancing hydrogen delivery in national energy systems: impact of the temporal flexibility of hydrogen delivery on export prices", "categories": ["eess.SY", "cs.SY"], "comment": "6 pages, 3 figures, 2 tables", "summary": "Hydrogen is expected to play a key role in the energy transition. Analyses\nexploring the price of hydrogen usually calculate average or marginal\nproduction costs regardless of the time of delivery. A key factor that affects\nthe price of hydrogen is the balancing costs, which we define as the expense of\nensuring a steady schedule of hydrogen delivery. We explore the effect of\ndelivering hydrogen to the export ports at different schedules, ranging from\nfully flexible to moderately stable with a daily and weekly buffer, to fully\nstable. We quantify the rise in hydrogen price with strict balancing constraint\nin three countries: Brazil, Morocco and Turkey, and three export volumes: 10,\n50 and 200 TWh. The price difference between the flexible and stable schedules\nwas found to reach a maximum of 36% in Brazil, 47% in Morocco and 18% in Turkey\nacross the different export volumes.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u6c22\u6c14\u4ea4\u4ed8\u65f6\u95f4\u8868\u5bf9\u4ef7\u683c\u7684\u5f71\u54cd\uff0c\u5f3a\u8c03\u5e73\u8861\u6210\u672c\u5bfc\u81f4\u7684\u4ef7\u683c\u4e0a\u5347\uff0c\u6700\u9ad8\u53ef\u8fbe47%\u3002", "motivation": "\u6c22\u6c14\u5728\u80fd\u6e90\u8f6c\u578b\u4e2d\u5173\u952e\uff0c\u4f46\u73b0\u6709\u5206\u6790\u5ffd\u7565\u4ea4\u4ed8\u65f6\u95f4\uff0c\u6545\u7814\u7a76\u5e73\u8861\u6210\u672c\u7684\u5f71\u54cd\u3002", "method": "\u6a21\u62df\u4e0d\u540c\u4ea4\u4ed8\u65f6\u95f4\u8868\uff08\u7075\u6d3b\u5230\u7a33\u5b9a\uff09\uff0c\u5728\u5df4\u897f\u3001\u6469\u6d1b\u54e5\u3001\u571f\u8033\u5176\u4e09\u56fd\uff0c\u51fa\u53e3\u91cf10\u300150\u3001200 TWh\u4e0b\u91cf\u5316\u4ef7\u683c\u53d8\u5316\u3002", "result": "\u4ef7\u683c\u5dee\u5f02\u6700\u5927\u4e3a\u5df4\u897f36%\u3001\u6469\u6d1b\u54e547%\u3001\u571f\u8033\u517618%\uff0c\u968f\u56fd\u5bb6\u4e0e\u51fa\u53e3\u91cf\u53d8\u5316\u3002", "conclusion": "\u4e25\u683c\u5e73\u8861\u7ea6\u675f\u663e\u8457\u63d0\u9ad8\u6c22\u6c14\u4ef7\u683c\uff0c\u5f3a\u8c03\u4ea4\u4ed8\u65f6\u95f4\u8868\u5728\u89c4\u5212\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2504.11190", "pdf": "https://arxiv.org/pdf/2504.11190", "abs": "https://arxiv.org/abs/2504.11190", "authors": ["Anna Sofia Lippolis", "Andrea Giovanni Nuzzolese", "Aldo Gangemi"], "title": "Enhancing multimodal analogical reasoning with Logic Augmented Generation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances in Large Language Models have demonstrated their capabilities\nacross a variety of tasks. However, automatically extracting implicit knowledge\nfrom natural language remains a significant challenge, as machines lack active\nexperience with the physical world. Given this scenario, semantic knowledge\ngraphs can serve as conceptual spaces that guide the automated text generation\nreasoning process to achieve more efficient and explainable results. In this\npaper, we apply a logic-augmented generation (LAG) framework that leverages the\nexplicit representation of a text through a semantic knowledge graph and\napplies it in combination with prompt heuristics to elicit implicit analogical\nconnections. This method generates extended knowledge graph triples\nrepresenting implicit meaning, enabling systems to reason on unlabeled\nmultimodal data regardless of the domain. We validate our work through three\nmetaphor detection and understanding tasks across four datasets, as they\nrequire deep analogical reasoning capabilities. The results show that this\nintegrated approach surpasses current baselines, performs better than humans in\nunderstanding visual metaphors, and enables more explainable reasoning\nprocesses, though still has inherent limitations in metaphor understanding,\nespecially for domain-specific metaphors. Furthermore, we propose a thorough\nerror analysis, discussing issues with metaphorical annotations and current\nevaluation methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLAG\u6846\u67b6\uff0c\u4f7f\u7528\u8bed\u4e49\u77e5\u8bc6\u56fe\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u9690\u542b\u77e5\u8bc6\u63d0\u53d6\u548c\u6bd4\u55bb\u7406\u89e3\u65b9\u9762\u7684\u6027\u80fd\u3002", "motivation": "\u673a\u5668\u96be\u4ee5\u4ece\u81ea\u7136\u8bed\u8a00\u4e2d\u63d0\u53d6\u9690\u542b\u77e5\u8bc6\uff0c\u7f3a\u4e4f\u7269\u7406\u4e16\u754c\u7ecf\u9a8c\uff0c\u56e0\u6b64\u9700\u8981\u8bed\u4e49\u77e5\u8bc6\u56fe\u4f5c\u4e3a\u6982\u5ff5\u7a7a\u95f4\u6307\u5bfc\u63a8\u7406\u3002", "method": "\u5e94\u7528\u903b\u8f91\u589e\u5f3a\u751f\u6210\uff08LAG\uff09\u6846\u67b6\uff0c\u7ed3\u5408\u8bed\u4e49\u77e5\u8bc6\u56fe\u548c\u63d0\u793a\u542f\u53d1\u5f0f\uff0c\u751f\u6210\u6269\u5c55\u7684\u77e5\u8bc6\u56fe\u4e09\u5143\u7ec4\u4ee5\u63d0\u53d6\u9690\u542b\u7c7b\u6bd4\u8fde\u63a5\u3002", "result": "\u5728\u4e09\u4e2a\u6bd4\u55bb\u68c0\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u548c\u4eba\u7c7b\uff0c\u5c24\u5176\u5728\u89c6\u89c9\u6bd4\u55bb\u7406\u89e3\u4e2d\u66f4\u53ef\u89e3\u91ca\uff0c\u4f46\u5b58\u5728\u9886\u57df\u7279\u5b9a\u6bd4\u55bb\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u901a\u8fc7\u9519\u8bef\u5206\u6790\u8ba8\u8bba\u4e86\u6bd4\u55bb\u6807\u6ce8\u548c\u8bc4\u4f30\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5e76\u6307\u51fa\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2504.10612", "pdf": "https://arxiv.org/pdf/2504.10612", "abs": "https://arxiv.org/abs/2504.10612", "authors": ["Michal Balcerak", "Tamaz Amiranashvili", "Suprosanna Shit", "Antonio Terpin", "Sebastian Kaltenbach", "Petros Koumoutsakos", "Bjoern Menze"], "title": "Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Generative models often map noise to data by matching flows or scores, but\nthese approaches become cumbersome for incorporating partial observations or\nadditional priors. Inspired by recent advances in Wasserstein gradient flows,\nwe propose Energy Matching, a framework that unifies flow-based approaches with\nthe flexibility of energy-based models (EBMs). Far from the data manifold,\nsamples move along curl-free, optimal transport paths from noise to data. As\nthey approach the data manifold, an entropic energy term guides the system into\na Boltzmann equilibrium distribution, explicitly capturing the underlying\nlikelihood structure of the data. We parameterize this dynamic with a single\ntime-independent scalar field, which serves as both a powerful generator and a\nflexible prior for effective regularization of inverse problems. Our method\nsubstantially outperforms existing EBMs on CIFAR-10 generation (FID 3.97\ncompared to 8.61), while retaining the simulation-free training of\ntransport-based approaches away from the data manifold. Additionally, we\nexploit the flexibility of our method and introduce an interaction energy for\ndiverse mode exploration. Our approach focuses on learning a static scalar\npotential energy -- without time conditioning, auxiliary generators, or\nadditional networks -- marking a significant departure from recent EBM methods.\nWe believe this simplified framework significantly advances EBM capabilities\nand paves the way for their broader adoption in generative modeling across\ndiverse domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEnergy Matching\u6846\u67b6\uff0c\u5c06\u751f\u6210\u6a21\u578b\u7684\u6d41\u65b9\u6cd5\u4e0e\u80fd\u91cf\u6a21\u578b\u7ed3\u5408\uff0c\u63d0\u9ad8\u751f\u6210\u6027\u80fd\u548c\u7075\u6d3b\u6027\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u5904\u7406\u90e8\u5206\u89c2\u5bdf\u548c\u989d\u5916\u5148\u9a8c\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u4f5c\u8005\u53d7Wasserstein\u68af\u5ea6\u6d41\u542f\u53d1\uff0c\u5f00\u53d1\u65b0\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u5355\u4e00\u65f6\u95f4\u65e0\u5173\u7684\u6807\u91cf\u573a\uff0c\u5f15\u5bfc\u6837\u672c\u4ece\u566a\u58f0\u901a\u8fc7\u6700\u4f18\u4f20\u8f93\u8def\u5f84\u5230\u6570\u636e\uff0c\u5e76\u7531\u71b5\u80fd\u5f15\u5bfc\u5230Boltzmann\u5e73\u8861\u3002", "result": "\u5728CIFAR-10\u4e0aFID\u5206\u6570\u4e3a3.97\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd58.61\uff1b\u4fdd\u7559\u65e0\u6a21\u62df\u8bad\u7ec3\uff0c\u5e76\u5f15\u5165\u4ea4\u4e92\u80fd\u91cf\u63a2\u7d22\u6a21\u5f0f\u3002", "conclusion": "\u7b80\u5316EBM\u6846\u67b6\uff0c\u63d0\u5347\u5176\u80fd\u529b\u548c\u5e94\u7528\u8303\u56f4\uff0c\u4fc3\u8fdb\u751f\u6210\u5efa\u6a21\u7684\u5e7f\u6cdb\u91c7\u7528\u3002"}}
{"id": "2504.11319", "pdf": "https://arxiv.org/pdf/2504.11319", "abs": "https://arxiv.org/abs/2504.11319", "authors": ["Yiqing Zhou", "Karsten Naert", "Dirk Nuyens"], "title": "Sensitivity Analysis of State Space Models for Scrap Composition Estimation in EAF and BOF", "categories": ["eess.SY", "cs.SY", "93C41, 90B30, 80A19, 93E11, 93C10"], "comment": null, "summary": "This study develops and analyzes linear and nonlinear state space models for\nestimating the elemental composition of scrap steel used in steelmaking, with\napplications to Electric Arc Furnace (EAF) and Basic Oxygen Furnace (BOF)\nprocesses. The models incorporate mass balance equations and are fitted using a\nmodified Kalman filter for linear cases and the Unscented Kalman Filter (UKF)\nfor nonlinear cases. Using Cu and Cr as representative elements, we assess the\nsensitivity of model predictions to measurement noise in key process variables,\nincluding steel mass, steel composition, scrap input mass, slag mass, and iron\noxide fraction in slag. Results show that the models are robust to moderate\nnoise levels in most variables, particularly when errors are below $10\\%$.\nHowever, accuracy significantly deteriorates with noise in slag mass\nestimation. These findings highlight the practical feasibility and limitations\nof applying state space models for real-time scrap composition estimation in\nindustrial settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u7ebf\u6027\u4e0e\u975e\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u4f30\u8ba1\u70bc\u94a2\u5e9f\u94a2\u5143\u7d20\u7ec4\u6210\uff0c\u5e94\u7528\u4e8e\u7535\u5f27\u7089\u548c\u78b1\u6027\u6c27\u6c14\u7089\uff0c\u4f7f\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u62df\u5408\uff0c\u7ed3\u679c\u663e\u793a\u5bf9\u5927\u591a\u6570\u53d8\u91cf\u566a\u58f0\u9c81\u68d2\uff0c\u4f46\u5bf9\u7089\u6e23\u8d28\u91cf\u566a\u58f0\u654f\u611f\u3002", "motivation": "\u52a8\u673a\u662f\u63d0\u9ad8\u70bc\u94a2\u8fc7\u7a0b\u4e2d\u5e9f\u94a2\u6210\u5206\u4f30\u8ba1\u51c6\u786e\u6027\uff0c\u4ee5\u4f18\u5316\u7535\u5f27\u7089\u548c\u78b1\u6027\u6c27\u6c14\u7089\u7684\u64cd\u4f5c\u6548\u7387\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u6784\u5efa\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7ed3\u5408\u8d28\u91cf\u5e73\u8861\u65b9\u7a0b\uff0c\u4f7f\u7528\u6539\u8fdb\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u548c\u65e0\u8ff9\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff08UKF\uff09\u62df\u5408\uff0c\u5e76\u4ee5Cu\u548cCr\u5143\u7d20\u8bc4\u4f30\u566a\u58f0\u654f\u611f\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6a21\u578b\u5bf9\u5927\u591a\u6570\u53d8\u91cf\u566a\u58f0\u6c34\u5e73\u4f4e\u4e8e10%\u65f6\u9c81\u68d2\uff0c\u4f46\u5bf9\u7089\u6e23\u8d28\u91cf\u566a\u58f0\u654f\u611f\uff0c\u51c6\u786e\u6027\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u4e86\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u5728\u5de5\u4e1a\u5b9e\u65f6\u4f30\u8ba1\u5e9f\u94a2\u6210\u5206\u7684\u53ef\u884c\u6027\u53ca\u5176\u5c40\u9650\u6027\u3002"}}
{"id": "2504.11200", "pdf": "https://arxiv.org/pdf/2504.11200", "abs": "https://arxiv.org/abs/2504.11200", "authors": ["Irene Celino", "Mario Scrocca", "Agnese Chiatti"], "title": "Mutual Understanding between People and Systems via Neurosymbolic AI and Knowledge Graphs", "categories": ["cs.AI"], "comment": "26 pages, 13 figures, 1 table; pre-print version of book chapter", "summary": "This chapter investigates the concept of mutual understanding between humans\nand systems, positing that Neuro-symbolic Artificial Intelligence (NeSy AI)\nmethods can significantly enhance this mutual understanding by leveraging\nexplicit symbolic knowledge representations with data-driven learning models.\nWe start by introducing three critical dimensions to characterize mutual\nunderstanding: sharing knowledge, exchanging knowledge, and governing\nknowledge. Sharing knowledge involves aligning the conceptual models of\ndifferent agents to enable a shared understanding of the domain of interest.\nExchanging knowledge relates to ensuring the effective and accurate\ncommunication between agents. Governing knowledge concerns establishing rules\nand processes to regulate the interaction between agents. Then, we present\nseveral different use case scenarios that demonstrate the application of NeSy\nAI and Knowledge Graphs to aid meaningful exchanges between human, artificial,\nand robotic agents. These scenarios highlight both the potential and the\nchallenges of combining top-down symbolic reasoning with bottom-up neural\nlearning, guiding the discussion of the coverage provided by current solutions\nalong the dimensions of sharing, exchanging, and governing knowledge.\nConcurrently, this analysis facilitates the identification of gaps and less\ndeveloped aspects in mutual understanding to address in future research.", "AI": {"tldr": "\u672c\u7ae0\u63a2\u8ba8\u795e\u7ecf\u7b26\u53f7AI\uff08NeSy AI\uff09\u5982\u4f55\u901a\u8fc7\u7ed3\u5408\u7b26\u53f7\u77e5\u8bc6\u548c\u6570\u636e\u9a71\u52a8\u6a21\u578b\u63d0\u5347\u4eba\u7c7b\u4e0e\u7cfb\u7edf\u76f8\u4e92\u7406\u89e3\uff0c\u5f15\u5165\u5171\u4eab\u3001\u4ea4\u6362\u548c\u6cbb\u7406\u77e5\u8bc6\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u901a\u8fc7\u7528\u4f8b\u573a\u666f\u5c55\u793a\u5e94\u7528\u6f5c\u529b\u3001\u6311\u6218\u548c\u7814\u7a76\u7a7a\u767d\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u4eba\u7c7b\u4e0eAI\u7cfb\u7edf\u76f8\u4e92\u7406\u89e3\u7684\u4e0d\u8db3\uff0c\u5229\u7528NeSy AI\u589e\u5f3a\u77e5\u8bc6\u5171\u4eab\u3001\u4ea4\u6362\u548c\u6cbb\u7406\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5b9a\u4e49\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\uff0c\u5e76\u4f7f\u7528NeSy AI\u548c\u77e5\u8bc6\u56fe\u8c31\u5728\u7528\u4f8b\u573a\u666f\u4e2d\u6f14\u793a\u7b26\u53f7\u63a8\u7406\u4e0e\u795e\u7ecf\u5b66\u4e60\u7684\u7ed3\u5408\u3002", "result": "\u7ed3\u679c\u5c55\u793a\u4e86NeSy AI\u7684\u6f5c\u529b\u4e0e\u6311\u6218\uff0c\u8bc6\u522b\u4e86\u5728\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u8986\u76d6\u4e0d\u8db3\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03NeSy AI\u53ef\u6539\u5584\u76f8\u4e92\u7406\u89e3\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u586b\u8865\u7a7a\u767d\u3002"}}
{"id": "2504.10677", "pdf": "https://arxiv.org/pdf/2504.10677", "abs": "https://arxiv.org/abs/2504.10677", "authors": ["Muhammad Al-Zafar Khan", "Jamal Al-Karaki"], "title": "Achieving Optimal Tissue Repair Through MARL with Reward Shaping and Curriculum Learning", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": "14 pages, 4 figures, submitted to the 10th International Conference\n  on Information and Communication Technology for Intelligent Systems (ICTIS)", "summary": "In this paper, we present a multi-agent reinforcement learning (MARL)\nframework for optimizing tissue repair processes using engineered biological\nagents. Our approach integrates: (1) stochastic reaction-diffusion systems\nmodeling molecular signaling, (2) neural-like electrochemical communication\nwith Hebbian plasticity, and (3) a biologically informed reward function\ncombining chemical gradient tracking, neural synchronization, and robust\npenalties. A curriculum learning scheme guides the agent through progressively\ncomplex repair scenarios. In silico experiments demonstrate emergent repair\nstrategies, including dynamic secretion control and spatial coordination.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4f18\u5316\u7ec4\u7ec7\u4fee\u590d\uff0c\u6574\u5408\u751f\u7269\u6a21\u578b\u548c\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u6709\u6548\u7b56\u7565\u3002", "motivation": "\u4f18\u5316\u4f7f\u7528\u5de5\u7a0b\u5316\u751f\u7269\u4ee3\u7406\u7684\u7ec4\u7ec7\u4fee\u590d\u8fc7\u7a0b\u3002", "method": "\u6574\u5408\u968f\u673a\u53cd\u5e94-\u6269\u6563\u7cfb\u7edf\u3001Hebbian\u53ef\u5851\u6027\u901a\u4fe1\u3001\u751f\u7269\u5956\u52b1\u51fd\u6570\u548c\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6848\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u5c55\u793a\u52a8\u6001\u5206\u6ccc\u63a7\u5236\u548c\u7a7a\u95f4\u534f\u8c03\u7b49\u7d27\u6025\u4fee\u590d\u7b56\u7565\u3002", "conclusion": "\u6846\u67b6\u5728\u865a\u62df\u5b9e\u9a8c\u4e2d\u6709\u6548\uff0c\u53ef\u80fd\u5e94\u7528\u4e8e\u5b9e\u9645\u7ec4\u7ec7\u4fee\u590d\u4f18\u5316\u3002"}}
{"id": "2504.11355", "pdf": "https://arxiv.org/pdf/2504.11355", "abs": "https://arxiv.org/abs/2504.11355", "authors": ["Alberto Castillo", "Elliot Pryor", "Anas El Fathi", "Boris Kovatchev", "Marc Breton"], "title": "Neural Networks for on-chip Model Predictive Control: a Method to Build Optimized Training Datasets and its application to Type-1 Diabetes", "categories": ["eess.SY", "cs.AI", "cs.SY"], "comment": null, "summary": "Training Neural Networks (NNs) to behave as Model Predictive Control (MPC)\nalgorithms is an effective way to implement them in constrained embedded\ndevices. By collecting large amounts of input-output data, where inputs\nrepresent system states and outputs are MPC-generated control actions, NNs can\nbe trained to replicate MPC behavior at a fraction of the computational cost.\nHowever, although the composition of the training data critically influences\nthe final NN accuracy, methods for systematically optimizing it remain\nunderexplored. In this paper, we introduce the concept of Optimally-Sampled\nDatasets (OSDs) as ideal training sets and present an efficient algorithm for\ngenerating them. An OSD is a parametrized subset of all the available data that\n(i) preserves existing MPC information up to a certain numerical resolution,\n(ii) avoids duplicate or near-duplicate states, and (iii) becomes saturated or\ncomplete. We demonstrate the effectiveness of OSDs by training NNs to replicate\nthe University of Virginia's MPC algorithm for automated insulin delivery in\nType-1 Diabetes, achieving a four-fold improvement in final accuracy. Notably,\ntwo OSD-trained NNs received regulatory clearance for clinical testing as the\nfirst NN-based control algorithm for direct human insulin dosing. This\nmethodology opens new pathways for implementing advanced optimizations on\nresource-constrained embedded platforms, potentially revolutionizing how\ncomplex algorithms are deployed.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4f7f\u7528\u4f18\u5316\u91c7\u6837\u6570\u636e\u96c6\uff08OSDs\uff09\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6a21\u4eff\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\uff0c\u4ee5\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u9ad8\u6548\u5b9e\u73b0\uff0c\u5e76\u5c55\u793a\u4e86\u663e\u8457\u51c6\u786e\u6027\u63d0\u5347\u548c\u4e34\u5e8a\u5e94\u7528\u3002", "motivation": "\u8bad\u7ec3\u6570\u636e\u7ec4\u6210\u5bf9\u795e\u7ecf\u7f51\u7edc\u51c6\u786e\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f18\u5316\u65b9\u6cd5\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff1b\u9700\u8981\u9ad8\u6548\u5730\u5728\u7ea6\u675f\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u5b9e\u73b0MPC\u3002", "method": "\u5f15\u5165OSDs\u6982\u5ff5\u548c\u751f\u6210\u7b97\u6cd5\uff0cOSDs\u662f\u53c2\u6570\u5316\u6570\u636e\u5b50\u96c6\uff0c\u4fdd\u7559MPC\u4fe1\u606f\u3001\u907f\u514d\u91cd\u590d\u72b6\u6001\uff0c\u5e76\u5b9e\u73b0\u6570\u636e\u9971\u548c\u3002", "result": "\u8bad\u7ec3NN\u590d\u5236\u7279\u5b9aMPC\u7b97\u6cd5\uff0c\u51c6\u786e\u6027\u63d0\u9ad8\u4e86\u56db\u500d\uff1b\u4e24\u4e2aOSDs\u8bad\u7ec3\u7684NN\u83b7\u5f97\u4e34\u5e8a\u6d4b\u8bd5\u76d1\u7ba1\u6279\u51c6\uff0c\u4f5c\u4e3a\u9996\u4e2a\u76f4\u63a5\u7528\u4e8e\u4eba\u7c7b\u80f0\u5c9b\u7d20\u5242\u91cf\u7684NN\u63a7\u5236\u7b97\u6cd5\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u5728\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u90e8\u7f72\u9ad8\u7ea7\u4f18\u5316\u7b97\u6cd5\u5f00\u8f9f\u65b0\u9014\u5f84\uff0c\u53ef\u80fd\u5f7b\u5e95\u6539\u53d8\u590d\u6742\u7b97\u6cd5\u7684\u90e8\u7f72\u65b9\u5f0f\u3002"}}
{"id": "2504.11239", "pdf": "https://arxiv.org/pdf/2504.11239", "abs": "https://arxiv.org/abs/2504.11239", "authors": ["Chang Yang", "Ruiyu Wang", "Junzhe Jiang", "Qi Jiang", "Qinggang Zhang", "Yanchen Deng", "Shuxin Li", "Shuyue Hu", "Bo Li", "Florian T. Pokorny", "Xiao Huang", "Xinrun Wang"], "title": "Nondeterministic Polynomial-time Problem Challenge: An Ever-Scaling Reasoning Benchmark for LLMs", "categories": ["cs.AI", "cs.CL"], "comment": "Preliminary work, 10 pages for main text", "summary": "Reasoning is the fundamental capability of large language models (LLMs). Due\nto the rapid progress of LLMs, there are two main issues of current benchmarks:\ni) these benchmarks can be crushed in a short time (less than 1 year), and ii)\nthese benchmarks may be easily hacked. To handle these issues, we propose the\never-scalingness for building the benchmarks which are uncrushable, unhackable,\nauto-verifiable and general. This paper presents Nondeterministic\nPolynomial-time Problem Challenge (NPPC), an ever-scaling reasoning benchmark\nfor LLMs. Specifically, the NPPC has three main modules: i) npgym, which\nprovides a unified interface of 25 well-known NP-complete problems and can\ngenerate any number of instances with any levels of complexities, ii) npsolver:\nwhich provides a unified interface to evaluate the problem instances with both\nonline and offline models via APIs and local deployments, respectively, and\niii) npeval: which provides the comprehensive and ready-to-use tools to analyze\nthe performances of LLMs over different problems, the number of tokens, the aha\nmoments, the reasoning errors and the solution errors. Extensive experiments\nover widely-used LLMs demonstrate: i) NPPC can successfully decrease the\nperformances of advanced LLMs' performances to below 10%, demonstrating that\nNPPC is uncrushable, ii) DeepSeek-R1, Claude-3.7-Sonnet, and o1/o3-mini are the\nmost powerful LLMs, where DeepSeek-R1 outperforms Claude-3.7-Sonnet and\no1/o3-mini in most NP-complete problems considered, and iii) the numbers of\ntokens, aha moments in the advanced LLMs, e.g., Claude-3.7-Sonnet and\nDeepSeek-R1, are observed first to increase and then decrease when the problem\ninstances become more and more difficult. We believe that NPPC is the first\never-scaling reasoning benchmark, serving as the uncrushable and unhackable\ntestbed for LLMs toward artificial general intelligence (AGI).", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faNPPC\uff0c\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u63a8\u7406\u57fa\u51c6\uff0c\u7528\u4e8e\u6d4b\u8bd5\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524dLLM\u57fa\u51c6\u5bb9\u6613\u88ab\u5feb\u901f\u8d85\u8d8a\u548c\u88abhack\uff0c\u56e0\u6b64\u9700\u8981\u6784\u5efa\u4e00\u4e2aever-scaling\u3001\u4e0d\u53ef\u88ab\u8d85\u8d8a\u548c\u4e0d\u53ef\u88abhack\u7684\u57fa\u51c6\u3002", "method": "NPPC\u5305\u62ec\u4e09\u4e2a\u6a21\u5757\uff1anpgym\u63d0\u4f9bNP-complete\u95ee\u9898\u7684\u63a5\u53e3\u548c\u5b9e\u4f8b\u751f\u6210\u3001npsolver\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u3001npeval\u7528\u4e8e\u5206\u6790\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u663e\u793aNPPC\u5c06\u5148\u8fdbLLM\u6027\u80fd\u964d\u81f310%\u4ee5\u4e0b\uff0cDeepSeek-R1\u7b49\u6a21\u578b\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u89c2\u5bdf\u5230\u96be\u5ea6\u589e\u52a0\u65f6token\u6570\u548caha moments\u7684\u53d8\u5316\u3002", "conclusion": "NPPC\u662f\u7b2c\u4e00\u4e2aever-scaling\u63a8\u7406\u57fa\u51c6\uff0c\u53ef\u4f5c\u4e3aLLM\u5411AGI\u53d1\u5c55\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2504.10694", "pdf": "https://arxiv.org/pdf/2504.10694", "abs": "https://arxiv.org/abs/2504.10694", "authors": ["Kristina Nikoli\u0107", "Luze Sun", "Jie Zhang", "Florian Tram\u00e8r"], "title": "The Jailbreak Tax: How Useful are Your Jailbreak Outputs?", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Jailbreak attacks bypass the guardrails of large language models to produce\nharmful outputs. In this paper, we ask whether the model outputs produced by\nexisting jailbreaks are actually useful. For example, when jailbreaking a model\nto give instructions for building a bomb, does the jailbreak yield good\ninstructions? Since the utility of most unsafe answers (e.g., bomb\ninstructions) is hard to evaluate rigorously, we build new jailbreak evaluation\nsets with known ground truth answers, by aligning models to refuse questions\nrelated to benign and easy-to-evaluate topics (e.g., biology or math). Our\nevaluation of eight representative jailbreaks across five utility benchmarks\nreveals a consistent drop in model utility in jailbroken responses, which we\nterm the jailbreak tax. For example, while all jailbreaks we tested bypass\nguardrails in models aligned to refuse to answer math, this comes at the\nexpense of a drop of up to 92% in accuracy. Overall, our work proposes the\njailbreak tax as a new important metric in AI safety, and introduces benchmarks\nto evaluate existing and future jailbreaks. We make the benchmark available at\nhttps://github.com/ethz-spylab/jailbreak-tax", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8bc4\u4f30\u4e86\u8d8a\u72f1\u653b\u51fb\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6548\u7528\uff0c\u53d1\u73b0\u8d8a\u72f1\u4f1a\u5bfc\u81f4\u8f93\u51fa\u8d28\u91cf\u4e0b\u964d\uff0c\u79f0\u4e3a\u201c\u8d8a\u72f1\u7a0e\u201d\uff0c\u5e76\u63d0\u4f9b\u4e86\u65b0\u57fa\u51c6\u3002", "motivation": "\u4f5c\u8005\u8d28\u7591\u73b0\u6709\u8d8a\u72f1\u653b\u51fb\u7684\u8f93\u51fa\u662f\u5426\u771f\u6b63\u6709\u7528\uff0c\u5c24\u5176\u662f\u5728\u96be\u4ee5\u8bc4\u4f30\u7684\u4e0d\u5b89\u5168\u4e3b\u9898\u4e0a\uff0c\u56e0\u6b64\u6784\u5efa\u4e86\u57fa\u4e8e\u826f\u6027\u4e3b\u9898\u7684\u8bc4\u4f30\u96c6\u3002", "method": "\u901a\u8fc7\u8ba9\u6a21\u578b\u62d2\u7edd\u56de\u7b54\u751f\u7269\u5b66\u6216\u6570\u5b66\u7b49\u4e3b\u9898\u7684\u95ee\u9898\uff0c\u521b\u5efa\u65b0\u8bc4\u4f30\u96c6\uff0c\u5e76\u6d4b\u8bd5\u516b\u79cd\u4ee3\u8868\u6027\u8d8a\u72f1\u653b\u51fb\u5728\u4e94\u4e2a\u6548\u7528\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u8d8a\u72f1\u653b\u51fb\u5bfc\u81f4\u6a21\u578b\u6548\u7528\u663e\u8457\u4e0b\u964d\uff0c\u4f8b\u5982\u6570\u5b66\u51c6\u786e\u7387\u4e0b\u964d\u9ad8\u8fbe92%\uff0c\u8bc1\u5b9e\u4e86\u201c\u8d8a\u72f1\u7a0e\u201d\u7684\u5b58\u5728\u3002", "conclusion": "\u63d0\u51fa\u201c\u8d8a\u72f1\u7a0e\u201d\u4f5c\u4e3aAI\u5b89\u5168\u65b0\u6307\u6807\uff0c\u5e76\u53d1\u5e03\u5f00\u6e90\u57fa\u51c6\u4ee5\u8bc4\u4f30\u672a\u6765\u8d8a\u72f1\u653b\u51fb\u3002"}}
{"id": "2504.11374", "pdf": "https://arxiv.org/pdf/2504.11374", "abs": "https://arxiv.org/abs/2504.11374", "authors": ["Yongkang Huo", "Fuvio Forni", "Rodolphe Sepulchre"], "title": "A Winner-Takes-All Mechanism for Event Generation", "categories": ["eess.SY", "cs.AI", "cs.SY"], "comment": null, "summary": "We present a novel framework for central pattern generator design that\nleverages the intrinsic rebound excitability of neurons in combination with\nwinner-takes-all computation. Our approach unifies decision-making and rhythmic\npattern generation within a simple yet powerful network architecture that\nemploys all-to-all inhibitory connections enhanced by designable excitatory\ninteractions. This design offers significant advantages regarding ease of\nimplementation, adaptability, and robustness. We demonstrate its efficacy\nthrough a ring oscillator model, which exhibits adaptive phase and frequency\nmodulation, making the framework particularly promising for applications in\nneuromorphic systems and robotics.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u4e2d\u5fc3\u6a21\u5f0f\u53d1\u751f\u5668\u8bbe\u8ba1\uff0c\u7ed3\u5408\u795e\u7ecf\u5143\u53cd\u5f39\u5174\u594b\u6027\u548c\u8d62\u5bb6\u901a\u5403\u8ba1\u7b97\uff0c\u7edf\u4e00\u51b3\u7b56\u548c\u8282\u5f8b\u6a21\u5f0f\u751f\u6210\uff0c\u9002\u7528\u4e8e\u795e\u7ecf\u5f62\u6001\u7cfb\u7edf\u548c\u673a\u5668\u4eba\u3002", "motivation": "\u52a8\u673a\u662f\u5229\u7528\u795e\u7ecf\u5143\u56fa\u6709\u7279\u6027\u521b\u5efa\u7b80\u5355\u3001\u6613\u5b9e\u73b0\u3001\u53ef\u9002\u5e94\u548c\u9c81\u68d2\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u4ee5\u89e3\u51b3\u51b3\u7b56\u548c\u8282\u5f8b\u6a21\u5f0f\u751f\u6210\u95ee\u9898\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u5168\u4e92\u6291\u8fde\u63a5\u5e76\u6dfb\u52a0\u53ef\u8bbe\u8ba1\u5174\u594b\u4ea4\u4e92\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u5e76\u901a\u8fc7\u73af\u5f62\u632f\u8361\u5668\u6a21\u578b\u8fdb\u884c\u6f14\u793a\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e86\u81ea\u9002\u5e94\u76f8\u4f4d\u548c\u9891\u7387\u8c03\u5236\uff0c\u8bc1\u660e\u4e86\u6846\u67b6\u5728\u6613\u7528\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8be5\u6846\u67b6\u5728\u795e\u7ecf\u5f62\u6001\u7cfb\u7edf\u548c\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u5177\u6709\u663e\u8457\u6f5c\u529b\u3002"}}
{"id": "2504.11243", "pdf": "https://arxiv.org/pdf/2504.11243", "abs": "https://arxiv.org/abs/2504.11243", "authors": ["Balahari Vignesh Balu", "Florian Geissler", "Francesco Carella", "Joao-Vitor Zacchi", "Josef Jiru", "Nuria Mata", "Reinhard Stolle"], "title": "Towards Automated Safety Requirements Derivation Using Agent-based RAG", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "9 pages, 3 figures", "summary": "We study the automated derivation of safety requirements in a self-driving\nvehicle use case, leveraging LLMs in combination with agent-based\nretrieval-augmented generation. Conventional approaches that utilise\npre-trained LLMs to assist in safety analyses typically lack domain-specific\nknowledge. Existing RAG approaches address this issue, yet their performance\ndeteriorates when handling complex queries and it becomes increasingly harder\nto retrieve the most relevant information. This is particularly relevant for\nsafety-relevant applications. In this paper, we propose the use of agent-based\nRAG to derive safety requirements and show that the retrieved information is\nmore relevant to the queries. We implement an agent-based approach on a\ndocument pool of automotive standards and the Apollo case study, as a\nrepresentative example of an automated driving perception system. Our solution\nis tested on a data set of safety requirement questions and answers, extracted\nfrom the Apollo data. Evaluating a set of selected RAG metrics, we present and\ndiscuss advantages of a agent-based approach compared to default RAG methods.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u57fa\u4e8e\u4ee3\u7406\u7684RAG\u65b9\u6cd5\u6765\u81ea\u52a8\u63a8\u5bfc\u81ea\u9a7e\u8f66\u7684\u5b89\u5168\u8981\u6c42\uff0c\u63d0\u9ad8\u4fe1\u606f\u68c0\u7d22\u7684\u76f8\u5173\u6027\u3002", "motivation": "\u4f20\u7edfLLM\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\uff0c\u73b0\u6709RAG\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u67e5\u8be2\u65f6\u6027\u80fd\u4e0b\u964d\uff0c\u5c24\u5176\u5728\u5b89\u5168\u76f8\u5173\u5e94\u7528\u4e2d\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u4ee3\u7406\u7684RAG\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8e\u6c7d\u8f66\u6807\u51c6\u548cApollo\u6848\u4f8b\u7814\u7a76\u7684\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u9009\u5b9a\u7684RAG\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4ee3\u7406-based RAG\u65b9\u6cd5\u5728\u68c0\u7d22\u76f8\u5173\u4fe1\u606f\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u52bf\uff0c\u6bd4\u9ed8\u8ba4RAG\u65b9\u6cd5\u66f4\u597d\u3002", "conclusion": "\u4ee3\u7406-based\u65b9\u6cd5\u5728\u5b89\u5168\u8981\u6c42\u63a8\u5bfc\u4e2d\u66f4\u6709\u6548\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u67e5\u8be2\u65f6\u3002"}}
{"id": "2504.10720", "pdf": "https://arxiv.org/pdf/2504.10720", "abs": "https://arxiv.org/abs/2504.10720", "authors": ["Kamaljyoti Nath", "Khemraj Shukla", "Victor C. Tsai", "Umair bin Waheed", "Christian Huber", "Omer Alpak", "Chuen-Song Chen", "Ligang Lu", "Amik St-Cyr"], "title": "Leveraging Deep Operator Networks (DeepONet) for Acoustic Full Waveform Inversion (FWI)", "categories": ["cs.LG"], "comment": null, "summary": "Full Waveform Inversion (FWI) is an important geophysical technique\nconsidered in subsurface property prediction. It solves the inverse problem of\npredicting high-resolution Earth interior models from seismic data. Traditional\nFWI methods are computationally demanding. Inverse problems in geophysics often\nface challenges of non-uniqueness due to limited data, as data are often\ncollected only on the surface. In this study, we introduce a novel methodology\nthat leverages Deep Operator Networks (DeepONet) to attempt to improve both the\nefficiency and accuracy of FWI. The proposed DeepONet methodology inverts\nseismic waveforms for the subsurface velocity field. This approach is able to\ncapture some key features of the subsurface velocity field. We have shown that\nthe architecture can be applied to noisy seismic data with an accuracy that is\nbetter than some other machine learning methods. We also test our proposed\nmethod with out-of-distribution prediction for different velocity models. The\nproposed DeepONet shows comparable and better accuracy in some velocity models\nthan some other machine learning methods. To improve the FWI workflow, we\npropose using the DeepONet output as a starting model for conventional FWI and\nthat it may improve FWI performance. While we have only shown that DeepONet\nfacilitates faster convergence than starting with a homogeneous velocity field,\nit may have some benefits compared to other approaches to constructing starting\nmodels. This integration of DeepONet into FWI may accelerate the inversion\nprocess and may also enhance its robustness and reliability.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528Deep Operator Networks (DeepONet) \u6539\u8fdbFull Waveform Inversion (FWI) \u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5904\u7406\u5730\u9707\u6570\u636e\u9006\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfFWI\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u4e14\u9006\u95ee\u9898\u56e0\u6570\u636e\u6709\u9650\u5b58\u5728\u975e\u552f\u4e00\u6027\u6311\u6218\u3002", "method": "\u5f15\u5165DeepONet\u65b9\u6cd5\u9006\u8f6c\u5730\u9707\u6ce2\u5f62\u4ee5\u83b7\u53d6\u5730\u4e0b\u901f\u5ea6\u573a\uff0c\u5e94\u7528\u4e8e\u566a\u58f0\u6570\u636e\u548c\u5206\u5e03\u5916\u9884\u6d4b\uff0c\u5e76\u5efa\u8bae\u7528DeepONet\u8f93\u51fa\u4f5c\u4e3a\u4f20\u7edfFWI\u7684\u8d77\u59cb\u6a21\u578b\u3002", "result": "DeepONet\u5728\u566a\u58f0\u6570\u636e\u548c\u67d0\u4e9b\u901f\u5ea6\u6a21\u578b\u4e2d\u6bd4\u5176\u4ed6\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u66f4\u51c6\u786e\uff0c\u5e76\u52a0\u901fFWI\u6536\u655b\u3002", "conclusion": "\u5c06DeepONet\u6574\u5408\u5230FWI\u4e2d\u53ef\u80fd\u52a0\u901f\u9006\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2504.11446", "pdf": "https://arxiv.org/pdf/2504.11446", "abs": "https://arxiv.org/abs/2504.11446", "authors": ["Federico Porcari", "Donatello Materassi", "Simone Formentin"], "title": "eXplainable AI for data driven control: an inverse optimal control approach", "categories": ["eess.SY", "cs.SY"], "comment": "Submitted to CDC 2025", "summary": "Understanding the behavior of black-box data-driven controllers is a key\nchallenge in modern control design. In this work, we propose an eXplainable AI\n(XAI) methodology based on Inverse Optimal Control (IOC) to obtain local\nexplanations for the behavior of a controller operating around a given region.\nSpecifically, we extract the weights assigned to tracking errors and control\neffort in the implicit cost function that a black-box controller is optimizing,\noffering a more transparent and interpretable representation of the\ncontroller's underlying objectives. This approach presents connections with\nwell-established XAI techniques, such as Local Interpretable Model-agnostic\nExplanations (LIME) since it is still based on a local approximation of the\ncontrol policy. However, rather being limited to a standard sensitivity\nanalysis, the explanation provided by our method relies on the solution of an\ninverse Linear Quadratic (LQ) problem, offering a structured and more\ncontrol-relevant perspective. Numerical examples demonstrate that the inferred\ncost function consistently provides a deeper understanding of the controller's\ndecision-making process, shedding light on otherwise counterintuitive or\nunexpected phenomena.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u9006\u6700\u4f18\u63a7\u5236\u7684XAI\u65b9\u6cd5\uff0c\u89e3\u91ca\u9ed1\u7bb1\u63a7\u5236\u5668\u7684\u884c\u4e3a\uff0c\u901a\u8fc7\u63d0\u53d6\u6210\u672c\u51fd\u6570\u6743\u91cd\u63d0\u4f9b\u5c40\u90e8\u89e3\u91ca\u3002", "motivation": "\u7406\u89e3\u9ed1\u7bb1\u6570\u636e\u9a71\u52a8\u63a7\u5236\u5668\u7684\u884c\u4e3a\u662f\u73b0\u4ee3\u63a7\u5236\u8bbe\u8ba1\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u4f7f\u7528\u9006\u7ebf\u6027\u4e8c\u6b21\u95ee\u9898\u6c42\u89e3\uff0c\u63d0\u53d6\u9690\u5f0f\u6210\u672c\u51fd\u6570\u4e2d\u8ddf\u8e2a\u8bef\u5dee\u548c\u63a7\u5236\u52aa\u529b\u7684\u6743\u91cd\uff0c\u5e76\u4e0eLIME\u7b49\u6280\u672f\u5173\u8054\u3002", "result": "\u6570\u503c\u4f8b\u5b50\u663e\u793a\uff0c\u63a8\u65ad\u7684\u6210\u672c\u51fd\u6570\u80fd\u66f4\u6df1\u5165\u7406\u89e3\u63a7\u5236\u5668\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u89e3\u91ca\u53cd\u76f4\u89c9\u73b0\u8c61\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u66f4\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u63a7\u5236\u5668\u76ee\u6807\u8868\u793a\uff0c\u63d0\u5347\u4e86\u5bf9\u9ed1\u7bb1\u7cfb\u7edf\u7684\u7406\u89e3\u3002"}}
{"id": "2504.11301", "pdf": "https://arxiv.org/pdf/2504.11301", "abs": "https://arxiv.org/abs/2504.11301", "authors": ["Yangyang Zhuang", "Wenjia Jiang", "Jiayu Zhang", "Ze Yang", "Joey Tianyi Zhou", "Chi Zhang"], "title": "Learning to Be A Doctor: Searching for Effective Medical Agent Architectures", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Model (LLM)-based agents have demonstrated strong capabilities\nacross a wide range of tasks, and their application in the medical domain holds\nparticular promise due to the demand for high generalizability and reliance on\ninterdisciplinary knowledge. However, existing medical agent systems often rely\non static, manually crafted workflows that lack the flexibility to accommodate\ndiverse diagnostic requirements and adapt to emerging clinical scenarios.\nMotivated by the success of automated machine learning (AutoML), this paper\nintroduces a novel framework for the automated design of medical agent\narchitectures. Specifically, we define a hierarchical and expressive agent\nsearch space that enables dynamic workflow adaptation through structured\nmodifications at the node, structural, and framework levels. Our framework\nconceptualizes medical agents as graph-based architectures composed of diverse,\nfunctional node types and supports iterative self-improvement guided by\ndiagnostic feedback. Experimental results on skin disease diagnosis tasks\ndemonstrate that the proposed method effectively evolves workflow structures\nand significantly enhances diagnostic accuracy over time. This work represents\nthe first fully automated framework for medical agent architecture design and\noffers a scalable, adaptable foundation for deploying intelligent agents in\nreal-world clinical environments.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f15\u5165\u4e86\u4e00\u4e2a\u81ea\u52a8\u8bbe\u8ba1\u533b\u7597\u4ee3\u7406\u67b6\u6784\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u52a8\u6001\u9002\u5e94\u548c\u8bca\u65ad\u51c6\u786e\u6027\u7684\u63d0\u5347\uff0c\u5728\u76ae\u80a4\u75c5\u8bca\u65ad\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "\u53d7AutoML\u6210\u529f\u542f\u53d1\uff0c\u9488\u5bf9\u73b0\u6709\u533b\u7597\u4ee3\u7406\u7cfb\u7edf\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u533b\u7597\u9886\u57df\u5bf9\u9ad8\u6cdb\u5316\u6027\u548c\u8de8\u5b66\u79d1\u77e5\u8bc6\u7684\u9700\u6c42\u3002", "method": "\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5206\u5c42\u4ee3\u7406\u641c\u7d22\u7a7a\u95f4\uff0c\u901a\u8fc7\u8282\u70b9\u3001\u7ed3\u6784\u548c\u6846\u67b6\u7ea7\u522b\u7684\u4fee\u6539\u5b9e\u73b0\u52a8\u6001\u5de5\u4f5c\u6d41\u9002\u5e94\uff1b\u5c06\u4ee3\u7406\u89c6\u4e3a\u56fe-based\u67b6\u6784\uff0c\u652f\u6301\u8bca\u65ad\u53cd\u9988\u5f15\u5bfc\u7684\u8fed\u4ee3\u6539\u8fdb\u3002", "result": "\u5728\u76ae\u80a4\u75c5\u8bca\u65ad\u4efb\u52a1\u7684\u5b9e\u9a8c\u4e2d\uff0c\u65b9\u6cd5\u6709\u6548\u5730\u6f14\u5316\u5de5\u4f5c\u6d41\u5e76\u663e\u8457\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u3002", "conclusion": "\u8fd9\u662f\u7b2c\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u533b\u7597\u4ee3\u7406\u67b6\u6784\u8bbe\u8ba1\u6846\u67b6\uff0c\u4e3a\u771f\u5b9e\u4e34\u5e8a\u73af\u5883\u4e2d\u90e8\u7f72\u667a\u80fd\u4ee3\u7406\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9002\u5e94\u6027\u57fa\u7840\u3002"}}
{"id": "2504.10735", "pdf": "https://arxiv.org/pdf/2504.10735", "abs": "https://arxiv.org/abs/2504.10735", "authors": ["Timur Carstensen", "Neeratyoy Mallik", "Frank Hutter", "Martin Rapp"], "title": "Frozen Layers: Memory-efficient Many-fidelity Hyperparameter Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As model sizes grow, finding efficient and cost-effective hyperparameter\noptimization (HPO) methods becomes increasingly crucial for deep learning\npipelines. While multi-fidelity HPO (MF-HPO) trades off computational resources\nrequired for DL training with lower fidelity estimations, existing fidelity\nsources often fail under lower compute and memory constraints. We propose a\nnovel fidelity source: the number of layers that are trained or frozen during\ntraining. For deep networks, this approach offers significant compute and\nmemory savings while preserving rank correlations between hyperparameters at\nlow fidelities compared to full model training. We demonstrate this in our\nempirical evaluation across ResNets and Transformers and additionally analyze\nthe utility of frozen layers as a fidelity in using GPU resources as a fidelity\nin HPO, and for a combined MF-HPO with other fidelity sources. This\ncontribution opens new applications for MF-HPO with hardware resources as a\nfidelity and creates opportunities for improved algorithms navigating joint\nfidelity spaces.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4fdd\u771f\u5ea6\u6765\u6e90\uff0c\u7528\u4e8e\u591a\u4fdd\u771f\u5ea6\u8d85\u53c2\u6570\u4f18\u5316\uff08MF-HPO\uff09\uff0c\u901a\u8fc7\u8bad\u7ec3\u6216\u51bb\u7ed3\u5c42\u6570\u6765\u8282\u7701\u8ba1\u7b97\u548c\u5185\u5b58\uff0c\u540c\u65f6\u4fdd\u6301\u8d85\u53c2\u6570\u76f8\u5173\u6027\u3002", "motivation": "\u968f\u7740\u6a21\u578b\u89c4\u6a21\u589e\u957f\uff0c\u9ad8\u6548\u7684\u8d85\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\u81f3\u5173\u91cd\u8981\uff0c\u800c\u73b0\u6709\u4fdd\u771f\u5ea6\u6765\u6e90\u5728\u4f4e\u8ba1\u7b97\u548c\u5185\u5b58\u7ea6\u675f\u4e0b\u5f80\u5f80\u5931\u6548\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u8bad\u7ec3\u6216\u51bb\u7ed3\u5c42\u6570\u4f5c\u4e3aMF-HPO\u4e2d\u7684\u4fdd\u771f\u5ea6\u6765\u6e90\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u5728ResNets\u548cTransformers\u4e0a\u663e\u793a\u4e86\u8ba1\u7b97\u548c\u5185\u5b58\u8282\u7701\uff0c\u5e76\u4fdd\u6301\u4e86\u8d85\u53c2\u6570\u79e9\u76f8\u5173\u6027\uff1b\u8fd8\u5206\u6790\u4e86\u4e0eGPU\u8d44\u6e90\u7ed3\u5408\u7684\u6548\u7528\u548c\u4e0e\u5176\u4ed6\u4fdd\u771f\u5ea6\u6765\u6e90\u7684\u8054\u5408\u4f7f\u7528\u3002", "conclusion": "\u4e3a\u4f7f\u7528\u786c\u4ef6\u8d44\u6e90\u4f5c\u4e3a\u4fdd\u771f\u5ea6\u7684MF-HPO\u5f00\u8f9f\u65b0\u5e94\u7528\uff0c\u5e76\u4e3a\u6539\u8fdb\u7b97\u6cd5\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002"}}
{"id": "2504.10497", "pdf": "https://arxiv.org/pdf/2504.10497", "abs": "https://arxiv.org/abs/2504.10497", "authors": ["Sunyi Liu", "Mengzhe Geng", "Rebecca Hart"], "title": "Exploring Generative AI Techniques in Government: A Case Study", "categories": ["cs.IR", "cs.AI", "cs.HC", "cs.MA", "cs.SY", "eess.SY"], "comment": "In submission to IEEE Intelligent Systems", "summary": "The swift progress of Generative Artificial intelligence (GenAI), notably\nLarge Language Models (LLMs), is reshaping the digital landscape. Recognizing\nthis transformative potential, the National Research Council of Canada (NRC)\nlaunched a pilot initiative to explore the integration of GenAI techniques into\nits daily operation for performance excellence, where 22 projects were launched\nin May 2024. Within these projects, this paper presents the development of the\nintelligent agent Pubbie as a case study, targeting the automation of\nperformance measurement, data management and insight reporting at the NRC.\nCutting-edge techniques are explored, including LLM orchestration and semantic\nembedding via RoBERTa, while strategic fine-tuning and few-shot learning\napproaches are incorporated to infuse domain knowledge at an affordable cost.\nThe user-friendly interface of Pubbie allows general government users to input\nqueries in natural language and easily upload or download files with a simple\nbutton click, greatly reducing manual efforts and accessibility barriers.", "AI": {"tldr": "\u9019\u7bc7\u8ad6\u6587\u4ecb\u7d39\u4e86Pubbie\u667a\u80fd\u4ee3\u7406\u7684\u958b\u767c\uff0c\u4f7f\u7528\u751f\u6210\u5f0fAI\u6280\u8853\u81ea\u52d5\u5316\u52a0\u62ff\u5927\u570b\u5bb6\u7814\u7a76\u59d4\u54e1\u6703\u7684\u6027\u80fd\u6e2c\u91cf\u3001\u6578\u64da\u7ba1\u7406\u548c\u6d1e\u5bdf\u5831\u544a\uff0c\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u7531\u65bc\u751f\u6210\u5f0fAI\u548c\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u5feb\u901f\u767c\u5c55\uff0c\u52a0\u62ff\u5927\u570b\u5bb6\u7814\u7a76\u59d4\u54e1\u6703\u555f\u52d5\u8a66\u9ede\u9805\u76ee\uff0c\u63a2\u7d22\u5c07GenAI\u6574\u5408\u5230\u65e5\u5e38\u904b\u71df\u4e2d\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63a2\u7d22LLM\u7de8\u6392\u3001RoBERTa\u8a9e\u7fa9\u5d4c\u5165\u3001\u7b56\u7565\u5fae\u8abf\u548c\u5c11\u6a23\u672c\u5b78\u7fd2\uff0c\u4ee5\u4f4e\u6210\u672c\u6ce8\u5165\u9818\u57df\u77e5\u8b58\u3002\u63d0\u4f9b\u7528\u6236\u53cb\u597d\u754c\u9762\uff0c\u652f\u6301\u81ea\u7136\u8a9e\u8a00\u67e5\u8a62\u548c\u7c21\u55ae\u6587\u4ef6\u4e0a\u50b3\u4e0b\u8f09\u3002", "result": "\u6e1b\u5c11\u4e86\u624b\u52d5\u52aa\u529b\u548c\u53ef\u8a2a\u554f\u6027\u969c\u7919\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u81ea\u52d5\u5316\u6c34\u5e73\u3002", "conclusion": "Pubbie\u7684\u958b\u767c\u5c55\u793a\u4e86GenAI\u5728\u653f\u5e9c\u6a5f\u69cb\u4e2d\u7684\u5be6\u969b\u61c9\u7528\u6f5b\u529b\uff0c\u6709\u52a9\u65bc\u63d0\u5347\u6027\u80fd\u548c\u64cd\u4f5c\u7c21\u4fbf\u6027\u3002"}}
{"id": "2504.11354", "pdf": "https://arxiv.org/pdf/2504.11354", "abs": "https://arxiv.org/abs/2504.11354", "authors": ["Haiming Wang", "Mert Unsal", "Xiaohan Lin", "Mantas Baksys", "Junqi Liu", "Marco Dos Santos", "Flood Sung", "Marina Vinyes", "Zhenzhe Ying", "Zekai Zhu", "Jianqiao Lu", "Hugues de Saxc\u00e9", "Bolton Bailey", "Chendong Song", "Chenjun Xiao", "Dehao Zhang", "Ebony Zhang", "Frederick Pu", "Han Zhu", "Jiawei Liu", "Jonas Bayer", "Julien Michel", "Longhui Yu", "L\u00e9o Dreyfus-Schmidt", "Lewis Tunstall", "Luigi Pagani", "Moreira Machado", "Pauline Bourigault", "Ran Wang", "Stanislas Polu", "Thibaut Barroyer", "Wen-Ding Li", "Yazhe Niu", "Yann Fleureau", "Yangyang Hu", "Zhouliang Yu", "Zihan Wang", "Zhilin Yang", "Zhengying Liu", "Jia Li"], "title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning", "categories": ["cs.AI"], "comment": "22 pages", "summary": "We introduce Kimina-Prover Preview, a large language model that pioneers a\nnovel reasoning-driven exploration paradigm for formal theorem proving, as\nshowcased in this preview release. Trained with a large-scale reinforcement\nlearning pipeline from Qwen2.5-72B, Kimina-Prover demonstrates strong\nperformance in Lean 4 proof generation by employing a structured reasoning\npattern we term \\textit{formal reasoning pattern}. This approach allows the\nmodel to emulate human problem-solving strategies in Lean, iteratively\ngenerating and refining proof steps. Kimina-Prover sets a new state-of-the-art\non the miniF2F benchmark, reaching 80.7% with pass@8192. Beyond improved\nbenchmark performance, our work yields several key insights: (1) Kimina-Prover\nexhibits high sample efficiency, delivering strong results even with minimal\nsampling (pass@1) and scaling effectively with computational budget, stemming\nfrom its unique reasoning pattern and RL training; (2) we demonstrate clear\nperformance scaling with model size, a trend previously unobserved for neural\ntheorem provers in formal mathematics; (3) the learned reasoning style,\ndistinct from traditional search algorithms, shows potential to bridge the gap\nbetween formal verification and informal mathematical intuition. We open source\ndistilled versions with 1.5B and 7B parameters of Kimina-Prover", "AI": {"tldr": "Kimina-Prover \u662f\u4e00\u79cd\u65b0\u578b\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u63a8\u7406\u9a71\u52a8\u63a2\u7d22\u8303\u5f0f\uff0c\u5728\u5f62\u5f0f\u5b9a\u7406\u8bc1\u660e\u4e2d\u8fbe\u5230\u4e00\u6d41\u6027\u80fd\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u6539\u8fdb\u5f62\u5f0f\u5b9a\u7406\u8bc1\u660e\u7684\u6548\u7387\uff0c\u6a21\u62df\u4eba\u7c7b\u95ee\u9898\u89e3\u51b3\u7b56\u7565\uff0c\u5e76\u6865\u63a5\u5f62\u5f0f\u9a8c\u8bc1\u4e0e\u975e\u6b63\u5f0f\u6570\u5b66\u76f4\u89c9\u3002", "method": "\u4f7f\u7528\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u7ba1\u9053\u4ece Qwen2.5-72B \u8bad\u7ec3\uff0c\u91c7\u7528 '\u5f62\u5f0f\u63a8\u7406\u6a21\u5f0f' \u5728 Lean 4 \u4e2d\u8fed\u4ee3\u751f\u6210\u548c\u5b8c\u5584\u8bc1\u660e\u6b65\u9aa4\u3002", "result": "\u5728 miniF2F \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230 80.7% \u7684 pass@8192 \u6210\u7ee9\uff0c\u5c55\u793a\u9ad8\u6837\u672c\u6548\u7387\u3001\u6a21\u578b\u5927\u5c0f\u6027\u80fd scaling\uff0c\u5e76\u5f00\u6e90 1.5B \u548c 7B \u53c2\u6570\u7684\u7b80\u5316\u7248\u672c\u3002", "conclusion": "Kimina-Prover \u7684\u5de5\u4f5c\u63ed\u793a\u4e86\u9ad8\u6548\u8bc1\u660e\u751f\u6210\u3001\u6027\u80fd scaling \u7684\u6f5c\u529b\uff0c\u5e76\u4e3a\u5f62\u5f0f\u4e0e\u975e\u5f62\u5f0f\u6570\u5b66\u6574\u5408\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002"}}
{"id": "2504.10752", "pdf": "https://arxiv.org/pdf/2504.10752", "abs": "https://arxiv.org/abs/2504.10752", "authors": ["Neil Mehta", "Ines Goncalves", "Alberto Montagna", "Mathis Fleury", "Gustavo Caetano", "Ines Esteves", "Athanasios Vourvopoulos", "Pulkit Grover", "Patricia Figueiredo"], "title": "Time-varying EEG spectral power predicts evoked and spontaneous fMRI motor brain activity", "categories": ["cs.LG", "q-bio.NC"], "comment": null, "summary": "Simultaneous EEG-fMRI recordings are increasingly used to investigate brain\nactivity by leveraging the complementary high spatial and high temporal\nresolution of fMRI and EEG signals respectively. It remains unclear, however,\nto what degree these two imaging modalities capture shared information about\nneural activity. Here, we investigate whether it is possible to predict both\ntask-evoked and spontaneous fMRI signals of motor brain networks from EEG\ntime-varying spectral power using interpretable models trained for individual\nsubjects with Sparse Group Lasso regularization. Critically, we test the\ntrained models on data acquired from each subject on a different day and obtain\nstatistical validation by comparison with appropriate null models as well as\nthe conventional EEG sensorimotor rhythm. We find significant prediction\nresults in most subjects, although less frequently for resting-state compared\nto task-based conditions. Furthermore, we interpret the model learned\nparameters to understand representations of EEG-fMRI coupling in terms of\npredictive EEG channels, frequencies, and haemodynamic delays. In conclusion,\nour work provides evidence of the ability to predict fMRI motor brain activity\nfrom EEG recordings alone across different days, in both task-evoked and\nspontaneous conditions, with statistical significance in individual subjects.\nThese results present great potential for translation to EEG neurofeedback\napplications.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528\u53ef\u89e3\u91ca\u6a21\u578b\u4eceEEG\u9884\u6d4bfMRI\u4fe1\u53f7\uff0c\u8de8\u5929\u9a8c\u8bc1\uff0c\u5728\u4e2a\u4f53\u6c34\u5e73\u4e0a\u663e\u793a\u663e\u8457\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u63a2\u8ba8EEG\u548cfMRI\u5728\u795e\u7ecf\u6d3b\u52a8\u4fe1\u606f\u5171\u4eab\u7a0b\u5ea6\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u4e3aEEG\u795e\u7ecf\u53cd\u9988\u5e94\u7528\u63d0\u4f9b\u6f5c\u529b\u3002", "method": "\u91c7\u7528Sparse Group Lasso\u6b63\u5219\u5316\u8bad\u7ec3\u53ef\u89e3\u91ca\u6a21\u578b\uff0c\u9488\u5bf9\u4e2a\u4f53\u53d7\u8bd5\u8005\uff0c\u5e76\u5728\u4e0d\u540c\u5929\u7684\u6570\u636e\u4e0a\u6d4b\u8bd5\uff0c\u4e0enull\u6a21\u578b\u548c\u4f20\u7edfEEG\u6bd4\u8f83\u3002", "result": "\u5728\u5927\u591a\u6570\u53d7\u8bd5\u8005\u4e2d\u9884\u6d4b\u663e\u8457\uff0c\u4efb\u52a1\u6761\u4ef6\u591a\u4e8e\u9759\u606f\u72b6\u6001\uff0c\u5e76\u89e3\u91caEEG\u901a\u9053\u3001\u9891\u7387\u548c\u8840\u6d41\u52a8\u529b\u5b66\u5ef6\u8fdf\u3002", "conclusion": "\u8bc1\u660e\u4e86\u4eceEEG\u5355\u72ec\u9884\u6d4bfMRI\u8fd0\u52a8\u8111\u6d3b\u52a8\u7684\u80fd\u529b\uff0c\u8de8\u4efb\u52a1\u548c\u81ea\u53d1\u6761\u4ef6\uff0c\u7edf\u8ba1\u663e\u8457\uff0c\u5177\u6709\u795e\u7ecf\u53cd\u9988\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.10699", "pdf": "https://arxiv.org/pdf/2504.10699", "abs": "https://arxiv.org/abs/2504.10699", "authors": ["Nan Wang", "Ricardo G. Sanfelice"], "title": "HyRRT-Connect: Bidirectional Motion Planning for Hybrid Dynamical Systems", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "59 pages, 9 figures, submitted to IJRR. arXiv admin note: substantial\n  text overlap with arXiv:2403.18413; text overlap with arXiv:2406.01802", "summary": "This paper proposes a bidirectional rapidly-exploring random trees (RRT)\nalgorithm to solve the motion planning problem for hybrid systems. The proposed\nalgorithm, called HyRRT-Connect, propagates in both forward and backward\ndirections in hybrid time until an overlap between the forward and backward\npropagation results is detected. Then, HyRRT-Connect constructs a motion plan\nthrough the reversal and concatenation of functions defined on hybrid time\ndomains, ensuring that the motion plan satisfies the given hybrid dynamics. To\naddress the potential discontinuity along the flow caused by tolerating some\ndistance between the forward and backward partial motion plans, we reconstruct\nthe backward partial motion plan by a forward-in-hybrid-time simulation from\nthe final state of the forward partial motion plan. effectively eliminating the\ndiscontinuity. The proposed algorithm is applied to an actuated bouncing ball\nsystem and a walking robot example to highlight its computational improvement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHyRRT-Connect\u7b97\u6cd5\uff0c\u7528\u4e8e\u6df7\u5408\u7cfb\u7edf\u7684\u53cc\u5411RRT\u8fd0\u52a8\u89c4\u5212\uff0c\u63d0\u9ad8\u6548\u7387\u5e76\u5904\u7406\u4e0d\u8fde\u7eed\u6027\u3002", "motivation": "\u4e3a\u4e86\u66f4\u6709\u6548\u5730\u89e3\u51b3\u6df7\u5408\u7cfb\u7edf\u7684\u8fd0\u52a8\u89c4\u5212\u95ee\u9898\uff0c\u7279\u522b\u662f\u5904\u7406\u4e0d\u8fde\u7eed\u6027\u548c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u7b97\u6cd5\u5728\u6df7\u5408\u65f6\u95f4\u5185\u53cc\u5411\u4f20\u64ad\uff0c\u68c0\u6d4b\u91cd\u53e0\u540e\u901a\u8fc7\u53cd\u8f6c\u548c\u8fde\u63a5\u51fd\u6570\u6784\u5efa\u8fd0\u52a8\u89c4\u5212\uff0c\u5e76\u901a\u8fc7\u524d\u5411\u6a21\u62df\u91cd\u5efa\u540e\u5411\u90e8\u5206\u6d88\u9664\u4e0d\u8fde\u7eed\u6027\u3002", "result": "\u5e94\u7528\u4e8e\u5f39\u8df3\u7403\u548c\u6b65\u884c\u673a\u5668\u4eba\u793a\u4f8b\uff0c\u5c55\u793a\u4e86\u8ba1\u7b97\u6548\u7387\u7684\u63d0\u5347\u3002", "conclusion": "\u7b97\u6cd5\u6709\u6548\u6d88\u9664\u4e0d\u8fde\u7eed\u6027\uff0c\u5e76\u6539\u5584\u6df7\u5408\u7cfb\u7edf\u8fd0\u52a8\u89c4\u5212\u7684\u8ba1\u7b97\u6027\u80fd\u3002"}}
{"id": "2504.11419", "pdf": "https://arxiv.org/pdf/2504.11419", "abs": "https://arxiv.org/abs/2504.11419", "authors": ["Li Jin", "Liu Jia"], "title": "Embodied World Models Emerge from Navigational Task in Open-Ended Environments", "categories": ["cs.AI", "cs.NE"], "comment": "Research on explainable meta-reinforcement learning AI", "summary": "Understanding how artificial systems can develop spatial awareness and\nreasoning has long been a challenge in AI research. Traditional models often\nrely on passive observation, but embodied cognition theory suggests that deeper\nunderstanding emerges from active interaction with the environment. This study\ninvestigates whether neural networks can autonomously internalize spatial\nconcepts through interaction, focusing on planar navigation tasks. Using Gated\nRecurrent Units (GRUs) combined with Meta-Reinforcement Learning (Meta-RL), we\nshow that agents can learn to encode spatial properties like direction,\ndistance, and obstacle avoidance. We introduce Hybrid Dynamical Systems (HDS)\nto model the agent-environment interaction as a closed dynamical system,\nrevealing stable limit cycles that correspond to optimal navigation strategies.\nRidge Representation allows us to map navigation paths into a fixed-dimensional\nbehavioral space, enabling comparison with neural states. Canonical Correlation\nAnalysis (CCA) confirms strong alignment between these representations,\nsuggesting that the agent's neural states actively encode spatial knowledge.\nIntervention experiments further show that specific neural dimensions are\ncausally linked to navigation performance. This work provides an approach to\nbridging the gap between action and perception in AI, offering new insights\ninto building adaptive, interpretable models that can generalize across complex\nenvironments. The causal validation of neural representations also opens new\navenues for understanding and controlling the internal mechanisms of AI\nsystems, pushing the boundaries of how machines learn and reason in dynamic,\nreal-world scenarios.", "AI": {"tldr": "\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u4e3b\u52a8\u4e92\u52a8\u5b66\u4e60\u7a7a\u95f4\u610f\u8bc6\uff0c\u4f7f\u7528Meta-RL\u7b49\u65b9\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u795e\u7ecf\u8868\u793a\u7684\u56e0\u679c\u5173\u7cfb\u3002", "motivation": "AI\u7814\u7a76\u4e2d\uff0c\u7406\u89e3\u4eba\u5de5\u7cfb\u7edf\u5982\u4f55\u53d1\u5c55\u7a7a\u95f4\u610f\u8bc6\u548c\u63a8\u7406\u662f\u4e00\u5927\u6311\u6218\uff0c\u4f20\u7edf\u6a21\u578b\u4f9d\u8d56\u88ab\u52a8\u89c2\u5bdf\uff0c\u800c\u5177\u8eab\u8ba4\u77e5\u7406\u8bba\u5f3a\u8c03\u4e3b\u52a8\u4e92\u52a8\u7684\u91cd\u8981\u6027\u3002", "method": "\u4f7f\u7528\u95e8\u63a7\u5faa\u73af\u5355\u5143(GRU)\u7ed3\u5408\u5143\u5f3a\u5316\u5b66\u4e60(Meta-RL)\uff0c\u5f15\u5165\u6df7\u5408\u52a8\u529b\u7cfb\u7edf(HDS)\u5efa\u6a21\uff0c\u91c7\u7528\u810a\u8868\u793a\u3001\u5178\u578b\u76f8\u5173\u5206\u6790(CCA)\u548c\u5e72\u9884\u5b9e\u9a8c\u3002", "result": "\u4ee3\u7406\u5b66\u4e60\u7f16\u7801\u65b9\u5411\u3001\u8ddd\u79bb\u548c\u907f\u969c\u7b49\u7a7a\u95f4\u5c5e\u6027\uff1b\u53d1\u73b0\u7a33\u5b9a\u6781\u9650\u73af\u5bf9\u5e94\u6700\u4f18\u5bfc\u822a\u7b56\u7565\uff1bCCA\u663e\u793a\u795e\u7ecf\u72b6\u6001\u4e0e\u884c\u4e3a\u8868\u793a\u9ad8\u5ea6\u4e00\u81f4\uff1b\u5e72\u9884\u5b9e\u9a8c\u8bc1\u5b9e\u7279\u5b9a\u795e\u7ecf\u7ef4\u5ea6\u4e0e\u5bfc\u822a\u6027\u80fd\u6709\u56e0\u679c\u8054\u7cfb\u3002", "conclusion": "\u672c\u7814\u7a76\u6865\u63a5\u884c\u52a8\u4e0e\u611f\u77e5\u7684\u5dee\u8ddd\uff0c\u63d0\u4f9b\u6784\u5efa\u9002\u5e94\u6027\u3001\u53ef\u89e3\u91caAI\u6a21\u578b\u7684\u65b0\u9014\u5f84\uff0c\u5e76\u4e3a\u7406\u89e3\u548c\u63a7\u5236AI\u5185\u90e8\u673a\u5236\u5f00\u8f9f\u65b0\u65b9\u5411\u3002"}}
{"id": "2504.10754", "pdf": "https://arxiv.org/pdf/2504.10754", "abs": "https://arxiv.org/abs/2504.10754", "authors": ["Arjun Subramonian", "Elvis Dohmatob"], "title": "auto-fpt: Automating Free Probability Theory Calculations for Machine Learning Theory", "categories": ["cs.LG", "cs.MS"], "comment": "Work in progress", "summary": "A large part of modern machine learning theory often involves computing the\nhigh-dimensional expected trace of a rational expression of large rectangular\nrandom matrices. To symbolically compute such quantities using free probability\ntheory, we introduce auto-fpt, a lightweight Python and SymPy-based tool that\ncan automatically produce a reduced system of fixed-point equations which can\nbe solved for the quantities of interest, and effectively constitutes a theory.\nWe overview the algorithmic ideas underlying auto-fpt and its applications to\nvarious interesting problems, such as the high-dimensional error of linearized\nfeed-forward neural networks, recovering well-known results. We hope that\nauto-fpt streamlines the majority of calculations involved in high-dimensional\nanalysis, while helping the machine learning community reproduce known and\nuncover new phenomena.", "AI": {"tldr": "auto-fpt \u662f\u4e00\u4e2a\u57fa\u4e8e\u81ea\u7531\u6982\u7387\u7406\u8bba\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u81ea\u52a8\u8ba1\u7b97\u9ad8\u7ef4\u968f\u673a\u77e9\u9635\u671f\u671b\u8ff9\uff0c\u5e76\u5e94\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u7406\u8bba\u5e38\u9700\u8ba1\u7b97\u9ad8\u7ef4\u968f\u673a\u77e9\u9635\u671f\u671b\u8ff9\uff0cauto-fpt \u65e8\u5728\u7b80\u5316\u8fd9\u4e9b\u8ba1\u7b97\uff0c\u5e2e\u52a9\u793e\u533a\u91cd\u73b0\u548c\u53d1\u73b0\u65b0\u73b0\u8c61\u3002", "method": "\u4f7f\u7528 Python \u548c SymPy \u5f00\u53d1\uff0c\u81ea\u52a8\u751f\u6210\u57fa\u4e8e\u81ea\u7531\u6982\u7387\u7406\u8bba\u7684\u56fa\u5b9a\u70b9\u65b9\u7a0b\u7cfb\u7edf\u3002", "result": "\u5e94\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u9ad8\u7ef4\u8bef\u5dee\u7b49\u95ee\u9898\uff0c\u6210\u529f\u6062\u590d\u5df2\u77e5\u7ed3\u679c\u3002", "conclusion": "\u5e0c\u671b\u7b80\u5316\u9ad8\u7ef4\u5206\u6790\u8ba1\u7b97\uff0c\u4fc3\u8fdb\u673a\u5668\u5b66\u4e60\u793e\u533a\u53d1\u5c55\u3002"}}
{"id": "2504.10767", "pdf": "https://arxiv.org/pdf/2504.10767", "abs": "https://arxiv.org/abs/2504.10767", "authors": ["Faiyaz Elahi Mullick", "Supriyo Bandyopadhyay", "Rob Baxter", "Tony J. Ragucci", "Avik W. Ghosh"], "title": "Adaptive Synaptogenesis Implemented on a Nanomagnetic Platform", "categories": ["cond-mat.dis-nn", "cs.NE", "cs.SY", "eess.SY"], "comment": null, "summary": "The human brain functions very differently from artificial neural networks\n(ANN) and possesses unique features that are absent in ANN. An important one\namong them is \"adaptive synaptogenesis\" that modifies synaptic weights when\nneeded to avoid catastrophic forgetting and promote lifelong learning. The key\naspect of this algorithm is supervised Hebbian learning, where weight\nmodifications in the neocortex driven by temporal coincidence are further\naccepted or vetoed by an added control mechanism from the hippocampus during\nthe training cycle, to make distant synaptic connections highly sparse and\nstrategic. In this work, we discuss various algorithmic aspects of adaptive\nsynaptogenesis tailored to edge computing, demonstrate its function using\nsimulations, and design nanomagnetic hardware accelerators for specific\nfunctions of synaptogenesis.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5927\u8111\u7684\u9002\u5e94\u6027\u7a81\u89e6\u53d1\u751f\u673a\u5236\u53ca\u5176\u5728AI\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u7b97\u6cd5\u8ba8\u8bba\u3001\u6a21\u62df\u6f14\u793a\u548c\u786c\u4ef6\u8bbe\u8ba1\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u4fc3\u8fdb\u7ec8\u8eab\u5b66\u4e60\uff0c\u6a21\u4eff\u5927\u8111\u7684\u72ec\u7279\u529f\u80fd\u5982\u9002\u5e94\u6027\u7a81\u89e6\u53d1\u751f\u3002", "method": "\u901a\u8fc7\u8ba8\u8bba\u7b97\u6cd5\u65b9\u9762\u3001\u4f7f\u7528\u6a21\u62df\u6f14\u793a\u529f\u80fd\uff0c\u5e76\u8bbe\u8ba1\u7eb3\u7c73\u78c1\u786c\u4ef6\u52a0\u901f\u5668\u6765\u5b9e\u73b0\u9002\u5e94\u6027\u7a81\u89e6\u53d1\u751f\u3002", "result": "\u6a21\u62df\u5c55\u793a\u4e86\u673a\u5236\u7684\u6709\u6548\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u786c\u4ef6\u52a0\u901f\u5668\u4ee5\u652f\u6301\u7a00\u758f\u548c\u6218\u7565\u6027\u7684\u7a81\u89e6\u8fde\u63a5\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u53ef\u63d0\u5347AI\u7cfb\u7edf\u7684\u5b66\u4e60\u80fd\u529b\uff0c\u907f\u514d\u9057\u5fd8\uff0c\u5e76\u9002\u7528\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u573a\u666f\u3002"}}
{"id": "1906.05682", "pdf": "https://arxiv.org/pdf/1906.05682", "abs": "https://arxiv.org/abs/1906.05682", "authors": ["Suraj Tripathi", "Abhay Kumar", "Abhiram Ramesh", "Chirag Singh", "Promod Yenigalla"], "title": "Focal Loss based Residual Convolutional Neural Network for Speech Emotion Recognition", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD", "stat.ML"], "comment": "Accepted in CICLing 2019", "summary": "This paper proposes a Residual Convolutional Neural Network (ResNet) based on\nspeech features and trained under Focal Loss to recognize emotion in speech.\nSpeech features such as Spectrogram and Mel-frequency Cepstral Coefficients\n(MFCCs) have shown the ability to characterize emotion better than just plain\ntext. Further Focal Loss, first used in One-Stage Object Detectors, has shown\nthe ability to focus the training process more towards hard-examples and\ndown-weight the loss assigned to well-classified examples, thus preventing the\nmodel from being overwhelmed by easily classifiable examples.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eResNet\u7684\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u65b9\u6cd5\uff0c\u4f7f\u7528\u8bed\u97f3\u7279\u5f81\uff08\u5982Spectrogram\u548cMFCC\uff09\u5e76\u91c7\u7528Focal Loss\u8bad\u7ec3\u3002", "motivation": "\u8bed\u97f3\u7279\u5f81\u6bd4\u7eaf\u6587\u672c\u66f4\u597d\u5730\u8868\u5f81\u60c5\u611f\uff0cFocal Loss\u80fd\u5173\u6ce8\u96be\u4f8b\u6837\u672c\uff0c\u9632\u6b62\u6a21\u578b\u88ab\u6613\u5206\u7c7b\u6837\u672c\u4e3b\u5bfc\u3002", "method": "\u63d0\u51faResNet\u6a21\u578b\uff0c\u4f7f\u7528Spectrogram\u548cMFCC\u7279\u5f81\uff0c\u8bad\u7ec3\u65f6\u5e94\u7528Focal Loss\u3002", "result": "\u6539\u8fdb\u4e86\u60c5\u611f\u8bc6\u522b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5bf9\u96be\u4f8b\u7684\u5904\u7406\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u63d0\u5347\u4e86\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2504.10766", "pdf": "https://arxiv.org/pdf/2504.10766", "abs": "https://arxiv.org/abs/2504.10766", "authors": ["Ming Li", "Yanhong Li", "Ziyue Li", "Tianyi Zhou"], "title": "How Instruction and Reasoning Data shape Post-Training: Data Quality through the Lens of Layer-wise Gradients", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "As the post-training of large language models (LLMs) advances from\ninstruction-following to complex reasoning tasks, understanding how different\ndata affect finetuning dynamics remains largely unexplored. In this paper, we\npresent a spectral analysis of layer-wise gradients induced by low/high-quality\ninstruction and reasoning data for LLM post-training. Our analysis reveals that\nwidely-studied metrics for data evaluation, e.g., IFD, InsTag, Difficulty, and\nReward, can be explained and unified by spectral properties computed from\ngradients' singular value decomposition (SVD). Specifically, higher-quality\ndata are usually associated with lower nuclear norms and higher effective\nranks. Notably, effective rank exhibits better robustness and resolution than\nnuclear norm in capturing subtle quality differences. For example, reasoning\ndata achieves substantially higher effective ranks than instruction data,\nimplying richer gradient structures on more complex tasks. Our experiments also\nhighlight that models within the same family share similar gradient patterns\nregardless of their sizes, whereas different model families diverge\nsignificantly. Providing a unified view on the effects of data quality across\ninstruction and reasoning data, this work illuminates the interplay between\ndata quality and training stability, shedding novel insights into developing\nbetter data exploration strategies for post-training.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u68af\u5ea6\u8c31\u5206\u6790\u7edf\u4e00\u6570\u636e\u8d28\u91cf\u6307\u6807\uff0c\u5e76\u63ed\u793aLLM\u540e\u8bad\u7ec3\u4e2d\u6570\u636e\u8d28\u91cf\u4e0e\u8bad\u7ec3\u7a33\u5b9a\u6027\u7684\u5173\u7cfb\u3002", "motivation": "\u63a2\u7d22\u4e0d\u540c\u6570\u636e\u8d28\u91cf\u5982\u4f55\u5f71\u54cdLLM\u4ece\u6307\u4ee4\u8ddf\u968f\u5230\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u5fae\u8c03\u52a8\u6001\uff0c\u8fd9\u65b9\u9762\u7814\u7a76\u5c1a\u4e0d\u5145\u5206\u3002", "method": "\u4f7f\u7528\u5c42\u7ea7\u68af\u5ea6\u5947\u5f02\u503c\u5206\u89e3(SVD)\u8fdb\u884c\u8c31\u5206\u6790\uff0c\u89e3\u91ca\u6307\u6807\u5982\u6838\u8303\u6570\u548c\u6709\u6548\u79e9\u3002", "result": "\u9ad8\u8d28\u91cf\u6570\u636e\u5177\u6709\u8f83\u4f4e\u6838\u8303\u6570\u548c\u8f83\u9ad8\u6709\u6548\u79e9\uff1b\u63a8\u7406\u6570\u636e\u6709\u6548\u79e9\u66f4\u9ad8\uff1b\u540c\u4e00\u6a21\u578b\u5bb6\u65cf\u68af\u5ea6\u6a21\u5f0f\u76f8\u4f3c\u3002", "conclusion": "\u63d0\u4f9b\u6570\u636e\u8d28\u91cf\u7edf\u4e00\u89c6\u89d2\uff0c\u9610\u660e\u5176\u4e0e\u8bad\u7ec3\u7a33\u5b9a\u6027\u7684\u4e92\u52a8\uff0c\u5e76\u4e3a\u4f18\u5316\u6570\u636e\u63a2\u7d22\u7b56\u7565\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002"}}
{"id": "2504.10962", "pdf": "https://arxiv.org/pdf/2504.10962", "abs": "https://arxiv.org/abs/2504.10962", "authors": ["Edvin Martin Andrejev", "Amith Manoharan", "Karl-Eerik Unt", "Arun Kumar Singh"], "title": "$\u03c0$-MPPI: A Projection-based Model Predictive Path Integral Scheme for Smooth Optimal Control of Fixed-Wing Aerial Vehicles", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "8 pages, 4 figures, submitted to IEEE RA-L", "summary": "Model Predictive Path Integral (MPPI) is a popular sampling-based Model\nPredictive Control (MPC) algorithm for nonlinear systems. It optimizes\ntrajectories by sampling control sequences and averaging them. However, a key\nissue with MPPI is the non-smoothness of the optimal control sequence, leading\nto oscillations in systems like fixed-wing aerial vehicles (FWVs). Existing\nsolutions use post-hoc smoothing, which fails to bound control derivatives.\nThis paper introduces a new approach: we add a projection filter $\\pi$ to\nminimally correct control samples, ensuring bounds on control magnitude and\nhigher-order derivatives. The filtered samples are then averaged using MPPI,\nleading to our $\\pi$-MPPI approach. We minimize computational overhead by using\na neural accelerated custom optimizer for the projection filter. $\\pi$-MPPI\noffers a simple way to achieve arbitrary smoothness in control sequences. While\nwe focus on FWVs, this projection filter can be integrated into any MPPI\npipeline. Applied to FWVs, $\\pi$-MPPI is easier to tune than the baseline,\nresulting in smoother, more robust performance.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165\u03c0-MPPI\u65b9\u6cd5\uff0c\u901a\u8fc7\u6dfb\u52a0\u6295\u5f71\u8fc7\u6ee4\u5668\u6539\u5584MPPI\u7b97\u6cd5\u7684\u63a7\u5236\u5e73\u6ed1\u6027\uff0c\u9488\u5bf9\u975e\u7ebf\u6027\u7cfb\u7edf\u5982\u56fa\u5b9a\u7ffc\u98de\u884c\u5668\u3002", "motivation": "MPPI\u7b97\u6cd5\u7684\u63a7\u5236\u5e8f\u5217\u4e0d\u5e73\u6ed1\u5bfc\u81f4\u7cfb\u7edf\u632f\u8361\uff0c\u73b0\u6709\u7684\u5e73\u6ed1\u89e3\u51b3\u65b9\u6848\u65e0\u6cd5\u9650\u5236\u63a7\u5236\u5bfc\u6570\u3002", "method": "\u6dfb\u52a0\u6295\u5f71\u8fc7\u6ee4\u5668\u03c0\u6700\u5c0f\u5316\u4fee\u6b63\u63a7\u5236\u6837\u672c\uff0c\u786e\u4fdd\u63a7\u5236\u5e45\u5ea6\u548c\u5bfc\u6570\u7684\u8fb9\u754c\uff0c\u5e76\u4f7f\u7528\u795e\u7ecf\u52a0\u901f\u7684\u81ea\u5b9a\u4e49\u4f18\u5316\u5668\u3002", "result": "\u03c0-MPPI\u66f4\u5bb9\u6613\u8c03\u53c2\uff0c\u5728\u56fa\u5b9a\u7ffc\u98de\u884c\u5668\u4e0a\u5b9e\u73b0\u66f4\u5e73\u6ed1\u548c\u9c81\u68d2\u7684\u6027\u80fd\u3002", "conclusion": "\u03c0-MPPI\u63d0\u4f9b\u7b80\u5355\u65b9\u6cd5\u5b9e\u73b0\u4efb\u610f\u5e73\u6ed1\u5ea6\u7684\u63a7\u5236\u5e8f\u5217\uff0c\u53ef\u6574\u5408\u5230\u4efb\u4f55MPPI\u7ba1\u9053\u4e2d\u3002"}}
{"id": "1908.08652", "pdf": "https://arxiv.org/pdf/1908.08652", "abs": "https://arxiv.org/abs/1908.08652", "authors": ["Abhay Kumar", "Nishant Jain", "Suraj Tripathi", "Chirag Singh", "Kamal Krishna"], "title": "MTCNET: Multi-task Learning Paradigm for Crowd Count Estimation", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "5 pages, 3 figures, Accepted in IEEE AVSS 2019", "summary": "We propose a Multi-Task Learning (MTL) paradigm based deep neural network\narchitecture, called MTCNet (Multi-Task Crowd Network) for crowd density and\ncount estimation. Crowd count estimation is challenging due to the non-uniform\nscale variations and the arbitrary perspective of an individual image. The\nproposed model has two related tasks, with Crowd Density Estimation as the main\ntask and Crowd-Count Group Classification as the auxiliary task. The auxiliary\ntask helps in capturing the relevant scale-related information to improve the\nperformance of the main task. The main task model comprises two blocks: VGG-16\nfront-end for feature extraction and a dilated Convolutional Neural Network for\ndensity map generation. The auxiliary task model shares the same front-end as\nthe main task, followed by a CNN classifier. Our proposed network achieves 5.8%\nand 14.9% lower Mean Absolute Error (MAE) than the state-of-the-art methods on\nShanghaiTech dataset without using any data augmentation. Our model also\noutperforms with 10.5% lower MAE on UCF_CC_50 dataset.", "AI": {"tldr": "\u7b80\u800c\u8a00\u4e4b\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edcMTCNet\uff0c\u7528\u4e8e\u4eba\u7fa4\u5bc6\u5ea6\u548c\u8ba1\u6570\u4f30\u8ba1\u3002", "motivation": "\u4eba\u7fa4\u8ba1\u6570\u4f30\u8ba1\u56e0\u975e\u5747\u5300\u5c3a\u5ea6\u53d8\u5316\u548c\u4efb\u610f\u89c6\u89d2\u800c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51faMTCNet\uff0c\u5305\u62ec\u4e3b\u8981\u4efb\u52a1\uff08\u5bc6\u5ea6\u4f30\u8ba1\uff0c\u4f7f\u7528VGG-16\u548c\u6269\u5f20CNN\u751f\u6210\u5bc6\u5ea6\u56fe\uff09\u548c\u8f85\u52a9\u4efb\u52a1\uff08\u8ba1\u6570\u7ec4\u5206\u7c7b\uff0c\u5171\u4eab\u524d\u7aef\u5e76\u7528CNN\u5206\u7c7b\u5668\uff09\u3002", "result": "\u5728ShanghaiTech\u6570\u636e\u96c6\u4e0aMAE\u964d\u4f4e5.8%\u548c14.9%\uff0c\u5728UCF_CC_50\u6570\u636e\u96c6\u4e0a\u964d\u4f4e10.5%\uff0c\u65e0\u9700\u6570\u636e\u589e\u5f3a\u3002", "conclusion": "\u6a21\u578b\u5728\u4eba\u7fa4\u8ba1\u6570\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2504.10770", "pdf": "https://arxiv.org/pdf/2504.10770", "abs": "https://arxiv.org/abs/2504.10770", "authors": ["Donglin Zhan", "Haoting Zhang", "Rhonda Righter", "Zeyu Zheng", "James Anderson"], "title": "Collaborative Bayesian Optimization via Wasserstein Barycenters", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Motivated by the growing need for black-box optimization and data privacy, we\nintroduce a collaborative Bayesian optimization (BO) framework that addresses\nboth of these challenges. In this framework agents work collaboratively to\noptimize a function they only have oracle access to. In order to mitigate\nagainst communication and privacy constraints, agents are not allowed to share\ntheir data but can share their Gaussian process (GP) surrogate models. To\nenable collaboration under these constraints, we construct a central model to\napproximate the objective function by leveraging the concept of Wasserstein\nbarycenters of GPs. This central model integrates the shared models without\naccessing the underlying data. A key aspect of our approach is a collaborative\nacquisition function that balances exploration and exploitation, allowing for\nthe optimization of decision variables collaboratively in each iteration. We\nprove that our proposed algorithm is asymptotically consistent and that its\nimplementation via Monte Carlo methods is numerically accurate. Through\nnumerical experiments, we demonstrate that our approach outperforms other\nbaseline collaborative frameworks and is competitive with centralized\napproaches that do not consider data privacy.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u534f\u4f5c\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u9ed1\u7bb1\u4f18\u5316\u548c\u6570\u636e\u9690\u79c1\u95ee\u9898\uff0c\u901a\u8fc7\u5171\u4eab\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\u800c\u975e\u6570\u636e\uff0c\u4f7f\u7528Wasserstein\u91cd\u5fc3\u8fdb\u884c\u534f\u4f5c\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6027\u80fd\u4f18\u5f02\u3002", "motivation": "\u53d7\u9ed1\u7bb1\u4f18\u5316\u548c\u6570\u636e\u9690\u79c1\u9700\u6c42\u589e\u957f\u7684\u9a71\u52a8\uff0c\u8bba\u6587\u5f15\u5165\u4ee3\u7406\u534f\u4f5c\u4f18\u5316\u6846\u67b6\u3002", "method": "\u6784\u5efa\u4e2d\u5fc3\u6a21\u578b\u4f7f\u7528Wasserstein\u91cd\u5fc3\u6574\u5408\u5171\u4eab\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\uff0c\u8bbe\u8ba1\u534f\u4f5c\u91c7\u96c6\u51fd\u6570\uff0c\u5e76\u901a\u8fc7\u8499\u7279\u5361\u7f57\u65b9\u6cd5\u5b9e\u73b0\u3002", "result": "\u8bc1\u660e\u7b97\u6cd5\u6e10\u8fd1\u4e00\u81f4\u6027\u548c\u6570\u503c\u51c6\u786e\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u5176\u4ed6\u534f\u4f5c\u6846\u67b6\uff0c\u5e76\u4e0e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u7ade\u4e89\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6570\u636e\u9690\u79c1\u7ea6\u675f\u4e0b\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u534f\u4f5c\u4f18\u5316\u3002"}}
{"id": "2504.11045", "pdf": "https://arxiv.org/pdf/2504.11045", "abs": "https://arxiv.org/abs/2504.11045", "authors": ["Shreenabh Agrawal", "Manan Tayal", "Aditya Singh", "Shishir Kolathaya"], "title": "Neural Control Barrier Functions from Physics Informed Neural Networks", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "8 pages, 5 figures", "summary": "As autonomous systems become increasingly prevalent in daily life, ensuring\ntheir safety is paramount. Control Barrier Functions (CBFs) have emerged as an\neffective tool for guaranteeing safety; however, manually designing them for\nspecific applications remains a significant challenge. With the advent of deep\nlearning techniques, recent research has explored synthesizing CBFs using\nneural networks-commonly referred to as neural CBFs. This paper introduces a\nnovel class of neural CBFs that leverages a physics-inspired neural network\nframework by incorporating Zubov's Partial Differential Equation (PDE) within\nthe context of safety. This approach provides a scalable methodology for\nsynthesizing neural CBFs applicable to high-dimensional systems. Furthermore,\nby utilizing reciprocal CBFs instead of zeroing CBFs, the proposed framework\nallows for the specification of flexible, user-defined safe regions. To\nvalidate the effectiveness of the approach, we present case studies on three\ndifferent systems: an inverted pendulum, autonomous ground navigation, and\naerial navigation in obstacle-laden environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u795e\u7ecf\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u65b9\u6cd5\uff0c\u4f7f\u7528Zubov's\u504f\u5fae\u5206\u65b9\u7a0b\u6765\u63d0\u5347\u81ea\u4e3b\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b\u7cfb\u7edf\u5728\u65e5\u5e38\u751f\u6d3b\u4e2d\u7684\u666e\u53ca\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u624b\u52a8\u8bbe\u8ba1\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u6b64\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5408\u6210\u795e\u7ecfCBF\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u542f\u53d1\u7684\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u5c06Zubov's PDE\u878d\u5165\u5b89\u5168\u6027\u4e0a\u4e0b\u6587\u4e2d\uff0c\u4f7f\u7528\u4e92\u60e0CBF\u5b9a\u4e49\u7075\u6d3b\u7684\u5b89\u5168\u533a\u57df\uff0c\u5e76\u9002\u7528\u4e8e\u9ad8\u7ef4\u7cfb\u7edf\u3002", "result": "\u901a\u8fc7\u5012\u7acb\u6446\u3001\u81ea\u4e3b\u5730\u9762\u5bfc\u822a\u548c\u7a7a\u4e2d\u969c\u788d\u73af\u5883\u5bfc\u822a\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u795e\u7ecfCBF\u5408\u6210\u6846\u67b6\uff0c\u80fd\u591f\u6307\u5b9a\u7528\u6237\u81ea\u5b9a\u4e49\u7684\u5b89\u5168\u533a\u57df\uff0c\u63d0\u9ad8\u4e86\u81ea\u4e3b\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2504.09861", "pdf": "https://arxiv.org/pdf/2504.09861", "abs": "https://arxiv.org/abs/2504.09861", "authors": ["Luyao Zhang"], "title": "EthosGPT: Mapping Human Value Diversity to Advance Sustainable Development Goals (SDGs)", "categories": ["cs.CY", "cs.AI", "cs.HC", "econ.GN", "q-fin.EC", "stat.AP"], "comment": null, "summary": "Large language models (LLMs) are transforming global decision-making and\nsocietal systems by processing diverse data at unprecedented scales. However,\ntheir potential to homogenize human values poses critical risks, similar to\nbiodiversity loss undermining ecological resilience. Rooted in the ancient\nGreek concept of ethos, meaning both individual character and the shared moral\nfabric of communities, EthosGPT draws on a tradition that spans from\nAristotle's virtue ethics to Adam Smith's moral sentiments as the ethical\nfoundation of economic cooperation. These traditions underscore the vital role\nof value diversity in fostering social trust, institutional legitimacy, and\nlong-term prosperity. EthosGPT addresses the challenge of value homogenization\nby introducing an open-source framework for mapping and evaluating LLMs within\na global scale of human values. Using international survey data on cultural\nindices, prompt-based assessments, and comparative statistical analyses,\nEthosGPT reveals both the adaptability and biases of LLMs across regions and\ncultures. It offers actionable insights for developing inclusive LLMs, such as\ndiversifying training data and preserving endangered cultural heritage to\nensure representation in AI systems. These contributions align with the United\nNations Sustainable Development Goals (SDGs), especially SDG 10 (Reduced\nInequalities), SDG 11.4 (Cultural Heritage Preservation), and SDG 16 (Peace,\nJustice and Strong Institutions). Through interdisciplinary collaboration,\nEthosGPT promotes AI systems that are both technically robust and ethically\ninclusive, advancing value plurality as a cornerstone for sustainable and\nequitable futures.", "AI": {"tldr": "EthosGPT \u662f\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5168\u7403\u4ef7\u503c\u89c2\u4e2d\u7684\u8868\u73b0\uff0c\u9632\u6b62\u4ef7\u503c\u540c\u8d28\u5316\uff0c\u4fc3\u8fdb\u6587\u5316\u591a\u6837\u6027\u3002", "motivation": "LLMs \u53ef\u80fd\u5bfc\u81f4\u4eba\u7c7b\u4ef7\u503c\u89c2\u540c\u8d28\u5316\uff0c\u7c7b\u4f3c\u4e8e\u751f\u7269\u591a\u6837\u6027\u4e27\u5931\u7684\u98ce\u9669\uff0c\u8bba\u6587\u501f\u9274\u5386\u53f2\u4f26\u7406\u4f20\u7edf\uff0c\u5f3a\u8c03\u4ef7\u503c\u591a\u6837\u6027\u5bf9\u793e\u4f1a\u4fe1\u4efb\u548c\u7e41\u8363\u7684\u91cd\u8981\u6027\u3002", "method": "\u4f7f\u7528\u56fd\u9645\u8c03\u67e5\u6570\u636e\u3001\u57fa\u4e8e\u63d0\u793a\u7684\u8bc4\u4f30\u548c\u6bd4\u8f83\u7edf\u8ba1\u5206\u6790\uff0c\u6620\u5c04\u548c\u8bc4\u4f30 LLMs \u5728\u4e0d\u540c\u5730\u533a\u548c\u6587\u5316\u4e2d\u7684\u9002\u5e94\u6027\u548c\u504f\u5dee\u3002", "result": "\u63ed\u793a LLMs \u7684\u9002\u5e94\u6027\u548c\u504f\u5dee\uff0c\u63d0\u4f9b\u89c1\u89e3\u5982\u591a\u6837\u5316\u8bad\u7ec3\u6570\u636e\u548c\u4fdd\u62a4\u6587\u5316\u9057\u4ea7\uff0c\u4ee5\u786e\u4fdd AI \u7cfb\u7edf\u7684\u5305\u5bb9\u6027\u3002", "conclusion": "\u901a\u8fc7\u8de8\u5b66\u79d1\u5408\u4f5c\uff0cEthosGPT \u63a8\u52a8\u4f26\u7406\u5305\u5bb9\u7684 AI \u7cfb\u7edf\uff0c\u63a8\u8fdb\u4ef7\u503c\u591a\u5143\u5316\uff0c\u652f\u6301\u8054\u5408\u56fd\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\uff0c\u5b9e\u73b0\u53ef\u6301\u7eed\u516c\u5e73\u672a\u6765\u3002"}}
{"id": "2504.10777", "pdf": "https://arxiv.org/pdf/2504.10777", "abs": "https://arxiv.org/abs/2504.10777", "authors": ["Manu Bhat", "Jonghyun Park", "Jianke Yang", "Nima Dehmamy", "Robin Walters", "Rose Yu"], "title": "AtlasD: Automatic Local Symmetry Discovery", "categories": ["cs.LG"], "comment": null, "summary": "Existing symmetry discovery methods predominantly focus on global\ntransformations across the entire system or space, but they fail to consider\nthe symmetries in local neighborhoods. This may result in the reported symmetry\ngroup being a misrepresentation of the true symmetry. In this paper, we\nformalize the notion of local symmetry as atlas equivariance. Our proposed\npipeline, automatic local symmetry discovery (AtlasD), recovers the local\nsymmetries of a function by training local predictor networks and then learning\na Lie group basis to which the predictors are equivariant. We demonstrate\nAtlasD is capable of discovering local symmetry groups with multiple connected\ncomponents in top-quark tagging and partial differential equation experiments.\nThe discovered local symmetry is shown to be a useful inductive bias that\nimproves the performance of downstream tasks in climate segmentation and vision\ntasks.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faAtlasD\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u5c40\u90e8\u5bf9\u79f0\u6027\uff0c\u53d1\u73b0\u5e76\u5e94\u7528\u5b83\u6765\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u5c40\u90e8\u90bb\u57df\u5bf9\u79f0\u6027\uff0c\u5bfc\u81f4\u5bf9\u79f0\u7fa4\u8bef\u62a5\uff0c\u9700\u8981\u5f00\u53d1\u5c40\u90e8\u5bf9\u79f0\u6027\u53d1\u73b0\u673a\u5236\u3002", "method": "\u8bad\u7ec3\u5c40\u90e8\u9884\u6d4b\u5668\u7f51\u7edc\u5e76\u5b66\u4e60\u674e\u7fa4\u57fa\uff0c\u5b9e\u73b0\u51fd\u6570\u7684\u5c40\u90e8\u5bf9\u79f0\u6027\uff08\u56fe\u96c6\u7b49\u53d8\u6027\uff09\u3002", "result": "\u5728\u9876\u5938\u514b\u6807\u8bb0\u548c\u504f\u5fae\u5206\u65b9\u7a0b\u5b9e\u9a8c\u4e2d\u53d1\u73b0\u591a\u8fde\u901a\u5206\u91cf\u5c40\u90e8\u5bf9\u79f0\u7fa4\uff0c\u5e76\u6539\u5584\u6c14\u5019\u5206\u5272\u548c\u89c6\u89c9\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u5c40\u90e8\u5bf9\u79f0\u6027\u4f5c\u4e3a\u5f52\u7eb3\u504f\u5dee\uff0c\u80fd\u663e\u8457\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2504.11064", "pdf": "https://arxiv.org/pdf/2504.11064", "abs": "https://arxiv.org/abs/2504.11064", "authors": ["Bo Ma", "Yi Ji", "Liyong Fang"], "title": "A Multi-UAV Formation Obstacle Avoidance Method Combined Improved Simulated Annealing and Adaptive Artificial Potential Field", "categories": ["cs.MA", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "The traditional Artificial Potential Field (APF) method exhibits limitations\nin its force distribution: excessive attraction when UAVs are far from the\ntarget may cause collisions with obstacles, while insufficient attraction near\nthe goal often results in failure to reach the target. Furthermore, APF is\nhighly susceptible to local minima, compromising motion reliability in complex\nenvironments. To address these challenges, this paper presents a novel hybrid\nobstacle avoidance algorithm-Deflected Simulated Annealing-Adaptive Artificial\nPotential Field (DSA-AAPF)-which combines an improved simulated annealing\nmechanism with an enhanced APF model. The proposed approach integrates a\nLeader-Follower distributed formation strategy with the APF framework, where\nthe resultant force formulation is redefined to smooth UAV trajectories. An\nadaptive gravitational gain function is introduced to dynamically adjust UAV\nvelocity based on environmental context, and a fast-converging controller\nensures accurate and efficient convergence to the target. Moreover, a\ndirectional deflection mechanism is embedded within the simulated annealing\nprocess, enabling UAVs to escape local minima caused by semi-enclosed obstacles\nthrough continuous rotational motion. The simulation results, covering\nformation reconfiguration, complex obstacle avoidance, and entrapment escape,\ndemonstrate the feasibility, robustness, and superiority of the proposed\nDSA-AAPF algorithm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDSA-AAPF\u6df7\u5408\u7b97\u6cd5\uff0c\u6539\u5584UAV\u969c\u788d\u907f\u514d\uff0c\u89e3\u51b3\u4f20\u7edfAPF\u7684\u5c40\u9650\u6027\uff0c\u5982\u5c40\u90e8\u6700\u5c0f\u503c\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfAPF\u65b9\u6cd5\u529b\u5206\u5e03\u4e0d\u5f53\uff0c\u53ef\u80fd\u5bfc\u81f4\u78b0\u649e\u6216\u65e0\u6cd5\u8fbe\u6807\uff0c\u4e14\u6613\u9677\u5c40\u90e8\u6700\u5c0f\u503c\uff0c\u5f71\u54cd\u590d\u6742\u73af\u5883\u4e0b\u7684\u53ef\u9760\u6027\u3002", "method": "\u7ed3\u5408\u6539\u8fdb\u6a21\u62df\u9000\u706b\u548c\u589e\u5f3aAPF\uff0c\u878d\u5165Leader-Follower\u7b56\u7565\u3001\u81ea\u9002\u5e94\u91cd\u529b\u589e\u76ca\u3001\u5feb\u901f\u6536\u655b\u63a7\u5236\u5668\u548c\u65b9\u5411\u504f\u8f6c\u673a\u5236\uff0c\u4ee5\u5e73\u6ed1\u8f68\u8ff9\u5e76\u9003\u79bb\u5c40\u90e8\u6700\u5c0f\u503c\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8bc1\u660eDSA-AAPF\u5728\u7f16\u961f\u91cd\u6784\u3001\u590d\u6742\u969c\u788d\u907f\u514d\u548c\u9003\u8131\u9677\u9631\u65b9\u9762\u5177\u6709\u53ef\u884c\u6027\u3001\u9c81\u68d2\u6027\u548c\u4f18\u8d8a\u6027\u3002", "conclusion": "DSA-AAPF\u7b97\u6cd5\u6709\u6548\u63d0\u5347UAV\u8fd0\u52a8\u53ef\u9760\u6027\u548c\u76ee\u6807\u5230\u8fbe\u7387\uff0c\u9002\u7528\u4e8e\u590d\u6742\u73af\u5883\u3002"}}
{"id": "2504.10489", "pdf": "https://arxiv.org/pdf/2504.10489", "abs": "https://arxiv.org/abs/2504.10489", "authors": ["Vikranth Udandarao", "Noel Abraham Tiju", "Muthuraj Vairamuthu", "Harsh Mistry", "Dhruv Kumar"], "title": "Roamify: Designing and Evaluating an LLM Based Google Chrome Extension for Personalised Itinerary Planning", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": "for code implementation, check\n  https://github.com/Roamify-Research/Roamify", "summary": "In this paper, we present Roamify, an Artificial Intelligence powered travel\nassistant that aims to ease the process of travel planning. We have tested and\nused multiple Large Language Models like Llama and T5 to generate personalised\nitineraries per user preferences. Results from user surveys highlight the\npreference for AI powered mediums over existing methods to help in travel\nplanning across all user age groups. These results firmly validate the\npotential need of such a travel assistant. We highlight the two primary design\nconsiderations for travel assistance: D1) incorporating a web-scraping method\nto gather up-to-date news articles about destinations from various blog\nsources, which significantly improves our itinerary suggestions, and D2)\nutilising user preferences to create customised travel experiences along with a\nrecommendation system which changes the itinerary according to the user needs.\nOur findings suggest that Roamify has the potential to improve and simplify how\nusers across multiple age groups plan their travel experiences.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Roamify\uff0c\u4e00\u6b3eAI\u9a71\u52a8\u7684\u65c5\u884c\u52a9\u624b\uff0c\u4f7f\u7528LLM\u751f\u6210\u4e2a\u6027\u5316\u884c\u7a0b\uff0c\u7528\u6237\u8c03\u67e5\u8bc1\u5b9e\u5176\u9700\u6c42\u548c\u6709\u6548\u6027\u3002", "motivation": "\u7b80\u5316\u65c5\u884c\u89c4\u5212\u8fc7\u7a0b\uff0c\u54cd\u5e94\u7528\u6237\u5bf9AI\u8f85\u52a9\u7684\u504f\u597d\uff0c\u6ee1\u8db3\u5404\u5e74\u9f84\u6bb5\u9700\u6c42\u3002", "method": "\u4f7f\u7528Llama\u548cT5\u7b49LLM\u751f\u6210\u884c\u7a0b\uff0c\u7ed3\u5408\u7f51\u7edc\u722c\u866b\u83b7\u53d6\u5b9e\u65f6\u76ee\u7684\u5730\u4fe1\u606f\uff0c\u5e76\u57fa\u4e8e\u7528\u6237\u504f\u597d\u548c\u63a8\u8350\u7cfb\u7edf\u5b9a\u5236\u4f53\u9a8c\u3002", "result": "\u7528\u6237\u8c03\u67e5\u663e\u793aAI\u8f85\u52a9\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u65c5\u884c\u52a9\u624b\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u8bc1\u660e\u5176\u6539\u5584\u884c\u7a0b\u5efa\u8bae\u7684\u6548\u679c\u3002", "conclusion": "Roamify\u6709\u6f5c\u529b\u7b80\u5316\u591a\u5e74\u9f84\u6bb5\u7528\u6237\u7684\u65c5\u884c\u89c4\u5212\uff0c\u63d0\u4f9b\u66f4\u4e2a\u6027\u5316\u7684\u4f53\u9a8c\u3002"}}
{"id": "2504.10807", "pdf": "https://arxiv.org/pdf/2504.10807", "abs": "https://arxiv.org/abs/2504.10807", "authors": ["Huseyin Tuna Erdinc", "Yunlin Zeng", "Abhinav Prakash Gahlot", "Felix J. Herrmann"], "title": "Power-scaled Bayesian Inference with Score-based Generative mModels", "categories": ["cs.LG", "cs.CV", "physics.geo-ph"], "comment": "8 pages, 4 figures", "summary": "We propose a score-based generative algorithm for sampling from power-scaled\npriors and likelihoods within the Bayesian inference framework. Our algorithm\nenables flexible control over prior-likelihood influence without requiring\nretraining for different power-scaling configurations. Specifically, we focus\non synthesizing seismic velocity models conditioned on imaged seismic. Our\nmethod enables sensitivity analysis by sampling from intermediate power\nposteriors, allowing us to assess the relative influence of the prior and\nlikelihood on samples of the posterior distribution. Through a comprehensive\nset of experiments, we evaluate the effects of varying the power parameter in\ndifferent settings: applying it solely to the prior, to the likelihood of a\nBayesian formulation, and to both simultaneously. The results show that\nincreasing the power of the likelihood up to a certain threshold improves the\nfidelity of posterior samples to the conditioning data (e.g., seismic images),\nwhile decreasing the prior power promotes greater structural diversity among\nsamples. Moreover, we find that moderate scaling of the likelihood leads to a\nreduced shot data residual, confirming its utility in posterior refinement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5f97\u5206\u7684\u751f\u6210\u7b97\u6cd5\uff0c\u7528\u4e8e\u4ece\u5e42\u7f29\u653e\u7684\u5148\u9a8c\u548c\u4f3c\u7136\u4e2d\u91c7\u6837\uff0c\u5b9e\u73b0\u8d1d\u53f6\u65af\u63a8\u7406\u4e2d\u5bf9\u540e\u9a8c\u5206\u5e03\u7684\u7075\u6d3b\u63a7\u5236\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5730\u9707\u901f\u5ea6\u6a21\u578b\u3002", "motivation": "\u4e3a\u4e86\u5728\u8d1d\u53f6\u65af\u63a8\u7406\u4e2d\u7075\u6d3b\u63a7\u5236\u5148\u9a8c\u548c\u4f3c\u7136\u7684\u76f8\u5bf9\u5f71\u54cd\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u5e76\u901a\u8fc7\u654f\u611f\u6027\u5206\u6790\u8bc4\u4f30\u5176\u5bf9\u540e\u9a8c\u5206\u5e03\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5f97\u5206\u7684\u751f\u6210\u7b97\u6cd5\uff0c\u4ece\u5e42\u7f29\u653e\u7684\u5148\u9a8c\u548c\u4f3c\u7136\u4e2d\u91c7\u6837\uff0c\u4e13\u6ce8\u4e8e\u6761\u4ef6\u5730\u9707\u56fe\u50cf\u7684\u5730\u9707\u901f\u5ea6\u6a21\u578b\u5408\u6210\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u63d0\u9ad8\u4f3c\u7136\u5e42\u53ef\u63d0\u5347\u540e\u9a8c\u6837\u672c\u5bf9\u6570\u636e\u7684\u4fdd\u771f\u5ea6\uff0c\u964d\u4f4e\u5148\u9a8c\u5e42\u53ef\u589e\u52a0\u6837\u672c\u7ed3\u6784\u591a\u6837\u6027\uff0c\u4e2d\u7b49\u4f3c\u7136\u7f29\u653e\u53ef\u51cf\u5c11\u5c04\u7ebf\u6570\u636e\u6b8b\u5dee\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u540e\u9a8c\u5206\u5e03\u7684\u7ec6\u5316\u548c\u654f\u611f\u6027\u5206\u6790\uff0c\u63d0\u9ad8\u4e86\u8d1d\u53f6\u65af\u63a8\u7406\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2504.11372", "pdf": "https://arxiv.org/pdf/2504.11372", "abs": "https://arxiv.org/abs/2504.11372", "authors": ["Zhengbing He", "Jorge Laval", "Yu Han", "Ryosuke Nishi", "Cathy Wu"], "title": "A Review of Traffic Wave Suppression Strategies: Variable Speed Limit vs. Jam-Absorption Driving", "categories": ["physics.soc-ph", "cs.SY", "eess.SY", "stat.AP"], "comment": null, "summary": "The main form of freeway traffic congestion is the familiar stop-and-go wave,\ncharacterized by wide moving jams that propagate indefinitely upstream provided\nenough traffic demand. They cause severe, long-lasting adverse effects, such as\nreduced traffic efficiency, increased driving risks, and higher vehicle\nemissions. This underscores the crucial importance of artificial intervention\nin the propagation of stop-and-go waves. Over the past two decades, two\nprominent strategies for stop-and-go wave suppression have emerged: variable\nspeed limit (VSL) and jam-absorption driving (JAD). Although they share similar\nresearch motivations, objectives, and theoretical foundations, the development\nof these strategies has remained relatively disconnected. To synthesize\nfragmented advances and drive the field forward, this paper first provides a\ncomprehensive review of the achievements in the stop-and-go wave\nsuppression-oriented VSL and JAD, respectively. It then focuses on bridging the\ntwo areas and identifying research opportunities from the following\nperspectives: fundamental diagrams, traffic dynamics modeling, traffic state\nestimation and prediction, stochasticity, scenarios for strategy validation,\nand field tests and practical deployment. We expect that through this review,\none area can effectively address its limitations by identifying and leveraging\nthe strengths of the other, thus promoting the overall research goal of freeway\nstop-and-go wave suppression.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u56de\u987e\u4e86\u53ef\u53d8\u901f\u5ea6\u9650\u5236\uff08VSL\uff09\u548c\u62e5\u5835\u5438\u6536\u9a7e\u9a76\uff08JAD\uff09\u5728\u6291\u5236\u9ad8\u901f\u516c\u8def\u505c\u8f66-\u8d77\u6b65\u6ce2\u65b9\u9762\u7684\u8fdb\u5c55\uff0c\u5e76\u63d0\u51fa\u6865\u63a5\u4e24\u4e2a\u9886\u57df\u4ee5\u63a8\u52a8\u7814\u7a76\u3002", "motivation": "\u6291\u5236\u505c\u8f66-\u8d77\u6b65\u6ce2\u4ee5\u63d0\u9ad8\u4ea4\u901a\u6548\u7387\u3001\u51cf\u5c11\u9a7e\u9a76\u98ce\u9669\u548c\u964d\u4f4e\u8f66\u8f86\u6392\u653e\u3002", "method": "\u5168\u9762\u56de\u987eVSL\u548cJAD\u7684\u6210\u5c31\uff0c\u5e76\u4ece\u57fa\u672c\u56fe\u3001\u4ea4\u901a\u52a8\u6001\u5efa\u6a21\u3001\u4ea4\u901a\u72b6\u6001\u4f30\u8ba1\u548c\u9884\u6d4b\u3001\u968f\u673a\u6027\u3001\u7b56\u7565\u9a8c\u8bc1\u573a\u666f\u4ee5\u53ca\u73b0\u573a\u6d4b\u8bd5\u548c\u5b9e\u9645\u90e8\u7f72\u89d2\u5ea6\u6865\u63a5\u4e24\u4e2a\u9886\u57df\u3002", "result": "\u671f\u671b\u901a\u8fc7\u6865\u63a5VSL\u548cJAD\uff0c\u89e3\u51b3\u5404\u81ea\u5c40\u9650\u6027\uff0c\u4fc3\u8fdb\u505c\u8f66-\u8d77\u6b65\u6ce2\u6291\u5236\u7814\u7a76\u3002", "conclusion": "\u901a\u8fc7\u8fd9\u4e2a\u56de\u987e\uff0c\u4e00\u4e2a\u9886\u57df\u53ef\u5229\u7528\u53e6\u4e00\u4e2a\u4f18\u52bf\uff0c\u63a8\u52a8\u6574\u4f53\u7814\u7a76\u76ee\u6807\u5b9e\u73b0\u3002"}}
{"id": "2504.10496", "pdf": "https://arxiv.org/pdf/2504.10496", "abs": "https://arxiv.org/abs/2504.10496", "authors": ["Ning Li", "Jingran Zhang", "Justin Cui"], "title": "ArxivBench: Can LLMs Assist Researchers in Conducting Research?", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable effectiveness in\ncompleting various tasks such as reasoning, translation, and question\nanswering. However the issue of factual incorrect content in LLM-generated\nresponses remains a persistent challenge. In this study, we evaluate both\nproprietary and open-source LLMs on their ability to respond with relevant\nresearch papers and accurate links to articles hosted on the arXiv platform,\nbased on high level prompts. To facilitate this evaluation, we introduce\narXivBench, a benchmark specifically designed to assess LLM performance across\neight major subject categories on arXiv and five subfields within computer\nscience, one of the most popular categories among them. Our findings reveal a\nconcerning accuracy of LLM-generated responses depending on the subject, with\nsome subjects experiencing significantly lower accuracy than others. Notably,\nClaude-3.5-Sonnet exhibits a substantial advantage in generating both relevant\nand accurate responses. And interestingly, most LLMs achieve a much higher\naccuracy in the Artificial Intelligence sub-field than other sub-fields. This\nbenchmark provides a standardized tool for evaluating the reliability of\nLLM-generated scientific responses, promoting more dependable use of LLMs in\nacademic and research environments. Our code is open-sourced at\nhttps://github.com/arxivBenchLLM/arXivBench and our dataset is available on\nhuggingface at https://huggingface.co/datasets/arXivBenchLLM/arXivBench.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63d0\u4f9barXiv\u76f8\u5173\u8bba\u6587\u548c\u51c6\u786e\u94fe\u63a5\u65b9\u9762\u7684\u6027\u80fd\uff0c\u5f15\u5165arXivBench\u57fa\u51c6\uff0c\u53d1\u73b0\u6a21\u578b\u51c6\u786e\u6027\u56e0\u4e3b\u9898\u800c\u5f02\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u54cd\u5e94\u4e2d\u5b58\u5728\u4e8b\u5b9e\u9519\u8bef\u95ee\u9898\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5728\u5b66\u672f\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u5f15\u5165arXivBench\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e13\u6709\u548c\u5f00\u6e90LLM\u5728\u516b\u4e2aarXiv\u4e3b\u8981\u4e3b\u9898\u7c7b\u522b\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u4e94\u4e2a\u5b50\u9886\u57df\u4e2d\u7684\u6027\u80fd\u3002", "result": "\u6a21\u578b\u51c6\u786e\u6027\u56e0\u4e3b\u9898\u4e0d\u540c\u800c\u53d8\u5316\uff0cClaude-3.5-Sonnet\u8868\u73b0\u6700\u4f73\uff0c\u5728\u4eba\u5de5\u667a\u80fd\u5b50\u9886\u57df\u51c6\u786e\u6027\u66f4\u9ad8\u3002", "conclusion": "arXivBench\u63d0\u4f9b\u6807\u51c6\u5316\u5de5\u5177\uff0c\u63d0\u5347LLM\u5728\u7814\u7a76\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u5e76\u5f00\u6e90\u4ee3\u7801\u548c\u6570\u636e\u96c6\u3002"}}
{"id": "2504.10817", "pdf": "https://arxiv.org/pdf/2504.10817", "abs": "https://arxiv.org/abs/2504.10817", "authors": ["Penghao Wang", "Qian Chen", "Teng Zhang", "Yingwei Zhang", "Wang Lu", "Yiqiang Chen"], "title": "FHBench: Towards Efficient and Personalized Federated Learning for Multimodal Healthcare", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated Learning (FL) has emerged as an effective solution for\nmulti-institutional collaborations without sharing patient data, offering a\nrange of methods tailored for diverse applications. However, real-world medical\ndatasets are often multimodal, and computational resources are limited, posing\nsignificant challenges for existing FL approaches. Recognizing these\nlimitations, we developed the Federated Healthcare Benchmark(FHBench), a\nbenchmark specifically designed from datasets derived from real-world\nhealthcare applications. FHBench encompasses critical diagnostic tasks across\ndomains such as the nervous, cardiovascular, and respiratory systems and\ngeneral pathology, providing comprehensive support for multimodal healthcare\nevaluations and filling a significant gap in existing benchmarks. Building on\nFHBench, we introduced Efficient Personalized Federated Learning with Adaptive\nLoRA(EPFL), a personalized FL framework that demonstrates superior efficiency\nand effectiveness across various healthcare modalities. Our results highlight\nthe robustness of FHBench as a benchmarking tool and the potential of EPFL as\nan innovative approach to advancing healthcare-focused FL, addressing key\nlimitations of existing methods.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f00\u53d1\u4e86\u533b\u7597\u8054\u90a6\u5b66\u4e60\u57fa\u51c6FHBench\u548cEPFL\u6846\u67b6\uff0c\u4ee5\u5904\u7406\u591a\u6a21\u6001\u533b\u7597\u6570\u636e\u5e76\u63d0\u9ad8\u8054\u90a6\u5b66\u4e60\u6548\u7387\u3002", "motivation": "\u9488\u5bf9\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u7684\u591a\u6a21\u6001\u6027\u548c\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\uff0c\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u57fa\u51c6\u548c\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86FHBench\u57fa\u51c6\uff0c\u6db5\u76d6\u795e\u7ecf\u3001\u5fc3\u8840\u7ba1\u3001\u547c\u5438\u7cfb\u7edf\u548c\u4e00\u822c\u75c5\u7406\u9886\u57df\uff0c\u5e76\u5f15\u5165EPFL\u6846\u67b6\uff0c\u4f7f\u7528Adaptive LoRA\u8fdb\u884c\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u3002", "result": "EPFL\u5728\u5404\u79cd\u533b\u7597\u6a21\u5f0f\u4e2d\u663e\u793a\u51fa\u4f18\u8d8a\u7684\u6548\u7387\u548c\u6548\u679c\uff0cFHBench\u4f5c\u4e3a\u57fa\u51c6\u5de5\u5177\u8bc1\u660e\u4e86\u5176\u7a33\u5065\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u89e3\u51b3\u4e86\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63a8\u8fdb\u4e86\u533b\u7597\u9886\u57df\u7684\u8054\u90a6\u5b66\u4e60\u5e94\u7528\u3002"}}
{"id": "2504.11421", "pdf": "https://arxiv.org/pdf/2504.11421", "abs": "https://arxiv.org/abs/2504.11421", "authors": ["Mahdi Hasanzadeh", "Kasem Khalil", "Cynthia Sturton", "Ahmad Patooghy"], "title": "HeatSense: Intelligent Thermal Anomaly Detection for Securing NoC-Enabled MPSoCs", "categories": ["cs.AR", "cs.SY", "eess.SY"], "comment": "14 pages,", "summary": "Multi-Processor System-on-Chips (MPSoCs) are highly vulnerable to thermal\nattacks that manipulate dynamic thermal management systems. To counter this, we\npropose an adaptive real-time monitoring mechanism that detects abnormal\nthermal patterns in chip tiles. Our design space exploration helped identify\nkey thermal features for an efficient anomaly detection module to be\nimplemented at routers of network-enabled MPSoCs. To minimize hardware\noverhead, we employ weighted moving average (WMA) calculations and bit-shift\noperations, ensuring a lightweight yet effective implementation. By defining a\nspectrum of abnormal behaviors, our system successfully detects and mitigates\nmalicious temperature fluctuations, reducing severe cases from 3.00{\\deg}C to\n1.9{\\deg}C. The anomaly detection module achieves up to 82% of accuracy in\ndetecting thermal attacks, which is only 10-15% less than top-performing\nmachine learning (ML) models like Random Forest. However, our approach reduces\nhardware usage by up to 75% for logic resources and 100% for specialized\nresources, making it significantly more efficient than ML-based solutions. This\nmethod provides a practical, low-cost solution for resource-constrained\nenvironments, ensuring resilience against thermal attacks while maintaining\nsystem performance.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5b9e\u65f6\u76d1\u63a7\u673a\u5236\uff0c\u7528\u4e8e\u68c0\u6d4bMPSoC\u4e2d\u7684\u70ed\u653b\u51fb\uff0c\u63d0\u9ad8\u6548\u7387\u5e76\u51cf\u5c11\u786c\u4ef6\u5f00\u9500\u3002", "motivation": "MPSoC\u6613\u53d7\u70ed\u653b\u51fb\u5f71\u54cd\uff0c\u9700\u8981\u9ad8\u6548\u673a\u5236\u5bf9\u6297\u52a8\u6001\u70ed\u7ba1\u7406\u7cfb\u7edf\u7684\u64cd\u7eb5\u3002", "method": "\u4f7f\u7528\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u8bc6\u522b\u70ed\u7279\u5f81\uff0c\u5728\u8def\u7531\u5668\u5b9e\u73b0\u5f02\u5e38\u68c0\u6d4b\u6a21\u5757\uff0c\u91c7\u7528\u52a0\u6743\u79fb\u52a8\u5e73\u5747\u548c\u4f4d\u79fb\u64cd\u4f5c\u6700\u5c0f\u5316\u786c\u4ef6\u5f00\u9500\u3002", "result": "\u5c06\u6e29\u5ea6\u6ce2\u52a8\u4ece3.00\u00b0C\u51cf\u81f31.9\u00b0C\uff0c\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe82%\uff0c\u786c\u4ef6\u4f7f\u7528\u51cf\u5c1175%\u903b\u8f91\u8d44\u6e90\u548c100%\u4e13\u7528\u8d44\u6e90\uff0c\u6bd4ML\u6a21\u578b\u9ad8\u6548\u3002", "conclusion": "\u63d0\u4f9b\u5b9e\u7528\u3001\u4f4e\u6210\u672c\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\uff0c\u786e\u4fdd\u70ed\u653b\u51fb\u62b5\u6297\u529b\u548c\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2504.10833", "pdf": "https://arxiv.org/pdf/2504.10833", "abs": "https://arxiv.org/abs/2504.10833", "authors": ["Shubham Kumar", "Dwip Dalal", "Narendra Ahuja"], "title": "Towards Spatially-Aware and Optimally Faithful Concept-Based Explanations", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Post-hoc, unsupervised concept-based explanation methods (U-CBEMs) are a\npromising tool for generating semantic explanations of the decision-making\nprocesses in deep neural networks, having applications in both model\nimprovement and understanding. It is vital that the explanation is accurate, or\nfaithful, to the model, yet we identify several limitations of prior\nfaithfulness metrics that inhibit an accurate evaluation; most notably, prior\nmetrics involve only the set of concepts present, ignoring how they may be\nspatially distributed. We address these limitations with Surrogate Faithfulness\n(SF), an evaluation method that introduces a spatially-aware surrogate and two\nnovel faithfulness metrics. Using SF, we produce Optimally Faithful (OF)\nexplanations, where concepts are found that maximize faithfulness. Our\nexperiments show that (1) adding spatial-awareness to prior U-CBEMs increases\nfaithfulness in all cases; (2) OF produces significantly more faithful\nexplanations than prior U-CBEMs (30% or higher improvement in error); (3) OF's\nlearned concepts generalize well to out-of-domain data and are more robust to\nadversarial examples, where prior U-CBEMs struggle.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faSurrogate Faithfulness (SF)\u65b9\u6cd5\u6765\u8bc4\u4f30\u548c\u4f18\u5316\u6982\u5ff5-based\u89e3\u91ca\u7684\u5fe0\u5b9e\u5ea6\uff0c\u5b9e\u9a8c\u663e\u793a\u663e\u8457\u6539\u5584\u3002", "motivation": "\u73b0\u6709\u5fe0\u5b9e\u5ea6\u6307\u6807\u5ffd\u7565\u6982\u5ff5\u7a7a\u95f4\u5206\u5e03\uff0c\u5bfc\u81f4\u8bc4\u4f30\u4e0d\u51c6\u786e\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165SF\u6846\u67b6\u548cOptimally Faithful (OF)\u89e3\u91ca\uff0c\u901a\u8fc7\u7a7a\u95f4\u611f\u77e5\u4ee3\u7406\u548c\u65b0\u6307\u6807\u6700\u5927\u5316\u5fe0\u5b9e\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6dfb\u52a0\u7a7a\u95f4\u611f\u77e5\u63d0\u9ad8\u5fe0\u5b9e\u5ea6\uff1bOF\u89e3\u91ca\u9519\u8bef\u7387\u964d\u4f4e30%\u4ee5\u4e0a\uff1bOF\u5728\u6cdb\u5316\u548c\u5bf9\u6297\u6837\u672c\u4e0a\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u89e3\u91ca\u7684\u5fe0\u5b9e\u5ea6\u3001\u6cdb\u5316\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2504.10498", "pdf": "https://arxiv.org/pdf/2504.10498", "abs": "https://arxiv.org/abs/2504.10498", "authors": ["Jianling Lu", "Mingqi Lv"], "title": "CCSK:Cognitive Convection of Self-Knowledge Based Retrieval Augmentation for Large Language Models", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "The performance of large language models (LLMs) in Q&A task increased\nsubstantially through Retrieval-Augmented Generation (RAG) which brings in\nexternal knowledge. However, the main difficulty lies in balancing the inherent\nself-knowledge of LLMs with external information retrieval (IR). The current\nthreshold-based methods apply one-dimensional static mechanisms with single\ncriterion. As a result, their IR decisions might be irrelevant to the LLMs'\nresponse under difficult queries. To alleviate this problem, we propose\nCognitive Convection of Self-Knowledge (CCSK). Different from traditional\nmethods that maintain single fixed IR activation criteria, CCSK implements a\ndynamic joint decision process via a Siamese Network module and a Response\nQuality Model. The Siamese Network calculates the cosine similarity between the\ncurrent query and the historical queries. The Response Quality Model evaluates\nthe responses of LLMs through LightGBM. The final decision of the CCSK is\nderived from the outputs of the two modules, as well as text features fused\nusing a multi-head attention mechanism. Extensive experiments on real-world\ndatasets show that CCSK significantly enhances the model's effectiveness in\ninformation retrieval.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCCSK\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u51b3\u7b56\u6539\u5584LLM\u5728Q&A\u4efb\u52a1\u4e2d\u7684\u5916\u90e8\u77e5\u8bc6\u68c0\u7d22\uff0c\u5b9e\u9a8c\u663e\u793a\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5f53\u524dRAG\u65b9\u6cd5\u5728\u5e73\u8861LLM\u81ea\u6709\u77e5\u8bc6\u548c\u5916\u90e8\u68c0\u7d22\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u9608\u503c-based\u65b9\u6cd5\u53ef\u80fd\u5bfc\u81f4\u65e0\u5173\u51b3\u7b56\u3002", "method": "\u63d0\u51faCCSK\uff0c\u4f7f\u7528Siamese Network\u8ba1\u7b97\u67e5\u8be2\u76f8\u4f3c\u5ea6\uff0cResponse Quality Model\u57fa\u4e8eLightGBM\u8bc4\u4f30\u54cd\u5e94\uff0c\u5e76\u7528\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u7279\u5f81\u8fdb\u884c\u52a8\u6001\u51b3\u7b56\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u663e\u793aCCSK\u663e\u8457\u63d0\u5347\u4fe1\u606f\u68c0\u7d22\u7684\u6709\u6548\u6027\u3002", "conclusion": "CCSK\u65b9\u6cd5\u6709\u6548\u5730\u7f13\u89e3\u4e86RAG\u4e2d\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2504.10850", "pdf": "https://arxiv.org/pdf/2504.10850", "abs": "https://arxiv.org/abs/2504.10850", "authors": ["Meiqi Liu", "Zhuoqun Huang", "Yue Xing"], "title": "How to Enhance Downstream Adversarial Robustness (almost) without Touching the Pre-Trained Foundation Model?", "categories": ["cs.LG", "cs.CR"], "comment": "22 pages, 2 figures, 12 tables. Include 10 pages of appendices", "summary": "With the rise of powerful foundation models, a pre-training-fine-tuning\nparadigm becomes increasingly popular these days: A foundation model is\npre-trained using a huge amount of data from various sources, and then the\ndownstream users only need to fine-tune and adapt it to specific downstream\ntasks. However, due to the high computation complexity of adversarial training,\nit is not feasible to fine-tune the foundation model to improve its robustness\non the downstream task. Observing the above challenge, we want to improve the\ndownstream robustness without updating/accessing the weights in the foundation\nmodel. Inspired from existing literature in robustness inheritance (Kim et al.,\n2020), through theoretical investigation, we identify a close relationship\nbetween robust contrastive learning with the adversarial robustness of\nsupervised learning. To further validate and utilize this theoretical insight,\nwe design a simple-yet-effective robust auto-encoder as a data pre-processing\nmethod before feeding the data into the foundation model. The proposed approach\nhas zero access to the foundation model when training the robust auto-encoder.\nExtensive experiments demonstrate the effectiveness of the proposed method in\nimproving the robustness of downstream tasks, verifying the connection between\nthe feature robustness (implied by small adversarial contrastive loss) and the\nrobustness of the downstream task.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u9700\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u5c31\u63d0\u9ad8\u4e0b\u6e38\u4efb\u52a1\u9c81\u68d2\u6027\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u9c81\u68d2\u81ea\u7f16\u7801\u5668\u4f5c\u4e3a\u6570\u636e\u9884\u5904\u7406\u3002", "motivation": "\u5bf9\u6297\u8bad\u7ec3\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u65e0\u6cd5\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u9700\u8981\u65e0\u6743\u8bbf\u95ee\u6a21\u578b\u6743\u91cd\u7684\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u9c81\u68d2\u81ea\u7f16\u7801\u5668\u4f5c\u4e3a\u6570\u636e\u9884\u5904\u7406\uff0c\u57fa\u4e8e\u9c81\u68d2\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u5bf9\u6297\u9c81\u68d2\u6027\u7684\u7406\u8bba\u8054\u7cfb\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u65b9\u6cd5\u6709\u6548\uff0c\u63d0\u9ad8\u4e0b\u6e38\u4efb\u52a1\u9c81\u68d2\u6027\uff0c\u5e76\u9a8c\u8bc1\u7279\u5f81\u9c81\u68d2\u6027\u4e0e\u4e0b\u6e38\u9c81\u68d2\u6027\u7684\u5173\u8054\u3002", "conclusion": "\u65b9\u6cd5\u7b80\u5355\u6709\u6548\uff0c\u8bc1\u5b9e\u7406\u8bba\u89c1\u89e3\u3002"}}
{"id": "2504.10500", "pdf": "https://arxiv.org/pdf/2504.10500", "abs": "https://arxiv.org/abs/2504.10500", "authors": ["Eya Mhedhbi", "Youssef Mourchid", "Alice Othmani"], "title": "Leveraging Auto-Distillation and Generative Self-Supervised Learning in Residual Graph Transformers for Enhanced Recommender Systems", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper introduces a cutting-edge method for enhancing recommender systems\nthrough the integration of generative self-supervised learning (SSL) with a\nResidual Graph Transformer. Our approach emphasizes the importance of superior\ndata enhancement through the use of pertinent pretext tasks, automated through\nrationale-aware SSL to distill clear ways of how users and items interact. The\nResidual Graph Transformer incorporates a topology-aware transformer for global\ncontext and employs residual connections to improve graph representation\nlearning. Additionally, an auto-distillation process refines self-supervised\nsignals to uncover consistent collaborative rationales. Experimental\nevaluations on multiple datasets demonstrate that our approach consistently\noutperforms baseline methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u751f\u6210\u5f0f\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u6b8b\u5dee\u56fe\u53d8\u6362\u5668\u7684\u521b\u65b0\u65b9\u6cd5\u6765\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f3a\u8c03\u901a\u8fc7\u5408\u7406\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6539\u5584\u6570\u636e\u589e\u5f3a\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u7528\u6237\u4e0e\u7269\u54c1\u7684\u4ea4\u4e92\u3002", "method": "\u5c06\u751f\u6210\u5f0f\u81ea\u76d1\u7763\u5b66\u4e60\u4e0e\u6b8b\u5dee\u56fe\u53d8\u6362\u5668\u6574\u5408\uff0c\u5305\u542b\u62d3\u6251\u611f\u77e5\u53d8\u6362\u5668\u3001\u6b8b\u5dee\u8fde\u63a5\u548c\u81ea\u52a8\u84b8\u998f\u8fc7\u7a0b\u6765\u63d0\u70bc\u81ea\u76d1\u7763\u4fe1\u53f7\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u4e2d\uff0c consistently \u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5148\u8fdb\u7684\u56fe\u8868\u793a\u5b66\u4e60\u6280\u672f\u6709\u6548\u5730\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2504.10851", "pdf": "https://arxiv.org/pdf/2504.10851", "abs": "https://arxiv.org/abs/2504.10851", "authors": ["Ruochen Jin", "Boning Tong", "Shu Yang", "Bojian Hou", "Li Shen"], "title": "ICAFS: Inter-Client-Aware Feature Selection for Vertical Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Vertical federated learning (VFL) enables a paradigm for vertically\npartitioned data across clients to collaboratively train machine learning\nmodels. Feature selection (FS) plays a crucial role in Vertical Federated\nLearning (VFL) due to the unique nature that data are distributed across\nmultiple clients. In VFL, different clients possess distinct subsets of\nfeatures for overlapping data samples, making the process of identifying and\nselecting the most relevant features a complex yet essential task. Previous FS\nefforts have primarily revolved around intra-client feature selection,\noverlooking vital feature interaction across clients, leading to subpar model\noutcomes. We introduce ICAFS, a novel multi-stage ensemble approach for\neffective FS in VFL by considering inter-client interactions. By employing\nconditional feature synthesis alongside multiple learnable feature selectors,\nICAFS facilitates ensemble FS over these selectors using synthetic embeddings.\nThis method bypasses the limitations of private gradient sharing and allows for\nmodel training using real data with refined embeddings. Experiments on multiple\nreal-world datasets demonstrate that ICAFS surpasses current state-of-the-art\nmethods in prediction accuracy.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faICAFS\uff0c\u4e00\u79cd\u8003\u8651\u5ba2\u6237\u7aef\u95f4\u4ea4\u4e92\u7684\u5782\u76f4\u8054\u90a6\u5b66\u4e60\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u5ffd\u7565\u5ba2\u6237\u7aef\u95f4\u7279\u5f81\u4ea4\u4e92\uff0c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0d\u4f73\u3002", "method": "ICAFS\u4f7f\u7528\u6761\u4ef6\u7279\u5f81\u5408\u6210\u548c\u591a\u4e2a\u53ef\u5b66\u4e60\u9009\u62e9\u5668\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u6210\u5d4c\u5165\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u907f\u514d\u79c1\u6709\u68af\u5ea6\u5171\u4eab\u3002", "result": "\u5b9e\u9a8c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u793a\uff0cICAFS\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "ICAFS\u6539\u8fdb\u4e86\u5782\u76f4\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u7279\u5f81\u9009\u62e9\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u5e76\u4fdd\u62a4\u4e86\u6570\u636e\u9690\u79c1\u3002"}}
{"id": "2504.10508", "pdf": "https://arxiv.org/pdf/2504.10508", "abs": "https://arxiv.org/abs/2504.10508", "authors": ["Jo\u00e3o Alberto de Oliveira Lima"], "title": "Poly-Vector Retrieval: Reference and Content Embeddings for Legal Documents", "categories": ["cs.IR", "cs.AI", "I.2.8"], "comment": "39 pages, 5 figures", "summary": "Retrieval-Augmented Generation (RAG) has emerged as an effective paradigm for\ngenerating contextually accurate answers by integrating Large Language Models\n(LLMs) with retrieval mechanisms. However, in legal contexts, users frequently\nreference norms by their labels or nicknames (e.g., Article 5 of the\nConstitution or Consumer Defense Code (CDC)), rather than by their content,\nposing challenges for traditional RAG approaches that rely solely on semantic\nembeddings of text. Furthermore, legal texts themselves heavily rely on\nexplicit cross-references (e.g., \"pursuant to Article 34\") that function as\npointers. Both scenarios pose challenges for traditional RAG approaches that\nrely solely on semantic embeddings of text, often failing to retrieve the\nnecessary referenced content. This paper introduces Poly-Vector Retrieval, a\nmethod assigning multiple distinct embeddings to each legal provision: one\nembedding captures the content (the full text), another captures the label (the\nidentifier or proper name), and optionally additional embeddings capture\nalternative denominations. Inspired by Frege's distinction between Sense and\nReference, this poly-vector retrieval approach treats labels, identifiers and\nreference markers as rigid designators and content embeddings as carriers of\nsemantic substance. Experiments on the Brazilian Federal Constitution\ndemonstrate that Poly-Vector Retrieval significantly improves retrieval\naccuracy for label-centric queries and potential to resolve internal and\nexternal cross-references, without compromising performance on purely semantic\nqueries. The study discusses philosophical and practical implications of\nexplicitly separating reference from content in vector embeddings and proposes\nfuture research directions for applying this approach to broader legal datasets\nand other domains characterized by explicit reference identifiers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPoly-Vector Retrieval\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3a\u6cd5\u5f8b\u6761\u6b3e\u5206\u914d\u591a\u4e2a\u5d4c\u5165\uff08\u5185\u5bb9\u3001\u6807\u7b7e\u7b49\uff09\uff0c\u6539\u5584RAG\u7cfb\u7edf\u5728\u6cd5\u5f8b\u4e0a\u4e0b\u6587\u4e2d\u7684\u68c0\u7d22\u51c6\u786e\u6027\u3002", "motivation": "\u6cd5\u5f8b\u67e5\u8be2\u4e2d\uff0c\u7528\u6237\u5e38\u4f7f\u7528\u6807\u7b7e\u6216\u6635\u79f0\u5f15\u7528\u89c4\u8303\uff0c\u4f20\u7edfRAG\u4f9d\u8d56\u8bed\u4e49\u5d4c\u5165\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u4ea4\u53c9\u5f15\u7528\u3002", "method": "\u5f15\u5165Poly-Vector Retrieval\uff0c\u4e3a\u6bcf\u4e2a\u6cd5\u5f8b\u6761\u6b3e\u5206\u914d\u4e0d\u540c\u5d4c\u5165\uff1a\u4e00\u4e2a\u6355\u83b7\u5185\u5bb9\uff0c\u4e00\u4e2a\u6355\u83b7\u6807\u7b7e\uff0c\u53ef\u9009\u6355\u83b7\u66ff\u4ee3\u540d\u79f0\uff0c\u53d7Frege\u7684Sense and Reference\u542f\u53d1\u3002", "result": "\u5b9e\u9a8c\u5728\u5df4\u897f\u8054\u90a6\u5baa\u6cd5\u4e0a\u663e\u793a\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6807\u7b7e\u4e2d\u5fc3\u67e5\u8be2\u7684\u68c0\u7d22\u51c6\u786e\u6027\uff0c\u5e76\u80fd\u5904\u7406\u4ea4\u53c9\u5f15\u7528\uff0c\u800c\u4e0d\u5f71\u54cd\u7eaf\u8bed\u4e49\u67e5\u8be2\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u5206\u79bb\u53c2\u8003\u548c\u5185\u5bb9\u7684\u54f2\u5b66\u53ca\u5b9e\u9645\u542b\u4e49\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u6cd5\u5f8b\u6570\u636e\u96c6\u548c\u5176\u4ed6\u9886\u57df\u7684\u65b9\u5411\u3002"}}
{"id": "2504.10900", "pdf": "https://arxiv.org/pdf/2504.10900", "abs": "https://arxiv.org/abs/2504.10900", "authors": ["Peiliang Gong", "Emadeldeen Eldele", "Min Wu", "Zhenghua Chen", "Xiaoli Li", "Daoqiang Zhang"], "title": "Bridging Distribution Gaps in Time Series Foundation Model Pretraining with Prototype-Guided Normalization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Foundation models have achieved remarkable success across diverse\nmachine-learning domains through large-scale pretraining on large, diverse\ndatasets. However, pretraining on such datasets introduces significant\nchallenges due to substantial mismatches in data distributions, a problem\nparticularly pronounced with time series data. In this paper, we tackle this\nissue by proposing a domain-aware adaptive normalization strategy within the\nTransformer architecture. Specifically, we replace the traditional LayerNorm\nwith a prototype-guided dynamic normalization mechanism (ProtoNorm), where\nlearned prototypes encapsulate distinct data distributions, and\nsample-to-prototype affinity determines the appropriate normalization layer.\nThis mechanism effectively captures the heterogeneity of time series\ncharacteristics, aligning pretrained representations with downstream tasks.\nThrough comprehensive empirical evaluation, we demonstrate that our method\nsignificantly outperforms conventional pretraining techniques across both\nclassification and forecasting tasks, while effectively mitigating the adverse\neffects of distribution shifts during pretraining. Incorporating ProtoNorm is\nas simple as replacing a single line of code. Extensive experiments on diverse\nreal-world time series benchmarks validate the robustness and generalizability\nof our approach, advancing the development of more versatile time series\nfoundation models.", "AI": {"tldr": "\u63d0\u51faProtoNorm\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5f52\u4e00\u5316\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u6027\u80fd\uff0c\u89e3\u51b3\u9884\u8bad\u7ec3\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u4e2d\u6570\u636e\u5206\u5e03\u4e0d\u5339\u914d\u7684\u6311\u6218\uff0c\u5c24\u5176\u5728\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u66f4\u663e\u8457\u3002", "method": "\u5728Transformer\u67b6\u6784\u4e2d\uff0c\u66ff\u6362LayerNorm\u4e3a\u539f\u578b\u5f15\u5bfc\u52a8\u6001\u5f52\u4e00\u5316\uff08ProtoNorm\uff09\uff0c\u4f7f\u7528\u5b66\u4e60\u539f\u578b\u548c\u6837\u672c\u4eb2\u548c\u5ea6\u8fdb\u884c\u5f52\u4e00\u5316\u3002", "result": "\u5728\u5206\u7c7b\u548c\u9884\u6d4b\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u7f13\u89e3\u5206\u5e03\u504f\u79fb\u5f71\u54cd\u3002", "conclusion": "\u63a8\u8fdb\u66f4\u901a\u7528\u3001\u9c81\u68d2\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u53d1\u5c55\uff0c\u6613\u4e8e\u5b9e\u73b0\u3002"}}
{"id": "2504.10509", "pdf": "https://arxiv.org/pdf/2504.10509", "abs": "https://arxiv.org/abs/2504.10509", "authors": ["Jakub Podolak", "Leon Peric", "Mina Janicijevic", "Roxana Petcu"], "title": "Beyond Reproducibility: Advancing Zero-shot LLM Reranking Efficiency with Setwise Insertion", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "This study presents a comprehensive reproducibility and extension analysis of\nthe Setwise prompting methodology for zero-shot ranking with Large Language\nModels (LLMs), as proposed by Zhuang et al. We evaluate its effectiveness and\nefficiency compared to traditional Pointwise, Pairwise, and Listwise approaches\nin document ranking tasks. Our reproduction confirms the findings of Zhuang et\nal., highlighting the trade-offs between computational efficiency and ranking\neffectiveness in Setwise methods. Building on these insights, we introduce\nSetwise Insertion, a novel approach that leverages the initial document ranking\nas prior knowledge, reducing unnecessary comparisons and uncertainty by\nfocusing on candidates more likely to improve the ranking results. Experimental\nresults across multiple LLM architectures (Flan-T5, Vicuna, and Llama) show\nthat Setwise Insertion yields a 31% reduction in query time, a 23% reduction in\nmodel inferences, and a slight improvement in reranking effectiveness compared\nto the original Setwise method. These findings highlight the practical\nadvantage of incorporating prior ranking knowledge into Setwise prompting for\nefficient and accurate zero-shot document reranking.", "AI": {"tldr": "\u672c\u7814\u7a76\u590d\u73b0\u5e76\u6269\u5c55Setwise\u63d0\u793a\u65b9\u6cd5\uff0c\u7528\u4e8eLLM\u7684\u96f6\u6837\u672c\u6392\u540d\uff0c\u5f15\u5165Setwise Insertion\u51cf\u5c11\u8ba1\u7b97\u5e76\u7565\u5fae\u63d0\u5347\u6548\u679c\u3002", "motivation": "\u590d\u73b0Zhuang et al.\u7684Setwise\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u65b0\u65b9\u6cd5\u63d0\u9ad8\u6548\u7387\u548c\u6392\u540d\u6548\u679c\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u7684\u8ba1\u7b97\u6743\u8861\u95ee\u9898\u3002", "method": "\u590d\u73b0\u539f\u65b9\u6cd5\uff0c\u5f15\u5165Setwise Insertion\uff0c\u5229\u7528\u521d\u59cb\u6392\u540d\u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\u51cf\u5c11\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u663e\u793aSetwise Insertion\u51cf\u5c1131%\u67e5\u8be2\u65f6\u95f4\u300123%\u6a21\u578b\u63a8\u7406\uff0c\u5e76\u7565\u5fae\u63d0\u9ad8\u91cd\u65b0\u6392\u540d\u6548\u679c\u3002", "conclusion": "\u5f3a\u8c03\u6574\u5408\u5148\u9a8c\u77e5\u8bc6\u7684\u5b9e\u9645\u4f18\u52bf\uff0c\u63d0\u9ad8\u96f6\u6837\u672c\u6587\u6863\u6392\u540d\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2504.10902", "pdf": "https://arxiv.org/pdf/2504.10902", "abs": "https://arxiv.org/abs/2504.10902", "authors": ["Rui Dai", "Sile Hu", "Xu Shen", "Yonggang Zhang", "Xinmei Tian", "Jieping Ye"], "title": "Leveraging Submodule Linearity Enhances Task Arithmetic Performance in LLMs", "categories": ["cs.LG"], "comment": "Accepted by ICLR 2025", "summary": "Task arithmetic is a straightforward yet highly effective strategy for model\nmerging, enabling the resultant model to exhibit multi-task capabilities.\nRecent research indicates that models demonstrating linearity enhance the\nperformance of task arithmetic. In contrast to existing methods that rely on\nthe global linearization of the model, we argue that this linearity already\nexists within the model's submodules. In particular, we present a statistical\nanalysis and show that submodules (e.g., layers, self-attentions, and MLPs)\nexhibit significantly higher linearity than the overall model. Based on these\nfindings, we propose an innovative model merging strategy that independently\nmerges these submodules. Especially, we derive a closed-form solution for\noptimal merging weights grounded in the linear properties of these submodules.\nExperimental results demonstrate that our method consistently outperforms the\nstandard task arithmetic approach and other established baselines across\ndifferent model scales and various tasks. This result highlights the benefits\nof leveraging the linearity of submodules and provides a new perspective for\nexploring solutions for effective and practical multi-task model merging.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5b50\u6a21\u5757\u7ebf\u6027\u6027\u7684\u6a21\u578b\u5408\u5e76\u7b56\u7565\uff0c\u63d0\u5347\u4efb\u52a1\u7b97\u672f\u7684\u591a\u4efb\u52a1\u80fd\u529b\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5168\u5c40\u7ebf\u6027\u5316\uff0c\u4f46\u5b50\u6a21\u5757\u5df2\u5177\u6709\u66f4\u9ad8\u7ebf\u6027\u6027\uff0c\u56e0\u6b64\u9700\u5f00\u53d1\u65b0\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u72ec\u7acb\u5408\u5e76\u5b50\u6a21\u5757\u7684\u65b9\u6cd5\uff0c\u5e76\u57fa\u4e8e\u5176\u7ebf\u6027\u7279\u6027\u63a8\u5bfc\u6700\u4f18\u5408\u5e76\u6743\u91cd\u7684\u95ed\u5f0f\u89e3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u548c\u4efb\u52a1\u4e0a consistently \u4f18\u4e8e\u6807\u51c6\u4efb\u52a1\u7b97\u672f\u548c\u5176\u4ed6\u57fa\u7ebf\u3002", "conclusion": "\u5f3a\u8c03\u5229\u7528\u5b50\u6a21\u5757\u7ebf\u6027\u6027\u7684\u4f18\u52bf\uff0c\u4e3a\u591a\u4efb\u52a1\u6a21\u578b\u5408\u5e76\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002"}}
{"id": "2504.10512", "pdf": "https://arxiv.org/pdf/2504.10512", "abs": "https://arxiv.org/abs/2504.10512", "authors": ["Minh-Anh Nguyen", "Dung D. Le"], "title": "JEPA4Rec: Learning Effective Language Representations for Sequential Recommendation via Joint Embedding Predictive Architecture", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Language representation learning has emerged as a promising approach for\nsequential recommendation, thanks to its ability to learn generalizable\nrepresentations. However, despite its advantages, this approach still struggles\nwith data sparsity and a limited understanding of common-sense user\npreferences. To address these limitations, we propose $\\textbf{JEPA4Rec}$, a\nframework that combines $\\textbf{J}$oint $\\textbf{E}$mbedding\n$\\textbf{P}$redictive $\\textbf{A}$rchitecture with language modeling of item\ntextual descriptions. JEPA4Rec captures semantically rich and transferable\nrepresentations, improving recommendation performance and reducing reliance on\nlarge-scale pre-training data. Specifically, JEPA4Rec represents items as text\nsentences by flattening descriptive information such as $\\textit{title,\ncategory}$, and other attributes. To encode these sentences, we employ a\nbidirectional Transformer encoder with modified embedding layers tailored for\ncapturing item information in recommendation datasets. We apply masking to text\nsentences and use them to predict the representations of the unmasked\nsentences, helping the model learn generalizable item embeddings. To further\nimprove recommendation performance and language understanding, we employ a\ntwo-stage training strategy incorporating self-supervised learning losses.\nExperiments on six real-world datasets demonstrate that JEPA4Rec consistently\noutperforms state-of-the-art methods, particularly in cross-domain,\ncross-platform, and low-resource scenarios.", "AI": {"tldr": "JEPA4Rec \u662f\u4e00\u79cd\u7ed3\u5408\u8054\u5408\u5d4c\u5165\u9884\u6d4b\u67b6\u6784\u548c\u8bed\u8a00\u5efa\u6a21\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u6570\u636e\u7a00\u758f\u6027\u548c\u7528\u6237\u504f\u597d\u95ee\u9898\uff0c\u63d0\u9ad8\u6027\u80fd\u5e76\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u6570\u636e\u7684\u4f9d\u8d56\u3002", "motivation": "\u8bed\u8a00\u8868\u793a\u5b66\u4e60\u5728\u6570\u636e\u7a00\u758f\u6027\u548c\u5bf9\u5e38\u8bc6\u7528\u6237\u504f\u597d\u7684\u6709\u9650\u7406\u89e3\u4e0a\u5b58\u5728\u6311\u6218\uff0c\u56e0\u6b64\u63d0\u51fa JEPA4Rec \u6765\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u548c\u63a8\u8350\u6548\u679c\u3002", "method": "JEPA4Rec \u5c06\u7269\u54c1\u8868\u793a\u4e3a\u6587\u672c\u53e5\u5b50\uff0c\u4f7f\u7528\u53cc\u5411 Transformer \u7f16\u7801\u5668\u3001\u63a9\u7801\u7b56\u7565\u548c\u4e24\u9636\u6bb5\u81ea\u76d1\u7763\u5b66\u4e60\u8bad\u7ec3\uff0c\u4ee5\u5b66\u4e60\u53ef\u8f6c\u79fb\u7684\u7269\u54c1\u5d4c\u5165\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cJEPA4Rec \u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u8de8\u57df\u3001\u8de8\u5e73\u53f0\u548c\u4f4e\u8d44\u6e90\u573a\u666f\u4e2d\u3002", "conclusion": "JEPA4Rec \u901a\u8fc7\u6355\u83b7\u8bed\u4e49\u4e30\u5bcc\u7684\u8868\u793a\uff0c\u6539\u5584\u63a8\u8350\u6027\u80fd\uff0c\u5e76\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2504.10917", "pdf": "https://arxiv.org/pdf/2504.10917", "abs": "https://arxiv.org/abs/2504.10917", "authors": ["Jialin Chen", "Haolan Zuo", "Haoyu Peter Wang", "Siqi Miao", "Pan Li", "Rex Ying"], "title": "Towards A Universal Graph Structural Encoder", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancements in large-scale pre-training have shown the potential to\nlearn generalizable representations for downstream tasks. In the graph domain,\nhowever, capturing and transferring structural information across different\ngraph domains remains challenging, primarily due to the inherent differences in\ntopological patterns across various contexts. Additionally, most existing\nmodels struggle to capture the complexity of rich graph structures, leading to\ninadequate exploration of the embedding space. To address these challenges, we\npropose GFSE, a universal graph structural encoder designed to capture\ntransferable structural patterns across diverse domains such as molecular\ngraphs, social networks, and citation networks. GFSE is the first cross-domain\ngraph structural encoder pre-trained with multiple self-supervised learning\nobjectives. Built on a Graph Transformer, GFSE incorporates attention\nmechanisms informed by graph inductive bias, enabling it to encode intricate\nmulti-level and fine-grained topological features. The pre-trained GFSE\nproduces generic and theoretically expressive positional and structural\nencoding for graphs, which can be seamlessly integrated with various downstream\ngraph feature encoders, including graph neural networks for vectorized features\nand Large Language Models for text-attributed graphs. Comprehensive experiments\non synthetic and real-world datasets demonstrate GFSE's capability to\nsignificantly enhance the model's performance while requiring substantially\nless task-specific fine-tuning. Notably, GFSE achieves state-of-the-art\nperformance in 81.6% evaluated cases, spanning diverse graph models and\ndatasets, highlighting its potential as a powerful and versatile encoder for\ngraph-structured data.", "AI": {"tldr": "GFSE \u662f\u4e00\u4e2a\u901a\u7528\u7684\u56fe\u7ed3\u6784\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u6355\u6349\u8de8\u57df\u7ed3\u6784\u6a21\u5f0f\uff0c\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u6355\u6349\u548c\u8f6c\u79fb\u56fe\u7ed3\u6784\u4fe1\u606f\uff0c\u7279\u522b\u662f\u62d3\u6251\u6a21\u5f0f\u5dee\u5f02\u548c\u5d4c\u5165\u7a7a\u95f4\u63a2\u7d22\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa GFSE\uff0c\u4f7f\u7528\u57fa\u4e8e Graph Transformer \u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u591a\u76ee\u6807\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\uff0c\u7f16\u7801\u591a\u5c42\u6b21\u62d3\u6251\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u663e\u793a GFSE \u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5728 81.6% \u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u51cf\u5c11\u7ec6\u8c03\u9700\u6c42\u3002", "conclusion": "GFSE \u4f5c\u4e3a\u5f3a\u5927\u901a\u7528\u7684\u56fe\u7ed3\u6784\u7f16\u7801\u5668\uff0c\u6709\u6f5c\u529b\u5e94\u7528\u4e8e\u5404\u79cd\u56fe\u6570\u636e\u3002"}}
{"id": "2504.10514", "pdf": "https://arxiv.org/pdf/2504.10514", "abs": "https://arxiv.org/abs/2504.10514", "authors": ["Yijun Liang", "Ming Li", "Chenrui Fan", "Ziyue Li", "Dang Nguyen", "Kwesi Cobbina", "Shweta Bhardwaj", "Jiuhai Chen", "Fuxiao Liu", "Tianyi Zhou"], "title": "ColorBench: Can VLMs See and Understand the Colorful World? A Comprehensive Benchmark for Color Perception, Reasoning, and Robustness", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "33 pages, including references and appendix. Code is available at\n  https://github.com/tianyi-lab/ColorBench", "summary": "Color plays an important role in human perception and usually provides\ncritical clues in visual reasoning. However, it is unclear whether and how\nvision-language models (VLMs) can perceive, understand, and leverage color as\nhumans. This paper introduces ColorBench, an innovative benchmark meticulously\ncrafted to assess the capabilities of VLMs in color understanding, including\ncolor perception, reasoning, and robustness. By curating a suite of diverse\ntest scenarios, with grounding in real applications, ColorBench evaluates how\nthese models perceive colors, infer meanings from color-based cues, and\nmaintain consistent performance under varying color transformations. Through an\nextensive evaluation of 32 VLMs with varying language models and vision\nencoders, our paper reveals some undiscovered findings: (i) The scaling law\n(larger models are better) still holds on ColorBench, while the language model\nplays a more important role than the vision encoder. (ii) However, the\nperformance gaps across models are relatively small, indicating that color\nunderstanding has been largely neglected by existing VLMs. (iii) CoT reasoning\nimproves color understanding accuracies and robustness, though they are\nvision-centric tasks. (iv) Color clues are indeed leveraged by VLMs on\nColorBench but they can also mislead models in some tasks. These findings\nhighlight the critical limitations of current VLMs and underscore the need to\nenhance color comprehension. Our ColorBenchcan serve as a foundational tool for\nadvancing the study of human-level color understanding of multimodal AI.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165ColorBench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u989c\u8272\u7406\u89e3\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5305\u62ec\u611f\u77e5\u3001\u63a8\u7406\u548c\u9c81\u68d2\u6027\uff0c\u5e76\u63ed\u793a\u5173\u952e\u53d1\u73b0\u3002", "motivation": "\u63a2\u8ba8VLMs\u662f\u5426\u548c\u5982\u4f55\u50cf\u4eba\u7c7b\u4e00\u6837\u611f\u77e5\u548c\u5229\u7528\u989c\u8272\uff0c\u63ed\u793a\u5f53\u524dAI\u5728\u989c\u8272\u7406\u89e3\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1ColorBench\u57fa\u51c6\uff0c\u901a\u8fc7\u591a\u6837\u5316\u7684\u6d4b\u8bd5\u573a\u666f\u8bc4\u4f3032\u4e2aVLMs\u5728\u989c\u8272\u611f\u77e5\u3001\u63a8\u7406\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u89c4\u6a21\u5b9a\u5f8b\u4f9d\u7136\u9002\u7528\uff0c\u8bed\u8a00\u6a21\u578b\u6bd4\u89c6\u89c9\u7f16\u7801\u5668\u66f4\u91cd\u8981\uff1b\u6a21\u578b\u95f4\u6027\u80fd\u5dee\u8ddd\u5c0f\uff1bCoT\u63a8\u7406\u6539\u5584\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff1b\u989c\u8272\u7ebf\u7d22\u53ef\u80fd\u8bef\u5bfc\u6a21\u578b\u3002", "conclusion": "\u5f53\u524dVLMs\u5728\u989c\u8272\u7406\u89e3\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u6539\u8fdb\uff0cColorBench\u53ef\u4f5c\u4e3a\u63a8\u8fdb\u591a\u6a21\u6001AI\u989c\u8272\u7406\u89e3\u7684\u5de5\u5177\u3002"}}
{"id": "2504.10923", "pdf": "https://arxiv.org/pdf/2504.10923", "abs": "https://arxiv.org/abs/2504.10923", "authors": ["Mingyi Zhu", "Zhaoxin Li", "Qiao Lin", "Li Ding"], "title": "Fast-Powerformer: A Memory-Efficient Transformer for Accurate Mid-Term Wind Power Forecasting", "categories": ["cs.LG", "eess.SP"], "comment": "Mingyi Zhu is the first author. Li Ding is the corresponding author", "summary": "Wind power forecasting (WPF), as a significant research topic within\nrenewable energy, plays a crucial role in enhancing the security, stability,\nand economic operation of power grids. However, due to the high stochasticity\nof meteorological factors (e.g., wind speed) and significant fluctuations in\nwind power output, mid-term wind power forecasting faces a dual challenge of\nmaintaining high accuracy and computational efficiency. To address these\nissues, this paper proposes an efficient and lightweight mid-term wind power\nforecasting model, termed Fast-Powerformer. The proposed model is built upon\nthe Reformer architecture, incorporating structural enhancements such as a\nlightweight Long Short-Term Memory (LSTM) embedding module, an input\ntransposition mechanism, and a Frequency Enhanced Channel Attention Mechanism\n(FECAM). These improvements enable the model to strengthen temporal feature\nextraction, optimize dependency modeling across variables, significantly reduce\ncomputational complexity, and enhance sensitivity to periodic patterns and\ndominant frequency components. Experimental results conducted on multiple\nreal-world wind farm datasets demonstrate that the proposed Fast-Powerformer\nachieves superior prediction accuracy and operational efficiency compared to\nmainstream forecasting approaches. Furthermore, the model exhibits fast\ninference speed and low memory consumption, highlighting its considerable\npractical value for real-world deployment scenarios.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u8f7b\u91cf\u7ea7\u7684\u4e2d\u671f\u98ce\u529b\u53d1\u7535\u9884\u6d4b\u6a21\u578bFast-Powerformer\uff0c\u4ee5\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u98ce\u529b\u53d1\u7535\u9884\u6d4b\u4e2d\u6c14\u8c61\u56e0\u7d20\u968f\u673a\u6027\u548c\u8f93\u51fa\u6ce2\u52a8\u5e26\u6765\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u53cc\u91cd\u6311\u6218\u3002", "method": "\u57fa\u4e8eReformer\u67b6\u6784\uff0c\u52a0\u5165\u8f7b\u91cfLSTM\u5d4c\u5165\u6a21\u5757\u3001\u8f93\u5165\u8f6c\u7f6e\u673a\u5236\u548c\u9891\u7387\u589e\u5f3a\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236(FECAM)\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u66f4\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3001\u64cd\u4f5c\u6548\u7387\u3001\u5feb\u901f\u63a8\u7406\u901f\u5ea6\u548c\u4f4e\u5185\u5b58\u6d88\u8017\u3002", "conclusion": "\u6a21\u578b\u5177\u6709\u663e\u8457\u7684\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u3002"}}
{"id": "2504.10521", "pdf": "https://arxiv.org/pdf/2504.10521", "abs": "https://arxiv.org/abs/2504.10521", "authors": ["Pardis Moradbeiki", "Mohammad Ali Zare Chahooki"], "title": "Integrating Emotion Distribution Networks and Textual Message Analysis for X User Emotional State Classification", "categories": ["cs.SI", "cs.AI", "cs.LG"], "comment": null, "summary": "As the popularity and reach of social networks continue to surge, a vast\nreservoir of opinions and sentiments across various subjects inundates these\nplatforms. Among these, X social network (formerly Twitter) stands as a\njuggernaut, boasting approximately 420 million active users. Extracting users'\nemotional and mental states from their expressed opinions on social media has\nbecome a common pursuit. While past methodologies predominantly focused on the\ntextual content of messages to analyze user sentiment, the interactive nature\nof these platforms suggests a deeper complexity. This study employs hybrid\nmethodologies, integrating textual analysis, profile examination, follower\nanalysis, and emotion dissemination patterns. Initially, user interactions are\nleveraged to refine emotion classification within messages, encompassing\nexchanges where users respond to each other. Introducing the concept of a\ncommunication tree, a model is extracted to map these interactions.\nSubsequently, users' bios and interests from this tree are juxtaposed with\nmessage text to enrich analysis. Finally, influential figures are identified\namong users' followers in the communication tree, categorized into different\ntopics to gauge interests. The study highlights that traditional sentiment\nanalysis methodologies, focusing solely on textual content, are inadequate in\ndiscerning sentiment towards significant events, notably the presidential\nelection. Comparative analysis with conventional methods reveals a substantial\nimprovement in accuracy with the incorporation of emotion distribution patterns\nand user profiles. The proposed approach yields a 12% increase in accuracy with\nemotion distribution patterns and a 15% increase when considering user\nprofiles, underscoring its efficacy in capturing nuanced sentiment dynamics.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u901a\u8fc7\u6574\u5408\u7528\u6237\u4e92\u52a8\u3001\u4e2a\u4eba\u8d44\u6599\u548c\u60c5\u611f\u4f20\u64ad\u6a21\u5f0f\u6539\u8fdb\u4e86Twitter\u60c5\u611f\u5206\u6790\uff0c\u51c6\u786e\u7387\u63d0\u534712%\u81f315%\u3002", "motivation": "\u793e\u4ea4\u7f51\u7edc\u7528\u6237\u6fc0\u589e\uff0c\u4f20\u7edf\u6587\u672c\u5206\u6790\u65b9\u6cd5\u4e0d\u8db3\u4ee5\u6355\u6349\u91cd\u5927\u4e8b\u4ef6\u5982\u603b\u7edf\u9009\u4e3e\u7684\u60c5\u611f\u52a8\u6001\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u5305\u62ec\u6587\u672c\u5206\u6790\u3001\u4e2a\u4eba\u8d44\u6599\u68c0\u67e5\u3001\u5173\u6ce8\u8005\u5206\u6790\u548c\u60c5\u611f\u4f20\u64ad\u6a21\u5f0f\uff1b\u5f15\u5165\u901a\u4fe1\u6811\u6a21\u578b\u6620\u5c04\u7528\u6237\u4e92\u52a8\u3002", "result": "\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u51c6\u786e\u7387\u63d0\u9ad812%\uff08\u4f7f\u7528\u60c5\u611f\u5206\u5e03\u6a21\u5f0f\uff09\u548c15%\uff08\u8003\u8651\u7528\u6237\u4e2a\u4eba\u8d44\u6599\uff09\u3002", "conclusion": "\u63d0\u51fa\u65b9\u6cd5\u66f4\u6709\u6548\u5730\u6355\u6349\u7ec6\u5fae\u60c5\u611f\uff0c\u5f3a\u8c03\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2504.10925", "pdf": "https://arxiv.org/pdf/2504.10925", "abs": "https://arxiv.org/abs/2504.10925", "authors": ["Ayan Chatterjee", "Barbara Ikica", "Babak Ravandi", "John Palowitch"], "title": "Transfer Learning for Temporal Link Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 7 figures", "summary": "Link prediction on graphs has applications spanning from recommender systems\nto drug discovery. Temporal link prediction (TLP) refers to predicting future\nlinks in a temporally evolving graph and adds additional complexity related to\nthe dynamic nature of graphs. State-of-the-art TLP models incorporate memory\nmodules alongside graph neural networks to learn both the temporal mechanisms\nof incoming nodes and the evolving graph topology. However, memory modules only\nstore information about nodes seen at train time, and hence such models cannot\nbe directly transferred to entirely new graphs at test time and deployment. In\nthis work, we study a new transfer learning task for temporal link prediction,\nand develop transfer-effective methods for memory-laden models. Specifically,\nmotivated by work showing the informativeness of structural signals for the TLP\ntask, we augment a structural mapping module to the existing TLP model\narchitectures, which learns a mapping from graph structural (topological)\nfeatures to memory embeddings. Our work paves the way for a memory-free\nfoundation model for TLP.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u65f6\u5e8f\u94fe\u63a5\u9884\u6d4b\u7684\u8f6c\u79fb\u5b66\u4e60\u4efb\u52a1\uff0c\u901a\u8fc7\u6dfb\u52a0\u7ed3\u6784\u6620\u5c04\u6a21\u5757\u4f7f\u6a21\u578b\u53ef\u8f6c\u79fb\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u65e0\u6cd5\u5e94\u7528\u4e8e\u65b0\u56fe\uff0c\u56e0\u4e3a\u8bb0\u5fc6\u6a21\u5757\u53ea\u5b58\u50a8\u8bad\u7ec3\u65f6\u7684\u8282\u70b9\u4fe1\u606f\u3002", "method": "\u5728\u65f6\u5e8f\u94fe\u63a5\u9884\u6d4b\u6a21\u578b\u4e2d\u6dfb\u52a0\u7ed3\u6784\u6620\u5c04\u6a21\u5757\uff0c\u5b66\u4e60\u4ece\u56fe\u62d3\u6251\u7279\u5f81\u5230\u8bb0\u5fc6\u5d4c\u5165\u7684\u6620\u5c04\u3002", "result": "\u5f00\u53d1\u4e86\u53ef\u8f6c\u79fb\u7684\u6a21\u578b\uff0c\u5e76\u4e3a\u65e0\u8bb0\u5fc6\u57fa\u7840\u6a21\u578b\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63a8\u52a8\u4e86\u65f6\u5e8f\u94fe\u63a5\u9884\u6d4b\u5411\u8bb0\u5fc6\u65e0\u5173\u7684\u901a\u7528\u6a21\u578b\u53d1\u5c55\u3002"}}
{"id": "2504.10529", "pdf": "https://arxiv.org/pdf/2504.10529", "abs": "https://arxiv.org/abs/2504.10529", "authors": ["Peiru Yang", "Xintian Li", "Zhiyang Hu", "Jiapeng Wang", "Jinhua Yin", "Huili Wang", "Lizhi He", "Shuai Yang", "Shangguang Wang", "Yongfeng Huang", "Tao Qi"], "title": "HeteRAG: A Heterogeneous Retrieval-augmented Generation Framework with Decoupled Knowledge Representations", "categories": ["cs.IR", "cs.AI"], "comment": "10 pages, 5 figures", "summary": "Retrieval-augmented generation (RAG) methods can enhance the performance of\nLLMs by incorporating retrieved knowledge chunks into the generation process.\nIn general, the retrieval and generation steps usually have different\nrequirements for these knowledge chunks. The retrieval step benefits from\ncomprehensive information to improve retrieval accuracy, whereas excessively\nlong chunks may introduce redundant contextual information, thereby diminishing\nboth the effectiveness and efficiency of the generation process. However,\nexisting RAG methods typically employ identical representations of knowledge\nchunks for both retrieval and generation, resulting in suboptimal performance.\nIn this paper, we propose a heterogeneous RAG framework (\\myname) that\ndecouples the representations of knowledge chunks for retrieval and generation,\nthereby enhancing the LLMs in both effectiveness and efficiency. Specifically,\nwe utilize short chunks to represent knowledge to adapt the generation step and\nutilize the corresponding chunk with its contextual information from\nmulti-granular views to enhance retrieval accuracy. We further introduce an\nadaptive prompt tuning method for the retrieval model to adapt the\nheterogeneous retrieval augmented generation process. Extensive experiments\ndemonstrate that \\myname achieves significant improvements compared to\nbaselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f02\u6784RAG\u6846\u67b6\uff0c\u901a\u8fc7\u4e3a\u68c0\u7d22\u548c\u751f\u6210\u4f7f\u7528\u4e0d\u540c\u7684\u77e5\u8bc6\u5757\u8868\u793a\u6765\u63d0\u5347LLM\u6027\u80fd\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u4f7f\u7528\u76f8\u540c\u7684\u77e5\u8bc6\u5757\u8868\u793a\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\uff0c\u56e0\u4e3a\u68c0\u7d22\u9700\u8981\u5168\u9762\u4fe1\u606f\uff0c\u800c\u751f\u6210\u8fc7\u7a0b\u4f1a\u56e0\u5197\u4f59\u4fe1\u606f\u800c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\\myname\u6846\u67b6\uff0c\u4f7f\u7528\u77ed\u77e5\u8bc6\u5757\u9002\u5e94\u751f\u6210\u6b65\u9aa4\uff0c\u5e76\u91c7\u7528\u591a\u7c92\u5ea6\u89c6\u56fe\u7684\u4e0a\u4e0b\u6587\u77e5\u8bc6\u5757\u63d0\u5347\u68c0\u7d22\u51c6\u786e\u6027\uff1b\u540c\u65f6\u5f15\u5165\u81ea\u9002\u5e94\u63d0\u793a\u8c03\u4f18\u65b9\u6cd5\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u663e\u793a\uff0c\\myname\u76f8\u8f83\u57fa\u7ebf\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u89e3\u8026\u68c0\u7d22\u548c\u751f\u6210\u8868\u793a\uff0c\u63d0\u5347\u4e86LLM\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2504.10932", "pdf": "https://arxiv.org/pdf/2504.10932", "abs": "https://arxiv.org/abs/2504.10932", "authors": ["Bo Wang", "Lizuo Liu", "Wei Cai"], "title": "Multi-scale DeepOnet (Mscale-DeepOnet) for Mitigating Spectral Bias in Learning High Frequency Operators of Oscillatory Functions", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "In this paper, a multi-scale DeepOnet (Mscale-DeepOnet) is proposed to reduce\nthe spectral bias of the DeepOnet in learning high-frequency mapping between\nhighly oscillatory functions, with an application to the nonlinear mapping\nbetween the coefficient of the Helmholtz equation and its solution. The\nMscale-DeepOnet introduces the multiscale neural network in the branch and\ntrunk networks of the original DeepOnet, the resulting Mscale-DeepOnet is shown\nto be able to capture various high-frequency components of the mapping itself\nand its image. Numerical results demonstrate the substantial improvement of the\nMscale-DeepOnet for the problem of wave scattering in the high-frequency regime\nover the normal DeepOnet with a similar number of network parameters.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u591a\u5c3a\u5ea6DeepOnet\uff08Mscale-DeepOnet\uff09\uff0c\u4ee5\u51cf\u5c11DeepOnet\u5728\u9ad8\u9891\u6620\u5c04\u5b66\u4e60\u4e2d\u7684\u8c31\u504f\u5dee\uff0c\u5e76\u5e94\u7528\u4e8eHelmholtz\u65b9\u7a0b\u7684\u7cfb\u6570\u4e0e\u89e3\u6620\u5c04\u3002\u6570\u503c\u7ed3\u679c\u663e\u793a\u5176\u5728\u9ad8\u9891\u6ce2\u6563\u5c04\u95ee\u9898\u4e0a\u7684\u663e\u8457\u6539\u5584\u3002", "motivation": "\u51cf\u5c11DeepOnet\u5728\u5b66\u4e60\u9ad8\u9891\u632f\u8361\u51fd\u6570\u6620\u5c04\u65f6\u7684\u8c31\u504f\u5dee\uff0c\u4ee5\u66f4\u597d\u5730\u5904\u7406\u9ad8\u9891\u6210\u5206\u3002", "method": "\u5728DeepOnet\u7684branch\u548ctrunk\u7f51\u7edc\u4e2d\u5f15\u5165\u591a\u5c3a\u5ea6\u795e\u7ecf\u7f51\u7edc\u3002", "result": "Mscale-DeepOnet\u5728\u9ad8\u9891\u6ce2\u6563\u5c04\u95ee\u9898\u4e0a\u6bd4\u666e\u901aDeepOnet\u6709\u663e\u8457\u6539\u5584\uff0c\u53c2\u6570\u6570\u91cf\u76f8\u4f3c\u3002", "conclusion": "Mscale-DeepOnet\u80fd\u6355\u83b7\u9ad8\u9891\u6210\u5206\uff0c\u63d0\u9ad8\u9ad8\u9891\u6620\u5c04\u7684\u5b66\u4e60\u80fd\u529b\u3002"}}
{"id": "2504.10936", "pdf": "https://arxiv.org/pdf/2504.10936", "abs": "https://arxiv.org/abs/2504.10936", "authors": ["Yuni Susanti", "Michael F\u00e4rber"], "title": "Can LLMs Leverage Observational Data? Towards Data-Driven Causal Discovery with LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Causal discovery traditionally relies on statistical methods applied to\nobservational data, often requiring large datasets and assumptions about\nunderlying causal structures. Recent advancements in Large Language Models\n(LLMs) have introduced new possibilities for causal discovery by providing\ndomain expert knowledge. However, it remains unclear whether LLMs can\neffectively process observational data for causal discovery. In this work, we\nexplore the potential of LLMs for data-driven causal discovery by integrating\nobservational data for LLM-based reasoning. Specifically, we examine whether\nLLMs can effectively utilize observational data through two prompting\nstrategies: pairwise prompting and breadth first search (BFS)-based prompting.\nIn both approaches, we incorporate the observational data directly into the\nprompt to assess LLMs' ability to infer causal relationships from such data.\nExperiments on benchmark datasets show that incorporating observational data\nenhances causal discovery, boosting F1 scores by up to 0.11 point using both\npairwise and BFS LLM-based prompting, while outperforming traditional\nstatistical causal discovery baseline by up to 0.52 points. Our findings\nhighlight the potential and limitations of LLMs for data-driven causal\ndiscovery, demonstrating their ability to move beyond textual metadata and\neffectively interpret and utilize observational data for more informed causal\nreasoning. Our studies lays the groundwork for future advancements toward fully\nLLM-driven causal discovery.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ed3\u5408\u89c2\u6d4b\u6570\u636e\u8fdb\u884c\u56e0\u679c\u53d1\u73b0\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0cF1\u5206\u6570\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u56e0\u679c\u53d1\u73b0\u4f9d\u8d56\u7edf\u8ba1\u65b9\u6cd5\u548c\u5927\u6837\u672c\u6570\u636e\uff0c\u800cLLM\u63d0\u4f9b\u4e86\u9886\u57df\u4e13\u5bb6\u77e5\u8bc6\uff0c\u4f46\u5176\u5904\u7406\u89c2\u6d4b\u6570\u636e\u7684\u80fd\u529b\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u672c\u7814\u7a76\u4f7f\u7528\u914d\u5bf9\u63d0\u793a\u548cBFS-based\u63d0\u793a\u7b56\u7565\uff0c\u5c06\u89c2\u6d4b\u6570\u636e\u76f4\u63a5\u878d\u5165LLM\u63d0\u793a\u4e2d\uff0c\u4ee5\u63a8\u65ad\u56e0\u679c\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u878d\u5165\u89c2\u6d4b\u6570\u636e\u540e\uff0cF1\u5206\u6570\u6700\u9ad8\u63d0\u53470.11\uff0c\u5e76\u6bd4\u4f20\u7edf\u7edf\u8ba1\u65b9\u6cd5\u9ad8\u51fa\u6700\u9ad80.52\u3002", "conclusion": "\u7814\u7a76\u7a81\u51fa\u4e86LLM\u5728\u56e0\u679c\u53d1\u73b0\u4e2d\u7684\u6f5c\u529b\u548c\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765LLM\u9a71\u52a8\u7684\u56e0\u679c\u53d1\u73b0\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2504.10538", "pdf": "https://arxiv.org/pdf/2504.10538", "abs": "https://arxiv.org/abs/2504.10538", "authors": ["Jiajie Su", "Qiyong Zhong", "Yunshan Ma", "Weiming Liu", "Chaochao Chen", "Xiaolin Zheng", "Jianwei Yin", "Tat-Seng Chua"], "title": "Distilling Transitional Pattern to Large Language Models for Multimodal Session-based Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Session-based recommendation (SBR) predicts the next item based on anonymous\nsessions. Traditional SBR explores user intents based on ID collaborations or\nauxiliary content. To further alleviate data sparsity and cold-start issues,\nrecent Multimodal SBR (MSBR) methods utilize simplistic pre-trained models for\nmodality learning but have limitations in semantic richness. Considering\nsemantic reasoning abilities of Large Language Models (LLM), we focus on the\nLLM-enhanced MSBR scenario in this paper, which leverages LLM cognition for\ncomprehensive multimodal representation generation, to enhance downstream MSBR.\nTackling this problem faces two challenges: i) how to obtain LLM cognition on\nboth transitional patterns and inherent multimodal knowledge, ii) how to align\nboth features into one unified LLM, minimize discrepancy while maximizing\nrepresentation utility. To this end, we propose a multimodal LLM-enhanced\nframework TPAD, which extends a distillation paradigm to decouple and align\ntransitional patterns for promoting MSBR. TPAD establishes parallel\nKnowledge-MLLM and Transfer-MLLM, where the former interprets item\nknowledge-reflected features and the latter extracts transition-aware features\nunderneath sessions. A transitional pattern alignment module harnessing mutual\ninformation estimation theory unites two MLLMs, alleviating distribution\ndiscrepancy and distilling transitional patterns into modal representations.\nExtensive experiments on real-world datasets demonstrate the effectiveness of\nour framework.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faTPAD\u6846\u67b6\uff0c\u4f7f\u7528\u591a\u6a21\u6001LLM\u589e\u5f3a\u4f1a\u8bdd\u63a8\u8350\u7cfb\u7edf\uff0c\u89e3\u51b3\u6570\u636e\u7a00\u758f\u548c\u51b7\u542f\u52a8\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u7f13\u89e3\u4f20\u7edf\u4f1a\u8bdd\u63a8\u8350\u4e2d\u7684\u6570\u636e\u7a00\u758f\u548c\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u5e76\u514b\u670d\u73b0\u6709\u591a\u6a21\u6001\u65b9\u6cd5\u5728\u8bed\u4e49\u4e30\u5bcc\u6027\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u5229\u7528LLM\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faTPAD\u6846\u67b6\uff0c\u5305\u62ecKnowledge-MLLM\u548cTransfer-MLLM\uff0c\u4ee5\u53ca\u4f7f\u7528\u4e92\u4fe1\u606f\u4f30\u8ba1\u7684\u8fc7\u6e21\u6a21\u5f0f\u5bf9\u9f50\u6a21\u5757\uff0c\u6765\u89e3\u8026\u548c\u5bf9\u9f50\u8fc7\u6e21\u6a21\u5f0f\uff0c\u51cf\u5c11\u5206\u5e03\u5dee\u5f02\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "TPAD\u6846\u67b6\u901a\u8fc7LLM\u589e\u5f3a\u591a\u6a21\u6001\u4f1a\u8bdd\u63a8\u8350\uff0c\u63d0\u9ad8\u4e86\u63a8\u8350\u6027\u80fd\u548c\u8868\u793a\u6548\u7528\u3002"}}
{"id": "2504.10957", "pdf": "https://arxiv.org/pdf/2504.10957", "abs": "https://arxiv.org/abs/2504.10957", "authors": ["Hongkang Li", "Yihua Zhang", "Shuai Zhang", "Meng Wang", "Sijia Liu", "Pin-Yu Chen"], "title": "When is Task Vector Provably Effective for Model Editing? A Generalization Analysis of Nonlinear Transformers", "categories": ["cs.LG"], "comment": "Published at ICLR 2025 as an oral paper", "summary": "Task arithmetic refers to editing the pre-trained model by adding a weighted\nsum of task vectors, each of which is the weight update from the pre-trained\nmodel to fine-tuned models for certain tasks. This approach recently gained\nattention as a computationally efficient inference method for model editing,\ne.g., multi-task learning, forgetting, and out-of-domain generalization\ncapabilities. However, the theoretical understanding of why task vectors can\nexecute various conceptual operations remains limited, due to the highly\nnon-convexity of training Transformer-based models. To the best of our\nknowledge, this paper provides the first theoretical characterization of the\ngeneralization guarantees of task vector methods on nonlinear Transformers. We\nconsider a conceptual learning setting, where each task is a binary\nclassification problem based on a discriminative pattern. We theoretically\nprove the effectiveness of task addition in simultaneously learning a set of\nirrelevant or aligned tasks, as well as the success of task negation in\nunlearning one task from irrelevant or contradictory tasks. Moreover, we prove\nthe proper selection of linear coefficients for task arithmetic to achieve\nguaranteed generalization to out-of-domain tasks. All of our theoretical\nresults hold for both dense-weight parameters and their low-rank\napproximations. Although established in a conceptual setting, our theoretical\nfindings were validated on a practical machine unlearning task using the large\nlanguage model Phi-1.5 (1.3B).", "AI": {"tldr": "\u4efb\u52a1\u7b97\u672f\u901a\u8fc7\u6dfb\u52a0\u4efb\u52a1\u5411\u91cf\u52a0\u6743\u548c\u7f16\u8f91\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u672c\u6587\u9996\u6b21\u4e3a\u975e\u7ebf\u6027Transformer\u63d0\u4f9b\u6cdb\u5316\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u9a8c\u8bc1\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u4efb\u52a1\u7b97\u672f\u5728\u6a21\u578b\u7f16\u8f91\u4e2d\u9ad8\u6548\uff0c\u4f46\u7406\u8bba\u7406\u89e3\u6709\u9650\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u975e\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u4f9b\u6cdb\u5316\u4fdd\u8bc1\u7684\u7406\u8bba\u8868\u5f81\u3002", "method": "\u91c7\u7528\u6982\u5ff5\u5b66\u4e60\u8bbe\u7f6e\uff0c\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\uff0c\u8bc1\u660e\u4efb\u52a1\u6dfb\u52a0\u3001\u5426\u5b9a\u548c\u7cfb\u6570\u9009\u62e9\u7684\u6709\u6548\u6027\uff0c\u652f\u6301\u7a20\u5bc6\u548c\u4f4e\u79e9\u53c2\u6570\u8fd1\u4f3c\u3002", "result": "\u8bc1\u660e\u4efb\u52a1\u7b97\u672f\u5728\u591a\u4efb\u52a1\u5b66\u4e60\u3001\u9057\u5fd8\u548c\u6cdb\u5316\u65b9\u9762\u7684\u6210\u529f\uff0c\u5e76\u901a\u8fc7Phi-1.5\u6a21\u578b\u9a8c\u8bc1\u673a\u5668\u9057\u5fd8\u4efb\u52a1\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86\u4efb\u52a1\u7b97\u672f\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u786e\u8ba4\u5176\u5b9e\u9645\u6709\u6548\u6027\uff0c\u63a8\u8fdb\u4e86\u6a21\u578b\u7f16\u8f91\u9886\u57df\u7684\u7406\u89e3\u3002"}}
{"id": "2504.10539", "pdf": "https://arxiv.org/pdf/2504.10539", "abs": "https://arxiv.org/abs/2504.10539", "authors": ["Yue Li"], "title": "Physics-Informed Neural Networks for Enhanced Interface Preservation in Lattice Boltzmann Multiphase Simulations", "categories": ["physics.flu-dyn", "cs.AI"], "comment": null, "summary": "This paper presents an improved approach for preserving sharp interfaces in\nmultiphase Lattice Boltzmann Method (LBM) simulations using Physics-Informed\nNeural Networks (PINNs). Interface diffusion is a common challenge in\nmultiphase LBM, leading to reduced accuracy in simulating phenomena where\ninterfacial dynamics are critical. We propose a coupled PINN-LBM framework that\nmaintains interface sharpness while preserving the physical accuracy of the\nsimulation. Our approach is validated through droplet simulations, with\nquantitative metrics measuring interface width, maximum gradient, phase\nseparation, effective interface width, and interface energy. The enhanced\nvisualization techniques employed in this work clearly demonstrate the superior\nperformance of PINN-LBM over standard LBM for multiphase simulations,\nparticularly in maintaining well-defined interfaces throughout the simulation.\nWe provide a comprehensive analysis of the results, showcasing how the neural\nnetwork integration effectively counteracts numerical diffusion, while\nmaintaining physical consistency with the underlying fluid dynamics.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528Physics-Informed Neural Networks (PINNs)\u6539\u8fdb\u7684\u591a\u76f8Lattice Boltzmann Method (LBM)\uff0c\u4ee5\u4fdd\u6301\u63a5\u53e3\u6e05\u6670\u3002", "motivation": "\u591a\u76f8LBM\u4e2d\u63a5\u53e3\u6269\u6563\u95ee\u9898\u5e38\u89c1\uff0c\u5bfc\u81f4\u6a21\u62df\u7cbe\u5ea6\u964d\u4f4e\uff0c\u5c24\u5176\u5728\u754c\u9762\u52a8\u6001\u5173\u952e\u7684\u573a\u666f\u3002", "method": "\u63d0\u51fa\u8026\u5408PINN-LBM\u6846\u67b6\uff0c\u901a\u8fc7\u6db2\u6ef4\u6a21\u62df\u548c\u6307\u6807\uff08\u5982\u63a5\u53e3\u5bbd\u5ea6\u3001\u6700\u5927\u68af\u5ea6\uff09\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "PINN-LBM\u5728\u63a5\u53e3\u6e05\u6670\u5ea6\u548c\u5bf9\u6297\u6570\u503c\u6269\u6563\u65b9\u9762\u4f18\u4e8e\u6807\u51c6LBM\uff0c\u5b9a\u91cf\u548c\u53ef\u89c6\u5316\u7ed3\u679c\u663e\u793a\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u6574\u5408\u6709\u6548\u51cf\u5c11\u6269\u6563\uff0c\u540c\u65f6\u4fdd\u6301\u6d41\u4f53\u52a8\u529b\u5b66\u7269\u7406\u4e00\u81f4\u6027\u3002"}}
{"id": "2504.10959", "pdf": "https://arxiv.org/pdf/2504.10959", "abs": "https://arxiv.org/abs/2504.10959", "authors": ["Xiaoyang He", "Xiaoxia Huang"], "title": "Learning-Based User Association for MmWave Vehicular Networks With Kernelized Contextual Bandits", "categories": ["cs.LG"], "comment": "Accepted by IEEE WCNC 2025", "summary": "Vehicles require timely channel conditions to determine the base station (BS)\nto communicate with, but it is costly to estimate the fast-fading mmWave\nchannels frequently. Without additional channel estimations, the proposed\nDistributed Kernelized Upper Confidence Bound (DK-UCB) algorithm estimates the\ncurrent instantaneous transmission rates utilizing past contexts, such as the\nvehicle's location and velocity, along with past instantaneous transmission\nrates. To capture the nonlinear mapping from a context to the instantaneous\ntransmission rate, DK-UCB maps a context into the reproducing kernel Hilbert\nspace (RKHS) where a linear mapping becomes observable. To improve estimation\naccuracy, we propose a novel kernel function in RKHS which incorporates the\npropagation characteristics of the mmWave signals. Moreover, DK-UCB encourages\na vehicle to share necessary information when it has conducted significant\nexplorations, which speeds up the learning process while maintaining affordable\ncommunication costs.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faDK-UCB\u7b97\u6cd5\uff0c\u4f7f\u7528\u8fc7\u53bb\u4e0a\u4e0b\u6587\u4f30\u8ba1mmWave\u4fe1\u9053\u77ac\u65f6\u4f20\u8f93\u7387\uff0c\u51cf\u5c11\u9891\u7e41\u4fe1\u9053\u4f30\u8ba1\u6210\u672c\u3002", "motivation": "\u8f66\u8f86\u9700\u8981\u53ca\u65f6\u4fe1\u9053\u6761\u4ef6\u9009\u62e9\u57fa\u7ad9\u901a\u4fe1\uff0c\u4f46\u9891\u7e41\u4f30\u8ba1\u5feb\u901f\u8870\u843dmmWave\u4fe1\u9053\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51faDK-UCB\u7b97\u6cd5\uff0c\u5229\u7528\u8fc7\u53bb\u4e0a\u4e0b\u6587\u548c\u4f20\u8f93\u7387\u6620\u5c04\u5230RKHS\uff0c\u4f7f\u7528\u65b0\u578b\u6838\u51fd\u6570\u6539\u8fdb\u51c6\u786e\u6027\uff0c\u5e76\u9f13\u52b1\u4fe1\u606f\u5171\u4eab\u52a0\u901f\u5b66\u4e60\u3002", "result": "\u63d0\u9ad8\u4e86\u4f30\u8ba1\u51c6\u786e\u6027\uff0c\u52a0\u901f\u5b66\u4e60\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u8d1f\u62c5\u901a\u4fe1\u6210\u672c\u3002", "conclusion": "DK-UCB\u7b97\u6cd5\u6709\u6548\u51cf\u5c11\u4fe1\u9053\u4f30\u8ba1\u6210\u672c\u5e76\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2504.10540", "pdf": "https://arxiv.org/pdf/2504.10540", "abs": "https://arxiv.org/abs/2504.10540", "authors": ["Zichao Yu", "Zhen Zou", "Guojiang Shao", "Chengwei Zhang", "Shengze Xu", "Jie Huang", "Feng Zhao", "Xiaodong Cun", "Wenyi Zhang"], "title": "AB-Cache: Training-Free Acceleration of Diffusion Models via Adams-Bashforth Cached Feature Reuse", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Diffusion models have demonstrated remarkable success in generative tasks,\nyet their iterative denoising process results in slow inference, limiting their\npracticality. While existing acceleration methods exploit the well-known\nU-shaped similarity pattern between adjacent steps through caching mechanisms,\nthey lack theoretical foundation and rely on simplistic computation reuse,\noften leading to performance degradation. In this work, we provide a\ntheoretical understanding by analyzing the denoising process through the\nsecond-order Adams-Bashforth method, revealing a linear relationship between\nthe outputs of consecutive steps. This analysis explains why the outputs of\nadjacent steps exhibit a U-shaped pattern. Furthermore, extending\nAdams-Bashforth method to higher order, we propose a novel caching-based\nacceleration approach for diffusion models, instead of directly reusing cached\nresults, with a truncation error bound of only \\(O(h^k)\\) where $h$ is the step\nsize. Extensive validation across diverse image and video diffusion models\n(including HunyuanVideo and FLUX.1-dev) with various schedulers demonstrates\nour method's effectiveness in achieving nearly $3\\times$ speedup while\nmaintaining original performance levels, offering a practical real-time\nsolution without compromising generation quality.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6269\u6563\u6a21\u578b\u52a0\u901f\u65b9\u6cd5\uff0c\u4f7f\u7528\u9ad8\u9636Adams-Bashforth\u65b9\u6cd5\u5b9e\u73b0\u8fd13\u500d\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8fed\u4ee3\u53bb\u566a\u8fc7\u7a0b\u5bfc\u81f4\u63a8\u7406\u7f13\u6162\uff0c\u73b0\u6709\u7684\u52a0\u901f\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\u4e14\u53ef\u80fd\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u901a\u8fc7\u4e8c\u9636Adams-Bashforth\u65b9\u6cd5\u5206\u6790\u53bb\u566a\u8fc7\u7a0b\uff0c\u63ed\u793a\u76f8\u90bb\u6b65\u9aa4\u7684\u7ebf\u6027\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u9ad8\u9636\u7f13\u5b58\u52a0\u901f\u65b9\u6cd5\uff0c\u622a\u65ad\u8bef\u5dee\u4e3aO(h^k)\u3002", "result": "\u5728\u591a\u79cd\u56fe\u50cf\u548c\u89c6\u9891\u6269\u6563\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u4e86\u8fd13\u500d\u52a0\u901f\u800c\u4e0d\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u5b9e\u65f6\u52a0\u901f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.10983", "pdf": "https://arxiv.org/pdf/2504.10983", "abs": "https://arxiv.org/abs/2504.10983", "authors": ["Zitai Kong", "Yiheng Zhu", "Yinlong Xu", "Hanjing Zhou", "Mingzhe Yin", "Jialu Wu", "Hongxia Xu", "Chang-Yu Hsieh", "Tingjun Hou", "Jian Wu"], "title": "ProtFlow: Fast Protein Sequence Design via Flow Matching on Compressed Protein Language Model Embeddings", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": null, "summary": "The design of protein sequences with desired functionalities is a fundamental\ntask in protein engineering. Deep generative methods, such as autoregressive\nmodels and diffusion models, have greatly accelerated the discovery of novel\nprotein sequences. However, these methods mainly focus on local or shallow\nresidual semantics and suffer from low inference efficiency, large modeling\nspace and high training cost. To address these challenges, we introduce\nProtFlow, a fast flow matching-based protein sequence design framework that\noperates on embeddings derived from semantically meaningful latent space of\nprotein language models. By compressing and smoothing the latent space,\nProtFlow enhances performance while training on limited computational\nresources. Leveraging reflow techniques, ProtFlow enables high-quality\nsingle-step sequence generation. Additionally, we develop a joint design\npipeline for the design scene of multichain proteins. We evaluate ProtFlow\nacross diverse protein design tasks, including general peptides and long-chain\nproteins, antimicrobial peptides, and antibodies. Experimental results\ndemonstrate that ProtFlow outperforms task-specific methods in these\napplications, underscoring its potential and broad applicability in\ncomputational protein sequence design and analysis.", "AI": {"tldr": "ProtFlow \u662f\u4e00\u79cd\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u86cb\u767d\u8d28\u5e8f\u5217\u8bbe\u8ba1\u6846\u67b6\uff0c\u63d0\u9ad8\u4e86\u751f\u6210\u6548\u7387\u548c\u6027\u80fd\uff0c\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u4f4e\u6548\u7387\u3001\u5927\u6a21\u578b\u7a7a\u95f4\u548c\u9ad8\u8bad\u7ec3\u6210\u672c\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u6846\u67b6\u6765\u52a0\u901f\u86cb\u767d\u8d28\u5e8f\u5217\u8bbe\u8ba1\u3002", "method": "\u5f15\u5165 ProtFlow\uff0c\u5229\u7528\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u6d41\u5339\u914d\uff0c\u538b\u7f29\u5e73\u6ed1\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7 reflow \u6280\u672f\u5b9e\u73b0\u5355\u6b65\u751f\u6210\u548c\u591a\u94fe\u86cb\u767d\u8054\u5408\u8bbe\u8ba1\u3002", "result": "ProtFlow \u5728\u4e00\u822c\u80bd\u3001\u591a\u94fe\u86cb\u767d\u3001\u6297\u83cc\u80bd\u548c\u6297\u4f53\u7b49\u4efb\u52a1\u4e2d\u4f18\u4e8e\u7279\u5b9a\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "ProtFlow \u5177\u6709\u5e7f\u9614\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u53ef\u63d0\u5347\u8ba1\u7b97\u86cb\u767d\u8d28\u5e8f\u5217\u8bbe\u8ba1\u548c\u5206\u6790\u7684\u6548\u7387\u548c\u9002\u7528\u6027\u3002"}}
{"id": "2504.10541", "pdf": "https://arxiv.org/pdf/2504.10541", "abs": "https://arxiv.org/abs/2504.10541", "authors": ["Xu Guo", "Tong Zhang", "Yuanzhi Wang", "Chenxu Wang", "Fuyun Wang", "Xudong Wang", "Xiaoya Zhang", "Xin Liu", "Zhen Cui"], "title": "Multi-Modal Hypergraph Enhanced LLM Learning for Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": "10 pages, 4 figures", "summary": "The burgeoning presence of Large Language Models (LLM) is propelling the\ndevelopment of personalized recommender systems. Most existing LLM-based\nmethods fail to sufficiently explore the multi-view graph structure\ncorrelations inherent in recommendation scenarios. To this end, we propose a\nnovel framework, Hypergraph Enhanced LLM Learning for multimodal Recommendation\n(HeLLM), designed to equip LLMs with the capability to capture intricate\nhigher-order semantic correlations by fusing graph-level contextual signals\nwith sequence-level behavioral patterns. In the recommender pre-training phase,\nwe design a user hypergraph to uncover shared interest preferences among users\nand an item hypergraph to capture correlations within multimodal similarities\namong items. The hypergraph convolution and synergistic contrastive learning\nmechanism are introduced to enhance the distinguishability of learned\nrepresentations. In the LLM fine-tuning phase, we inject the learned\ngraph-structured embeddings directly into the LLM's architecture and integrate\nsequential features capturing each user's chronological behavior. This process\nenables hypergraphs to leverage graph-structured information as global context,\nenhancing the LLM's ability to perceive complex relational patterns and\nintegrate multimodal information, while also modeling local temporal dynamics.\nExtensive experiments demonstrate the superiority of our proposed method over\nstate-of-the-art baselines, confirming the advantages of fusing\nhypergraph-based context with sequential user behavior in LLMs for\nrecommendation.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faHeLLM\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u8d85\u56fe\u7ed3\u6784\u548cLLM\u63d0\u5347\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM-based\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u63a2\u7d22\u63a8\u8350\u573a\u666f\u4e2d\u7684\u591a\u89c6\u56fe\u56fe\u7ed3\u6784\u76f8\u5173\u6027\uff0c\u56e0\u6b64\u9700\u6355\u6349\u66f4\u9ad8\u9636\u8bed\u4e49\u76f8\u5173\u6027\u3002", "method": "\u63d0\u51faHeLLM\u6846\u67b6\uff0c\u5305\u62ec\u7528\u6237\u548c\u7269\u54c1\u8d85\u56fe\u3001\u8d85\u56fe\u5377\u79ef\u3001\u5bf9\u6bd4\u5b66\u4e60\uff0c\u4ee5\u53caLLM\u5fae\u8c03\u9636\u6bb5\u6ce8\u5165\u56fe\u7ed3\u6784\u5d4c\u5165\u548c\u5e8f\u5217\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eHeLLM\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5c55\u793a\u4e86\u878d\u5408\u8d85\u56fe\u4e0a\u4e0b\u6587\u548c\u5e8f\u5217\u884c\u4e3a\u7684\u4f18\u52bf\u3002", "conclusion": "HeLLM\u589e\u5f3aLLM\u5bf9\u590d\u6742\u5173\u7cfb\u548c\u591a\u6a21\u6001\u4fe1\u606f\u7684\u5904\u7406\uff0c\u63d0\u9ad8\u4e86\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2504.10987", "pdf": "https://arxiv.org/pdf/2504.10987", "abs": "https://arxiv.org/abs/2504.10987", "authors": ["Samuel Maddock", "Shripad Gade", "Graham Cormode", "Will Bullock"], "title": "Leveraging Vertical Public-Private Split for Improved Synthetic Data Generation", "categories": ["cs.LG", "cs.CR"], "comment": "Accepted to the Synthetic Data x Data Access Problem (SynthData)\n  workshop @ ICLR 2025", "summary": "Differentially Private Synthetic Data Generation (DP-SDG) is a key enabler of\nprivate and secure tabular-data sharing, producing artificial data that carries\nthrough the underlying statistical properties of the input data. This typically\ninvolves adding carefully calibrated statistical noise to guarantee individual\nprivacy, at the cost of synthetic data quality. Recent literature has explored\nscenarios where a small amount of public data is used to help enhance the\nquality of synthetic data. These methods study a horizontal public-private\npartitioning which assumes access to a small number of public rows that can be\nused for model initialization, providing a small utility gain. However,\nrealistic datasets often naturally consist of public and private attributes,\nmaking a vertical public-private partitioning relevant for practical synthetic\ndata deployments. We propose a novel framework that adapts horizontal\npublic-assisted methods into the vertical setting. We compare this framework\nagainst our alternative approach that uses conditional generation, highlighting\ninitial limitations of public-data assisted methods and proposing future\nresearch directions to address these challenges.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u6846\u67b6\uff0c\u5c06\u6c34\u5e73\u516c\u5171\u8f85\u52a9\u65b9\u6cd5\u9002\u5e94\u5230\u5782\u76f4\u516c\u5171-\u79c1\u6709\u5206\u533a\uff0c\u4ee5\u63d0\u5347\u5dee\u5206\u9690\u79c1\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u8d28\u91cf\uff0c\u5e76\u4e0e\u6761\u4ef6\u751f\u6210\u65b9\u6cd5\u6bd4\u8f83\uff0c\u7a81\u51fa\u4e86\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ec5\u5904\u7406\u6c34\u5e73\u5206\u533a\uff08\u4f7f\u7528\u5c11\u91cf\u516c\u5171\u884c\uff09\uff0c\u4f46\u73b0\u5b9e\u6570\u636e\u96c6\u5e38\u6709\u5782\u76f4\u5206\u533a\uff08\u516c\u5171\u548c\u79c1\u6709\u5c5e\u6027\uff09\uff0c\u9700\u8981\u66f4\u5b9e\u7528\u65b9\u6cd5\u6765\u63d0\u9ad8\u5408\u6210\u6570\u636e\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u6846\u67b6\u9002\u5e94\u5782\u76f4\u8bbe\u7f6e\uff0c\u5e76\u4f7f\u7528\u6761\u4ef6\u751f\u6210\u4f5c\u4e3a\u5907\u9009\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u53d1\u73b0\u516c\u5171\u6570\u636e\u8f85\u52a9\u65b9\u6cd5\u7684\u521d\u59cb\u9650\u5236\uff0c\u5e76\u5efa\u8bae\u672a\u6765\u7814\u7a76\u65b9\u5411\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "conclusion": "\u5f3a\u8c03\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6765\u6539\u8fdb\u65b9\u6cd5\uff0c\u89e3\u51b3\u5782\u76f4\u5206\u533a\u4e2d\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u5408\u6210\u6570\u636e\u8d28\u91cf\u3002"}}
{"id": "2504.10548", "pdf": "https://arxiv.org/pdf/2504.10548", "abs": "https://arxiv.org/abs/2504.10548", "authors": ["Sandeep Hans", "Atul Kumar", "Toshikai Yasue", "Kouichi Ono", "Saravanan Krishnan", "Devika Sondhi", "Fumiko Satoh", "Gerald Mitchell", "Sachin Kumar", "Diptikalyan Saha"], "title": "Automated Testing of COBOL to Java Transformation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Recent advances in Large Language Model (LLM) based Generative AI techniques\nhave made it feasible to translate enterprise-level code from legacy languages\nsuch as COBOL to modern languages such as Java or Python. While the results of\nLLM-based automatic transformation are encouraging, the resulting code cannot\nbe trusted to correctly translate the original code, making manual validation\nof translated Java code from COBOL a necessary but time-consuming and\nlabor-intensive process. In this paper, we share our experience of developing a\ntesting framework for IBM Watsonx Code Assistant for Z (WCA4Z) [5], an\nindustrial tool designed for COBOL to Java translation. The framework automates\nthe process of testing the functional equivalence of the translated Java code\nagainst the original COBOL programs in an industry context. Our framework uses\nsymbolic execution to generate unit tests for COBOL, mocking external calls and\ntransforming them into JUnit tests to validate semantic equivalence with\ntranslated Java. The results not only help identify and repair any detected\ndiscrepancies but also provide feedback to improve the AI model.", "AI": {"tldr": "\u672c\u8bba\u6587\u5206\u4eab\u4e86\u5f00\u53d1IBM WCA4Z\u6d4b\u8bd5\u6846\u67b6\u7684\u7ecf\u9a8c\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u9a8c\u8bc1COBOL\u5230Java\u7ffb\u8bd1\u7684\u51fd\u6570\u7b49\u4ef7\u6027\u3002", "motivation": "LLM-based\u4ee3\u7801\u7ffb\u8bd1\u867d\u6709\u8fdb\u5c55\uff0c\u4f46\u4e0d\u53ef\u9760\uff0c\u9700\u8981\u624b\u52a8\u9a8c\u8bc1\uff0c\u8017\u65f6\u8d39\u529b\uff0c\u56e0\u6b64\u5f00\u53d1\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u7b26\u53f7\u6267\u884c\u751f\u6210COBOL\u5355\u5143\u6d4b\u8bd5\uff0c\u6a21\u62df\u5916\u90e8\u8c03\u7528\uff0c\u5e76\u8f6c\u6362\u4e3aJUnit\u6d4b\u8bd5\u4ee5\u9a8c\u8bc1Java\u4ee3\u7801\u7684\u8bed\u4e49\u7b49\u4ef7\u6027\u3002", "result": "\u6846\u67b6\u6709\u52a9\u4e8e\u8bc6\u522b\u548c\u4fee\u590d\u7ffb\u8bd1\u5dee\u5f02\uff0c\u5e76\u4e3aAI\u6a21\u578b\u63d0\u4f9b\u6539\u8fdb\u53cd\u9988\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u6709\u6548\u63d0\u9ad8\u4e86\u7ffb\u8bd1\u9a8c\u8bc1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2504.11022", "pdf": "https://arxiv.org/pdf/2504.11022", "abs": "https://arxiv.org/abs/2504.11022", "authors": ["Joana Reuss", "Jan Macdonald", "Simon Becker", "Konrad Schultka", "Lorenz Richter", "Marco K\u00f6rner"], "title": "Meta-learning For Few-Shot Time Series Crop Type Classification: A Benchmark On The EuroCropsML Dataset", "categories": ["cs.LG", "cs.CV"], "comment": "19 pages, 7 figures, 12 tables", "summary": "Spatial imbalances in crop type data pose significant challenges for accurate\nclassification in remote sensing applications. Algorithms aiming at\ntransferring knowledge from data-rich to data-scarce tasks have thus surged in\npopularity. However, despite their effectiveness in previous evaluations, their\nperformance in challenging real-world applications is unclear and needs to be\nevaluated. This study benchmarks transfer learning and several meta-learning\nalgorithms, including (First-Order) Model-Agnostic Meta-Learning ((FO)-MAML),\nAlmost No Inner Loop (ANIL), and Task-Informed Meta-Learning (TIML), on the\nreal-world EuroCropsML time series dataset, which combines farmer-reported crop\ndata with Sentinel-2 satellite observations from Estonia, Latvia, and Portugal.\nOur findings indicate that MAML-based meta-learning algorithms achieve slightly\nhigher accuracy compared to simpler transfer learning methods when applied to\ncrop type classification tasks in Estonia after pre-training on data from\nLatvia. However, this improvement comes at the cost of increased computational\ndemands and training time. Moreover, we find that the transfer of knowledge\nbetween geographically disparate regions, such as Estonia and Portugal, poses\nsignificant challenges to all investigated algorithms. These insights\nunderscore the trade-offs between accuracy and computational resource\nrequirements in selecting machine learning methods for real-world crop type\nclassification tasks and highlight the difficulties of transferring knowledge\nbetween different regions of the Earth. To facilitate future research in this\ndomain, we present the first comprehensive benchmark for evaluating transfer\nand meta-learning methods for crop type classification under real-world\nconditions. The corresponding code is publicly available at\nhttps://github.com/dida-do/eurocrops-meta-learning.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u5bf9\u8f6c\u79fb\u5b66\u4e60\u548c\u5143\u5b66\u4e60\u7b97\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u4f5c\u7269\u7c7b\u578b\u5206\u7c7b\u4e2d\u7684\u6027\u80fd\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5143\u5b66\u4e60\u7b97\u6cd5\u51c6\u786e\u6027\u7565\u9ad8\u4f46\u8ba1\u7b97\u6210\u672c\u589e\u52a0\uff0c\u5e76\u7a81\u51fa\u4e86\u8de8\u533a\u57df\u77e5\u8bc6\u8f6c\u79fb\u7684\u6311\u6218\u3002", "motivation": "\u7a7a\u95f4\u6570\u636e\u4e0d\u5e73\u8861\u5bfc\u81f4\u8fdc\u7a0b sensing \u5206\u7c7b\u56f0\u96be\uff0c\u9700\u8981\u8bc4\u4f30\u8f6c\u79fb\u548c\u5143\u5b66\u4e60\u7b97\u6cd5\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u5728EuroCropsML\u6570\u636e\u96c6\u4e0a\u57fa\u51c6\u6d4b\u8bd5\u8f6c\u79fb\u5b66\u4e60\u548c\u5143\u5b66\u4e60\u7b97\u6cd5\uff08\u5982FO-MAML\u3001ANIL\u3001TIML\uff09\uff0c\u4f7f\u7528\u7231\u6c99\u5c3c\u4e9a\u3001\u62c9\u8131\u7ef4\u4e9a\u548c\u8461\u8404\u7259\u7684Sentinel-2\u536b\u661f\u6570\u636e\u3002", "result": "MAML-based\u7b97\u6cd5\u5728\u7231\u6c99\u5c3c\u4e9a\u4efb\u52a1\u4e0a\u9884\u8bad\u7ec3\u540e\u51c6\u786e\u6027\u7565\u9ad8\uff0c\u4f46\u8ba1\u7b97\u9700\u6c42\u589e\u52a0\uff1b\u7231\u6c99\u5c3c\u4e9a\u548c\u8461\u8404\u7259\u95f4\u77e5\u8bc6\u8f6c\u79fb\u5bf9\u6240\u6709\u7b97\u6cd5\u90fd\u5177\u6311\u6218\u3002", "conclusion": "\u5f3a\u8c03\u51c6\u786e\u6027\u548c\u8d44\u6e90\u6743\u8861\u3001\u533a\u57df\u77e5\u8bc6\u8f6c\u79fb\u96be\u5ea6\uff0c\u5e76\u63d0\u4f9b\u57fa\u51c6\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\uff0c\u4ee3\u7801\u516c\u5f00\u5728GitHub\u3002"}}
{"id": "2504.11026", "pdf": "https://arxiv.org/pdf/2504.11026", "abs": "https://arxiv.org/abs/2504.11026", "authors": ["Alexandru Vasilache", "Jona Scholz", "Vincent Schilling", "Sven Nitzsche", "Florian Kaelber", "Johannes Korsch", "Juergen Becker"], "title": "A PyTorch-Compatible Spike Encoding Framework for Energy-Efficient Neuromorphic Applications", "categories": ["cs.LG"], "comment": "A preliminary version of this work was accepted at the 20th\n  International Conference on Systems (ICONS 2025), May 18-22, 2025, Nice,\n  France. The conference proceedings will be published by IARIA Press (ISSN:\n  2308-4243, ISBN: 978-1-68558-278-4) and archived in the ThinkMind Digital\n  Library. The proposed Spike Encoding Framework can be accessed at\n  https://github.com/Alex-Vasilache/Spike-Encoding", "summary": "Spiking Neural Networks (SNNs) offer promising energy efficiency advantages,\nparticularly when processing sparse spike trains. However, their\nincompatibility with traditional datasets, which consist of batches of input\nvectors rather than spike trains, necessitates the development of efficient\nencoding methods. This paper introduces a novel, open-source PyTorch-compatible\nPython framework for spike encoding, designed for neuromorphic applications in\nmachine learning and reinforcement learning. The framework supports a range of\nencoding algorithms, including Leaky Integrate-and-Fire (LIF), Step Forward\n(SF), Pulse Width Modulation (PWM), and Ben's Spiker Algorithm (BSA), as well\nas specialized encoding strategies covering population coding and reinforcement\nlearning scenarios. Furthermore, we investigate the performance trade-offs of\neach method on embedded hardware using C/C++ implementations, considering\nenergy consumption, computation time, spike sparsity, and reconstruction\naccuracy. Our findings indicate that SF typically achieves the lowest\nreconstruction error and offers the highest energy efficiency and fastest\nencoding speed, achieving the second-best spike sparsity. At the same time,\nother methods demonstrate particular strengths depending on the signal\ncharacteristics. This framework and the accompanying empirical analysis provide\nvaluable resources for selecting optimal encoding strategies for\nenergy-efficient SNN applications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5f00\u6e90\u7684PyTorch\u517c\u5bb9\u6846\u67b6\uff0c\u7528\u4e8eSNN\u8109\u51b2\u7f16\u7801\uff0c\u5e76\u8bc4\u4f30\u591a\u79cd\u65b9\u6cd5\uff0c\u53d1\u73b0SF\u6548\u7387\u6700\u9ad8\u3002", "motivation": "SNN\u5904\u7406\u7a00\u758f\u8109\u51b2\u65f6\u80fd\u91cf\u6548\u7387\u9ad8\uff0c\u4f46\u4e0e\u4f20\u7edf\u6570\u636e\u96c6\u4e0d\u517c\u5bb9\uff0c\u9700\u8981\u9ad8\u6548\u7f16\u7801\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u652f\u6301LIF\u3001SF\u3001PWM\u3001BSA\u7b49\u7b97\u6cd5\u7684\u6846\u67b6\uff0c\u5e76\u7528C/C++\u5728\u5d4c\u5165\u5f0f\u786c\u4ef6\u4e0a\u8bc4\u4f30\u6027\u80fd\u3002", "result": "SF\u91cd\u5efa\u9519\u8bef\u6700\u4f4e\uff0c\u80fd\u91cf\u6548\u7387\u548c\u901f\u5ea6\u6700\u9ad8\uff0c\u8109\u51b2\u7a00\u758f\u6027\u7b2c\u4e8c\u597d\uff1b\u5176\u4ed6\u65b9\u6cd5\u5728\u7279\u5b9a\u573a\u666f\u6709\u4f18\u52bf\u3002", "conclusion": "\u6846\u67b6\u548c\u5206\u6790\u4e3a\u9009\u62e9\u6700\u4f73\u7f16\u7801\u7b56\u7565\u4ee5\u5b9e\u73b0SNN\u80fd\u91cf\u9ad8\u6548\u5e94\u7528\u63d0\u4f9b\u8d44\u6e90\u3002"}}
{"id": "2504.11054", "pdf": "https://arxiv.org/pdf/2504.11054", "abs": "https://arxiv.org/abs/2504.11054", "authors": ["Andrea Tirinzoni", "Ahmed Touati", "Jesse Farebrother", "Mateusz Guzek", "Anssi Kanervisto", "Yingchen Xu", "Alessandro Lazaric", "Matteo Pirotta"], "title": "Zero-Shot Whole-Body Humanoid Control via Behavioral Foundation Models", "categories": ["cs.LG"], "comment": "Published at ICLR 2025", "summary": "Unsupervised reinforcement learning (RL) aims at pre-training agents that can\nsolve a wide range of downstream tasks in complex environments. Despite recent\nadvancements, existing approaches suffer from several limitations: they may\nrequire running an RL process on each downstream task to achieve a satisfactory\nperformance, they may need access to datasets with good coverage or\nwell-curated task-specific samples, or they may pre-train policies with\nunsupervised losses that are poorly correlated with the downstream tasks of\ninterest. In this paper, we introduce a novel algorithm regularizing\nunsupervised RL towards imitating trajectories from unlabeled behavior\ndatasets. The key technical novelty of our method, called Forward-Backward\nRepresentations with Conditional-Policy Regularization, is to train\nforward-backward representations to embed the unlabeled trajectories to the\nsame latent space used to represent states, rewards, and policies, and use a\nlatent-conditional discriminator to encourage policies to ``cover'' the states\nin the unlabeled behavior dataset. As a result, we can learn policies that are\nwell aligned with the behaviors in the dataset, while retaining zero-shot\ngeneralization capabilities for reward-based and imitation tasks. We\ndemonstrate the effectiveness of this new approach in a challenging humanoid\ncontrol problem: leveraging observation-only motion capture datasets, we train\nMeta Motivo, the first humanoid behavioral foundation model that can be\nprompted to solve a variety of whole-body tasks, including motion tracking,\ngoal reaching, and reward optimization. The resulting model is capable of\nexpressing human-like behaviors and it achieves competitive performance with\ntask-specific methods while outperforming state-of-the-art unsupervised RL and\nmodel-based baselines.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u65e0\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u4eff\u65e0\u6807\u7b7e\u884c\u4e3a\u6570\u636e\u96c6\u6765\u9884\u8bad\u7ec3\u4ee3\u7406\uff0c\u5b9e\u73b0\u4e0b\u6e38\u4efb\u52a1\u7684\u96f6\u6837\u672c\u6cdb\u5316\uff0c\u5e76\u5728\u4eba\u5f62\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763RL\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u9700\u9488\u5bf9\u4e0b\u6e38\u4efb\u52a1\u8fd0\u884cRL\u3001\u4f9d\u8d56\u7279\u5b9a\u6570\u636e\u96c6\u6216\u9884\u8bad\u7ec3\u7b56\u7565\u4e0e\u4efb\u52a1\u76f8\u5173\u6027\u5dee\uff0c\u56e0\u6b64\u9700\u5f00\u53d1\u66f4\u6709\u6548\u7684\u9884\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u5f15\u5165Forward-Backward Representations with Conditional-Policy Regularization\u7b97\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3\u524d\u5411-\u540e\u5411\u8868\u793a\u5d4c\u5165\u8f68\u8ff9\uff0c\u5e76\u4f7f\u7528\u6761\u4ef6\u9274\u522b\u5668\u9f13\u52b1\u7b56\u7565\u8986\u76d6\u65e0\u6807\u7b7e\u6570\u636e\u96c6\u4e2d\u7684\u72b6\u6001\u3002", "result": "\u8bad\u7ec3\u51faMeta Motivo\u6a21\u578b\uff0c\u80fd\u5904\u7406\u4eba\u5f62\u673a\u5668\u4eba\u4efb\u52a1\u5982\u8fd0\u52a8\u8ddf\u8e2a\u3001\u76ee\u6807\u5230\u8fbe\u548c\u5956\u52b1\u4f18\u5316\uff0c\u8868\u73b0\u51fa\u7c7b\u4eba\u884c\u4e3a\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u65e0\u76d1\u7763RL\u548c\u6a21\u578b\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u7b56\u7565\u4e0e\u884c\u4e3a\u7684\u5bf9\u9f50\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u6027\u80fd\u3002"}}
{"id": "2504.11074", "pdf": "https://arxiv.org/pdf/2504.11074", "abs": "https://arxiv.org/abs/2504.11074", "authors": ["Zhou Fang", "Gianmarco Mengaldo"], "title": "Dynamical errors in machine learning forecasts", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": null, "summary": "In machine learning forecasting, standard error metrics such as mean absolute\nerror (MAE) and mean squared error (MSE) quantify discrepancies between\npredictions and target values. However, these metrics do not directly evaluate\nthe physical and/or dynamical consistency of forecasts, an increasingly\ncritical concern in scientific and engineering applications.\n  Indeed, a fundamental yet often overlooked question is whether machine\nlearning forecasts preserve the dynamical behavior of the underlying system.\nAddressing this issue is essential for assessing the fidelity of machine\nlearning models and identifying potential failure modes, particularly in\napplications where maintaining correct dynamical behavior is crucial.\n  In this work, we investigate the relationship between standard forecasting\nerror metrics, such as MAE and MSE, and the dynamical properties of the\nunderlying system. To achieve this goal, we use two recently developed\ndynamical indices: the instantaneous dimension ($d$), and the inverse\npersistence ($\\theta$). Our results indicate that larger forecast errors --\ne.g., higher MSE -- tend to occur in states with higher $d$ (higher complexity)\nand higher $\\theta$ (lower persistence). To further assess dynamical\nconsistency, we propose error metrics based on the dynamical indices that\nmeasure the discrepancy of the forecasted $d$ and $\\theta$ versus their correct\nvalues. Leveraging these dynamical indices-based metrics, we analyze direct and\nrecursive forecasting strategies for three canonical datasets -- Lorenz,\nKuramoto-Sivashinsky equation, and Kolmogorov flow -- as well as a real-world\nweather forecasting task. Our findings reveal substantial distortions in\ndynamical properties in ML forecasts, especially for long forecast lead times\nor long recursive simulations, providing complementary information on ML\nforecast fidelity that can be used to improve ML models.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u4e2d\u6807\u51c6\u9519\u8bef\u6307\u6807\uff08\u5982MAE\u548cMSE\uff09\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u57fa\u4e8e\u52a8\u6001\u6307\u6807\uff08\u5982\u77ac\u65f6\u7ef4\u5ea6d\u548c\u9006\u6301\u4e45\u6027\u03b8\uff09\u7684\u5ea6\u91cf\u65b9\u6cd5\uff0c\u4ee5\u8bc4\u4f30\u9884\u6d4b\u7684\u52a8\u6001\u4e00\u81f4\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u63ed\u793aML\u9884\u6d4b\u7684\u6f5c\u5728\u95ee\u9898\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u662f\u5426\u4fdd\u7559\u5e95\u5c42\u7cfb\u7edf\u7684\u52a8\u6001\u884c\u4e3a\u95ee\u9898\uff0c\u8fd9\u5728\u79d1\u5b66\u548c\u5de5\u7a0b\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u8bc4\u4f30\u6a21\u578b\u7684\u4fdd\u771f\u5ea6\u548c\u8bc6\u522b\u5931\u8d25\u6a21\u5f0f\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u52a8\u6001\u6307\u6807d\u548c\u03b8\uff0c\u63d0\u51fa\u57fa\u4e8e\u8fd9\u4e9b\u6307\u6807\u7684\u9519\u8bef\u5ea6\u91cf\uff0c\u5e76\u5206\u6790\u76f4\u63a5\u548c\u9012\u5f52\u9884\u6d4b\u7b56\u7565\u5728Lorenz\u3001Kuramoto-Sivashinsky\u65b9\u7a0b\u3001Kolmogorov\u6d41\u52a8\u548c\u5929\u6c14\u9884\u6d4b\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u8f83\u5927\u7684\u9884\u6d4b\u9519\u8bef\u4e0e\u66f4\u9ad8\u7684\u52a8\u6001\u590d\u6742\u6027\u548c\u66f4\u4f4e\u7684\u6301\u4e45\u6027\u76f8\u5173\uff0cML\u9884\u6d4b\u5728\u957f\u9884\u6d4b\u65f6\u6bb5\u5185\u5b58\u5728\u663e\u8457\u7684\u52a8\u6001\u5c5e\u6027\u626d\u66f2\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u8fd9\u4e9b\u52a8\u6001\u6307\u6807-based\u5ea6\u91cf\u63d0\u4f9b\u4e86\u4e92\u8865\u4fe1\u606f\uff0c\u53ef\u7528\u4e8e\u6539\u8fdbML\u6a21\u578b\u7684\u9884\u6d4b\u4fdd\u771f\u5ea6\u3002"}}
{"id": "2504.11089", "pdf": "https://arxiv.org/pdf/2504.11089", "abs": "https://arxiv.org/abs/2504.11089", "authors": ["Fuyin Lai", "Edith Heiter", "Guillaume Bied", "Jefrey Lijffijt"], "title": "InfoClus: Informative Clustering of High-dimensional Data Embeddings", "categories": ["cs.LG", "cs.CV"], "comment": "17 pages, 9 figures", "summary": "Developing an understanding of high-dimensional data can be facilitated by\nvisualizing that data using dimensionality reduction. However, the\nlow-dimensional embeddings are often difficult to interpret. To facilitate the\nexploration and interpretation of low-dimensional embeddings, we introduce a\nnew concept named partitioning with explanations. The idea is to partition the\ndata shown through the embedding into groups, each of which is given a sparse\nexplanation using the original high-dimensional attributes. We introduce an\nobjective function that quantifies how much we can learn through observing the\nexplanations of the data partitioning, using information theory, and also how\ncomplex the explanations are. Through parameterization of the complexity, we\ncan tune the solutions towards the desired granularity. We propose InfoClus,\nwhich optimizes the partitioning and explanations jointly, through greedy\nsearch constrained over a hierarchical clustering. We conduct a qualitative and\nquantitative analysis of InfoClus on three data sets. We contrast the results\non the Cytometry data with published manual analysis results, and compare with\ntwo other recent methods for explaining embeddings (RVX and VERA). These\ncomparisons highlight that InfoClus has distinct advantages over existing\nprocedures and methods. We find that InfoClus can automatically create good\nstarting points for the analysis of dimensionality-reduction-based scatter\nplots.", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u5f15\u5165InfoClus\u65b9\u6cd5\uff0c\u7528\u4e8e\u5bf9\u9ad8\u7ef4\u6570\u636e\u7684\u4f4e\u7ef4\u5d4c\u5165\u8fdb\u884c\u5206\u533a\u548c\u89e3\u91ca\uff0c\u4ee5\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u9ad8\u7ef4\u6570\u636e\u7684\u4f4e\u7ef4\u5d4c\u5165\u5f80\u5f80\u96be\u4ee5\u89e3\u91ca\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u5206\u533a\u548c\u89e3\u91ca\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u76ee\u6807\u51fd\u6570\uff0c\u901a\u8fc7InfoClus\u5728\u5c42\u6b21\u805a\u7c7b\u4e0a\u4f7f\u7528\u8d2a\u5a6a\u641c\u7d22\u8054\u5408\u4f18\u5316\u5206\u533a\u548c\u89e3\u91ca\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9a\u6027\u548c\u5b9a\u91cf\u5206\u6790\u663e\u793a\uff0cInfoClus\u4f18\u4e8eRVX\u548cVERA\u65b9\u6cd5\uff0c\u5e76\u80fd\u63d0\u4f9b\u826f\u597d\u7684\u5206\u6790\u8d77\u70b9\u3002", "conclusion": "InfoClus\u80fd\u6709\u6548\u4fc3\u8fdb\u5d4c\u5165\u7684\u53ef\u63a2\u7d22\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2504.10557", "pdf": "https://arxiv.org/pdf/2504.10557", "abs": "https://arxiv.org/abs/2504.10557", "authors": ["Serge Lionel Nikiema", "Jordan Samhi", "Abdoul Kader Kabor\u00e9", "Jacques Klein", "Tegawend\u00e9 F. Bissyand\u00e9"], "title": "The Code Barrier: What LLMs Actually Understand?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Understanding code represents a core ability needed for automating software\ndevelopment tasks. While foundation models like LLMs show impressive results\nacross many software engineering challenges, the extent of their true semantic\nunderstanding beyond simple token recognition remains unclear. This research\nuses code obfuscation as a structured testing framework to evaluate LLMs'\nsemantic understanding capabilities. We methodically apply controlled\nobfuscation changes to source code and measure comprehension through two\ncomplementary tasks: generating accurate descriptions of obfuscated code and\nperforming deobfuscation, a skill with important implications for reverse\nengineering applications.\n  Our testing approach includes 13 cutting-edge models, covering both\ncode-specialized (e.g., StarCoder2) and general-purpose (e.g., GPT-4o)\narchitectures, evaluated on a benchmark created from CodeNet and consisting of\nfiltered 250 Java programming problems and their solutions. Findings show a\nstatistically significant performance decline as obfuscation complexity\nincreases, with unexpected resilience shown by general-purpose models compared\nto their code-focused counterparts. While some models successfully identify\nobfuscation techniques, their ability to reconstruct the underlying program\nlogic remains constrained, suggesting limitations in their semantic\nrepresentation mechanisms. This research introduces a new evaluation approach\nfor assessing code comprehension in language models and establishes empirical\nbaselines for advancing research in security-critical code analysis\napplications such as reverse engineering and adversarial code analysis.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u4ee3\u7801\u6df7\u6dc6\u6d4b\u8bd5\u6846\u67b6\u8bc4\u4f30LLM\u7684\u4ee3\u7801\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u53d1\u73b0\u901a\u7528\u6a21\u578b\u6bd4\u4ee3\u7801\u4e13\u7528\u6a21\u578b\u66f4\u5177\u97e7\u6027\uff0c\u4f46\u6574\u4f53\u80fd\u529b\u6709\u9650\u3002", "motivation": "\u4e3a\u4e86\u8bc4\u4f30LLM\u662f\u5426\u5177\u6709\u771f\u6b63\u7684\u8bed\u4e49\u7406\u89e3\uff0c\u800c\u975e\u4ec5\u9650\u4e8e\u6807\u8bb0\u8bc6\u522b\u3002", "method": "\u901a\u8fc7\u5bf9\u6e90\u4ee3\u7801\u65bd\u52a0\u53d7\u63a7\u6df7\u6dc6\uff0c\u5e76\u901a\u8fc7\u63cf\u8ff0\u6df7\u6dc6\u4ee3\u7801\u548c\u53bb\u6df7\u6dc6\u4efb\u52a1\u8bc4\u4f3013\u4e2a\u6a21\u578b\uff08\u5305\u62ec\u4ee3\u7801\u4e13\u7528\u548c\u901a\u7528\u6a21\u578b\uff09\uff0c\u4f7f\u7528CodeNet\u57fa\u51c6\u7684250\u4e2aJava\u95ee\u9898\u3002", "result": "\u6df7\u6dc6\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff1b\u901a\u7528\u6a21\u578b\u663e\u793a\u610f\u5916\u97e7\u6027\uff1b\u6a21\u578b\u80fd\u8bc6\u522b\u6df7\u6dc6\u6280\u672f\uff0c\u4f46\u91cd\u5efa\u7a0b\u5e8f\u903b\u8f91\u80fd\u529b\u53d7\u9650\u3002", "conclusion": "\u5f15\u5165\u65b0\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e3a\u9006\u5411\u5de5\u7a0b\u548c\u5bf9\u6297\u4ee3\u7801\u5206\u6790\u7b49\u5b89\u5168\u5173\u952e\u5e94\u7528\u5efa\u7acb\u7ecf\u9a8c\u57fa\u51c6\u3002"}}
{"id": "2504.11118", "pdf": "https://arxiv.org/pdf/2504.11118", "abs": "https://arxiv.org/abs/2504.11118", "authors": ["Henrik Krauss", "Takehisa Yairi"], "title": "Revealing Covert Attention by Analyzing Human and Reinforcement Learning Agent Gameplay", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "This study introduces a novel method for revealing human covert attention\npatterns using gameplay data alone, utilizing offline attention techniques from\nreinforcement learning (RL). We propose the contextualized, task-relevant (CTR)\nattention network, which generates attention maps from both human and RL agent\ngameplay in Atari environments. These maps are sparse yet retain the necessary\ninformation for the current player's decision making. We compare the\nCTR-derived attention maps with a temporally integrated overt attention (TIOA)\nmodel based on eye-tracking data, serving as a point of comparison and\ndiscussion. Visual inspection reveals distinct attention patterns: human CTR\nmaps focus on the player and rather nearby opponents, occasionally shifting\nbetween stronger focus and broader views - sometimes even attending to empty\nspace ahead. In contrast, agent maps maintain a consistent broad focus on most\nobjects, including distant ones and the player. Quantitative analysis further\ndemonstrates that human CTR maps align more closely with TIOA than agent maps\ndo. Our findings indicate that the CTR attention network can effectively reveal\nhuman covert attention patterns from gameplay alone, without the need for\nadditional data like brain activity recordings. This work contributes to\nunderstanding human-agent attention differences and enables the development of\nRL agents augmented with human covert attention.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u4ec5\u7528\u6e38\u620f\u6570\u636e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u63ed\u793a\u4eba\u7c7b\u9690\u853d\u6ce8\u610f\u529b\u6a21\u5f0f\u3002", "motivation": "\u4e3a\u4e86\u4ec5\u7528\u6e38\u620f\u6570\u636e\u7406\u89e3\u4eba\u7c7b\u6ce8\u610f\u529b\u6a21\u5f0f\uff0c\u4e0e\u4ee3\u7406\u6ce8\u610f\u529b\u5dee\u5f02\uff0c\u5e76\u5f00\u53d1\u589e\u5f3a\u578b\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u3002", "method": "\u63d0\u51faCTR\u6ce8\u610f\u529b\u7f51\u7edc\uff0c\u4eceAtari\u6e38\u620f\u6570\u636e\u751f\u6210\u6ce8\u610f\u529b\u5730\u56fe\uff0c\u5e76\u4e0e\u57fa\u4e8e\u773c\u52a8\u8ffd\u8e2a\u7684TIOA\u6a21\u578b\u6bd4\u8f83\u3002", "result": "\u4eba\u7c7bCTR\u5730\u56fe\u5173\u6ce8\u9644\u8fd1\u5bf9\u8c61\uff0c\u4e0eTIOA\u66f4\u63a5\u8fd1\uff1b\u4ee3\u7406\u5730\u56fe\u5219\u5e7f\u6cdb\u800c\u4e00\u81f4\uff0c\u5b9a\u91cf\u5206\u6790\u8bc1\u5b9e\u5dee\u5f02\u3002", "conclusion": "CTR\u7f51\u7edc\u6709\u6548\u63ed\u793a\u4eba\u7c7b\u9690\u853d\u6ce8\u610f\u529b\uff0c\u65e0\u9700\u989d\u5916\u6570\u636e\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u4eba\u7c7b-\u4ee3\u7406\u6ce8\u610f\u529b\u5dee\u5f02\u548cRL\u4ee3\u7406\u5f00\u53d1\u3002"}}
{"id": "2504.11130", "pdf": "https://arxiv.org/pdf/2504.11130", "abs": "https://arxiv.org/abs/2504.11130", "authors": ["Zixiong Yu", "Songtao Tian", "Guhan Chen"], "title": "Divergence of Empirical Neural Tangent Kernel in Classification Problems", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "This paper demonstrates that in classification problems, fully connected\nneural networks (FCNs) and residual neural networks (ResNets) cannot be\napproximated by kernel logistic regression based on the Neural Tangent Kernel\n(NTK) under overtraining (i.e., when training time approaches infinity).\nSpecifically, when using the cross-entropy loss, regardless of how large the\nnetwork width is (as long as it is finite), the empirical NTK diverges from the\nNTK on the training samples as training time increases. To establish this\nresult, we first demonstrate the strictly positive definiteness of the NTKs for\nmulti-layer FCNs and ResNets. Then, we prove that during training, % with the\ncross-entropy loss, the neural network parameters diverge if the smallest\neigenvalue of the empirical NTK matrix (Gram matrix) with respect to training\nsamples is bounded below by a positive constant. This behavior contrasts\nsharply with the lazy training regime commonly observed in regression problems.\nConsequently, using a proof by contradiction, we show that the empirical NTK\ndoes not uniformly converge to the NTK across all times on the training samples\nas the network width increases. We validate our theoretical results through\nexperiments on both synthetic data and the MNIST classification task. This\nfinding implies that NTK theory is not applicable in this context, with\nsignificant theoretical implications for understanding neural networks in\nclassification problems.", "AI": {"tldr": "\u672c\u8bba\u6587\u8bc1\u660e\uff0cFCN\u548cResNet\u5728\u5206\u7c7b\u95ee\u9898\u4e2d\u4e0d\u80fd\u88ab\u57fa\u4e8eNTK\u7684\u6838\u903b\u8f91\u56de\u5f52\u8fd1\u4f3c\uff0c\u56e0\u4e3a\u7ecf\u9a8cNTK\u5728\u8fc7\u5ea6\u8bad\u7ec3\u65f6\u53d1\u6563\u3002", "motivation": "\u63a2\u8ba8\u795e\u7ecf\u7f51\u7edc\u5728\u5206\u7c7b\u95ee\u9898\u4e2d\u7684\u884c\u4e3a\uff0c\u5f3a\u8c03\u4e0e\u56de\u5f52\u95ee\u9898\u7684\u5dee\u5f02\uff0c\u63ed\u793aNTK\u7406\u8bba\u7684\u5c40\u9650\u6027\u3002", "method": "\u9996\u5148\u8bc1\u660eNTK\u7684\u4e25\u683c\u6b63\u5b9a\u6027\uff0c\u7136\u540e\u8bc1\u660e\u53c2\u6570\u53d1\u6563\uff0c\u5e76\u901a\u8fc7\u53cd\u8bc1\u6cd5\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u7ecf\u9a8cNTK\u4e0d\u6536\u655b\u3002", "result": "\u7ecf\u9a8cNTK\u5728\u8bad\u7ec3\u65f6\u53d1\u6563\uff0c\u4e0d\u5747\u5300\u6536\u655b\u4e8eNTK\uff1b\u901a\u8fc7\u5408\u6210\u6570\u636e\u548cMNIST\u5b9e\u9a8c\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "NTK\u7406\u8bba\u4e0d\u9002\u7528\u4e8e\u5206\u7c7b\u95ee\u9898\uff0c\u5bf9\u795e\u7ecf\u7f51\u7edc\u7406\u8bba\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2504.11195", "pdf": "https://arxiv.org/pdf/2504.11195", "abs": "https://arxiv.org/abs/2504.11195", "authors": ["Lijun Sheng", "Jian Liang", "Zilei Wang", "Ran He"], "title": "R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning", "categories": ["cs.LG", "cs.CR", "cs.CV"], "comment": "CVPR 2025", "summary": "Vision-language models (VLMs), such as CLIP, have gained significant\npopularity as foundation models, with numerous fine-tuning methods developed to\nenhance performance on downstream tasks. However, due to their inherent\nvulnerability and the common practice of selecting from a limited set of\nopen-source models, VLMs suffer from a higher risk of adversarial attacks than\ntraditional vision models. Existing defense techniques typically rely on\nadversarial fine-tuning during training, which requires labeled data and lacks\nof flexibility for downstream tasks. To address these limitations, we propose\nrobust test-time prompt tuning (R-TPT), which mitigates the impact of\nadversarial attacks during the inference stage. We first reformulate the\nclassic marginal entropy objective by eliminating the term that introduces\nconflicts under adversarial conditions, retaining only the pointwise entropy\nminimization. Furthermore, we introduce a plug-and-play reliability-based\nweighted ensembling strategy, which aggregates useful information from reliable\naugmented views to strengthen the defense. R-TPT enhances defense against\nadversarial attacks without requiring labeled training data while offering high\nflexibility for inference tasks. Extensive experiments on widely used\nbenchmarks with various attacks demonstrate the effectiveness of R-TPT. The\ncode is available in https://github.com/TomSheng21/R-TPT.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faR-TPT\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u9636\u6bb5\u9632\u5fa1\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u65e0\u9700\u6807\u8bb0\u6570\u636e\uff0c\u63d0\u4f9b\u7075\u6d3b\u6027\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6613\u53d7\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u4e14\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u4f9d\u8d56\u6807\u8bb0\u6570\u636e\u548c\u7f3a\u4e4f\u7075\u6d3b\u6027\u3002", "method": "\u91cd\u65b0\u5236\u5b9a\u8fb9\u9645\u71b5\u76ee\u6807\uff0c\u53ea\u4fdd\u7559\u70b9\u71b5\u6700\u5c0f\u5316\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u53ef\u9760\u6027\u7684\u52a0\u6743\u96c6\u6210\u7b56\u7565\u3002", "result": "\u5728\u5404\u79cd\u57fa\u51c6\u548c\u653b\u51fb\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660eR-TPT\u7684\u6709\u6548\u6027\u3002", "conclusion": "R-TPT\u589e\u5f3a\u9632\u5fa1\u80fd\u529b\uff0c\u65e0\u9700\u6807\u8bb0\u6570\u636e\uff0c\u5e76\u63d0\u4f9b\u9ad8\u7075\u6d3b\u6027\u3002"}}
{"id": "2504.10584", "pdf": "https://arxiv.org/pdf/2504.10584", "abs": "https://arxiv.org/abs/2504.10584", "authors": ["Roni H. Goldshmid", "John O. Dabiri", "John E. Sader"], "title": "Visual anemometry of natural vegetation from their leaf motion", "categories": ["physics.flu-dyn", "cs.AI", "cs.CV", "physics.ao-ph"], "comment": null, "summary": "High-resolution, near-ground wind-speed data are critical for improving the\naccuracy of weather predictions and climate models,$^{1-3}$ supporting wildfire\ncontrol efforts,$^{4-7}$ and ensuring the safe passage of airplanes during\ntakeoff and landing maneouvers.$^{8,9}$ Quantitative wind speed anemometry\ngenerally employs on-site instrumentation for accurate single-position data or\nsophisticated remote techniques such as Doppler radar for quantitative field\nmeasurements. It is widely recognized that the wind-induced motion of\nvegetation depends in a complex manner on their structure and mechanical\nproperties, obviating their use in quantitative anemometry.$^{10-14}$ We\nanalyze measurements on a host of different vegetation showing that leaf motion\ncan be decoupled from the leaf's branch and support structure, at\nlow-to-moderate wind speed, $U_{wind}$. This wind speed range is characterized\nby a leaf Reynolds number, enabling the development of a remote, quantitative\nanemometry method based on the formula,\n$U_{wind}\\approx740\\sqrt{{\\mu}U_{leaf}/{\\rho}D}$, that relies only on the leaf\nsize $D$, its measured fluctuating (RMS) speed $U_{leaf}$, the air viscosity\n$\\mu$, and its mass density $\\rho$. This formula is corroborated by a\nfirst-principles model and validated using a host of laboratory and field tests\non diverse vegetation types, ranging from oak, olive, and magnolia trees\nthrough to camphor and bullgrass. The findings of this study open the door to a\nnew paradigm in anemometry, using natural vegetation to enable remote and rapid\nquantitative field measurements at global locations with minimal cost.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u53f6\u7247\u8fd0\u52a8\u7684\u8fdc\u7a0b\u5b9a\u91cf\u98ce\u901f\u6d4b\u91cf\u65b9\u6cd5\uff0c\u4f7f\u7528\u516c\u5f0f\u5728\u591a\u79cd\u690d\u7269\u4e0a\u9a8c\u8bc1\u3002", "motivation": "\u9ad8\u5206\u8fa8\u7387\u98ce\u901f\u6570\u636e\u5bf9\u5929\u6c14\u9884\u6d4b\u3001\u91ce\u706b\u63a7\u5236\u548c\u98de\u673a\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u6210\u672c\u9ad8\u6216\u590d\u6742\uff0c\u7814\u7a76\u65e8\u5728\u5229\u7528\u81ea\u7136\u690d\u88ab\u53f6\u7247\u8fd0\u52a8\u5b9e\u73b0\u5ec9\u4ef7\u6d4b\u91cf\u3002", "method": "\u5206\u6790\u4e0d\u540c\u690d\u88ab\u7684\u6d4b\u91cf\u6570\u636e\uff0c\u5728\u4f4e\u5230\u4e2d\u7b49\u98ce\u901f\u4e0b\u89e3\u8026\u53f6\u7247\u8fd0\u52a8\uff0c\u5f00\u53d1\u516c\u5f0fU_wind\u2248740\u221a(\u03bcU_leaf/\u03c1D)\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5ba4\u548c\u73b0\u573a\u6d4b\u8bd5\u9a8c\u8bc1\u3002", "result": "\u516c\u5f0f\u88ab\u7b2c\u4e00\u6027\u539f\u7406\u6a21\u578b\u8bc1\u5b9e\uff0c\u5e76\u5728\u6a61\u6811\u3001\u6a44\u6984\u6811\u7b49\u5404\u79cd\u690d\u7269\u4e0a\u6709\u6548\u9a8c\u8bc1\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5f00\u8f9f\u4e86\u4f7f\u7528\u81ea\u7136\u690d\u88ab\u8fdb\u884c\u8fdc\u7a0b\u3001\u5feb\u901f\u3001\u5ec9\u4ef7\u98ce\u901f\u6d4b\u91cf\u7684\u5168\u65b0\u8303\u5f0f\u3002"}}
{"id": "2504.11197", "pdf": "https://arxiv.org/pdf/2504.11197", "abs": "https://arxiv.org/abs/2504.11197", "authors": ["Shangyu Liu", "Zhenzhe Zheng", "Xiaoyao Huang", "Fan Wu", "Jie Wu"], "title": "Efficient Distributed Retrieval-Augmented Generation for Enhancing Language Model Performance", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.IR"], "comment": null, "summary": "Small language models (SLMs) support efficient deployments on\nresource-constrained edge devices, but their limited capacity compromises\ninference performance. Retrieval-augmented generation (RAG) is a promising\nsolution to enhance model performance by integrating external databases,\nwithout requiring intensive on-device model retraining. However, large-scale\npublic databases and user-specific private contextual documents are typically\nlocated on the cloud and the device separately, while existing RAG\nimplementations are primarily centralized. To bridge this gap, we propose\nDRAGON, a distributed RAG framework to enhance on-device SLMs through both\ngeneral and personal knowledge without the risk of leaking document privacy.\nSpecifically, DRAGON decomposes multi-document RAG into multiple parallel token\ngeneration processes performed independently and locally on the cloud and the\ndevice, and employs a newly designed Speculative Aggregation, a dual-side\nspeculative algorithm to avoid frequent output synchronization between the\ncloud and device. A new scheduling algorithm is further introduced to identify\nthe optimal aggregation side based on real-time network conditions. Evaluations\non real-world hardware testbed demonstrate a significant performance\nimprovement of DRAGON-up to 1.9x greater gains over standalone SLM compared to\nthe centralized RAG, substantial reduction in per-token latency, and negligible\nTime to First Token (TTFT) overhead.", "AI": {"tldr": "DRAGON \u662f\u4e00\u4e2a\u5206\u5e03\u5f0f RAG \u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e0d\u6cc4\u9732\u9690\u79c1\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u90e8\u7f72\u9ad8\u6548\uff0c\u4f46\u6027\u80fd\u6709\u9650\uff1b\u73b0\u6709 RAG \u5b9e\u73b0\u96c6\u4e2d\u5f0f\uff0c\u65e0\u6cd5\u5904\u7406\u4e91\u7aef\u548c\u8bbe\u5907\u7aef\u6570\u636e\u5206\u79bb\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa DRAGON \u6846\u67b6\uff0c\u5c06 RAG \u5206\u89e3\u4e3a\u5e76\u884c token \u751f\u6210\uff0c\u4f7f\u7528\u53cc\u4fa7\u63a8\u6d4b\u805a\u5408\u7b97\u6cd5\u907f\u514d\u540c\u6b65\uff0c\u5e76\u5f15\u5165\u8c03\u5ea6\u7b97\u6cd5\u57fa\u4e8e\u7f51\u7edc\u6761\u4ef6\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe 1.9 \u500d\uff0c\u964d\u4f4e\u6bcf\u4e2a token \u5ef6\u8fdf\uff0cTTFT \u5f00\u9500\u53ef\u5ffd\u7565\u3002", "conclusion": "DRAGON \u6846\u67b6\u6709\u6548\u63d0\u5347 SLM \u6027\u80fd\uff0c\u540c\u65f6\u786e\u4fdd\u9690\u79c1\u548c\u6548\u7387\u3002"}}
{"id": "2504.11216", "pdf": "https://arxiv.org/pdf/2504.11216", "abs": "https://arxiv.org/abs/2504.11216", "authors": ["Gergely D. N\u00e9meth", "Eros Fan\u00ec", "Yeat Jeng Ng", "Barbara Caputo", "Miguel \u00c1ngel Lozano", "Nuria Oliver", "Novi Quadrianto"], "title": "Diversity-Driven Learning: Tackling Spurious Correlations and Data Heterogeneity in Federated Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated Learning (FL) enables decentralized training of machine learning\nmodels on distributed data while preserving privacy. However, in real-world FL\nsettings, client data is often non-identically distributed and imbalanced,\nresulting in statistical data heterogeneity which impacts the generalization\ncapabilities of the server's model across clients, slows convergence and\nreduces performance. In this paper, we address this challenge by first\nproposing a characterization of statistical data heterogeneity by means of 6\nmetrics of global and client attribute imbalance, class imbalance, and spurious\ncorrelations. Next, we create and share 7 computer vision datasets for binary\nand multiclass image classification tasks in Federated Learning that cover a\nbroad range of statistical data heterogeneity and hence simulate real-world\nsituations. Finally, we propose FedDiverse, a novel client selection algorithm\nin FL which is designed to manage and leverage data heterogeneity across\nclients by promoting collaboration between clients with complementary data\ndistributions. Experiments on the seven proposed FL datasets demonstrate\nFedDiverse's effectiveness in enhancing the performance and robustness of a\nvariety of FL methods while having low communication and computational\noverhead.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faFedDiverse\u7b97\u6cd5\u5904\u7406\u8054\u90a6\u5b66\u4e60\u4e2d\u6570\u636e\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u7aef\u6570\u636e\u975e\u72ec\u7acb\u540c\u5206\u5e03\u548c\u4e0d\u5e73\u8861\uff0c\u5bfc\u81f4\u6a21\u578b\u6cdb\u5316\u5dee\u3001\u6536\u655b\u6162\u548c\u6027\u80fd\u964d\u4f4e\u3002", "method": "\u63d0\u51fa6\u4e2a\u6570\u636e\u5f02\u8d28\u6027\u5ea6\u91cf\u6307\u6807\u3001\u521b\u5efa7\u4e2a\u8ba1\u7b97\u673a\u89c6\u89c9\u6570\u636e\u96c6\u3001\u5e76\u5f00\u53d1FedDiverse\u5ba2\u6237\u7aef\u9009\u62e9\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793aFedDiverse\u63d0\u5347\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u901a\u4fe1\u548c\u8ba1\u7b97\u5f00\u9500\u4f4e\u3002", "conclusion": "FedDiverse\u662f\u7ba1\u7406\u6570\u636e\u5f02\u8d28\u6027\u7684\u6709\u6548\u7b56\u7565\u3002"}}
{"id": "2504.10636", "pdf": "https://arxiv.org/pdf/2504.10636", "abs": "https://arxiv.org/abs/2504.10636", "authors": ["Tianshi Mu", "Pranjal Rawat", "John Rust", "Chengjun Zhang", "Qixuan Zhong"], "title": "Who is More Bayesian: Humans or ChatGPT?", "categories": ["econ.GN", "cs.AI", "q-fin.EC", "stat.ME"], "comment": "86 pages, 19 figures", "summary": "We compare the performance of human and artificially intelligent (AI)\ndecision makers in simple binary classification tasks where the optimal\ndecision rule is given by Bayes Rule. We reanalyze choices of human subjects\ngathered from laboratory experiments conducted by El-Gamal and Grether and Holt\nand Smith. We confirm that while overall, Bayes Rule represents the single best\nmodel for predicting human choices, subjects are heterogeneous and a\nsignificant share of them make suboptimal choices that reflect judgement biases\ndescribed by Kahneman and Tversky that include the ``representativeness\nheuristic'' (excessive weight on the evidence from the sample relative to the\nprior) and ``conservatism'' (excessive weight on the prior relative to the\nsample). We compare the performance of AI subjects gathered from recent\nversions of large language models (LLMs) including several versions of ChatGPT.\nThese general-purpose generative AI chatbots are not specifically trained to do\nwell in narrow decision making tasks, but are trained instead as ``language\npredictors'' using a large corpus of textual data from the web. We show that\nChatGPT is also subject to biases that result in suboptimal decisions. However\nwe document a rapid evolution in the performance of ChatGPT from sub-human\nperformance for early versions (ChatGPT 3.5) to superhuman and nearly perfect\nBayesian classifications in the latest versions (ChatGPT 4o).", "AI": {"tldr": "\u672c\u8bba\u6587\u6bd4\u8f83\u4eba\u7c7b\u548cAI\u5728\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4f7f\u7528Bayes\u89c4\u5219\u4f5c\u4e3a\u57fa\u51c6\u3002\u53d1\u73b0\u4eba\u7c7b\u548c\u65e9\u671fChatGPT\u5b58\u5728\u504f\u5dee\uff0c\u4f46\u6700\u65b0ChatGPT\u5df2\u8fbe\u5230\u8fd1\u4e4e\u5b8c\u7f8e\u6c34\u5e73\u3002", "motivation": "\u52a8\u673a\u662f\u8bc4\u4f30AI\u51b3\u7b56\u4e0e\u4eba\u7c7b\u51b3\u7b56\u7684\u5f02\u540c\uff0c\u7279\u522b\u662f\u8ba4\u77e5\u504f\u5dee\u548cAI\u6f14\u53d8\uff0c\u4ee5\u7406\u89e3AI\u5728\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u8fdb\u6b65\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u91cd\u65b0\u5206\u6790\u4eba\u7c7b\u5b9e\u9a8c\u6570\u636e\uff08\u6765\u81eaEl-Gamal\u548cGrether\u3001Holt\u548cSmith\u7684\u5b9e\u9a8c\u5ba4\u7814\u7a76\uff09\uff0c\u5e76\u6d4b\u8bd5\u4e0d\u540c\u7248\u672c\u7684ChatGPT\u6a21\u578b\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4eba\u7c7b\u51b3\u7b56\u5b58\u5728\u5f02\u8d28\u6027\u548c\u504f\u5dee\uff08\u5982\u4ee3\u8868\u6027\u542f\u53d1\u5f0f\u548c\u4fdd\u5b88\u4e3b\u4e49\uff09\uff1bChatGPT\u4e5f\u53d7\u504f\u5dee\u5f71\u54cd\uff0c\u4f46\u4eceChatGPT 3.5\u7684\u4e9a\u4eba\u7c7b\u6c34\u5e73\u6f14\u53d8\u4e3aChatGPT 4o\u7684\u8d85\u4eba\u7c7b\u8fd1\u4e4e\u5b8c\u7f8e\u8868\u73b0\u3002", "conclusion": "\u7ed3\u8bba\u662fAI\u6a21\u578b\u5982ChatGPT\u5728\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u5feb\u901f\u6f14\u53d8\uff0c\u8868\u660eAI\u6b63\u671d\u7740\u66f4\u4f18\u51b3\u7b56\u65b9\u5411\u53d1\u5c55\uff0c\u53ef\u80fd\u8d85\u8d8a\u4eba\u7c7b\u3002"}}
{"id": "2504.11229", "pdf": "https://arxiv.org/pdf/2504.11229", "abs": "https://arxiv.org/abs/2504.11229", "authors": ["Reece Adamson"], "title": "The Forward-Forward Algorithm: Characterizing Training Behavior", "categories": ["cs.LG"], "comment": null, "summary": "The Forward-Forward algorithm is an alternative learning method which\nconsists of two forward passes rather than a forward and backward pass employed\nby backpropagation. Forward-Forward networks employ layer local loss functions\nwhich are optimized based on the layer activation for each forward pass rather\nthan a single global objective function. This work explores the dynamics of\nmodel and layer accuracy changes in Forward-Forward networks as training\nprogresses in pursuit of a mechanistic understanding of their internal\nbehavior. Treatments to various system characteristics are applied to\ninvestigate changes in layer and overall model accuracy as training progresses,\nhow accuracy is impacted by layer depth, and how strongly individual layer\naccuracy is correlated with overall model accuracy. The empirical results\npresented suggest that layers deeper within Forward-Forward networks experience\na delay in accuracy improvement relative to shallower layers and that shallower\nlayer accuracy is strongly correlated with overall model accuracy.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86Forward-Forward\u7f51\u7edc\u7684\u8bad\u7ec3\u52a8\u6001\uff0c\u53d1\u73b0\u6d45\u5c42\u51c6\u786e\u7387\u63d0\u5347\u66f4\u5feb\uff0c\u5e76\u4e0e\u6574\u4f53\u6a21\u578b\u51c6\u786e\u7387\u9ad8\u5ea6\u76f8\u5173\u3002", "motivation": "\u4e3a\u4e86\u673a\u68b0\u6027\u5730\u7406\u89e3Forward-Forward\u7f51\u7edc\u7684\u5185\u90e8\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u5e94\u7528\u5404\u79cd\u7cfb\u7edf\u7279\u5f81\u5904\u7406\uff0c\u8c03\u67e5\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5c42\u548c\u6574\u4f53\u6a21\u578b\u51c6\u786e\u7387\u7684\u53d8\u5316\uff0c\u4ee5\u53ca\u51c6\u786e\u7387\u4e0e\u5c42\u6df1\u5ea6\u7684\u5173\u7cfb\u3002", "result": "\u7ecf\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7f51\u7edc\u4e2d\u66f4\u6df1\u7684\u5c42\u5728\u51c6\u786e\u7387\u63d0\u5347\u4e0a\u5b58\u5728\u5ef6\u8fdf\uff0c\u6d45\u5c42\u51c6\u786e\u7387\u4e0e\u6574\u4f53\u6a21\u578b\u51c6\u786e\u7387\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "\u6d45\u5c42\u51c6\u786e\u7387\u66f4\u65e9\u6539\u5584\u5e76\u5f3a\u70c8\u5f71\u54cd\u6574\u4f53\u6027\u80fd\uff0c\u6df1\u5c42\u6709\u5ef6\u8fdf\u3002"}}
{"id": "2504.10637", "pdf": "https://arxiv.org/pdf/2504.10637", "abs": "https://arxiv.org/abs/2504.10637", "authors": ["Afra Amini", "Tim Vieira", "Ryan Cotterell"], "title": "Better Estimation of the KL Divergence Between Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Estimating the Kullback--Leibler (KL) divergence between language models has\nmany applications, e.g., reinforcement learning from human feedback (RLHF),\ninterpretability, and knowledge distillation. However, computing the exact KL\ndivergence between two arbitrary language models is intractable. Thus,\npractitioners often resort to the use of sampling-based estimators. While it is\neasy to fashion a simple Monte Carlo (MC) estimator that provides an unbiased\nestimate of the KL divergence between language models, this estimator\nnotoriously suffers from high variance, and can even result in a negative\nestimate of the KL divergence, a non-negative quantity. In this paper, we\nintroduce a Rao--Blackwellized estimator that is also unbiased and provably has\nvariance less than or equal to that of the standard Monte Carlo estimator. In\nan empirical study on sentiment-controlled fine-tuning, we show that our\nestimator provides more stable KL estimates and reduces variance substantially\nin practice. Additionally, we derive an analogous Rao--Blackwellized estimator\nof the gradient of the KL divergence, which leads to more stable training and\nproduces models that more frequently appear on the Pareto frontier of reward\nvs. KL compared to the ones trained with the MC estimator of the gradient.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRao-Blackwellized\u4f30\u8ba1\u5668\u6765\u51cf\u5c11\u8bed\u8a00\u6a21\u578bKL\u6563\u5ea6\u4f30\u8ba1\u7684\u65b9\u5dee\uff0c\u63d0\u9ad8\u7a33\u5b9a\u6027\uff0c\u5e76\u5728\u7ecf\u9a8c\u7814\u7a76\u4e2d\u663e\u793a\u51fa\u4f18\u52bf\u3002", "motivation": "KL\u6563\u5ea6\u4f30\u8ba1\u5728RLHF\u3001\u89e3\u91ca\u6027\u548c\u77e5\u8bc6\u84b8\u998f\u7b49\u5e94\u7528\u4e2d\u91cd\u8981\uff0c\u4f46\u6807\u51c6Monte Carlo\u4f30\u8ba1\u5668\u65b9\u5dee\u9ad8\u4e14\u53ef\u80fd\u7ed9\u51fa\u8d1f\u503c\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u5f15\u5165\u65e0\u504f\u7684Rao-Blackwellized\u4f30\u8ba1\u5668\u53ca\u5176KL\u6563\u5ea6\u68af\u5ea6\u4f30\u8ba1\u5668\uff0c\u65b9\u5dee\u4e0d\u5927\u4e8eMonte Carlo\u4f30\u8ba1\u5668\u3002", "result": "\u7ecf\u9a8c\u7814\u7a76\u663e\u793a\uff0c\u65b9\u5dee\u663e\u8457\u964d\u4f4e\uff0c\u4f30\u8ba1\u66f4\u7a33\u5b9a\uff0c\u8bad\u7ec3\u66f4\u53ef\u9760\uff0c\u6a21\u578b\u66f4\u5e38\u4f4d\u4e8e\u5956\u52b1\u4e0eKL\u7684Pareto\u524d\u6cbf\u3002", "conclusion": "\u8be5\u4f30\u8ba1\u5668\u6709\u6548\u51cf\u5c11KL\u6563\u5ea6\u4f30\u8ba1\u7684\u65b9\u5dee\uff0c\u63d0\u9ad8\u4e86\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2504.11250", "pdf": "https://arxiv.org/pdf/2504.11250", "abs": "https://arxiv.org/abs/2504.11250", "authors": ["Jeroen Middelhuis", "Zaharah Bukhsh", "Ivo Adan", "Remco Dijkman"], "title": "A Rollout-Based Algorithm and Reward Function for Efficient Resource Allocation in Business Processes", "categories": ["cs.LG", "cs.AI"], "comment": "Pre-print submitted to the 23rd International Conference on Business\n  Process Management", "summary": "Resource allocation plays a critical role in minimizing cycle time and\nimproving the efficiency of business processes. Recently, Deep Reinforcement\nLearning (DRL) has emerged as a powerful tool to optimize resource allocation\npolicies in business processes. In the DRL framework, an agent learns a policy\nthrough interaction with the environment, guided solely by reward signals that\nindicate the quality of its decisions. However, existing algorithms are not\nsuitable for dynamic environments such as business processes. Furthermore,\nexisting DRL-based methods rely on engineered reward functions that approximate\nthe desired objective, but a misalignment between reward and objective can lead\nto undesired decisions or suboptimal policies. To address these issues, we\npropose a rollout-based DRL algorithm and a reward function to optimize the\nobjective directly. Our algorithm iteratively improves the policy by evaluating\nexecution trajectories following different actions. Our reward function\ndirectly decomposes the objective function of minimizing the mean cycle time.\nMaximizing our reward function guarantees that the objective function is\nminimized without requiring extensive reward engineering. The results show that\nour method consistently learns the optimal policy in all six evaluated business\nprocesses, outperforming the state-of-the-art algorithm that can only learn the\noptimal policy in two of the evaluated processes.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8erollout\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u548c\u5956\u52b1\u51fd\u6570\uff0c\u76f4\u63a5\u4f18\u5316\u4e1a\u52a1\u6d41\u7a0b\u8d44\u6e90\u5206\u914d\u4ee5\u6700\u5c0f\u5316\u5e73\u5747\u5468\u671f\u65f6\u95f4\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4e0d\u9002\u5408\u52a8\u6001\u4e1a\u52a1\u73af\u5883\uff0c\u4e14\u5956\u52b1\u51fd\u6570\u53ef\u80fd\u5bfc\u81f4\u6b21\u4f18\u7b56\u7565\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51farollout-based DRL\u7b97\u6cd5\u548c\u76f4\u63a5\u5206\u89e3\u76ee\u6807\u51fd\u6570\u7684\u5956\u52b1\u51fd\u6570\uff0c\u901a\u8fc7\u8fed\u4ee3\u8bc4\u4f30\u6267\u884c\u8f68\u8ff9\u6765\u6539\u8fdb\u7b56\u7565\u3002", "result": "\u5728\u6240\u6709\u516d\u4e2a\u8bc4\u4f30\u7684\u4e1a\u52a1\u6d41\u7a0b\u4e2d\u5b66\u4e60\u5230\u6700\u4f18\u7b56\u7565\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u7b97\u6cd5\uff0c\u540e\u8005\u4ec5\u5728\u4e24\u4e2a\u6d41\u7a0b\u4e2d\u6210\u529f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4fdd\u8bc1\u76ee\u6807\u51fd\u6570\u6700\u5c0f\u5316\uff0c\u65e0\u9700\u590d\u6742\u7684\u5956\u52b1\u5de5\u7a0b\u3002"}}
{"id": "2504.10646", "pdf": "https://arxiv.org/pdf/2504.10646", "abs": "https://arxiv.org/abs/2504.10646", "authors": ["Saif Punjwani", "Larry Heck"], "title": "Weight-of-Thought Reasoning: Exploring Neural Network Weights for Enhanced LLM Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable reasoning\ncapabilities when prompted with strategies such as Chain-of-Thought (CoT).\nHowever, these approaches focus on token-level output without considering\ninternal weight dynamics. We introduce Weight-of-Thought (WoT) reasoning, a\nnovel approach that examines neural network weights before inference to\nidentify reasoning pathways. Unlike existing methods, WoT explores the weight\nspace through graph-based message passing, multi-step reasoning processes, and\nattention mechanisms. Our implementation creates an interconnected graph of\nreasoning nodes. Experiments on diverse reasoning tasks (syllogistic,\nmathematical, algebraic, combinatorial, and geometric) demonstrate that WoT\nachieves superior performance compared to traditional methods, particularly for\ncomplex problems. This approach leads to both improved performance and greater\ninterpretability of the reasoning process, offering a promising direction for\nenhancing LLM reasoning capabilities.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faWeight-of-Thought (WoT)\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5982Chain-of-Thought\u5173\u6ce8\u8f93\u51fa\u5c42\u9762\uff0c\u5ffd\u7565\u5185\u90e8\u6743\u91cd\u52a8\u6001\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u6743\u91cd\u7a7a\u95f4\u6765\u6539\u8fdb\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5f15\u5165WoT\u63a8\u7406\uff0c\u5229\u7528\u56fe-based\u6d88\u606f\u4f20\u9012\u3001\u591a\u6b65\u63a8\u7406\u548c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6784\u5efa\u4e92\u8054\u7684\u63a8\u7406\u8282\u70b9\u56fe\u3002", "result": "\u5728\u903b\u8f91\u3001\u6570\u5b66\u3001\u4ee3\u6570\u3001\u7ec4\u5408\u548c\u51e0\u4f55\u4efb\u52a1\u7684\u5b9e\u9a8c\u4e2d\uff0cWoT\u663e\u793a\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u5c24\u5176\u5728\u590d\u6742\u95ee\u9898\u4e0a\uff0c\u5e76\u63d0\u9ad8\u4e86\u63a8\u7406\u8fc7\u7a0b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2504.11255", "pdf": "https://arxiv.org/pdf/2504.11255", "abs": "https://arxiv.org/abs/2504.11255", "authors": ["Mark Cheung", "Sridhar Venkatesan"], "title": "Reconstructing Fine-Grained Network Data using Autoencoder Architectures with Domain Knowledge Penalties", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "The ability to reconstruct fine-grained network session data, including\nindividual packets, from coarse-grained feature vectors is crucial for\nimproving network security models. However, the large-scale collection and\nstorage of raw network traffic pose significant challenges, particularly for\ncapturing rare cyberattack samples. These challenges hinder the ability to\nretain comprehensive datasets for model training and future threat detection.\nTo address this, we propose a machine learning approach guided by formal\nmethods to encode and reconstruct network data. Our method employs autoencoder\nmodels with domain-informed penalties to impute PCAP session headers from\nstructured feature representations. Experimental results demonstrate that\nincorporating domain knowledge through constraint-based loss terms\nsignificantly improves reconstruction accuracy, particularly for categorical\nfeatures with session-level encodings. By enabling efficient reconstruction of\ndetailed network sessions, our approach facilitates data-efficient model\ntraining while preserving privacy and storage efficiency.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u548c\u5f62\u5f0f\u65b9\u6cd5\u4ece\u7c97\u7c92\u5ea6\u7279\u5f81\u5411\u91cf\u91cd\u5efa\u7ec6\u7c92\u5ea6\u7f51\u7edc\u4f1a\u8bdd\u6570\u636e\uff0c\u4ee5\u63d0\u5347\u7f51\u7edc\u5b89\u5168\u6a21\u578b\uff0c\u540c\u65f6\u89e3\u51b3\u6570\u636e\u5b58\u50a8\u6311\u6218\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u5927\u89c4\u6a21\u6536\u96c6\u548c\u5b58\u50a8\u539f\u59cb\u7f51\u7edc\u6d41\u91cf\u5e26\u6765\u7684\u56f0\u96be\uff0c\u7279\u522b\u662f\u6355\u83b7\u7a00\u6709\u7f51\u7edc\u653b\u51fb\u6837\u672c\u7684\u6311\u6218\uff0c\u8fd9\u963b\u788d\u4e86\u5168\u9762\u6570\u636e\u96c6\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\u548c\u5a01\u80c1\u68c0\u6d4b\u3002", "method": "\u65b9\u6cd5\u662f\u91c7\u7528\u81ea\u7f16\u7801\u5668\u6a21\u578b\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u7684\u60e9\u7f5a\u9879\uff0c\u901a\u8fc7\u5f62\u5f0f\u65b9\u6cd5\u6307\u5bfc\uff0c\u4ece\u7ed3\u6784\u5316\u7279\u5f81\u8868\u793a\u4e2d\u63a8\u65adPCAP\u4f1a\u8bdd\u5934\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u901a\u8fc7\u7ea6\u675f-based\u635f\u5931\u9879\u878d\u5165\u9886\u57df\u77e5\u8bc6\u663e\u8457\u63d0\u9ad8\u4e86\u91cd\u5efa\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u7c7b\u522b\u7279\u5f81\u7684\u4f1a\u8bdd\u7ea7\u7f16\u7801\u4e0a\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8fd9\u79cd\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6548\u91cd\u5efa\uff0c\u4fc3\u8fdb\u6570\u636e\u9ad8\u6548\u8bad\u7ec3\uff0c\u5e76\u4fdd\u6301\u9690\u79c1\u548c\u5b58\u50a8\u6548\u7387\u3002"}}
{"id": "2504.10650", "pdf": "https://arxiv.org/pdf/2504.10650", "abs": "https://arxiv.org/abs/2504.10650", "authors": ["\u00c9va Sz\u00e9kely", "J\u016bra Miniota", "M\u00ed\u0161a", "Hejn\u00e1"], "title": "Will AI shape the way we speak? The emerging sociolinguistic influence of synthetic voices", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "eess.AS", "I.2.7; K.4.2; H.5.2"], "comment": "5 pages, 0 figures, International Workshop on Spoken Dialogue Systems\n  Technology (IWSDS) 2025", "summary": "The growing prevalence of conversational voice interfaces, powered by\ndevelopments in both speech and language technologies, raises important\nquestions about their influence on human communication. While written\ncommunication can signal identity through lexical and stylistic choices,\nvoice-based interactions inherently amplify socioindexical elements - such as\naccent, intonation, and speech style - which more prominently convey social\nidentity and group affiliation. There is evidence that even passive media such\nas television is likely to influence the audience's linguistic patterns. Unlike\npassive media, conversational AI is interactive, creating a more immersive and\nreciprocal dynamic that holds a greater potential to impact how individuals\nspeak in everyday interactions. Such heightened influence can be expected to\narise from phenomena such as acoustic-prosodic entrainment and linguistic\naccommodation, which occur naturally during interaction and enable users to\nadapt their speech patterns in response to the system. While this phenomenon is\nstill emerging, its potential societal impact could provide organisations,\nmovements, and brands with a subtle yet powerful avenue for shaping and\ncontrolling public perception and social identity. We argue that the\nsocioindexical influence of AI-generated speech warrants attention and should\nbecome a focus of interdisciplinary research, leveraging new and existing\nmethodologies and technologies to better understand its implications.", "AI": {"tldr": "\u8bed\u97f3AI\u7684\u4e92\u52a8\u7279\u6027\u53ef\u80fd\u663e\u8457\u5f71\u54cd\u4eba\u7c7b\u6c9f\u901a\u548c\u793e\u4f1a\u8eab\u4efd\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "motivation": "\u63a2\u8ba8\u8bed\u97f3\u63a5\u53e3\u5bf9\u793e\u4f1a\u8eab\u4efd\u548c\u8bed\u8a00\u6a21\u5f0f\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u4e92\u52a8\u573a\u666f\u4e0b\u3002", "method": "\u5efa\u8bae\u4f7f\u7528\u8de8\u5b66\u79d1\u65b9\u6cd5\u7814\u7a76\u8bed\u97f3\u9002\u5e94\u548c\u8bed\u8a00\u987a\u5e94\u73b0\u8c61\u3002", "result": "\u8bba\u8bc1\u4e86\u8bed\u97f3AI\u53ef\u80fd subtlely \u5851\u9020\u516c\u4f17\u611f\u77e5\u548c\u793e\u4f1a\u8eab\u4efd\u3002", "conclusion": "\u547c\u5401\u5c06AI\u8bed\u97f3\u7684\u793e\u4f1a\u6307\u6570\u5f71\u54cd\u4f5c\u4e3a\u7814\u7a76\u91cd\u70b9\u3002"}}
{"id": "2504.11264", "pdf": "https://arxiv.org/pdf/2504.11264", "abs": "https://arxiv.org/abs/2504.11264", "authors": ["Ruochi Zhang", "Qian Yang", "Xiaoyang Wang", "Haoran Wu", "Qiong Zhou", "Yu Wang", "Kewei Li", "Yueying Wang", "Yusi Fan", "Jiale Zhang", "Lan Huang", "Chang Liu", "Fengfeng Zhou"], "title": "DeepSelective: Feature Gating and Representation Matching for Interpretable Clinical Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapid accumulation of Electronic Health Records (EHRs) has transformed\nhealthcare by providing valuable data that enhance clinical predictions and\ndiagnoses. While conventional machine learning models have proven effective,\nthey often lack robust representation learning and depend heavily on\nexpert-crafted features. Although deep learning offers powerful solutions, it\nis often criticized for its lack of interpretability. To address these\nchallenges, we propose DeepSelective, a novel end to end deep learning\nframework for predicting patient prognosis using EHR data, with a strong\nemphasis on enhancing model interpretability. DeepSelective combines data\ncompression techniques with an innovative feature selection approach,\nintegrating custom-designed modules that work together to improve both accuracy\nand interpretability. Our experiments demonstrate that DeepSelective not only\nenhances predictive accuracy but also significantly improves interpretability,\nmaking it a valuable tool for clinical decision-making. The source code is\nfreely available at http://www.healthinformaticslab.org/supp/resources.php .", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faDeepSelective\u6846\u67b6\uff0c\u4f7f\u7528EHR\u6570\u636e\u9884\u6d4b\u60a3\u8005\u9884\u540e\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7f3a\u4e4f\u9c81\u68d2\u8868\u793a\u5b66\u4e60\u3001\u4f9d\u8d56\u4e13\u5bb6\u7279\u5f81\uff0c\u4ee5\u53ca\u6df1\u5ea6\u5b66\u4e60\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faDeepSelective\u6846\u67b6\uff0c\u7ed3\u5408\u6570\u636e\u538b\u7f29\u6280\u672f\u548c\u521b\u65b0\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u96c6\u6210\u81ea\u5b9a\u4e49\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8fd9\u662f\u4e00\u79cd\u6709\u4ef7\u503c\u7684\u4e34\u5e8a\u51b3\u7b56\u5de5\u5177\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u4ee3\u7801\u3002"}}
{"id": "2504.10655", "pdf": "https://arxiv.org/pdf/2504.10655", "abs": "https://arxiv.org/abs/2504.10655", "authors": ["Lingyu Kong", "Nima Shoghi", "Guoxiang Hu", "Pan Li", "Victor Fung"], "title": "MatterTune: An Integrated, User-Friendly Platform for Fine-Tuning Atomistic Foundation Models to Accelerate Materials Simulation and Discovery", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.LG"], "comment": null, "summary": "Geometric machine learning models such as graph neural networks have achieved\nremarkable success in recent years in chemical and materials science research\nfor applications such as high-throughput virtual screening and atomistic\nsimulations. The success of these models can be attributed to their ability to\neffectively learn latent representations of atomic structures directly from the\ntraining data. Conversely, this also results in high data requirements for\nthese models, hindering their application to problems which are data sparse\nwhich are common in this domain. To address this limitation, there is a growing\ndevelopment in the area of pre-trained machine learning models which have\nlearned general, fundamental, geometric relationships in atomistic data, and\nwhich can then be fine-tuned to much smaller application-specific datasets. In\nparticular, models which are pre-trained on diverse, large-scale atomistic\ndatasets have shown impressive generalizability and flexibility to downstream\napplications, and are increasingly referred to as atomistic foundation models.\nTo leverage the untapped potential of these foundation models, we introduce\nMatterTune, a modular and extensible framework that provides advanced\nfine-tuning capabilities and seamless integration of atomistic foundation\nmodels into downstream materials informatics and simulation workflows, thereby\nlowering the barriers to adoption and facilitating diverse applications in\nmaterials science. In its current state, MatterTune supports a number of\nstate-of-the-art foundation models such as ORB, MatterSim, JMP, and\nEquformerV2, and hosts a wide range of features including a modular and\nflexible design, distributed and customizable fine-tuning, broad support for\ndownstream informatics tasks, and more.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86MatterTune\u6846\u67b6\uff0c\u7528\u4e8e\u5fae\u8c03\u539f\u5b50\u57fa\u7840\u6a21\u578b\u4ee5\u63d0\u5347\u6750\u6599\u79d1\u5b66\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3\u51e0\u4f55\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6570\u636e\u9700\u6c42\u9ad8\u7684\u95ee\u9898\uff0c\u5e76\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u5904\u7406\u6570\u636e\u7a00\u758f\u573a\u666f\u3002", "method": "\u5f00\u53d1MatterTune\u6a21\u5757\u5316\u6846\u67b6\uff0c\u652f\u6301\u5fae\u8c03\u5982ORB\u3001MatterSim\u7b49\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u5206\u5e03\u5f0f\u7ec6\u8c03\u548c\u4efb\u52a1\u96c6\u6210\u529f\u80fd\u3002", "result": "MatterTune\u63d0\u5347\u4e86\u6a21\u578b\u6cdb\u5316\u6027\u548c\u6613\u7528\u6027\uff0c\u4fc3\u8fdb\u6750\u6599\u4fe1\u606f\u5b66\u548c\u6a21\u62df\u5e94\u7528\u3002", "conclusion": "MatterTune\u964d\u4f4e\u4e86\u539f\u5b50\u57fa\u7840\u6a21\u578b\u91c7\u7528\u95e8\u69db\uff0c\u63a8\u52a8\u6750\u6599\u79d1\u5b66\u591a\u6837\u5e94\u7528\u3002"}}
{"id": "2504.11284", "pdf": "https://arxiv.org/pdf/2504.11284", "abs": "https://arxiv.org/abs/2504.11284", "authors": ["Michal Lukasik", "Lin Chen", "Harikrishna Narasimhan", "Aditya Krishna Menon", "Wittawat Jitkrittum", "Felix X. Yu", "Sashank J. Reddi", "Gang Fu", "Mohammadhossein Bateni", "Sanjiv Kumar"], "title": "Bipartite Ranking From Multiple Labels: On Loss Versus Label Aggregation", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "comment": null, "summary": "Bipartite ranking is a fundamental supervised learning problem, with the goal\nof learning a ranking over instances with maximal area under the ROC curve\n(AUC) against a single binary target label. However, one may often observe\nmultiple binary target labels, e.g., from distinct human annotators. How can\none synthesize such labels into a single coherent ranking? In this work, we\nformally analyze two approaches to this problem -- loss aggregation and label\naggregation -- by characterizing their Bayes-optimal solutions. Based on this,\nwe show that while both methods can yield Pareto-optimal solutions, loss\naggregation can exhibit label dictatorship: one can inadvertently (and\nundesirably) favor one label over others. This suggests that label aggregation\ncan be preferable to loss aggregation, which we empirically verify.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5206\u6790\u4e86\u5728\u4e8c\u90e8\u6392\u540d\u95ee\u9898\u4e2d\uff0c\u9762\u5bf9\u591a\u4e2a\u4e8c\u5143\u76ee\u6807\u6807\u7b7e\u65f6\uff0c\u635f\u5931\u805a\u5408\u548c\u6807\u7b7e\u805a\u5408\u7684\u6bd4\u8f83\uff0c\u7ed3\u679c\u663e\u793a\u6807\u7b7e\u805a\u5408\u66f4\u53ef\u53d6\uff0c\u4ee5\u907f\u514d\u6807\u7b7e\u72ec\u88c1\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u4e8c\u90e8\u6392\u540d\u4e2d\u591a\u4e2a\u4e8c\u5143\u6807\u7b7e\uff08\u5982\u4e0d\u540c\u6807\u6ce8\u8005\uff09\u7684\u5408\u6210\u95ee\u9898\uff0c\u4ee5\u83b7\u5f97\u6700\u5927AUC\u7684\u6392\u540d\u3002", "method": "\u65b9\u6cd5\u662f\u901a\u8fc7\u8868\u5f81Bayes\u6700\u4f18\u89e3\u6765\u6b63\u5f0f\u5206\u6790\u635f\u5931\u805a\u5408\u548c\u6807\u7b7e\u805a\u5408\u4e24\u79cd\u65b9\u6cd5\u3002", "result": "\u7ed3\u679c\u8868\u660e\u4e24\u79cd\u65b9\u6cd5\u5747\u53ef\u4ea7\u751fPareto\u6700\u4f18\u89e3\uff0c\u4f46\u635f\u5931\u805a\u5408\u53ef\u80fd\u5bfc\u81f4\u6807\u7b7e\u72ec\u88c1\uff0c\u7ecf\u9a8c\u9a8c\u8bc1\u652f\u6301\u6807\u7b7e\u805a\u5408\u66f4\u4f18\u3002", "conclusion": "\u7ed3\u8bba\u662f\u6807\u7b7e\u805a\u5408\u6bd4\u635f\u5931\u805a\u5408\u66f4\u53ef\u53d6\uff0c\u4ee5\u9632\u6b62\u65e0\u610f\u4e2d\u504f\u597d\u67d0\u4e2a\u6807\u7b7e\u3002"}}
{"id": "2504.10660", "pdf": "https://arxiv.org/pdf/2504.10660", "abs": "https://arxiv.org/abs/2504.10660", "authors": ["Paul Rosu"], "title": "LITERA: An LLM Based Approach to Latin-to-English Translation", "categories": ["cs.CL", "cs.AI"], "comment": "NAACL Findings", "summary": "This paper introduces an LLM-based Latin-to-English translation platform\ndesigned to address the challenges of translating Latin texts. We named the\nmodel LITERA, which stands for Latin Interpretation and Translations into\nEnglish for Research Assistance. Through a multi-layered translation process\nutilizing a fine-tuned version of GPT-4o-mini and GPT-4o, LITERA offers an\nunprecedented level of accuracy, showcased by greatly improved BLEU scores,\nparticularly in classical Latin, along with improved BLEURT scores. The\ndevelopment of LITERA involved close collaboration with Duke University's\nClassical Studies Department, which was instrumental in creating a small,\nhigh-quality parallel Latin-English dataset. This paper details the\narchitecture, fine-tuning methodology, and prompting strategies used in LITERA,\nemphasizing its ability to produce literal translations.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86LITERA\uff0c\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u62c9\u4e01\u8bed\u5230\u82f1\u8bed\u7ffb\u8bd1\u5e73\u53f0\uff0c\u4f7f\u7528\u5fae\u8c03\u7684GPT-4o-mini\u548cGPT-4o\uff0c\u63d0\u9ad8\u4e86\u7ffb\u8bd1\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u62c9\u4e01\u8bed\u6587\u672c\u7ffb\u8bd1\u7684\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u4e0e\u675c\u514b\u5927\u5b66\u53e4\u5178\u7814\u7a76\u7cfb\u5408\u4f5c\uff0c\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u7ffb\u8bd1\u5de5\u5177\u4ee5\u8f85\u52a9\u7814\u7a76\u3002", "method": "\u91c7\u7528\u591a\u5c42\u7ffb\u8bd1\u8fc7\u7a0b\u3001\u5fae\u8c03GPT-4o-mini\u548cGPT-4o\u3001\u521b\u5efa\u5c0f\u578b\u9ad8\u8d28\u5e76\u884c\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u7279\u5b9a\u7684\u63d0\u793a\u7b56\u7565\u3002", "result": "\u663e\u8457\u63d0\u9ad8\u4e86BLEU\u5206\u6570\u548cBLEURT\u5206\u6570\uff0c\u5c24\u5176\u5728\u53e4\u5178\u62c9\u4e01\u8bed\u65b9\u9762\u7684\u51c6\u786e\u6027\u3002", "conclusion": "LITERA\u80fd\u591f\u63d0\u4f9b\u9ad8\u7cbe\u5ea6\u7684\u5b57\u9762\u7ffb\u8bd1\uff0c\u63d0\u5347\u4e86\u53e4\u5178\u7814\u7a76\u4e2d\u7684\u8f85\u52a9\u529f\u80fd\u3002"}}
{"id": "2504.11320", "pdf": "https://arxiv.org/pdf/2504.11320", "abs": "https://arxiv.org/abs/2504.11320", "authors": ["Ruicheng Ao", "Gan Luo", "David Simchi-Levi", "Xinshang Wang"], "title": "Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints", "categories": ["cs.LG", "cs.AI", "cs.DC", "math.OC", "stat.ML"], "comment": "42 pages, 18 figures", "summary": "Large Language Models (LLMs) are indispensable in today's applications, but\ntheir inference procedure -- generating responses by processing text in\nsegments and using a memory-heavy Key-Value (KV) cache -- demands significant\ncomputational resources, particularly under memory constraints. This paper\nformulates LLM inference optimization as a multi-stage online scheduling\nproblem where sequential prompt arrivals and KV cache growth render\nconventional scheduling ineffective. We develop a fluid dynamics approximation\nto provide a tractable benchmark that guides algorithm design. Building on\nthis, we propose the Waiting for Accumulated Inference Threshold (WAIT)\nalgorithm, which uses multiple thresholds to schedule incoming prompts\noptimally when output lengths are known, and extend it to Nested WAIT for cases\nwith unknown output lengths. Theoretical analysis shows that both algorithms\nachieve near-optimal performance against the fluid benchmark in heavy traffic\nconditions, balancing throughput, latency, and Time to First Token (TTFT).\nExperiments with the Llama-7B model on an A100 GPU using both synthetic and\nreal-world datasets demonstrate improved throughput and reduced latency\nrelative to established baselines like vLLM and Sarathi. This work bridges\noperations research and machine learning, offering a rigorous framework for the\nefficient deployment of LLMs under memory constraints.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faWAIT\u548cNested WAIT\u7b97\u6cd5\u4f18\u5316LLM\u63a8\u7406\u8c03\u5ea6\uff0c\u63d0\u9ad8\u5185\u5b58\u7ea6\u675f\u4e0b\u7684\u6548\u7387\u3002", "motivation": "LLM\u63a8\u7406\u56e0KV\u7f13\u5b58\u589e\u957f\u800c\u8d44\u6e90\u5bc6\u96c6\uff0c\u4f20\u7edf\u8c03\u5ea6\u65e0\u6548\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u5f62\u5f0f\u5316\u4e3a\u591a\u9636\u6bb5\u5728\u7ebf\u8c03\u5ea6\u95ee\u9898\uff0c\u4f7f\u7528\u6d41\u4f53\u52a8\u529b\u5b66\u8fd1\u4f3c\u57fa\u51c6\uff0c\u5f00\u53d1WAIT\u548cNested WAIT\u7b97\u6cd5\u3002", "result": "\u7b97\u6cd5\u8fd1\u4f3c\u6700\u4f18\uff0c\u5b9e\u9a8c\u663e\u793aLlama-7B\u6a21\u578b\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u6539\u5584\u3002", "conclusion": "\u6865\u63a5\u8fd0\u7b79\u5b66\u4e0e\u673a\u5668\u5b66\u4e60\uff0c\u63d0\u4f9b\u9ad8\u6548LLM\u90e8\u7f72\u6846\u67b6\u3002"}}
{"id": "2504.10663", "pdf": "https://arxiv.org/pdf/2504.10663", "abs": "https://arxiv.org/abs/2504.10663", "authors": ["Mykola Trokhymovych", "Oleksandr Kosovan", "Nathan Forrester", "Pablo Arag\u00f3n", "Diego Saez-Trumper", "Ricardo Baeza-Yates"], "title": "Characterizing Knowledge Manipulation in a Russian Wikipedia Fork", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Wikipedia is powered by MediaWiki, a free and open-source software that is\nalso the infrastructure for many other wiki-based online encyclopedias. These\ninclude the recently launched website Ruwiki, which has copied and modified the\noriginal Russian Wikipedia content to conform to Russian law. To identify\npractices and narratives that could be associated with different forms of\nknowledge manipulation, this article presents an in-depth analysis of this\nRussian Wikipedia fork. We propose a methodology to characterize the main\nchanges with respect to the original version. The foundation of this study is a\ncomprehensive comparative analysis of more than 1.9M articles from Russian\nWikipedia and its fork. Using meta-information and geographical, temporal,\ncategorical, and textual features, we explore the changes made by Ruwiki\neditors. Furthermore, we present a classification of the main topics of\nknowledge manipulation in this fork, including a numerical estimation of their\nscope. This research not only sheds light on significant changes within Ruwiki,\nbut also provides a methodology that could be applied to analyze other\nWikipedia forks and similar collaborative projects.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u6bd4\u8f83\u5206\u6790Ruwiki\uff08\u4fc4\u7f57\u65af\u7ef4\u57fa\u767e\u79d1\u7684\u5206\u652f\uff09\uff0c\u8bc6\u522b\u77e5\u8bc6\u64cd\u7eb5\u7684\u5b9e\u8df5\u548c\u53d9\u4e8b\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u53ef\u5e94\u7528\u4e8e\u5176\u4ed6\u7ef4\u57fa\u5206\u53c9\u7684\u5206\u6790\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u8bc6\u522b\u4e0e\u77e5\u8bc6\u64cd\u7eb5\u76f8\u5173\u7684\u5b9e\u8df5\u548c\u53d9\u4e8b\uff0c\u7279\u522b\u662f\u9488\u5bf9Ruwiki\u8fd9\u79cd\u4fee\u6539\u5185\u5bb9\u4ee5\u7b26\u5408\u4fc4\u7f57\u65af\u6cd5\u5f8b\u7684\u7ef4\u57fa\u767e\u79d1\u5206\u652f\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u8868\u5f81\u53d8\u5316\u7684\u65b9\u6cd5ology\uff1b\u5bf9\u8d85\u8fc7190\u4e07\u7bc7\u6587\u7ae0\u8fdb\u884c\u5168\u9762\u6bd4\u8f83\u5206\u6790\uff0c\u4f7f\u7528\u5143\u4fe1\u606f\u3001\u5730\u7406\u3001\u65f6\u95f4\u3001\u7c7b\u522b\u548c\u6587\u672c\u7279\u5f81\uff1b\u5bf9\u77e5\u8bc6\u64cd\u7eb5\u4e3b\u9898\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u63a2\u7d22Ruwiki\u7f16\u8f91\u6240\u505a\u7684\u53d8\u5316\uff1b\u5448\u73b0\u77e5\u8bc6\u64cd\u7eb5\u4e3b\u9898\u7684\u5206\u7c7b\u548c\u6570\u503c\u4f30\u8ba1\u3002", "conclusion": "\u63ed\u793aRuwiki\u4e2d\u7684\u91cd\u5927\u53d8\u5316\uff0c\u5e76\u63d0\u4f9b\u4e00\u79cd\u53ef\u5e94\u7528\u4e8e\u5206\u6790\u5176\u4ed6\u7ef4\u57fa\u767e\u79d1\u5206\u53c9\u548c\u7c7b\u4f3c\u534f\u4f5c\u9879\u76ee\u7684methodology\u3002"}}
{"id": "2504.11321", "pdf": "https://arxiv.org/pdf/2504.11321", "abs": "https://arxiv.org/abs/2504.11321", "authors": ["Pedro Henrique da Costa Avelar", "Min Wu", "Sophia Tsoka"], "title": "Subset-Contrastive Multi-Omics Network Embedding", "categories": ["cs.LG"], "comment": null, "summary": "Motivation: Network-based analyses of omics data are widely used, and while\nmany of these methods have been adapted to single-cell scenarios, they often\nremain memory- and space-intensive. As a result, they are better suited to\nbatch data or smaller datasets. Furthermore, the application of network-based\nmethods in multi-omics often relies on similarity-based networks, which lack\nstructurally-discrete topologies. This limitation may reduce the effectiveness\nof graph-based methods that were initially designed for topologies with better\ndefined structures. Results: We propose Subset-Contrastive multi-Omics Network\nEmbedding (SCONE), a method that employs contrastive learning techniques on\nlarge datasets through a scalable subgraph contrastive approach. By exploiting\nthe pairwise similarity basis of many network-based omics methods, we\ntransformed this characteristic into a strength, developing an approach that\naims to achieve scalable and effective analysis. Our method demonstrates\nsynergistic omics integration for cell type clustering in single-cell data.\nAdditionally, we evaluate its performance in a bulk multi-omics integration\nscenario, where SCONE performs comparable to the state-of-the-art despite\nutilising limited views of the original data. We anticipate that our findings\nwill motivate further research into the use of subset contrastive methods for\nomics data.", "AI": {"tldr": "SCONE \u662f\u4e00\u79cd\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u7684\u53ef\u6269\u5c55\u5b50\u56fe\u5bf9\u6bd4\u65b9\u6cd5\uff0c\u7528\u4e8eomics\u6570\u636e\u7f51\u7edc\u5d4c\u5165\uff0c\u5728\u5355\u7ec6\u80de\u548c\u6279\u91cf\u591a\u7ec4\u5b66\u6574\u5408\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u7f51\u7edc-based omics\u6570\u636e\u5206\u6790\u5728\u5355\u7ec6\u80de\u573a\u666f\u4e0b\u5185\u5b58\u5bc6\u96c6\uff0c\u4e14\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u7f51\u7edc\u7f3a\u4e4f\u79bb\u6563\u62d3\u6251\uff0c\u964d\u4f4e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faSCONE\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u6269\u5c55\u7684\u5b50\u56fe\u5bf9\u6bd4\u5b66\u4e60\u6280\u672f\uff0c\u5229\u7528\u7f51\u7edc\u76f8\u4f3c\u6027\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21omics\u6570\u636e\u7684\u53ef\u6269\u5c55\u5206\u6790\u3002", "result": "\u5728\u5355\u7ec6\u80de\u6570\u636e\u4e2d\u5c55\u793a\u534f\u540comics\u6574\u5408\u7528\u4e8e\u7ec6\u80de\u7c7b\u578b\u805a\u7c7b\uff0c\u5728\u6279\u91cf\u591a\u7ec4\u5b66\u6574\u5408\u4e2d\u6027\u80fd\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\uff0c\u5c3d\u7ba1\u4f7f\u7528\u6709\u9650\u7684\u6570\u636e\u89c6\u56fe\u3002", "conclusion": "\u9884\u671f\u8fd9\u5c06\u6fc0\u53d1\u5bf9\u5b50\u96c6\u5bf9\u6bd4\u65b9\u6cd5\u5728omics\u6570\u636e\u4e2d\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u3002"}}
{"id": "2504.11336", "pdf": "https://arxiv.org/pdf/2504.11336", "abs": "https://arxiv.org/abs/2504.11336", "authors": ["Abitha Thankaraj", "Yiding Jiang", "J. Zico Kolter", "Yonatan Bisk"], "title": "Looking beyond the next token", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The structure of causal language model training assumes that each token can\nbe accurately predicted from the previous context. This contrasts with humans'\nnatural writing and reasoning process, where goals are typically known before\nthe exact argument or phrasings. While this mismatch has been well studied in\nthe literature, the working assumption has been that architectural changes are\nneeded to address this mismatch. We argue that rearranging and processing the\ntraining data sequences can allow models to more accurately imitate the true\ndata-generating process, and does not require any other changes to the\narchitecture or training infrastructure. We demonstrate that this technique,\nTrelawney, and the inference algorithms derived from it allow us to improve\nperformance on several key benchmarks that span planning, algorithmic\nreasoning, and story generation tasks. Finally, our method naturally enables\nthe generation of long-term goals at no additional cost. We investigate how\nusing the model's goal-generation capability can further improve planning and\nreasoning. Additionally, we believe Trelawney could potentially open doors to\nnew capabilities beyond the current language modeling paradigm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTrelawney\u6280\u672f\uff0c\u901a\u8fc7\u91cd\u6392\u8bad\u7ec3\u6570\u636e\u5e8f\u5217\u6765\u6539\u5584\u56e0\u679c\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\uff0c\u4e0e\u4eba\u7c7b\u5199\u4f5c\u8fc7\u7a0b\u66f4\u5339\u914d\uff0c\u63d0\u5347\u89c4\u5212\u3001\u7b97\u6cd5\u63a8\u7406\u548c\u6545\u4e8b\u751f\u6210\u7b49\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u56e0\u679c\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u5047\u8bbe\u4e0e\u4eba\u7c7b\u5199\u4f5c\u8fc7\u7a0b\uff08\u76ee\u6807\u5148\u4e8e\u5185\u5bb9\uff09\u7684\u5931\u914d\u95ee\u9898\uff0c\u907f\u514d\u901a\u8fc7\u67b6\u6784\u4fee\u6539\u6765\u5904\u7406\u3002", "method": "Trelawney\u6280\u672f\uff0c\u91cd\u6392\u548c\u5904\u7406\u8bad\u7ec3\u6570\u636e\u5e8f\u5217\uff0c\u5e76\u5f00\u53d1\u76f8\u5e94\u7684\u63a8\u7406\u7b97\u6cd5\u3002", "result": "\u5728\u89c4\u5212\u3001\u7b97\u6cd5\u63a8\u7406\u548c\u6545\u4e8b\u751f\u6210\u57fa\u51c6\u4e0a\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u514d\u8d39\u542f\u7528\u957f\u671f\u76ee\u6807\u751f\u6210\uff0c\u8fdb\u4e00\u6b65\u6539\u5584\u89c4\u5212\u548c\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "Trelawney\u53ef\u80fd\u5f00\u542f\u8d85\u8d8a\u5f53\u524d\u8bed\u8a00\u5efa\u6a21\u8303\u5f0f\u7684\u5168\u65b0\u80fd\u529b\u3002"}}
{"id": "2504.10679", "pdf": "https://arxiv.org/pdf/2504.10679", "abs": "https://arxiv.org/abs/2504.10679", "authors": ["F. A. Rizvi", "T. Navojith", "A. M. N. H. Adhikari", "W. P. U. Senevirathna", "Dharshana Kasthurirathna", "Lakmini Abeywardhana"], "title": "Keyword Extraction, and Aspect Classification in Sinhala, English, and Code-Mixed Content", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "6 Pages, 2 figures, 7 Tables", "summary": "Brand reputation in the banking sector is maintained through insightful\nanalysis of customer opinion on code-mixed and multilingual content.\nConventional NLP models misclassify or ignore code-mixed text, when mix with\nlow resource languages such as Sinhala-English and fail to capture\ndomain-specific knowledge. This study introduces a hybrid NLP method to improve\nkeyword extraction, content filtering, and aspect-based classification of\nbanking content. Keyword extraction in English is performed with a hybrid\napproach comprising a fine-tuned SpaCy NER model, FinBERT-based KeyBERT\nembeddings, YAKE, and EmbedRank, which results in a combined accuracy of 91.2%.\nCode-mixed and Sinhala keywords are extracted using a fine-tuned XLM-RoBERTa\nmodel integrated with a domain-specific Sinhala financial vocabulary, and it\nresults in an accuracy of 87.4%. To ensure data quality, irrelevant comment\nfiltering was performed using several models, with the BERT-base-uncased model\nachieving 85.2% for English and XLM-RoBERTa 88.1% for Sinhala, which was better\nthan GPT-4o, SVM, and keyword-based filtering. Aspect classification followed\nthe same pattern, with the BERT-base-uncased model achieving 87.4% for English\nand XLM-RoBERTa 85.9% for Sinhala, both exceeding GPT-4 and keyword-based\napproaches. These findings confirm that fine-tuned transformer models\noutperform traditional methods in multilingual financial text analysis. The\npresent framework offers an accurate and scalable solution for brand reputation\nmonitoring in code-mixed and low-resource banking environments.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u6df7\u5408NLP\u65b9\u6cd5\u6765\u63d0\u5347\u94f6\u884c\u9886\u57df\u4ee3\u7801\u6df7\u5408\u5185\u5bb9\u7684\u5206\u6790\uff0c\u5305\u62ec\u5173\u952e\u8bcd\u63d0\u53d6\u3001\u5185\u5bb9\u8fc7\u6ee4\u548c\u57fa\u4e8e\u65b9\u9762\u7684\u5206\u7c7b\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u4f20\u7edfNLP\u6a21\u578b\u5728\u5904\u7406\u4ee3\u7801\u6df7\u5408\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982Sinhala-English\uff09\u65f6\u7684\u8bef\u5206\u7c7b\u548c\u5ffd\u7565\u95ee\u9898\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u6349\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u3002", "method": "\u65b9\u6cd5\u4f7f\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u82f1\u8bed\u5173\u952e\u8bcd\u63d0\u53d6\u7ed3\u5408\u5fae\u8c03SpaCy NER\u3001FinBERT-based KeyBERT\u3001YAKE\u548cEmbedRank\uff1b\u4ee3\u7801\u6df7\u5408\u548cSinhala\u5173\u952e\u8bcd\u63d0\u53d6\u4f7f\u7528\u5fae\u8c03XLM-RoBERTa\u6574\u5408\u7279\u5b9aSinhala\u91d1\u878d\u8bcd\u6c47\uff1b\u8fc7\u6ee4\u548c\u5206\u7c7b\u4f7f\u7528BERT-base-uncased\u548cXLM-RoBERTa\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u82f1\u8bed\u5173\u952e\u8bcd\u63d0\u53d6\u51c6\u786e\u738791.2%\uff0cSinhala\u51c6\u786e\u738787.4%\uff1b\u8fc7\u6ee4\u51c6\u786e\u7387\u82f1\u8bed85.2%\u3001Sinhala 88.1%\uff1b\u5206\u7c7b\u51c6\u786e\u7387\u82f1\u8bed87.4%\u3001Sinhala 85.9%\uff0c\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u8be5\u6846\u67b6\u4e3a\u4ee3\u7801\u6df7\u5408\u548c\u4f4e\u8d44\u6e90\u94f6\u884c\u73af\u5883\u63d0\u4f9b\u51c6\u786e\u3001\u53ef\u6269\u5c55\u7684\u54c1\u724c\u58f0\u8a89\u76d1\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.11343", "pdf": "https://arxiv.org/pdf/2504.11343", "abs": "https://arxiv.org/abs/2504.11343", "authors": ["Wei Xiong", "Jiarui Yao", "Yuhui Xu", "Bo Pang", "Lei Wang", "Doyen Sahoo", "Junnan Li", "Nan Jiang", "Tong Zhang", "Caiming Xiong", "Hanze Dong"], "title": "A Minimalist Approach to LLM Reasoning: from Rejection Sampling to Reinforce", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": "12 pages, 4 figures", "summary": "Reinforcement learning (RL) has become a prevailing approach for fine-tuning\nlarge language models (LLMs) on complex reasoning tasks. Among recent methods,\nGRPO stands out for its empirical success in training models such as\nDeepSeek-R1, yet the sources of its effectiveness remain poorly understood. In\nthis work, we revisit GRPO from a reinforce-like algorithm perspective and\nanalyze its core components. Surprisingly, we find that a simple rejection\nsampling baseline, RAFT, which trains only on positively rewarded samples,\nyields competitive performance than GRPO and PPO. Our ablation studies reveal\nthat GRPO's main advantage arises from discarding prompts with entirely\nincorrect responses, rather than from its reward normalization. Motivated by\nthis insight, we propose Reinforce-Rej, a minimal extension of policy gradient\nthat filters both entirely incorrect and entirely correct samples.\nReinforce-Rej improves KL efficiency and stability, serving as a lightweight\nyet effective alternative to more complex RL algorithms. We advocate RAFT as a\nrobust and interpretable baseline, and suggest that future advances should\nfocus on more principled designs for incorporating negative samples, rather\nthan relying on them indiscriminately. Our findings provide guidance for future\nwork in reward-based LLM post-training.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790GRPO\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0RAFT\u57fa\u7ebf\u6027\u80fd\u7ade\u4e89\u6027\u5f3a\uff0c\u63d0\u51faReinforce-Rej\u65b9\u6cd5\uff0c\u5e76\u5efa\u8bae\u672a\u6765\u5173\u6ce8\u8d1f\u6837\u672c\u5904\u7406\u3002", "motivation": "GRPO\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u6709\u6548\u6027\u6765\u6e90\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002", "method": "\u4ece\u5f3a\u5316\u5b66\u4e60\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6GRPO\uff0c\u6bd4\u8f83RAFT\u548cPPO\uff0c\u8fdb\u884c\u6d88\u878d\u5b9e\u9a8c\uff0c\u5e76\u63d0\u51faReinforce-Rej\u65b9\u6cd5\u3002", "result": "RAFT\u57fa\u7ebf\u4e0eGRPO\u548cPPO\u6027\u80fd\u76f8\u5f53\uff0cGRPO\u4f18\u52bf\u4e3b\u8981\u6765\u81ea\u4e22\u5f03\u5b8c\u5168\u9519\u8bef\u54cd\u5e94\uff0cReinforce-Rej\u63d0\u9ad8\u4e86KL\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u63a8\u8350RAFT\u4f5c\u4e3a\u7a33\u5065\u57fa\u7ebf\uff0c\u5efa\u8bae\u672a\u6765\u5de5\u4f5c\u5173\u6ce8\u66f4\u539f\u5219\u6027\u7684\u8d1f\u6837\u672c\u6574\u5408\u8bbe\u8ba1\u3002"}}
{"id": "2504.10685", "pdf": "https://arxiv.org/pdf/2504.10685", "abs": "https://arxiv.org/abs/2504.10685", "authors": ["Yuqian Fu", "Xingyu Qiu", "Bin Ren", "Yanwei Fu", "Radu Timofte", "Nicu Sebe", "Ming-Hsuan Yang", "Luc Van Gool", "Kaijin Zhang", "Qingpeng Nong", "Xiugang Dong", "Hong Gao", "Xiangsheng Zhou", "Jiancheng Pan", "Yanxing Liu", "Xiao He", "Jiahao Li", "Yuze Sun", "Xiaomeng Huang", "Zhenyu Zhang", "Ran Ma", "Yuhan Liu", "Zijian Zhuang", "Shuai Yi", "Yixiong Zou", "Lingyi Hong", "Mingxi Chen", "Runze Li", "Xingdong Sheng", "Wenqiang Zhang", "Weisen Chen", "Yongxin Yan", "Xinguo Chen", "Yuanjie Shao", "Zhengrong Zuo", "Nong Sang", "Hao Wu", "Haoran Sun", "Shuming Hu", "Yan Zhang", "Zhiguang Shi", "Yu Zhang", "Chao Chen", "Tao Wang", "Da Feng", "Linhai Zhuo", "Ziming Lin", "Yali Huang", "Jie Me", "Yiming Yang", "Mi Guo", "Mingyuan Jiu", "Mingliang Xu", "Maomao Xiong", "Qunshu Zhang", "Xinyu Cao", "Yuqing Yang", "Dianmo Sheng", "Xuanpu Zhao", "Zhiyu Li", "Xuyang Ding", "Wenqian Li"], "title": "NTIRE 2025 Challenge on Cross-Domain Few-Shot Object Detection: Methods and Results", "categories": ["cs.CV", "cs.AI"], "comment": "accepted by CVPRW 25 @ NTIRE", "summary": "Cross-Domain Few-Shot Object Detection (CD-FSOD) poses significant challenges\nto existing object detection and few-shot detection models when applied across\ndomains. In conjunction with NTIRE 2025, we organized the 1st CD-FSOD\nChallenge, aiming to advance the performance of current object detectors on\nentirely novel target domains with only limited labeled data. The challenge\nattracted 152 registered participants, received submissions from 42 teams, and\nconcluded with 13 teams making valid final submissions. Participants approached\nthe task from diverse perspectives, proposing novel models that achieved new\nstate-of-the-art (SOTA) results under both open-source and closed-source\nsettings. In this report, we present an overview of the 1st NTIRE 2025 CD-FSOD\nChallenge, highlighting the proposed solutions and summarizing the results\nsubmitted by the participants.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u6982\u8ff0\u4e86\u7b2c1\u5c4aNTIRE 2025\u8de8\u57df\u5c11\u6837\u672c\u7269\u4f53\u68c0\u6d4b\u6311\u6218\u8d5b\uff0c\u65e8\u5728\u63d0\u5347\u68c0\u6d4b\u5668\u5728\u65b0\u57df\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u603b\u7ed3\u4e86\u53c2\u4e0e\u8005\u7684\u6210\u679c\u3002", "motivation": "\u89e3\u51b3\u8de8\u57df\u5c11\u6837\u672c\u7269\u4f53\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u6311\u6218\u8d5b\u63a8\u8fdb\u68c0\u6d4b\u5668\u5728\u65b0\u57df\u6709\u9650\u6570\u636e\u4e0b\u7684\u6027\u80fd\u3002", "method": "\u7ec4\u7ec7\u6311\u6218\u8d5b\uff0c\u5438\u5f15\u53c2\u4e0e\u8005\u63d0\u51fa\u65b0\u6a21\u578b\uff0c\u5728\u5f00\u6e90\u548c\u95ed\u6e90\u8bbe\u7f6e\u4e0b\u4f18\u5316\u68c0\u6d4b\u65b9\u6cd5\u3002", "result": "152\u4eba\u6ce8\u518c\uff0c42\u4e2a\u56e2\u961f\u63d0\u4ea4\uff0c13\u4e2a\u56e2\u961f\u6709\u6548\u6700\u7ec8\u63d0\u4ea4\uff0c\u5e76\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c\u3002", "conclusion": "\u6311\u6218\u8d5b\u6210\u529f\u5c55\u793a\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5bf9\u53c2\u4e0e\u8005\u7ed3\u679c\u8fdb\u884c\u4e86\u603b\u7ed3\u3002"}}
{"id": "2504.11344", "pdf": "https://arxiv.org/pdf/2504.11344", "abs": "https://arxiv.org/abs/2504.11344", "authors": ["Yunyang Cao", "Juekai Lin", "Hongye Wang", "Wenhao Li", "Bo Jin"], "title": "Interpretable Hybrid-Rule Temporal Point Processes", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Temporal Point Processes (TPPs) are widely used for modeling event sequences\nin various medical domains, such as disease onset prediction, progression\nanalysis, and clinical decision support. Although TPPs effectively capture\ntemporal dynamics, their lack of interpretability remains a critical challenge.\nRecent advancements have introduced interpretable TPPs. However, these methods\nfail to incorporate numerical features, thereby limiting their ability to\ngenerate precise predictions. To address this issue, we propose Hybrid-Rule\nTemporal Point Processes (HRTPP), a novel framework that integrates temporal\nlogic rules with numerical features, improving both interpretability and\npredictive accuracy in event modeling. HRTPP comprises three key components:\nbasic intensity for intrinsic event likelihood, rule-based intensity for\nstructured temporal dependencies, and numerical feature intensity for dynamic\nprobability modulation. To effectively discover valid rules, we introduce a\ntwo-phase rule mining strategy with Bayesian optimization. To evaluate our\nmethod, we establish a multi-criteria assessment framework, incorporating rule\nvalidity, model fitting, and temporal predictive accuracy. Experimental results\non real-world medical datasets demonstrate that HRTPP outperforms\nstate-of-the-art interpretable TPPs in terms of predictive performance and\nclinical interpretability. In case studies, the rules extracted by HRTPP\nexplain the disease progression, offering valuable contributions to medical\ndiagnosis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHRTPP\u6846\u67b6\uff0c\u7ed3\u5408\u65f6\u95f4\u903b\u8f91\u89c4\u5219\u548c\u6570\u503c\u7279\u5f81\uff0c\u63d0\u9ad8Temporal Point Processes\u5728\u533b\u7597\u4e8b\u4ef6\u5efa\u6a21\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "Temporal Point Processes\u867d\u80fd\u6355\u83b7\u65f6\u95f4\u52a8\u6001\uff0c\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff1b\u73b0\u6709\u53ef\u89e3\u91ca\u65b9\u6cd5\u65e0\u6cd5\u6574\u5408\u6570\u503c\u7279\u5f81\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002", "method": "\u63d0\u51faHRTPP\u6846\u67b6\uff0c\u5305\u62ec\u57fa\u672c\u5f3a\u5ea6\u3001\u57fa\u4e8e\u89c4\u5219\u7684\u5f3a\u5ea6\u548c\u6570\u503c\u7279\u5f81\u5f3a\u5ea6\uff1b\u91c7\u7528\u4e24\u9636\u6bb5\u89c4\u5219\u6316\u6398\u7b56\u7565\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u3002", "result": "\u5728\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u4e0a\uff0cHRTPP\u5728\u9884\u6d4b\u6027\u80fd\u548c\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1b\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u63d0\u53d6\u89c4\u5219\u89e3\u91ca\u4e86\u75be\u75c5\u8fdb\u5c55\u3002", "conclusion": "HRTPP\u4e3a\u533b\u7597\u8bca\u65ad\u63d0\u4f9b\u5b9d\u8d35\u8d21\u732e\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2504.11345", "pdf": "https://arxiv.org/pdf/2504.11345", "abs": "https://arxiv.org/abs/2504.11345", "authors": ["Luis Miguel Pardo", "Daniel Sebasti\u00e1n"], "title": "Erzeugunsgrad, VC-Dimension and Neural Networks with rational activation function", "categories": ["cs.LG", "math.AG", "13F20, 14A10, 68T07"], "comment": "50 pages", "summary": "The notion of Erzeugungsgrad was introduced by Joos Heintz in 1983 to bound\nthe number of non-empty cells occurring after a process of quantifier\nelimination. We extend this notion and the combinatorial bounds of Theorem 2 in\nHeintz (1983) using the degree for constructible sets defined in\nPardo-Sebasti\\'an (2022). We show that the Erzeugungsgrad is the key ingredient\nto connect affine Intersection Theory over algebraically closed fields and the\nVC-Theory of Computational Learning Theory for families of classifiers given by\nparameterized families of constructible sets. In particular, we prove that the\nVC-dimension and the Krull dimension are linearly related up to logarithmic\nfactors based on Intersection Theory. Using this relation, we study the density\nof correct test sequences in evasive varieties. We apply these ideas to analyze\nparameterized families of neural networks with rational activation function.", "AI": {"tldr": "\u7b80\u800c\u8a00\u4e4b\uff0c\u672c\u6587\u6269\u5c55Erzeugungsgrad\u6982\u5ff5\uff0c\u8fde\u63a5\u4ee3\u6570\u5c01\u95ed\u57df\u7684\u4eff\u5c04\u4ea4\u96c6\u7406\u8bba\u4e0e\u8ba1\u7b97\u5b66\u4e60\u7406\u8bba\u7684VC\u7406\u8bba\uff0c\u8bc1\u660eVC\u7ef4\u6570\u548cKrull\u7ef4\u6570\u7ebf\u6027\u76f8\u5173\uff0c\u5e76\u5e94\u7528\u4e8e\u7406\u6027\u6fc0\u6d3b\u51fd\u6570\u7684\u795e\u7ecf\u7f51\u7edc\u3002", "motivation": "\u52a8\u673a\u662f\u6865\u63a5\u4ea4\u96c6\u7406\u8bba\u548cVC\u7406\u8bba\uff0c\u5206\u6790\u53c2\u6570\u5316\u6784\u9020\u96c6\u65cf\u7684\u590d\u6742\u6027\uff0c\u4ee5\u63d0\u5347\u673a\u5668\u5b66\u4e60\u4e2d\u5206\u7c7b\u5668\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u6269\u5c55Heintz (1983)\u7684\u6982\u5ff5\uff0c\u4f7f\u7528Pardo-Sebasti\u00e1n (2022)\u7684\u5ea6\u91cf\uff0c\u8bc1\u660e\u7ef4\u6570\u5173\u7cfb\uff0c\u5e76\u5e94\u7528\u4e8e\u9003\u907f\u54c1\u79cd\u548c\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u7ed3\u679c\u663e\u793aVC\u7ef4\u6570\u548cKrull\u7ef4\u6570\u7ebf\u6027\u76f8\u5173\uff08\u8003\u8651\u5bf9\u6570\u56e0\u5b50\uff09\uff0c\u5e76\u7814\u7a76\u4e86\u6b63\u786e\u6d4b\u8bd5\u5e8f\u5217\u7684\u5bc6\u5ea6\u3002", "conclusion": "\u7ed3\u8bba\u662f\u901a\u8fc7\u7406\u8bba\u8054\u7cfb\uff0c\u6539\u8fdb\u4e86\u5bf9\u53c2\u6570\u5316\u795e\u7ecf\u7f51\u7edc\u7684\u5206\u6790\u548c\u5e94\u7528\u3002"}}
{"id": "2504.11353", "pdf": "https://arxiv.org/pdf/2504.11353", "abs": "https://arxiv.org/abs/2504.11353", "authors": ["Jundi Huang", "Dawei Zhan"], "title": "An Adaptive Dropout Approach for High-Dimensional Bayesian Optimization", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Bayesian optimization (BO) is a widely used algorithm for solving expensive\nblack-box optimization problems. However, its performance decreases\nsignificantly on high-dimensional problems due to the inherent\nhigh-dimensionality of the acquisition function. In the proposed algorithm, we\nadaptively dropout the variables of the acquisition function along the\niterations. By gradually reducing the dimension of the acquisition function,\nthe proposed approach has less and less difficulty to optimize the acquisition\nfunction. Numerical experiments demonstrate that AdaDropout effectively tackle\nhigh-dimensional challenges and improve solution quality where standard\nBayesian optimization methods often struggle. Moreover, it achieves superior\nresults when compared with state-of-the-art high-dimensional Bayesian\noptimization approaches. This work provides a simple yet efficient solution for\nhigh-dimensional expensive optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAdaDropout\u7b97\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u4e22\u5f03\u83b7\u53d6\u51fd\u6570\u53d8\u91cf\u6765\u6539\u5584\u9ad8\u7ef4Bayesian\u4f18\u5316\u95ee\u9898\u3002", "motivation": "Bayesian\u4f18\u5316\u5728\u9ad8\u7ef4\u95ee\u9898\u4e0a\u6027\u80fd\u4e0b\u964d\uff0c\u7531\u4e8e\u83b7\u53d6\u51fd\u6570\u7684\u9ad8\u7ef4\u6027\u3002", "method": "\u81ea\u9002\u5e94\u5730\u6cbf\u8fed\u4ee3\u4e22\u5f03\u83b7\u53d6\u51fd\u6570\u53d8\u91cf\uff0c\u9010\u6b65\u51cf\u5c11\u7ef4\u5ea6\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u663e\u793aAdaDropout\u6709\u6548\u5904\u7406\u9ad8\u7ef4\u6311\u6218\uff0c\u63d0\u9ad8\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\uff0c\u5e76\u4f18\u4e8e\u6807\u51c6\u548c\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u9ad8\u7ef4\u6602\u8d35\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.10700", "pdf": "https://arxiv.org/pdf/2504.10700", "abs": "https://arxiv.org/abs/2504.10700", "authors": ["Jesun Firoz", "Franco Pellegrini", "Mario Geiger", "Darren Hsu", "Jenna A. Bilbrey", "Han-Yi Chou", "Maximilian Stadler", "Markus Hoehnerbach", "Tingyu Wang", "Dejun Lin", "Emine Kucukbenli", "Henry W. Sprueill", "Ilyes Batatia", "Sotiris S. Xantheas", "MalSoon Lee", "Chris Mundy", "Gabor Csanyi", "Justin S. Smith", "Ponnuswamy Sadayappan", "Sutanay Choudhury"], "title": "Optimizing Data Distribution and Kernel Performance for Efficient Training of Chemistry Foundation Models: A Case Study with MACE", "categories": ["cs.DC", "cs.AI"], "comment": "Accepted at The 34th ACM International Symposium on High-Performance\n  Parallel and Distributed Computing (HPDC 2025)", "summary": "Chemistry Foundation Models (CFMs) that leverage Graph Neural Networks (GNNs)\noperating on 3D molecular graph structures are becoming indispensable tools for\ncomputational chemists and materials scientists. These models facilitate the\nunderstanding of matter and the discovery of new molecules and materials. In\ncontrast to GNNs operating on a large homogeneous graphs, GNNs used by CFMs\nprocess a large number of geometric graphs of varying sizes, requiring\ndifferent optimization strategies than those developed for large homogeneous\nGNNs. This paper presents optimizations for two critical phases of CFM\ntraining: data distribution and model training, targeting MACE - a\nstate-of-the-art CFM. We address the challenge of load balancing in data\ndistribution by formulating it as a multi-objective bin packing problem. We\npropose an iterative algorithm that provides a highly effective, fast, and\npractical solution, ensuring efficient data distribution. For the training\nphase, we identify symmetric tensor contraction as the key computational kernel\nin MACE and optimize this kernel to improve the overall performance. Our\ncombined approach of balanced data distribution and kernel optimization\nsignificantly enhances the training process of MACE. Experimental results\ndemonstrate a substantial speedup, reducing per-epoch execution time for\ntraining from 12 to 2 minutes on 740 GPUs with a 2.6M sample dataset.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4f18\u5316\u4e86\u5316\u5b66\u57fa\u7840\u6a21\u578bMACE\u7684\u8bad\u7ec3\uff0c\u901a\u8fc7\u6570\u636e\u5206\u5e03\u8d1f\u8f7d\u5747\u8861\u548c\u5185\u6838\u4f18\u5316\uff0c\u5c06\u8bad\u7ec3\u65f6\u95f4\u4ece12\u5206\u949f\u7f29\u77ed\u52302\u5206\u949f\u3002", "motivation": "\u5316\u5b66\u57fa\u7840\u6a21\u578b\u4f7f\u7528GNN\u5904\u74063D\u5206\u5b50\u56fe\uff0c\u9700\u8981\u9488\u5bf9\u5904\u7406\u5927\u91cf\u5927\u5c0f\u4e0d\u4e00\u7684\u51e0\u4f55\u56fe\u7684\u7279\u6027\u8fdb\u884c\u4f18\u5316\uff0c\u4ee5\u63d0\u5347\u6548\u7387\u3002", "method": "\u5c06\u8d1f\u8f7d\u5747\u8861\u95ee\u9898\u8868\u8ff0\u4e3a\u591a\u76ee\u6807bin packing\u95ee\u9898\uff0c\u63d0\u51fa\u8fed\u4ee3\u7b97\u6cd5\u7528\u4e8e\u6570\u636e\u5206\u5e03\uff1b\u4f18\u5316MACE\u4e2d\u7684\u5bf9\u79f0\u5f20\u91cf\u6536\u7f29\u5185\u6838\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728740\u4e2aGPU\u548c2.6M\u6837\u672c\u6570\u636e\u96c6\u4e0a\uff0c\u8bad\u7ec3\u6bcf\u4e2aepoch\u7684\u65f6\u95f4\u4ece12\u5206\u949f\u51cf\u5c11\u52302\u5206\u949f\u3002", "conclusion": "\u7ed3\u5408\u5e73\u8861\u6570\u636e\u5206\u5e03\u548c\u5185\u6838\u4f18\u5316\u663e\u8457\u63d0\u5347\u4e86MACE\u7684\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2504.11364", "pdf": "https://arxiv.org/pdf/2504.11364", "abs": "https://arxiv.org/abs/2504.11364", "authors": ["Tianwei Ni", "Allen Nie", "Sapana Chaudhary", "Yao Liu", "Huzefa Rangwala", "Rasool Fakoor"], "title": "Teaching Large Language Models to Reason through Learning and Forgetting", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Leveraging inference-time search in large language models has proven\neffective in further enhancing a trained model's capability to solve complex\nmathematical and reasoning problems. However, this approach significantly\nincreases computational costs and inference time, as the model must generate\nand evaluate multiple candidate solutions to identify a viable reasoning path.\nTo address this, we propose an effective approach that integrates search\ncapabilities directly into the model by fine-tuning it using both successful\n(learning) and failed reasoning paths (forgetting) derived from diverse search\nmethods. While fine-tuning the model with these data might seem\nstraightforward, we identify a critical issue: the model's search capability\ntends to degrade rapidly if fine-tuning is performed naively. We show that this\ndegradation can be substantially mitigated by employing a smaller learning\nrate. Extensive experiments on the challenging Game-of-24 and Countdown\nmathematical reasoning benchmarks show that our approach not only outperforms\nboth standard fine-tuning and inference-time search baselines but also\nsignificantly reduces inference time by 180$\\times$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u6210\u529f\u548c\u5931\u8d25\u7684\u63a8\u7406\u8def\u5f84\u6574\u5408\u641c\u7d22\u80fd\u529b\uff0c\u5927\u5927\u51cf\u5c11\u4e86\u63a8\u7406\u65f6\u95f4\uff0c\u540c\u65f6\u6539\u8fdb\u4e86\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u63a8\u7406\u95ee\u9898\u65f6\uff0c\u63a8\u7406\u65f6\u641c\u7d22\u5e26\u6765\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u63a8\u7406\u65f6\u95f4\u3002", "method": "\u4f7f\u7528\u4ece\u5404\u79cd\u641c\u7d22\u65b9\u6cd5\u4e2d\u83b7\u5f97\u7684\u6210\u529f\u548c\u5931\u8d25\u63a8\u7406\u8def\u5f84\u6570\u636e\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u91c7\u7528\u8f83\u5c0f\u7684\u5b66\u4e60\u7387\u6765\u9632\u6b62\u641c\u7d22\u80fd\u529b\u7684\u9000\u5316\u3002", "result": "\u5728Game-of-24\u548cCountdown\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f18\u4e8e\u6807\u51c6\u5fae\u8c03\u548c\u63a8\u7406\u65f6\u641c\u7d22\u57fa\u7ebf\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u8fbe180\u500d\u7684\u63a8\u7406\u65f6\u95f4\u51cf\u5c11\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5730\u5c06\u641c\u7d22\u80fd\u529b\u6574\u5408\u5230\u6a21\u578b\u4e2d\uff0c\u589e\u5f3a\u4e86\u63a8\u7406\u4efb\u52a1\u7684\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2504.11383", "pdf": "https://arxiv.org/pdf/2504.11383", "abs": "https://arxiv.org/abs/2504.11383", "authors": ["Wei Wanga", "Maryam Hakimzadeh", "Haihui Ruan", "Somdatta Goswami"], "title": "Accelerating Multiscale Modeling with Hybrid Solvers: Coupling FEM and Neural Operators with Domain Decomposition", "categories": ["cs.LG"], "comment": null, "summary": "Numerical solvers for partial differential equations (PDEs) face challenges\nbalancing computational cost and accuracy, especially in multiscale and dynamic\nsystems. Neural operators can significantly speed up simulations; however, they\noften face challenges such as error accumulation and limited generalization in\nmultiphysics problems. This work introduces a novel hybrid framework that\nintegrates physics-informed DeepONet with FEM through domain decomposition. The\ncore innovation lies in adaptively coupling FEM and DeepONet subdomains via a\nSchwarz alternating method. This methodology strategically allocates\ncomputationally demanding regions to a pre-trained Deep Operator Network, while\nthe remaining computational domain is solved through FEM. To address dynamic\nsystems, we integrate the Newmark time-stepping scheme directly into the\nDeepONet, significantly mitigating error accumulation in long-term simulations.\nFurthermore, an adaptive subdomain evolution enables the ML-resolved region to\nexpand dynamically, capturing emerging fine-scale features without remeshing.\nThe framework's efficacy has been validated across a range of solid mechanics\nproblems, including static, quasi-static, and dynamic regimes, demonstrating\naccelerated convergence rates (up to 20% improvement compared to FE-FE\napproaches), while preserving solution fidelity with error < 1%. Our case\nstudies show that our proposed hybrid solver: (1) maintains solution continuity\nacross subdomain interfaces, (2) reduces computational costs by eliminating\nfine mesh requirements, (3) mitigates error accumulation in time-dependent\nsimulations, and (4) enables automatic adaptation to evolving physical\nphenomena. This work bridges the gap between numerical methods and AI-driven\nsurrogates, offering a scalable pathway for high-fidelity simulations in\nengineering and scientific applications.", "AI": {"tldr": "\u672c\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u6df7\u5408\u6846\u67b6\uff0c\u5c06DeepONet\u4e0e\u6709\u9650\u5143\u65b9\u6cd5\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u9ad8\u6548\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u3002", "motivation": "\u504f\u5fae\u5206\u65b9\u7a0b\u6570\u503c\u6c42\u89e3\u5668\u5728\u8ba1\u7b97\u6210\u672c\u4e0e\u51c6\u786e\u6027\u95f4\u96be\u4ee5\u5e73\u8861\uff0c\u5c24\u5176\u5728\u591a\u5c3a\u5ea6\u52a8\u6001\u7cfb\u7edf\u4e2d\uff1b\u795e\u7ecf\u7b97\u5b50\u867d\u53ef\u52a0\u901f\u6a21\u62df\uff0c\u4f46\u5b58\u5728\u9519\u8bef\u79ef\u7d2f\u548c\u6cdb\u5316\u6027\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u5f15\u5165\u7269\u7406\u4fe1\u606fDeepONet\u4e0e\u6709\u9650\u5143\u65b9\u6cd5\u6df7\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u57df\u5206\u89e3\u548cSchwarz\u4ea4\u66ff\u65b9\u6cd5\u81ea\u9002\u5e94\u8026\u5408\uff0c\u5c06Newmark\u65f6\u95f4\u6b65\u8fdb\u65b9\u6848\u96c6\u6210\u5230DeepONet\uff0c\u5e76\u5b9e\u73b0\u81ea\u9002\u5e94\u5b50\u57df\u6f14\u5316\u3002", "result": "\u5728\u56fa\u4f53\u529b\u5b66\u95ee\u9898\u4e2d\u9a8c\u8bc1\uff0c\u6536\u655b\u7387\u63d0\u9ad820%\u3001\u9519\u8bef\u5c0f\u4e8e1%\uff0c\u4fdd\u6301\u89e3\u8fde\u7eed\u6027\u3001\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3001\u7f13\u89e3\u9519\u8bef\u79ef\u7d2f\uff0c\u5e76\u81ea\u52a8\u9002\u5e94\u6f14\u5316\u73b0\u8c61\u3002", "conclusion": "\u6865\u63a5\u6570\u503c\u65b9\u6cd5\u4e0eAI\u9a71\u52a8\u4ee3\u7406\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u9ad8\u4fdd\u771f\u6a21\u62df\u8def\u5f84\uff0c\u7528\u4e8e\u5de5\u7a0b\u548c\u79d1\u5b66\u5e94\u7528\u3002"}}
{"id": "2504.10738", "pdf": "https://arxiv.org/pdf/2504.10738", "abs": "https://arxiv.org/abs/2504.10738", "authors": ["Ankit Kumar Shaw", "Kun Jiang", "Tuopu Wen", "Chandan Kumar Sah", "Yining Shi", "Mengmeng Yang", "Diange Yang", "Xiaoli Lian"], "title": "CleanMAP: Distilling Multimodal LLMs for Confidence-Driven Crowdsourced HD Map Updates", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.RO", "I.2.9; I.2.7; I.2.10; I.5.5; I.5.4; I.2.11"], "comment": "Kun Jiang, Mengmeng Yang and Diange Yang are Corresponding Author.\n  The main paper and supplementary material are both included here, total 23\n  pages (main paper is 10 pages and supplementary material is 13 pages), total\n  17 figures (6 figures in main paper and 11 figures in supplementary\n  material), this paper is Accepted to CVPR WDFM-AD Workshop 2025, The code\n  will be available at https://Ankit-Zefan.github.io/CleanMap/", "summary": "The rapid growth of intelligent connected vehicles (ICVs) and integrated\nvehicle-road-cloud systems has increased the demand for accurate, real-time HD\nmap updates. However, ensuring map reliability remains challenging due to\ninconsistencies in crowdsourced data, which suffer from motion blur, lighting\nvariations, adverse weather, and lane marking degradation. This paper\nintroduces CleanMAP, a Multimodal Large Language Model (MLLM)-based\ndistillation framework designed to filter and refine crowdsourced data for\nhigh-confidence HD map updates. CleanMAP leverages an MLLM-driven lane\nvisibility scoring model that systematically quantifies key visual parameters,\nassigning confidence scores (0-10) based on their impact on lane detection. A\nnovel dynamic piecewise confidence-scoring function adapts scores based on lane\nvisibility, ensuring strong alignment with human evaluations while effectively\nfiltering unreliable data. To further optimize map accuracy, a\nconfidence-driven local map fusion strategy ranks and selects the top-k\nhighest-scoring local maps within an optimal confidence range (best score minus\n10%), striking a balance between data quality and quantity. Experimental\nevaluations on a real-world autonomous vehicle dataset validate CleanMAP's\neffectiveness, demonstrating that fusing the top three local maps achieves the\nlowest mean map update error of 0.28m, outperforming the baseline (0.37m) and\nmeeting stringent accuracy thresholds (<= 0.32m). Further validation with\nreal-vehicle data confirms 84.88% alignment with human evaluators, reinforcing\nthe model's robustness and reliability. This work establishes CleanMAP as a\nscalable and deployable solution for crowdsourced HD map updates, ensuring more\nprecise and reliable autonomous navigation. The code will be available at\nhttps://Ankit-Zefan.github.io/CleanMap/", "AI": {"tldr": "CleanMAP \u662f\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8fc7\u6ee4\u4f17\u5305\u6570\u636e\u4ee5\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u9ad8\u6e05\u5730\u56fe\u66f4\u65b0\u3002", "motivation": "\u667a\u80fd\u7f51\u8054\u6c7d\u8f66\u548c\u8f66\u8f86-\u9053\u8def-\u4e91\u7cfb\u7edf\u5feb\u901f\u53d1\u5c55\uff0c\u5bf9\u5b9e\u65f6\u9ad8\u6e05\u5730\u56fe\u66f4\u65b0\u9700\u6c42\u589e\u52a0\uff0c\u4f46\u4f17\u5305\u6570\u636e\u56e0\u8fd0\u52a8\u6a21\u7cca\u3001\u5149\u7167\u53d8\u5316\u3001\u6076\u52a3\u5929\u6c14\u548c\u8f66\u9053\u6807\u8bb0\u9000\u5316\u7b49\u56e0\u7d20\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\u3002", "method": "CleanMAP \u5229\u7528 MLLM \u9a71\u52a8\u7684\u8f66\u9053\u53ef\u89c1\u6027\u8bc4\u5206\u6a21\u578b\u91cf\u5316\u89c6\u89c9\u53c2\u6570\u5e76\u5206\u914d\u7f6e\u4fe1\u5ea6\u5206\u6570\uff080-10\uff09\uff0c\u7ed3\u5408\u52a8\u6001\u5206\u6bb5\u7f6e\u4fe1\u5ea6\u51fd\u6570\u548c\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u5c40\u90e8\u5730\u56fe\u878d\u5408\u7b56\u7565\u4f18\u5316\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u878d\u5408\u524d\u4e09\u5f20\u5c40\u90e8\u5730\u56fe\u7684\u5e73\u5747\u66f4\u65b0\u9519\u8bef\u4e3a 0.28m\uff0c\u6bd4\u57fa\u7ebf\uff080.37m\uff09\u4f4e\uff0c\u5e76\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u4e00\u81f4\u6027\u8fbe 84.88%\u3002", "conclusion": "CleanMAP \u88ab\u786e\u7acb\u4e3a\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u786e\u4fdd\u81ea\u52a8\u5bfc\u822a\u66f4\u7cbe\u786e\u548c\u53ef\u9760\u3002"}}
{"id": "2504.11386", "pdf": "https://arxiv.org/pdf/2504.11386", "abs": "https://arxiv.org/abs/2504.11386", "authors": ["Jiafeng Xiong", "Rizos Sakellariou"], "title": "Trajectory Encoding Temporal Graph Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Temporal Graph Networks (TGNs) have demonstrated significant success in\ndynamic graph tasks such as link prediction and node classification. Both tasks\ncomprise transductive settings, where the model predicts links among known\nnodes, and in inductive settings, where it generalises learned patterns to\npreviously unseen nodes. Existing TGN designs face a dilemma under these dual\nscenarios. Anonymous TGNs, which rely solely on temporal and structural\ninformation, offer strong inductive generalisation but struggle to distinguish\nknown nodes. In contrast, non-anonymous TGNs leverage node features to excel in\ntransductive tasks yet fail to adapt to new nodes. To address this challenge,\nwe propose Trajectory Encoding TGN (TETGN). Our approach introduces\nautomatically expandable node identifiers (IDs) as learnable temporal\npositional features and performs message passing over these IDs to capture each\nnode's historical context. By integrating this trajectory-aware module with a\nstandard TGN using multi-head attention, TETGN effectively balances\ntransductive accuracy with inductive generalisation. Experimental results on\nthree real-world datasets show that TETGN significantly outperforms strong\nbaselines on both link prediction and node classification tasks, demonstrating\nits ability to unify the advantages of anonymous and non-anonymous models for\ndynamic graph learning.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faTrajectory Encoding TGN (TETGN)\uff0c\u901a\u8fc7\u5f15\u5165\u53ef\u6269\u5c55\u8282\u70b9\u6807\u8bc6\u7b26\u548c\u6d88\u606f\u4f20\u9012\u673a\u5236\uff0c\u5e73\u8861\u52a8\u6001\u56fe\u4efb\u52a1\u4e2d\u7684\u4f20\u9012\u5f0f\u548c\u5f52\u7eb3\u5f0f\u6027\u80fd\u3002", "motivation": "\u73b0\u6709Temporal Graph Networks (TGNs) \u5728\u4f20\u9012\u5f0f\u548c\u5f52\u7eb3\u5f0f\u573a\u666f\u4e0b\u5b58\u5728\u56f0\u5883\uff1a\u533f\u540d\u6a21\u578b\u5f52\u7eb3\u80fd\u529b\u5f3a\u4f46\u65e0\u6cd5\u533a\u5206\u5df2\u77e5\u8282\u70b9\uff0c\u975e\u533f\u540d\u6a21\u578b\u5728\u4f20\u9012\u5f0f\u4efb\u52a1\u4e2d\u51fa\u8272\u4f46\u65e0\u6cd5\u9002\u5e94\u65b0\u8282\u70b9\u3002", "method": "\u63d0\u51faTETGN\uff0c\u4f7f\u7528\u81ea\u52a8\u53ef\u6269\u5c55\u7684\u8282\u70b9\u6807\u8bc6\u7b26\u4f5c\u4e3a\u53ef\u5b66\u4e60\u7684temporal positional features\uff0c\u5e76\u901a\u8fc7\u8fd9\u4e9b\u6807\u8bc6\u7b26\u8fdb\u884c\u6d88\u606f\u4f20\u9012\uff0c\u4e0e\u6807\u51c6TGN\u7ed3\u5408\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cTETGN \u5728\u94fe\u63a5\u9884\u6d4b\u548c\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "TETGN \u6210\u529f\u7edf\u4e00\u533f\u540d\u548c\u975e\u533f\u540d\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u63d0\u5347\u4e86\u52a8\u6001\u56fe\u5b66\u4e60\u7684\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2504.10746", "pdf": "https://arxiv.org/pdf/2504.10746", "abs": "https://arxiv.org/abs/2504.10746", "authors": ["Xiulong Liu", "Anurag Kumar", "Paul Calamia", "Sebastia V. Amengual", "Calvin Murdock", "Ishwarya Ananthabhotla", "Philip Robinson", "Eli Shlizerman", "Vamsi Krishna Ithapu", "Ruohan Gao"], "title": "Hearing Anywhere in Any Environment", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "comment": "CVPR 2025", "summary": "In mixed reality applications, a realistic acoustic experience in spatial\nenvironments is as crucial as the visual experience for achieving true\nimmersion. Despite recent advances in neural approaches for Room Impulse\nResponse (RIR) estimation, most existing methods are limited to the single\nenvironment on which they are trained, lacking the ability to generalize to new\nrooms with different geometries and surface materials. We aim to develop a\nunified model capable of reconstructing the spatial acoustic experience of any\nenvironment with minimum additional measurements. To this end, we present xRIR,\na framework for cross-room RIR prediction. The core of our generalizable\napproach lies in combining a geometric feature extractor, which captures\nspatial context from panorama depth images, with a RIR encoder that extracts\ndetailed acoustic features from only a few reference RIR samples. To evaluate\nour method, we introduce ACOUSTICROOMS, a new dataset featuring high-fidelity\nsimulation of over 300,000 RIRs from 260 rooms. Experiments show that our\nmethod strongly outperforms a series of baselines. Furthermore, we successfully\nperform sim-to-real transfer by evaluating our model on four real-world\nenvironments, demonstrating the generalizability of our approach and the\nrealism of our dataset.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faxRIR\u6846\u67b6\uff0c\u7528\u4e8e\u8de8\u623f\u95f4\u623f\u95f4\u8109\u51b2\u54cd\u5e94\uff08RIR\uff09\u9884\u6d4b\uff0c\u4ee5\u63d0\u5347\u6df7\u5408\u73b0\u5b9e\u4e2d\u7684\u58f0\u5b66\u6c89\u6d78\u611f\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u4e8e\u5355\u4e00\u73af\u5883\uff0c\u65e0\u6cd5\u6cdb\u5316\u5230\u4e0d\u540c\u51e0\u4f55\u548c\u6750\u6599\u7684\u65b0\u623f\u95f4\uff0c\u800c\u58f0\u5b66\u4f53\u9a8c\u5bf9\u6df7\u5408\u73b0\u5b9e\u6c89\u6d78\u611f\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7ed3\u5408\u51e0\u4f55\u7279\u5f81\u63d0\u53d6\u5668\uff08\u4ece\u5168\u666f\u6df1\u5ea6\u56fe\u50cf\u6355\u83b7\u7a7a\u95f4\u4e0a\u4e0b\u6587\uff09\u548cRIR\u7f16\u7801\u5668\uff08\u4ece\u5c11\u91cf\u53c2\u8003RIR\u6837\u672c\u63d0\u53d6\u58f0\u5b66\u7279\u5f81\uff09\uff0c\u6784\u5efa\u901a\u7528\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5e76\u5728\u56db\u4e2a\u771f\u5b9e\u73af\u5883\u4e2d\u5b9e\u73b0\u6a21\u62df\u5230\u771f\u5b9e\u8f6c\u79fb\uff0c\u8bc1\u660e\u4e86\u6cdb\u5316\u6027\u548c\u6570\u636e\u96c6\u7684\u771f\u5b9e\u6027\u3002", "conclusion": "\u5c55\u793a\u4e86xRIR\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u63a8\u52a8\u4e86\u7a7a\u95f4\u58f0\u5b66\u91cd\u5efa\u7684\u8fdb\u5c55\u3002"}}
{"id": "2504.11393", "pdf": "https://arxiv.org/pdf/2504.11393", "abs": "https://arxiv.org/abs/2504.11393", "authors": ["Ian Magnusson", "Nguyen Tai", "Ben Bogin", "David Heineman", "Jena D. Hwang", "Luca Soldaini", "Akshita Bhagia", "Jiacheng Liu", "Dirk Groeneveld", "Oyvind Tafjord", "Noah A. Smith", "Pang Wei Koh", "Jesse Dodge"], "title": "DataDecide: How to Predict Best Pretraining Data with Small Experiments", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Because large language models are expensive to pretrain on different\ndatasets, using smaller-scale experiments to decide on data is crucial for\nreducing costs. Which benchmarks and methods of making decisions from observed\nperformance at small scale most accurately predict the datasets that yield the\nbest large models? To empower open exploration of this question, we release\nmodels, data, and evaluations in DataDecide -- the most extensive open suite of\nmodels over differences in data and scale. We conduct controlled pretraining\nexperiments across 25 corpora with differing sources, deduplication, and\nfiltering up to 100B tokens, model sizes up to 1B parameters, and 3 random\nseeds. We find that the ranking of models at a single, small size (e.g., 150M\nparameters) is a strong baseline for predicting best models at our larger\ntarget scale (1B) (~80% of com parisons correct). No scaling law methods among\n8 baselines exceed the compute-decision frontier of single-scale predictions,\nbut DataDecide can measure improvement in future scaling laws. We also identify\nthat using continuous likelihood metrics as proxies in small experiments makes\nbenchmarks including MMLU, ARC, HellaSwag, MBPP, and HumanEval >80% predictable\nat the target 1B scale with just 0.01% of the compute.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86DataDecide\u5957\u4ef6\uff0c\u901a\u8fc7\u5c0f\u89c4\u6a21\u5b9e\u9a8c\u9884\u6d4b\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u53d1\u73b0\u5355\u89c4\u6a21\u9884\u6d4b\u5df2\u5f88\u51c6\u786e\uff0c\u4e14\u4f7f\u7528\u8fde\u7eed\u4f3c\u7136\u6307\u6807\u80fd\u9ad8\u6548\u9884\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u4f7f\u7528\u5c0f\u89c4\u6a21\u5b9e\u9a8c\u9009\u62e9\u6570\u636e\u4ee5\u964d\u4f4e\u6210\u672c\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u5982\u4f55\u7528\u5c0f\u89c4\u6a21\u6027\u80fd\u51c6\u786e\u9884\u6d4b\u6700\u4f73\u6570\u636e\u96c6\u3002", "method": "\u53d1\u5e03DataDecide\u5f00\u653e\u5957\u4ef6\uff0c\u5305\u62ec\u6a21\u578b\u3001\u6570\u636e\u548c\u8bc4\u4f30\u3002\u8fdb\u884c\u63a7\u5236\u9884\u8bad\u7ec3\u5b9e\u9a8c\uff0c\u6d89\u53ca25\u4e2a\u8bed\u6599\u5e93\u3001\u4e0d\u540c\u53bb\u91cd\u8fc7\u6ee4\u3001\u89c4\u6a21\u81f3100B tokens\u3001\u6a21\u578b\u5927\u5c0f\u81f31B\u53c2\u6570\u30013\u4e2a\u968f\u673a\u79cd\u5b50\uff0c\u5e76\u6bd4\u8f838\u79cd\u57fa\u51c6\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u5355\u5c0f\u89c4\u6a21\u6a21\u578b\u6392\u540d\u80fd\u9884\u6d4b\u76ee\u6807\u5927\u89c4\u6a21\u6a21\u578b\u6027\u80fd\uff08\u7ea680%\u6b63\u786e\uff09\u3002\u65e0\u7f29\u653e\u5b9a\u5f8b\u65b9\u6cd5\u4f18\u4e8e\u5355\u89c4\u6a21\u9884\u6d4b\u3002\u4f7f\u7528\u8fde\u7eed\u4f3c\u7136\u6307\u6807\u4f5c\u4e3a\u4ee3\u7406\uff0c\u80fd\u4ee50.01%\u8ba1\u7b97\u9884\u6d4bMMLU\u7b49\u57fa\u51c6>80%\u51c6\u786e\u3002", "conclusion": "DataDecide\u4fc3\u8fdb\u672a\u6765\u7f29\u653e\u5b9a\u5f8b\u6539\u8fdb\uff0c\u8bc1\u5b9e\u5c0f\u89c4\u6a21\u5b9e\u9a8c\u80fd\u6709\u6548\u9884\u6d4b\u5927\u89c4\u6a21\u6027\u80fd\uff0c\u7279\u522b\u662f\u4f7f\u7528\u7279\u5b9a\u6307\u6807\u3002"}}
{"id": "2504.10751", "pdf": "https://arxiv.org/pdf/2504.10751", "abs": "https://arxiv.org/abs/2504.10751", "authors": ["Daniel T. Larsson", "Dipankar Maity"], "title": "Communication-aware Hierarchical Map Compression of Time-Varying Environments for Mobile Robots", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": null, "summary": "In this paper, we develop a systematic framework for the time-sequential\ncompression of dynamic probabilistic occupancy grids. Our approach leverages\nideas from signal compression theory to formulate an optimization problem that\nsearches for a multi-resolution hierarchical encoder that balances the quality\nof the compressed map (distortion) with its description size, the latter of\nwhich relates to the bandwidth required to reliably transmit the map to other\nagents or to store map estimates in on-board memory. The resulting optimization\nproblem allows for multi-resolution map compressions to be obtained that\nsatisfy available communication or memory resources, and does not require\nknowledge of the occupancy map dynamics. We develop an algorithm to solve our\nproblem, and demonstrate the utility of the proposed framework in simulation on\nboth static (i.e., non-time varying) and dynamic (time-varying) occupancy maps.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u52a8\u6001\u6982\u7387\u5360\u7528\u7f51\u683c\u7684\u65f6\u95f4\u5e8f\u5217\u538b\u7f29\uff0c\u5e73\u8861\u538b\u7f29\u8d28\u91cf\u4e0e\u8d44\u6e90\u9700\u6c42\u3002", "motivation": "\u4e3a\u4e86\u5728\u6709\u9650\u7684\u901a\u4fe1\u5e26\u5bbd\u6216\u5b58\u50a8\u8d44\u6e90\u4e0b\uff0c\u9ad8\u6548\u538b\u7f29\u5360\u7528\u5730\u56fe\uff0c\u540c\u65f6\u4e0d\u9700\u77e5\u9053\u5730\u56fe\u52a8\u6001\u3002", "method": "\u5229\u7528\u4fe1\u53f7\u538b\u7f29\u7406\u8bba\uff0c\u5236\u5b9a\u4f18\u5316\u95ee\u9898\uff0c\u5f00\u53d1\u7b97\u6cd5\u6c42\u89e3\u591a\u5206\u8fa8\u7387\u5206\u5c42\u7f16\u7801\u5668\u3002", "result": "\u5728\u6a21\u62df\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u5728\u9759\u6001\u548c\u52a8\u6001\u5360\u7528\u5730\u56fe\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6846\u67b6\u80fd\u53ef\u9760\u538b\u7f29\u5730\u56fe\uff0c\u6ee1\u8db3\u8d44\u6e90\u7ea6\u675f\uff0c\u5e76\u8bc1\u660e\u5176\u5b9e\u7528\u6027\u3002"}}
{"id": "2504.11397", "pdf": "https://arxiv.org/pdf/2504.11397", "abs": "https://arxiv.org/abs/2504.11397", "authors": ["Raghav Pant", "Sikan Li", "Xingjian Li", "Hassan Iqbal", "Krishna Kumar"], "title": "MLPs and KANs for data-driven learning in physical problems: A performance comparison", "categories": ["cs.LG", "physics.comp-ph"], "comment": "30 pages, 18 figures, 8 tables", "summary": "There is increasing interest in solving partial differential equations (PDEs)\nby casting them as machine learning problems. Recently, there has been a spike\nin exploring Kolmogorov-Arnold Networks (KANs) as an alternative to traditional\nneural networks represented by Multi-Layer Perceptrons (MLPs). While showing\npromise, their performance advantages in physics-based problems remain largely\nunexplored. Several critical questions persist: Can KANs capture complex\nphysical dynamics and under what conditions might they outperform traditional\narchitectures? In this work, we present a comparative study of KANs and MLPs\nfor learning physical systems governed by PDEs. We assess their performance\nwhen applied in deep operator networks (DeepONet) and graph network-based\nsimulators (GNS), and test them on physical problems that vary significantly in\nscale and complexity. Drawing inspiration from the Kolmogorov Representation\nTheorem, we examine the behavior of KANs and MLPs across shallow and deep\nnetwork architectures. Our results reveal that although KANs do not\nconsistently outperform MLPs when configured as deep neural networks, they\ndemonstrate superior expressiveness in shallow network settings, significantly\noutpacing MLPs in accuracy over our test cases. This suggests that KANs are a\npromising choice, offering a balance of efficiency and accuracy in applications\ninvolving physical systems.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86Kolmogorov-Arnold Networks (KANs) \u548c\u591a\u5c42\u611f\u77e5\u673a (MLPs) \u5728\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b (PDEs) \u65b9\u9762\u7684\u6027\u80fd\uff0c\u53d1\u73b0KANs\u5728\u6d45\u5c42\u7f51\u7edc\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u52a8\u673a\u662f\u63a2\u7d22KANs\u662f\u5426\u80fd\u5728\u7269\u7406\u7cfb\u7edf\u4e2d\u8d85\u8d8aMLPs\u7684\u6027\u80fd\uff0c\u54cd\u5e94\u673a\u5668\u5b66\u4e60\u6c42\u89e3PDEs\u7684\u65e5\u76ca\u5174\u8da3\u548c\u5173\u952e\u95ee\u9898\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5728\u6df1\u5ea6\u64cd\u4f5c\u7b26\u7f51\u7edc (DeepONet) \u548c\u56fe\u7f51\u7edc\u6a21\u62df\u5668 (GNS) \u4e2d\u6bd4\u8f83KANs\u548cMLPs\u7684\u8868\u73b0\uff0c\u5e76\u6d4b\u8bd5\u4e0d\u540c\u89c4\u6a21\u548c\u590d\u6742\u5ea6\u7684\u7269\u7406\u95ee\u9898\uff0c\u8003\u5bdf\u6d45\u5c42\u548c\u6df1\u5c42\u7f51\u7edc\u3002", "result": "\u7ed3\u679c\u663e\u793aKANs\u5728\u6df1\u5c42\u7f51\u7edc\u4e2d\u4e0d\u4e00\u81f4\u5730\u4f18\u4e8eMLPs\uff0c\u4f46\u5728\u6d45\u5c42\u7f51\u7edc\u4e2d\u51c6\u786e\u6027\u66f4\u9ad8\u3002", "conclusion": "\u7ed3\u8bba\u662fKANs\u5728\u7269\u7406\u7cfb\u7edf\u5e94\u7528\u4e2d\u5177\u6709\u524d\u666f\uff0c\u63d0\u4f9b\u6548\u7387\u548c\u51c6\u786e\u6027\u7684\u5e73\u8861\u3002"}}
{"id": "2504.10753", "pdf": "https://arxiv.org/pdf/2504.10753", "abs": "https://arxiv.org/abs/2504.10753", "authors": ["Radin Cheraghi", "Amir Mohammad Mahfoozi", "Sepehr Zolfaghari", "Mohammadshayan Shabani", "Maryam Ramezani", "Hamid R. Rabiee"], "title": "Epistemic Uncertainty-aware Recommendation Systems via Bayesian Deep Ensemble Learning", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "10 pages", "summary": "Recommending items to users has long been a fundamental task, and studies\nhave tried to improve it ever since. Most well-known models commonly employ\nrepresentation learning to map users and items into a unified embedding space\nfor matching assessment. These approaches have primary limitations, especially\nwhen dealing with explicit feedback and sparse data contexts. Two primary\nlimitations are their proneness to overfitting and failure to incorporate\nepistemic uncertainty in predictions. To address these problems, we propose a\nnovel Bayesian Deep Ensemble Collaborative Filtering method named BDECF. To\nimprove model generalization and quality, we utilize Bayesian Neural Networks,\nwhich incorporate uncertainty within their weight parameters. In addition, we\nintroduce a new interpretable non-linear matching approach for the user and\nitem embeddings, leveraging the advantages of the attention mechanism.\nFurthermore, we endorse the implementation of an ensemble-based supermodel to\ngenerate more robust and reliable predictions, resulting in a more complete\nmodel. Empirical evaluation through extensive experiments and ablation studies\nacross a range of publicly accessible real-world datasets with differing\nsparsity characteristics confirms our proposed method's effectiveness and the\nimportance of its components.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684Bayesian Deep Ensemble Collaborative Filtering\u65b9\u6cd5\uff08BDECF\uff09\uff0c\u4ee5\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u8fc7\u62df\u5408\u548c\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u8350\u6a21\u578b\u5728\u5904\u7406\u663e\u5f0f\u53cd\u9988\u548c\u7a00\u758f\u6570\u636e\u65f6\u5bb9\u6613\u8fc7\u62df\u5408\uff0c\u4e14\u672a\u80fd\u7eb3\u5165\u8ba4\u8bc6\u8bba\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51faBDECF\u65b9\u6cd5\uff0c\u4f7f\u7528Bayesian Neural Networks\u5904\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u5f15\u5165\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u53ef\u89e3\u91ca\u975e\u7ebf\u6027\u5339\u914d\u65b9\u6cd5\uff0c\u5e76\u91c7\u7528\u96c6\u6210\u6a21\u578b\u63d0\u9ad8\u9884\u6d4b\u9c81\u68d2\u6027\u3002", "result": "\u901a\u8fc7\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\uff0c\u8bc1\u5b9e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u7ec4\u4ef6\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9884\u6d4b\u8d28\u91cf\u3002"}}
{"id": "2504.11412", "pdf": "https://arxiv.org/pdf/2504.11412", "abs": "https://arxiv.org/abs/2504.11412", "authors": ["Yudong Luo", "Yangchen Pan", "Jiaqi Tan", "Pascal Poupart"], "title": "Measures of Variability for Risk-averse Policy Gradient", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Risk-averse reinforcement learning (RARL) is critical for decision-making\nunder uncertainty, which is especially valuable in high-stake applications.\nHowever, most existing works focus on risk measures, e.g., conditional\nvalue-at-risk (CVaR), while measures of variability remain underexplored. In\nthis paper, we comprehensively study nine common measures of variability,\nnamely Variance, Gini Deviation, Mean Deviation, Mean-Median Deviation,\nStandard Deviation, Inter-Quantile Range, CVaR Deviation, Semi_Variance, and\nSemi_Standard Deviation. Among them, four metrics have not been previously\nstudied in RARL. We derive policy gradient formulas for these unstudied\nmetrics, improve gradient estimation for Gini Deviation, analyze their gradient\nproperties, and incorporate them with the REINFORCE and PPO frameworks to\npenalize the dispersion of returns.\n  Our empirical study reveals that variance-based metrics lead to unstable\npolicy updates. In contrast, CVaR Deviation and Gini Deviation show consistent\nperformance across different randomness and evaluation domains, achieving high\nreturns while effectively learning risk-averse policies. Mean Deviation and\nSemi_Standard Deviation are also competitive across different scenarios. This\nwork provides a comprehensive overview of variability measures in RARL,\noffering practical insights for risk-aware decision-making and guiding future\nresearch on risk metrics and RARL algorithms.", "AI": {"tldr": "\u672c\u8bba\u6587\u5168\u9762\u7814\u7a76\u4e86\u4e5d\u79cd\u53d8\u5f02\u6027\u5ea6\u91cf\u5728\u98ce\u9669\u538c\u6076\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\uff0c\u5bfc\u51fa\u4e86\u65b0\u68af\u5ea6\u516c\u5f0f\uff0c\u5e76\u901a\u8fc7\u7ecf\u9a8c\u7814\u7a76\u6bd4\u8f83\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u98ce\u9669\u538c\u6076\u5f3a\u5316\u5b66\u4e60\u4e3b\u8981\u5173\u6ce8\u98ce\u9669\u5ea6\u91cf\u5982CVaR\uff0c\u800c\u53d8\u5f02\u6027\u5ea6\u91cf\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5bfc\u51fa\u4e86\u56db\u79cd\u672a\u7814\u7a76\u5ea6\u91cf\u7684\u7b56\u7565\u68af\u5ea6\u516c\u5f0f\uff0c\u6539\u8fdb\u4e86Gini Deviation\u68af\u5ea6\u4f30\u8ba1\uff0c\u5206\u6790\u4e86\u68af\u5ea6\u5c5e\u6027\uff0c\u5e76\u4e0eREINFORCE\u548cPPO\u6846\u67b6\u7ed3\u5408\u4ee5\u60e9\u7f5a\u56de\u62a5\u79bb\u6563\u3002", "result": "\u7ecf\u9a8c\u7814\u7a76\u663e\u793a\uff0c\u65b9\u5dee-based\u5ea6\u91cf\u4e0d\u7a33\u5b9a\uff0c\u800cCVaR Deviation\u548cGini Deviation\u8868\u73b0\u4e00\u81f4\uff0c\u63d0\u4f9b\u9ad8\u56de\u62a5\u5e76\u6709\u6548\u5b66\u4e60\u98ce\u9669\u538c\u6076\u7b56\u7565\u3002", "conclusion": "\u672c\u5de5\u4f5c\u63d0\u4f9b\u4e86\u53d8\u5f02\u6027\u5ea6\u91cf\u5728\u98ce\u9669\u538c\u6076\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5168\u9762\u6982\u8ff0\uff0c\u4e3a\u98ce\u9669\u611f\u77e5\u51b3\u7b56\u63d0\u4f9b\u6d1e\u89c1\uff0c\u5e76\u6307\u5bfc\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2504.11433", "pdf": "https://arxiv.org/pdf/2504.11433", "abs": "https://arxiv.org/abs/2504.11433", "authors": ["Indu Kant Deo", "Rajeev K. Jaiman"], "title": "Predicting Wave Dynamics using Deep Learning with Multistep Integration Inspired Attention and Physics-Based Loss Decomposition", "categories": ["cs.LG", "cs.NA", "math.NA", "physics.flu-dyn"], "comment": "30 pages, 14 figures", "summary": "In this paper, we present a physics-based deep learning framework for\ndata-driven prediction of wave propagation in fluid media. The proposed\napproach, termed Multistep Integration-Inspired Attention (MI2A), combines a\ndenoising-based convolutional autoencoder for reduced latent representation\nwith an attention-based recurrent neural network with long-short-term memory\ncells for time evolution of reduced coordinates. This proposed architecture\ndraws inspiration from classical linear multistep methods to enhance stability\nand long-horizon accuracy in latent-time integration. Despite the efficiency of\nhybrid neural architectures in modeling wave dynamics, autoregressive\npredictions are often prone to accumulating phase and amplitude errors over\ntime. To mitigate this issue within the MI2A framework, we introduce a novel\nloss decomposition strategy that explicitly separates the training loss\nfunction into distinct phase and amplitude components. We assess the\nperformance of MI2A against two baseline reduced-order models trained with\nstandard mean-squared error loss: a sequence-to-sequence recurrent neural\nnetwork and a variant using Luong-style attention. To demonstrate the\neffectiveness of the MI2A model, we consider three benchmark wave propagation\nproblems of increasing complexity, namely one-dimensional linear convection,\nthe nonlinear viscous Burgers equation, and the two-dimensional Saint-Venant\nshallow water system. Our results demonstrate that the MI2A framework\nsignificantly improves the accuracy and stability of long-term predictions,\naccurately preserving wave amplitude and phase characteristics. Compared to the\nstandard long-short term memory and attention-based models, MI2A-based deep\nlearning exhibits superior generalization and temporal accuracy, making it a\npromising tool for real-time wave modeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMI2A\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u81ea\u7f16\u7801\u5668\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u63d0\u9ad8\u6d41\u4f53\u6ce2\u4f20\u64ad\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u89e3\u51b3\u81ea\u56de\u5f52\u9884\u6d4b\u4e2d\u76f8\u4f4d\u548c\u5e45\u5ea6\u9519\u8bef\u79ef\u7d2f\u7684\u95ee\u9898\uff0c\u5e76\u4ece\u7ecf\u5178\u591a\u6b65\u65b9\u6cd5\u4e2d\u6c72\u53d6\u7075\u611f\u4ee5\u63d0\u5347\u957f\u671f\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u53bb\u566a\u5377\u79ef\u81ea\u7f16\u7801\u5668\u8fdb\u884c\u6f5c\u5728\u8868\u793a\uff0c\u6ce8\u610f\u529b-based RNN with LSTM \u8fdb\u884c\u65f6\u95f4\u6f14\u5316\uff0c\u5e76\u5f15\u5165\u635f\u5931\u51fd\u6570\u5206\u89e3\u7b56\u7565\u5206\u79bb\u76f8\u4f4d\u548c\u5e45\u5ea6\u3002", "result": "\u5728\u7ebf\u6027\u5bf9\u6d41\u3001Burgers\u65b9\u7a0b\u548c\u6d45\u6c34\u7cfb\u7edf\u7b49\u57fa\u51c6\u95ee\u9898\u4e0a\uff0cMI2A\u663e\u8457\u6539\u5584\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3001\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MI2A\u662f\u5b9e\u65f6\u6ce2\u5efa\u6a21\u7684\u7406\u60f3\u5de5\u5177\uff0c\u4f18\u4e8e\u6807\u51c6LSTM\u548c\u6ce8\u610f\u529b\u6a21\u578b\u3002"}}
{"id": "2504.10768", "pdf": "https://arxiv.org/pdf/2504.10768", "abs": "https://arxiv.org/abs/2504.10768", "authors": ["Ralf Schm\u00e4lzle", "Sue Lim", "Yuetong Du", "Gary Bente"], "title": "The Art of Audience Engagement: LLM-Based Thin-Slicing of Scientific Talks", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.HC"], "comment": null, "summary": "This paper examines the thin-slicing approach - the ability to make accurate\njudgments based on minimal information - in the context of scientific\npresentations. Drawing on research from nonverbal communication and personality\npsychology, we show that brief excerpts (thin slices) reliably predict overall\npresentation quality. Using a novel corpus of over one hundred real-life\nscience talks, we employ Large Language Models (LLMs) to evaluate transcripts\nof full presentations and their thin slices. By correlating LLM-based\nevaluations of short excerpts with full-talk assessments, we determine how much\ninformation is needed for accurate predictions. Our results demonstrate that\nLLM-based evaluations align closely with human ratings, proving their validity,\nreliability, and efficiency. Critically, even very short excerpts (less than 10\npercent of a talk) strongly predict overall evaluations. This suggests that the\nfirst moments of a presentation convey relevant information that is used in\nquality evaluations and can shape lasting impressions. The findings are robust\nacross different LLMs and prompting strategies. This work extends thin-slicing\nresearch to public speaking and connects theories of impression formation to\nLLMs and current research on AI communication. We discuss implications for\ncommunication and social cognition research on message reception. Lastly, we\nsuggest an LLM-based thin-slicing framework as a scalable feedback tool to\nenhance human communication.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5728\u79d1\u5b66\u6f14\u8bb2\u4e2d\u4f7f\u7528\u8584\u5207\u7247\u65b9\u6cd5\uff08\u57fa\u4e8e\u5c11\u91cf\u4fe1\u606f\u8fdb\u884c\u5224\u65ad\uff09\uff0c\u53d1\u73b0LLM\u80fd\u51c6\u786e\u9884\u6d4b\u6f14\u8bb2\u8d28\u91cf\uff0c\u751a\u81f3\u77ed\u7247\u6bb5\uff08\u5c11\u4e8e10%\uff09\u5373\u53ef\uff0c\u5e76\u63d0\u51faLLM\u6846\u67b6\u4f5c\u4e3a\u53cd\u9988\u5de5\u5177\u3002", "motivation": "\u57fa\u4e8e\u975e\u8bed\u8a00\u6c9f\u901a\u548c\u4e2a\u6027\u5fc3\u7406\u5b66\u7684\u7814\u7a76\uff0c\u63a2\u8ba8\u8584\u5207\u7247\u65b9\u6cd5\u5728\u79d1\u5b66\u6f14\u8bb2\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u8bc1\u660e\u7b80\u77ed\u7247\u6bb5\u80fd\u53ef\u9760\u9884\u6d4b\u6574\u4f53\u8d28\u91cf\u3002", "method": "\u4f7f\u7528\u4e00\u4e2a\u5305\u542b\u4e00\u767e\u591a\u4e2a\u771f\u5b9e\u79d1\u5b66\u6f14\u8bb2\u7684\u8bed\u6599\u5e93\uff0c\u91c7\u7528LLM\u8bc4\u4f30\u5b8c\u6574\u6f14\u8bb2\u548c\u8584\u5207\u7247\u7684\u8f6c\u5f55\u6587\u672c\uff0c\u901a\u8fc7\u76f8\u5173\u6027\u5206\u6790\u786e\u5b9a\u6240\u9700\u4fe1\u606f\u91cf\u3002", "result": "LLM\u8bc4\u4f30\u4e0e\u4eba\u7c7b\u8bc4\u5206\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5373\u4f7f\u4e0d\u523010%\u7684\u6f14\u8bb2\u7247\u6bb5\u4e5f\u80fd\u5f3a\u70c8\u9884\u6d4b\u6574\u4f53\u8bc4\u4ef7\uff1b\u7ed3\u679c\u5728\u4e0d\u540cLLM\u548c\u63d0\u793a\u7b56\u7565\u4e0b\u7a33\u5065\u3002", "conclusion": "\u6269\u5c55\u8584\u5207\u7247\u7814\u7a76\u5230\u516c\u5f00\u6f14\u8bb2\uff0c\u8fde\u63a5\u5370\u8c61\u5f62\u6210\u7406\u8bba\uff0c\u8ba8\u8bba\u5bf9\u6c9f\u901a\u548c\u793e\u4f1a\u8ba4\u77e5\u7814\u7a76\u7684\u5f71\u54cd\uff0c\u5e76\u5efa\u8baeLLM-based\u8584\u5207\u7247\u6846\u67b6\u4f5c\u4e3a\u53ef\u6269\u5c55\u7684\u53cd\u9988\u5de5\u5177\u3002"}}
{"id": "2504.11438", "pdf": "https://arxiv.org/pdf/2504.11438", "abs": "https://arxiv.org/abs/2504.11438", "authors": ["Lewis Clifton", "Xin Tian", "Duangdao Palasuwan", "Phandee Watanaboonyongcharoen", "Ponlapat Rojnuckarin", "Nantheera Anantrasirichai"], "title": "Mamba-Based Ensemble learning for White Blood Cell Classification", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "White blood cell (WBC) classification assists in assessing immune health and\ndiagnosing various diseases, yet manual classification is labor-intensive and\nprone to inconsistencies. Recent advancements in deep learning have shown\npromise over traditional methods; however, challenges such as data imbalance\nand the computational demands of modern technologies, such as Transformer-based\nmodels which do not scale well with input size, limit their practical\napplication. This paper introduces a novel framework that leverages Mamba\nmodels integrated with ensemble learning to improve WBC classification. Mamba\nmodels, known for their linear complexity, provide a scalable alternative to\nTransformer-based approaches, making them suitable for deployment in\nresource-constrained environments. Additionally, we introduce a new WBC\ndataset, Chula-WBC-8, for benchmarking. Our approach not only validates the\neffectiveness of Mamba models in this domain but also demonstrates their\npotential to significantly enhance classification efficiency without\ncompromising accuracy. The source code can be found at\nhttps://github.com/LewisClifton/Mamba-WBC-Classification.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165\u4e86\u4e00\u4e2a\u4f7f\u7528Mamba\u6a21\u578b\u548c\u96c6\u6210\u5b66\u4e60\u7684\u65b0\u6846\u67b6\u6765\u6539\u5584\u767d\u7ec6\u80de\u5206\u7c7b\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u6570\u636e\u96c6Chula-WBC-8\uff0c\u4ee5\u63d0\u9ad8\u6548\u7387\u800c\u4e0d\u964d\u4f4e\u51c6\u786e\u6027\u3002", "motivation": "\u624b\u52a8\u767d\u7ec6\u80de\u5206\u7c7b\u52b3\u52a8\u5bc6\u96c6\u4e14\u6613\u51fa\u9519\uff0c\u6df1\u5ea6\u5b66\u4e60\u9762\u4e34\u6570\u636e\u4e0d\u5e73\u8861\u548c\u8ba1\u7b97\u9700\u6c42\u6311\u6218\uff0c\u5c24\u5176\u662fTransformer\u6a21\u578b\u7684\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u5f15\u5165Mamba\u6a21\u578b\uff08\u7ebf\u6027\u590d\u6742\u5ea6\uff09\u4e0e\u96c6\u6210\u5b66\u4e60\u76f8\u7ed3\u5408\u7684\u6846\u67b6\uff0c\u5e76\u521b\u5efa\u65b0\u6570\u636e\u96c6Chula-WBC-8\u7528\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u9a8c\u8bc1\u4e86Mamba\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u63d0\u9ad8\u4e86\u5206\u7c7b\u6548\u7387\u800c\u4e0d\u964d\u4f4e\u51c6\u786e\u6027\u3002", "conclusion": "\u5c55\u793a\u4e86Mamba\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u4f9b\u4e86\u6e90\u4ee3\u7801\u94fe\u63a5\u3002"}}
{"id": "2504.10781", "pdf": "https://arxiv.org/pdf/2504.10781", "abs": "https://arxiv.org/abs/2504.10781", "authors": ["Kamran Majid"], "title": "Neural Network Emulation of the Classical Limit in Quantum Systems via Learned Observable Mappings", "categories": ["quant-ph", "cs.AI"], "comment": null, "summary": "The classical limit of quantum mechanics, formally investigated through\nframeworks like strict deformation quantization, remains a profound area of\ninquiry in the philosophy of physics. This paper explores a computational\napproach employing a neural network to emulate the emergence of classical\nbehavior from the quantum harmonic oscillator as Planck's constant $\\hbar$\napproaches zero. We develop and train a neural network architecture to learn\nthe mapping from initial expectation values and $\\hbar$ to the time evolution\nof the expectation value of position. By analyzing the network's predictions\nacross different regimes of hbar, we aim to provide computational insights into\nthe nature of the quantum-classical transition. This work demonstrates the\npotential of machine learning as a complementary tool for exploring\nfoundational questions in quantum mechanics and its classical limit.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\u6a21\u62df\u91cf\u5b50\u8c10\u632f\u5b50\u4ece\u91cf\u5b50\u5230\u7ecf\u5178\u7684\u8fc7\u6e21\uff0c\u5f53\u0127\u8d8b\u8fd1\u4e8e\u96f6\u65f6\u3002", "motivation": "\u63a2\u8ba8\u91cf\u5b50\u529b\u5b66\u7684\u7ecf\u5178\u6781\u9650\uff0c\u8fd9\u662f\u7269\u7406\u54f2\u5b66\u4e2d\u7684\u4e00\u4e2a\u6df1\u523b\u9886\u57df\uff0c\u4f7f\u7528\u8ba1\u7b97\u65b9\u6cd5\u5982\u673a\u5668\u5b66\u4e60\u6765\u83b7\u5f97\u6d1e\u89c1\u3002", "method": "\u5f00\u53d1\u5e76\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff0c\u5b66\u4e60\u4ece\u521d\u59cb\u671f\u671b\u503c\u548c\u0127\u5230\u4f4d\u7f6e\u671f\u671b\u503c\u65f6\u95f4\u6f14\u5316\u7684\u6620\u5c04\u3002", "result": "\u7f51\u7edc\u9884\u6d4b\u5728\u4e0d\u540c\u0127\u6761\u4ef6\u4e0b\u7684\u5206\u6790\uff0c\u63d0\u4f9b\u91cf\u5b50-\u7ecf\u5178\u8fc7\u6e21\u7684\u8ba1\u7b97\u6d1e\u89c1\uff0c\u5e76\u5c55\u793a\u673a\u5668\u5b66\u4e60\u5728\u8fd9\u4e00\u9886\u57df\u7684\u6f5c\u529b\u3002", "conclusion": "\u8bc1\u660e\u673a\u5668\u5b66\u4e60\u53ef\u4ee5\u4f5c\u4e3a\u63a2\u7d22\u91cf\u5b50\u529b\u5b66\u57fa\u7840\u95ee\u9898\u548c\u7ecf\u5178\u6781\u9650\u7684\u8865\u5145\u5de5\u5177\u3002"}}
{"id": "2504.11453", "pdf": "https://arxiv.org/pdf/2504.11453", "abs": "https://arxiv.org/abs/2504.11453", "authors": ["Matthew Thomas Jackson", "Uljad Berdica", "Jarek Liesen", "Shimon Whiteson", "Jakob Nicolaus Foerster"], "title": "A Clean Slate for Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Progress in offline reinforcement learning (RL) has been impeded by ambiguous\nproblem definitions and entangled algorithmic designs, resulting in\ninconsistent implementations, insufficient ablations, and unfair evaluations.\nAlthough offline RL explicitly avoids environment interaction, prior methods\nfrequently employ extensive, undocumented online evaluation for hyperparameter\ntuning, complicating method comparisons. Moreover, existing reference\nimplementations differ significantly in boilerplate code, obscuring their core\nalgorithmic contributions. We address these challenges by first introducing a\nrigorous taxonomy and a transparent evaluation protocol that explicitly\nquantifies online tuning budgets. To resolve opaque algorithmic design, we\nprovide clean, minimalistic, single-file implementations of various model-free\nand model-based offline RL methods, significantly enhancing clarity and\nachieving substantial speed-ups. Leveraging these streamlined implementations,\nwe propose Unifloral, a unified algorithm that encapsulates diverse prior\napproaches within a single, comprehensive hyperparameter space, enabling\nalgorithm development in a shared hyperparameter space. Using Unifloral with\nour rigorous evaluation protocol, we develop two novel algorithms - TD3-AWR\n(model-free) and MoBRAC (model-based) - which substantially outperform\nestablished baselines. Our implementation is publicly available at\nhttps://github.com/EmptyJackson/unifloral.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u7edf\u4e00\u6846\u67b6Unifloral\u548c\u65b0\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u8fdb\u5c55\u53d7\u6a21\u7cca\u95ee\u9898\u5b9a\u4e49\u548c\u7b97\u6cd5\u8bbe\u8ba1\u7ea0\u7f20\u5f71\u54cd\uff0c\u5bfc\u81f4\u5b9e\u73b0\u4e0d\u4e00\u81f4\u3001\u8bc4\u4f30\u4e0d\u516c\u548c\u4f9d\u8d56\u5728\u7ebf\u8c03\u4f18\u3002", "method": "\u5f15\u5165\u4e25\u683c\u5206\u7c7b\u6cd5\u3001\u900f\u660e\u8bc4\u4f30\u534f\u8bae\uff0c\u63d0\u4f9b\u7b80\u6d01\u5b9e\u73b0\uff0c\u63d0\u51faUnifloral\u7b97\u6cd5\u7edf\u4e00\u591a\u79cd\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1TD3-AWR\u548cMoBRAC\u7b97\u6cd5\u3002", "result": "\u65b0\u7b97\u6cd5TD3-AWR\u548cMoBRAC\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u6846\u67b6\u548c\u4e25\u683c\u8bc4\u4f30\uff0c\u63d0\u9ad8\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u7814\u7a76\u6548\u7387\u548c\u516c\u5e73\u6027\uff0c\u5b9e\u73b0\u5df2\u516c\u5f00\u3002"}}
{"id": "2504.10784", "pdf": "https://arxiv.org/pdf/2504.10784", "abs": "https://arxiv.org/abs/2504.10784", "authors": ["Mikolaj Walczak", "Uttej Kallakuri", "Tinoosh Mohsenin"], "title": "ATLASv2: LLM-Guided Adaptive Landmark Acquisition and Navigation on the Edge", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Autonomous systems deployed on edge devices face significant challenges,\nincluding resource constraints, real-time processing demands, and adapting to\ndynamic environments. This work introduces ATLASv2, a novel system that\nintegrates a fine-tuned TinyLLM, real-time object detection, and efficient path\nplanning to enable hierarchical, multi-task navigation and manipulation all on\nthe edge device, Jetson Nano. ATLASv2 dynamically expands its navigable\nlandmarks by detecting and localizing objects in the environment which are\nsaved to its internal knowledge base to be used for future task execution. We\nevaluate ATLASv2 in real-world environments, including a handcrafted home and\noffice setting constructed with diverse objects and landmarks. Results show\nthat ATLASv2 effectively interprets natural language instructions, decomposes\nthem into low-level actions, and executes tasks with high success rates. By\nleveraging generative AI in a fully on-board framework, ATLASv2 achieves\noptimized resource utilization with minimal prompting latency and power\nconsumption, bridging the gap between simulated environments and real-world\napplications.", "AI": {"tldr": "ATLASv2 \u662f\u4e00\u4e2a\u5728 Jetson Nano \u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fd0\u884c\u7684\u7cfb\u7edf\uff0c\u96c6\u6210\u4e86 TinyLLM\u3001\u5b9e\u65f6\u7269\u4f53\u68c0\u6d4b\u548c\u8def\u5f84\u89c4\u5212\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u81ea\u4e3b\u5bfc\u822a\u548c\u64cd\u4f5c\u3002", "motivation": "\u89e3\u51b3\u81ea\u4e3b\u7cfb\u7edf\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u8d44\u6e90\u7ea6\u675f\u3001\u5b9e\u65f6\u5904\u7406\u9700\u6c42\u548c\u52a8\u6001\u73af\u5883\u9002\u5e94\u6311\u6218\u3002", "method": "\u5f15\u5165 ATLASv2 \u7cfb\u7edf\uff0c\u901a\u8fc7\u5fae\u8c03 TinyLLM\u3001\u5b9e\u65f6\u7269\u4f53\u68c0\u6d4b\u548c\u9ad8\u6548\u8def\u5f84\u89c4\u5212\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u5206\u5c42\u591a\u4efb\u52a1\u5bfc\u822a\u548c\u64cd\u4f5c\u3002", "result": "\u5b9e\u4e16\u754c\u8bc4\u4f30\u663e\u793a\u9ad8\u6210\u529f\u7387\uff0c\u4f18\u5316\u4e86\u8d44\u6e90\u5229\u7528\uff0c\u51cf\u5c11\u4e86\u5ef6\u8fdf\u548c\u529f\u8017\u3002", "conclusion": "\u6865\u63a5\u4e86\u6a21\u62df\u73af\u5883\u4e0e\u771f\u5b9e\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u901a\u8fc7\u5168 onboard \u7684\u751f\u6210\u5f0f AI \u6846\u67b6\u3002"}}
{"id": "2504.11454", "pdf": "https://arxiv.org/pdf/2504.11454", "abs": "https://arxiv.org/abs/2504.11454", "authors": ["Cheng-Yen", "Hsieh", "Xinyou Wang", "Daiheng Zhang", "Dongyu Xue", "Fei Ye", "Shujian Huang", "Zaixiang Zheng", "Quanquan Gu"], "title": "Elucidating the Design Space of Multimodal Protein Language Models", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "Project Page: https://bytedance.github.io/dplm/dplm-2.1/", "summary": "Multimodal protein language models (PLMs) integrate sequence and token-based\nstructural information, serving as a powerful foundation for protein modeling,\ngeneration, and design. However, the reliance on tokenizing 3D structures into\ndiscrete tokens causes substantial loss of fidelity about fine-grained\nstructural details and correlations. In this paper, we systematically elucidate\nthe design space of multimodal PLMs to overcome their limitations. We identify\ntokenization loss and inaccurate structure token predictions by the PLMs as\nmajor bottlenecks. To address these, our proposed design space covers improved\ngenerative modeling, structure-aware architectures and representation learning,\nand data exploration. Our advancements approach finer-grained supervision,\ndemonstrating that token-based multimodal PLMs can achieve robust structural\nmodeling. The effective design methods dramatically improve the structure\ngeneration diversity, and notably, folding abilities of our 650M model by\nreducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3B\nbaselines and on par with the specialized folding models.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u6539\u8fdb\u591a\u6a21\u6001\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\uff0c\u89e3\u51b3\u6807\u8bb0\u5316\u635f\u5931\u95ee\u9898\uff0c\u63d0\u9ad8\u7ed3\u6784\u5efa\u6a21\u548c\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5728\u5c063D\u7ed3\u6784\u79bb\u6563\u5316\u4e3a\u6807\u8bb0\u65f6\u4e22\u5931\u7ec6\u7c92\u5ea6\u7ec6\u8282\u548c\u76f8\u5173\u6027\uff0c\u9700\u8981\u514b\u670d\u6807\u8bb0\u5316\u635f\u5931\u548c\u7ed3\u6784\u9884\u6d4b\u4e0d\u51c6\u7684\u74f6\u9888\u3002", "method": "\u9610\u8ff0\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5305\u62ec\u6539\u8fdb\u751f\u6210\u6a21\u578b\u3001\u7ed3\u6784\u611f\u77e5\u67b6\u6784\u3001\u8868\u793a\u5b66\u4e60\u3001\u6570\u636e\u63a2\u7d22\u548c\u66f4\u7ec6\u7c92\u5ea6\u7684\u76d1\u7763\u3002", "result": "\u5c06RMSD\u4ece5.52\u964d\u4f4e\u52302.36\uff0c\u63d0\u9ad8\u7ed3\u6784\u751f\u6210\u591a\u6837\u6027\uff0c\u4f18\u4e8e3B\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u4e0e\u4e13\u4e1a\u6298\u53e0\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "\u57fa\u4e8e\u6807\u8bb0\u7684\u591a\u6a21\u6001\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u8fd9\u4e9b\u6539\u8fdb\u53ef\u5b9e\u73b0\u7a33\u5065\u7684\u7ed3\u6784\u5efa\u6a21\u3002"}}
{"id": "2504.10786", "pdf": "https://arxiv.org/pdf/2504.10786", "abs": "https://arxiv.org/abs/2504.10786", "authors": ["Gene Tangtartharakul", "Katherine R. Storrs"], "title": "Visual Language Models show widespread visual deficits on neuropsychological tests", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2.0; I.2.10"], "comment": "31 pages, 3 figures, 1 supplementary document with 1 figure and 51\n  sample images", "summary": "Visual Language Models (VLMs) show remarkable performance in visual reasoning\ntasks, successfully tackling college-level challenges that require high-level\nunderstanding of images. However, some recent reports of VLMs struggling to\nreason about elemental visual concepts like orientation, position, continuity,\nand occlusion suggest a potential gulf between human and VLM vision. Here we\nuse the toolkit of neuropsychology to systematically assess the capabilities of\nthree state-of-the-art VLMs across visual domains. Using 51 tests drawn from\nsix clinical and experimental batteries, we characterise the visual abilities\nof leading VLMs relative to normative performance in healthy adults. While the\nmodels excel in straightforward object recognition tasks, we find widespread\ndeficits in low- and mid-level visual abilities that would be considered\nclinically significant in humans. These selective deficits, profiled through\nvalidated test batteries, suggest that an artificial system can achieve complex\nobject recognition without developing foundational visual concepts that in\nhumans require no explicit training.", "AI": {"tldr": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u7ea7\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u57fa\u7840\u89c6\u89c9\u6982\u5ff5\u5b58\u5728\u7f3a\u9677\uff0c\u4e0e\u4eba\u7c7b\u89c6\u89c9\u6709\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u6700\u8fd1\u62a5\u544a\u663e\u793aVLMs\u5728\u5143\u7d20\u89c6\u89c9\u6982\u5ff5\u4e0a\u6323\u624e\uff0c\u63ed\u793a\u4e86\u4eba\u7c7b\u4e0eVLM\u89c6\u89c9\u7684\u6f5c\u5728\u5dee\u8ddd\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u4f7f\u752851\u4e2a\u6d4b\u8bd5\uff0c\u4ece\u516d\u4e2a\u4e34\u5e8a\u548c\u5b9e\u9a8c\u7535\u6c60\u4e2d\uff0c\u8bc4\u4f30\u4e09\u4e2a\u6700\u5148\u8fdb\u7684VLMs\u3002", "result": "\u6a21\u578b\u5728\u7269\u4f53\u8bc6\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4f4e\u7ea7\u548c\u4e2d\u7ea7\u89c6\u89c9\u80fd\u529b\u5b58\u5728\u5e7f\u6cdb\u7f3a\u9677\uff0c\u5728\u4eba\u7c7b\u4e2d\u88ab\u89c6\u4e3a\u4e34\u5e8a\u610f\u4e49\u3002", "conclusion": "\u4eba\u5de5\u7cfb\u7edf\u53ef\u5b9e\u73b0\u590d\u6742\u7269\u4f53\u8bc6\u522b\uff0c\u800c\u65e0\u9700\u4eba\u7c7b\u81ea\u7136\u53d1\u5c55\u7684\u57fa\u7840\u89c6\u89c9\u6982\u5ff5\u3002"}}
{"id": "2410.10291", "pdf": "https://arxiv.org/pdf/2410.10291", "abs": "https://arxiv.org/abs/2410.10291", "authors": ["Xiangru Zhu", "Penglei Sun", "Yaoxian Song", "Yanghua Xiao", "Zhixu Li", "Chengyu Wang", "Jun Huang", "Bei Yang", "Xiaoxiao Xu"], "title": "Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "comment": "Accepted by ICLR 2025", "summary": "Accurate interpretation and visualization of human instructions are crucial\nfor text-to-image (T2I) synthesis. However, current models struggle to capture\nsemantic variations from word order changes, and existing evaluations, relying\non indirect metrics like text-image similarity, fail to reliably assess these\nchallenges. This often obscures poor performance on complex or uncommon\nlinguistic patterns by the focus on frequent word combinations. To address\nthese deficiencies, we propose a novel metric called SemVarEffect and a\nbenchmark named SemVarBench, designed to evaluate the causality between\nsemantic variations in inputs and outputs in T2I synthesis. Semantic variations\nare achieved through two types of linguistic permutations, while avoiding\neasily predictable literal variations. Experiments reveal that the\nCogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1.\nSemantic variations in object relations are less understood than attributes,\nscoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in\nUNet or Transformers plays a crucial role in handling semantic variations, a\nfactor previously overlooked by a focus on textual encoders. Our work\nestablishes an effective evaluation framework that advances the T2I synthesis\ncommunity's exploration of human instruction understanding. Our benchmark and\ncode are available at https://github.com/zhuxiangru/SemVarBench .", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSemVarEffect\u6307\u6807\u548cSemVarBench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u5408\u6210\u4e2d\u8f93\u5165\u8bed\u4e49\u53d8\u5316\u4e0e\u8f93\u51fa\u56e0\u679c\u5173\u7cfb\u3002", "motivation": "\u5f53\u524d\u6a21\u578b\u96be\u4ee5\u5904\u7406\u8bcd\u5e8f\u53d8\u5316\u5e26\u6765\u7684\u8bed\u4e49\u5dee\u5f02\uff0c\u73b0\u6709\u7684\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u95f4\u63a5\u6307\u6807\uff0c\u96be\u4ee5\u53ef\u9760\u8bc4\u4f30\u590d\u6742\u8bed\u8a00\u6a21\u5f0f\u3002", "method": "\u63d0\u51faSemVarEffect\u6307\u6807\u548cSemVarBench\u57fa\u51c6\uff0c\u901a\u8fc7\u8bed\u8a00\u7f6e\u6362\u5b9e\u73b0\u8bed\u4e49\u53d8\u5316\uff0c\u907f\u514d\u7b80\u5355\u5b57\u9762\u53d8\u5316\u3002", "result": "CogView-3-Plus\u548cIdeogram 2\u5f97\u52060.2/1\uff1b\u5bf9\u8c61\u5173\u7cfb\u7406\u89e3\u5f97\u52060.07/1\uff0c\u5c5e\u6027\u7406\u89e3\u5f97\u52060.17-0.19/1\uff1b\u8de8\u6a21\u6001\u5bf9\u9f50\u5728\u5904\u7406\u8bed\u4e49\u53d8\u5316\u4e2d\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u5efa\u7acb\u4e86\u6709\u6548\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u63a8\u52a8\u6587\u672c\u5230\u56fe\u50cf\u5408\u6210\u793e\u533a\u66f4\u597d\u5730\u7406\u89e3\u4eba\u7c7b\u6307\u4ee4\u3002"}}
{"id": "2504.10797", "pdf": "https://arxiv.org/pdf/2504.10797", "abs": "https://arxiv.org/abs/2504.10797", "authors": ["Annabella Sakunkoo", "Jonathan Sakunkoo"], "title": "Name of Thrones: Evaluating How LLMs Rank Student Names, Race, and Gender in Status Hierarchies", "categories": ["cs.CL", "cs.AI", "cs.HC", "H.5; J.4"], "comment": null, "summary": "Across cultures, names tell a lot about their bearers as they carry deep\npersonal and cultural significance. Names also serve as powerful signals of\ngender, race, and status in the social hierarchy - a pecking order in which\nindividual positions shape others' expectations on their perceived competence\nand worth. With the widespread adoption of LLMs and as names are often an input\nfor LLMs, it is crucial to evaluate whether LLMs may sort people into status\npositions based on first and last names and, if so, whether it is in an unfair,\nbiased fashion. While prior work has primarily investigated biases in first\nnames, little attention has been paid to last names and even less to the\ncombined effects of first and last names. In this study, we conduct a\nlarge-scale analysis of name variations across 5 ethnicities to examine how AI\nexhibits name biases. Our study investigates three key characteristics of\ninequality and finds that LLMs reflect and reinforce status hierarchies based\non names that signal gender and ethnicity as they encode differential\nexpectations of competence, leadership, and economic potential. Contrary to the\ncommon assumption that AI tends to favor Whites, we show that East and, in some\ncontexts, South Asian names receive higher rankings. We also disaggregate\nAsians, a population projected to be the largest immigrant group in the U.S. by\n2055. Our results challenge the monolithic Asian model minority assumption,\nillustrating a more complex and stratified model of bias. Gender moderates\nbiases, with girls facing unfair disadvantages in certain racial groups.\nAdditionally, spanning cultural categories by adopting Western first names\nimproves AI-perceived status for East and Southeast Asian students,\nparticularly for girls. Our findings underscore the importance of\nintersectional and more nuanced understandings of race, gender, and mixed\nidentities in the evaluation of LLMs.", "AI": {"tldr": "This paper examines how large language models (LLMs) exhibit biases based on first and last names across ethnicities and genders, revealing complex status hierarchies and the impact of name choices.", "motivation": "To evaluate whether LLMs unfairly sort individuals into status positions based on names that signal gender, race, and status, given their widespread use.", "method": "Large-scale analysis of name variations across 5 ethnicities to investigate inequality characteristics in LLMs.", "result": "LLMs reflect status hierarchies; East and South Asian names sometimes rank higher; gender moderates biases, disadvantaging girls in some groups; adopting Western names improves perceived status for certain Asian individuals.", "conclusion": "Emphasizes the need for intersectional understandings of race, gender, and identities in LLM evaluation to address biases."}}
{"id": "2504.10810", "pdf": "https://arxiv.org/pdf/2504.10810", "abs": "https://arxiv.org/abs/2504.10810", "authors": ["Anmol Singhal Navya Singhal"], "title": "PatrolVision: Automated License Plate Recognition in the wild", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted in IEEE Southeast Con 2025. To be published in IEEEXplore", "summary": "Adoption of AI driven techniques in public services remains low due to\nchallenges related to accuracy and speed of information at population scale.\nComputer vision techniques for traffic monitoring have not gained much\npopularity despite their relative strength in areas such as autonomous driving.\nDespite large number of academic methods for Automatic License Plate\nRecognition (ALPR) systems, very few provide an end to end solution for\npatrolling in the city. This paper presents a novel prototype for a low power\nGPU based patrolling system to be deployed in an urban environment on\nsurveillance vehicles for automated vehicle detection, recognition and\ntracking. In this work, we propose a complete ALPR system for Singapore license\nplates having both single and double line creating our own YOLO based network.\nWe focus on unconstrained capture scenarios as would be the case in real world\napplication, where the license plate (LP) might be considerably distorted due\nto oblique views. In this work, we first detect the license plate from the full\nimage using RFB-Net and rectify multiple distorted license plates in a single\nimage. After that, the detected license plate image is fed to our network for\ncharacter recognition. We evaluate the performance of our proposed system on a\nnewly built dataset covering more than 16,000 images. The system was able to\ncorrectly detect license plates with 86\\% precision and recognize characters of\na license plate in 67\\% of the test set, and 89\\% accuracy with one incorrect\ncharacter (partial match). We also test latency of our system and achieve 64FPS\non Tesla P4 GPU", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8eYOLO\u7684\u81ea\u52a8\u8f66\u724c\u8bc6\u522b(ALPR)\u7cfb\u7edf\uff0c\u7528\u4e8e\u57ce\u5e02\u5de1\u903b\u8f66\u8f86\uff0c\u9488\u5bf9\u65b0\u52a0\u5761\u8f66\u724c\u7684\u975e\u7ea6\u675f\u573a\u666f\uff0c\u5b9e\u73b0\u4e8686%\u7684\u68c0\u6d4b\u7cbe\u5ea6\u548c67%\u7684\u5b57\u7b26\u8bc6\u522b\u51c6\u786e\u7387\u3002", "motivation": "AI\u5728\u516c\u5171\u670d\u52a1\u4e2d\u7684\u91c7\u7528\u7387\u4f4e\uff0c\u7531\u4e8e\u51c6\u786e\u6027\u548c\u901f\u5ea6\u95ee\u9898\uff1b\u8ba1\u7b97\u673a\u89c6\u89c9\u5728\u4ea4\u901a\u76d1\u63a7\u4e2d\u672a\u666e\u53ca\uff1b\u7f3a\u4e4f\u7aef\u5230\u7aefALPR\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528RFB-Net\u68c0\u6d4b\u5e76\u6821\u6b63\u8f66\u724c\uff0c\u7136\u540e\u91c7\u7528\u81ea\u5b9a\u4e49YOLO\u7f51\u7edc\u8fdb\u884c\u5b57\u7b26\u8bc6\u522b\uff0c\u9488\u5bf9\u5355\u53cc\u884c\u65b0\u52a0\u5761\u8f66\u724c\u7684\u626d\u66f2\u573a\u666f\u3002", "result": "\u68c0\u6d4b\u7cbe\u5ea686%\uff0c\u5b57\u7b26\u8bc6\u522b\u51c6\u786e\u738767%\uff0c\u90e8\u5206\u5339\u914d89%\uff0c\u5ef6\u8fdf64FPS on Tesla P4 GPU\u3002", "conclusion": "\u7cfb\u7edf\u5c55\u793a\u4e86\u5728\u5b9e\u9645\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u7aef\u5230\u7aefALPR\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.10812", "pdf": "https://arxiv.org/pdf/2504.10812", "abs": "https://arxiv.org/abs/2504.10812", "authors": ["Kejia Gao", "Liguo Zhou", "Mingjun Liu", "Alois Knoll"], "title": "E2E Parking Dataset: An Open Benchmark for End-to-End Autonomous Parking", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "End-to-end learning has shown great potential in autonomous parking, yet the\nlack of publicly available datasets limits reproducibility and benchmarking.\nWhile prior work introduced a visual-based parking model and a pipeline for\ndata generation, training, and close-loop test, the dataset itself was not\nreleased. To bridge this gap, we create and open-source a high-quality dataset\nfor end-to-end autonomous parking. Using the original model, we achieve an\noverall success rate of 85.16% with lower average position and orientation\nerrors (0.24 meters and 0.34 degrees).", "AI": {"tldr": "\u672c\u6587\u521b\u5efa\u5e76\u5f00\u6e90\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u81ea\u52a8\u6cca\u8f66\u6570\u636e\u96c6\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u96c6\u7f3a\u5931\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u539f\u6709\u6a21\u578b\u5b9e\u73b0\u4e8685.16%\u7684\u6210\u529f\u7387\u548c\u4f4e\u8bef\u5dee\u3002", "motivation": "\u7f3a\u4e4f\u516c\u5f00\u53ef\u7528\u7684\u6570\u636e\u96c6\u9650\u5236\u4e86\u518d\u73b0\u6027\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u57fa\u4e8e\u539f\u6709\u6a21\u578b\u548c\u6570\u636e\u751f\u6210\u3001\u8bad\u7ec3\u3001\u95ed\u73af\u6d4b\u8bd5\u7684\u7ba1\u9053\u3002", "result": "\u5b9e\u73b0\u4e8685.16%\u7684\u6574\u4f53\u6210\u529f\u7387\uff0c\u5e73\u5747\u4f4d\u7f6e\u8bef\u5dee0.24\u7c73\uff0c\u65b9\u5411\u8bef\u5dee0.34\u5ea6\u3002", "conclusion": "\u8fd9\u4e2a\u6570\u636e\u96c6\u586b\u8865\u4e86\u7a7a\u767d\uff0c\u4fc3\u8fdb\u4e86\u81ea\u52a8\u6cca\u8f66\u7814\u7a76\u7684\u518d\u73b0\u6027\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2504.10507", "pdf": "https://arxiv.org/pdf/2504.10507", "abs": "https://arxiv.org/abs/2504.10507", "authors": ["Anirudhan Badrinath", "Prabhat Agarwal", "Laksh Bhasin", "Jaewon Yang", "Jiajing Xu", "Charles Rosenberg"], "title": "PinRec: Outcome-Conditioned, Multi-Token Generative Retrieval for Industry-Scale Recommendation Systems", "categories": ["cs.IR", "cs.LG"], "comment": "Submitted to KDD ADS 2025", "summary": "Generative retrieval methods utilize generative sequential modeling\ntechniques, such as transformers, to generate candidate items for recommender\nsystems. These methods have demonstrated promising results in academic\nbenchmarks, surpassing traditional retrieval models like two-tower\narchitectures. However, current generative retrieval methods lack the\nscalability required for industrial recommender systems, and they are\ninsufficiently flexible to satisfy the multiple metric requirements of modern\nsystems.\n  This paper introduces PinRec, a novel generative retrieval model developed\nfor applications at Pinterest. PinRec utilizes outcome-conditioned generation,\nenabling modelers to specify how to balance various outcome metrics, such as\nthe number of saves and clicks, to effectively align with business goals and\nuser exploration. Additionally, PinRec incorporates multi-token generation to\nenhance output diversity while optimizing generation. Our experiments\ndemonstrate that PinRec can successfully balance performance, diversity, and\nefficiency, delivering a significant positive impact to users using generative\nmodels. This paper marks a significant milestone in generative retrieval, as it\npresents, to our knowledge, the first rigorous study on implementing generative\nretrieval at the scale of Pinterest.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86PinRec\uff0c\u4e00\u79cd\u7528\u4e8ePinterest\u7684\u751f\u6210\u5f0f\u68c0\u7d22\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u679c\u6761\u4ef6\u751f\u6210\u548c\u591a\u6807\u8bb0\u751f\u6210\uff0c\u63d0\u9ad8\u4e86\u53ef\u4f38\u7f29\u6027\u3001\u7075\u6d3b\u6027\u548c\u6307\u6807\u5e73\u8861\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u5f0f\u68c0\u7d22\u65b9\u6cd5\u7f3a\u4e4f\u5de5\u4e1a\u7ea7\u53ef\u4f38\u7f29\u6027\u548c\u7075\u6d3b\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u73b0\u4ee3\u63a8\u8350\u7cfb\u7edf\u7684\u591a\u6307\u6807\u9700\u6c42\u3002", "method": "\u5f15\u5165PinRec\uff0c\u4f7f\u7528\u7ed3\u679c\u6761\u4ef6\u751f\u6210\u6765\u5e73\u8861\u6307\u6807\uff08\u5982\u4fdd\u5b58\u548c\u70b9\u51fb\u6b21\u6570\uff09\uff0c\u5e76\u91c7\u7528\u591a\u6807\u8bb0\u751f\u6210\u4f18\u5316\u8f93\u51fa\u591a\u6837\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660ePinRec\u5728\u6027\u80fd\u3001\u591a\u6837\u6027\u548c\u6548\u7387\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u5bf9\u7528\u6237\u4ea7\u751f\u79ef\u6781\u5f71\u54cd\uff0c\u662f\u9996\u4e2a\u5728Pinterest\u89c4\u6a21\u4e0a\u5b9e\u65bd\u751f\u6210\u5f0f\u68c0\u7d22\u7684\u4e25\u8c28\u7814\u7a76\u3002", "conclusion": "\u8fd9\u6807\u5fd7\u7740\u751f\u6210\u5f0f\u68c0\u7d22\u9886\u57df\u7684\u4e00\u4e2a\u91cd\u8981\u91cc\u7a0b\u7891\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.10821", "pdf": "https://arxiv.org/pdf/2504.10821", "abs": "https://arxiv.org/abs/2504.10821", "authors": ["Arpan Nagar", "Joseph Bensabat", "Jokent Gaza", "Moinak Dey"], "title": "Progressive Rock Music Classification", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "20 pages", "summary": "This study investigates the classification of progressive rock music, a genre\ncharacterized by complex compositions and diverse instrumentation, distinct\nfrom other musical styles. Addressing this Music Information Retrieval (MIR)\ntask, we extracted comprehensive audio features, including spectrograms,\nMel-Frequency Cepstral Coefficients (MFCCs), chromagrams, and beat positions\nfrom song snippets using the Librosa library. A winner-take-all voting strategy\nwas employed to aggregate snippet-level predictions into final song\nclassifications. We conducted a comparative analysis of various machine\nlearning techniques. Ensemble methods, encompassing Bagging (Random Forest,\nExtraTrees, Bagging Classifier) and Boosting (XGBoost, Gradient Boosting), were\nexplored, utilizing Principal Component Analysis (PCA) for dimensionality\nreduction to manage computational constraints with high-dimensional feature\nsets. Additionally, deep learning approaches were investigated, including the\ndevelopment of custom 1D Convolutional Neural Network (1D CNN) architectures\n(named \"Zuck\" and \"Satya\") featuring specific layer configurations,\nnormalization, and activation functions. Furthermore, we fine-tuned a\nstate-of-the-art Audio Spectrogram Transformer (AST) model, leveraging its\nattention-based mechanisms for audio classification. Performance evaluation on\nvalidation and test sets revealed varying effectiveness across models, with\nensemble methods like Extra Trees achieving test accuracies up to 76.38%. This\nresearch provides insights into the application and relative performance of\ndiverse machine learning paradigms for the nuanced task of progressive rock\ngenre classification.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u5404\u79cd\u673a\u5668\u5b66\u4e60\u6280\u672f\u5bf9\u524d\u536b\u6447\u6eda\u97f3\u4e50\u8fdb\u884c\u5206\u7c7b\uff0c\u6700\u9ad8\u51c6\u786e\u7387\u8fbe76.38%\u3002", "motivation": "\u89e3\u51b3\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u4e2d\u524d\u536b\u6447\u6eda\u97f3\u4e50\u5206\u7c7b\u7684\u6311\u6218\uff0c\u8be5\u6d41\u6d3e\u5177\u6709\u590d\u6742\u4f5c\u66f2\u548c\u591a\u6837\u4e50\u5668\u3002", "method": "\u63d0\u53d6\u97f3\u9891\u7279\u5f81\uff08\u5982\u9891\u8c31\u56fe\u3001MFCC\u7b49\uff09\uff0c\u91c7\u7528\u6295\u7968\u7b56\u7565\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff08\u96c6\u6210\u5982Bagging\u3001Boosting\u548c\u6df1\u5ea6\u5b66\u4e60\u59821D CNN\u3001AST\uff09\uff0c\u5e76\u7528PCA\u964d\u7ef4\u3002", "result": "Extra Trees\u7b49\u6a21\u578b\u6d4b\u8bd5\u51c6\u786e\u7387\u8fbe76.38%\uff0c\u5176\u4ed6\u6a21\u578b\u6027\u80fd\u5404\u5f02\u3002", "conclusion": "\u4e3a\u524d\u536b\u6447\u6eda\u97f3\u4e50\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u5e94\u7528\u6d1e\u5bdf\u548c\u6027\u80fd\u6bd4\u8f83\u3002"}}
{"id": "2504.10823", "pdf": "https://arxiv.org/pdf/2504.10823", "abs": "https://arxiv.org/abs/2504.10823", "authors": ["Ayoung Lee", "Ryan Sungmo Kwon", "Peter Railton", "Lu Wang"], "title": "CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from Multiple Perspectives", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Navigating high-stakes dilemmas involving conflicting values is challenging\neven for humans, let alone for AI. Yet prior work in evaluating the reasoning\ncapabilities of large language models (LLMs) in such situations has been\nlimited to everyday scenarios. To close this gap, this work first introduces\nCLASH (Character perspective-based LLM Assessments in Situations with\nHigh-stakes), a meticulously curated dataset consisting of 345 high-impact\ndilemmas along with 3,795 individual perspectives of diverse values. In\nparticular, we design CLASH in a way to support the study of critical aspects\nof value-based decision-making processes which are missing from prior work,\nincluding understanding decision ambivalence and psychological discomfort as\nwell as capturing the temporal shifts of values in characters' perspectives. By\nbenchmarking 10 open and closed frontier models, we uncover several key\nfindings. (1) Even the strongest models, such as GPT-4o and Claude-Sonnet,\nachieve less than 50% accuracy in identifying situations where the decision\nshould be ambivalent, while they perform significantly better in clear-cut\nscenarios. (2) While LLMs reasonably predict psychological discomfort as marked\nby human, they inadequately comprehend perspectives involving value shifts,\nindicating a need for LLMs to reason over complex values. (3) Our experiments\nalso reveal a significant correlation between LLMs' value preferences and their\nsteerability towards a given value. (4) Finally, LLMs exhibit greater\nsteerability when engaged in value reasoning from a third-party perspective,\ncompared to a first-person setup, though certain value pairs benefit uniquely\nfrom the first-person framing.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f15\u5165CLASH\u6570\u636e\u96c6\u8bc4\u4f30LLM\u5728\u9ad8\u98ce\u9669\u4ef7\u503c\u51b2\u7a81\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u6a21\u7cca\u51b3\u7b56\u548c\u4ef7\u503c\u8f6c\u53d8\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "motivation": "\u586b\u8865\u73b0\u6709\u5de5\u4f5c\u5bf9LLM\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u4f30\u7a7a\u767d\uff0c\u7279\u522b\u662f\u5904\u7406\u51b3\u7b56\u6a21\u7cca\u6027\u3001\u5fc3\u7406\u4e0d\u9002\u548c\u4ef7\u503c\u8f6c\u53d8\u3002", "method": "\u5f15\u5165CLASH\u6570\u636e\u96c6\uff08345\u4e2a\u56f0\u5883\u30013795\u4e2a\u89c6\u89d2\uff09\uff0c\u5e76\u5bf910\u4e2aLLM\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u6a21\u578b\u5728\u6a21\u7cca\u51b3\u7b56\u51c6\u786e\u7387\u4e0d\u8db350%\uff1b\u80fd\u9884\u6d4b\u5fc3\u7406\u4e0d\u9002\u4f46\u5904\u7406\u4ef7\u503c\u8f6c\u53d8\u5dee\uff1b\u4ef7\u503c\u504f\u597d\u4e0e\u53ef\u64cd\u63a7\u6027\u76f8\u5173\uff1b\u7b2c\u4e09\u65b9\u89c6\u89d2\u4e0b\u53ef\u64cd\u63a7\u6027\u66f4\u5f3a\u3002", "conclusion": "LLM\u9700\u6539\u8fdb\u590d\u6742\u4ef7\u503c\u63a8\u7406\uff0c\u4e0d\u540c\u89c6\u89d2\u53ef\u63d0\u5347\u53ef\u64cd\u63a7\u6027\u3002"}}
{"id": "2504.10836", "pdf": "https://arxiv.org/pdf/2504.10836", "abs": "https://arxiv.org/abs/2504.10836", "authors": ["Yiran Guo", "Wei Chen", "Bo Ai"], "title": "Uplink Assisted Joint Channel Estimation and CSI Feedback: An Approach Based on Deep Joint Source-Channel Coding", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "In frequency division duplex (FDD) multiple-input multiple-output (MIMO)\nwireless communication systems, the acquisition of downlink channel state\ninformation (CSI) is essential for maximizing spatial resource utilization and\nimproving system spectral efficiency. The separate design of modules in\nAI-based CSI feedback architectures under traditional modular communication\nframeworks, including channel estimation (CE), CSI compression and feedback,\nleads to sub-optimal performance. In this paper, we propose an uplink assisted\njoint CE and and CSI feedback approach via deep learning for downlink CSI\nacquisition, which mitigates performance degradation caused by distribution\nbias across separately trained modules in traditional modular communication\nframeworks. The proposed network adopts a deep joint source-channel coding\n(DJSCC) architecture to mitigate the cliff effect encountered in the\nconventional separate source-channel coding. Furthermore, we exploit the uplink\nCSI as auxiliary information to enhance CSI reconstruction accuracy by\nleveraging the partial reciprocity between the uplink and downlink channels in\nFDD systems, without introducing additional overhead. The effectiveness of\nuplink CSI as assisted information and the necessity of an end-toend\nmulti-module joint training architecture is validated through comprehensive\nablation and scalability experiments.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8054\u5408\u4fe1\u9053\u4f30\u8ba1\u548cCSI\u53cd\u9988\u65b9\u6cd5\uff0c\u7528\u4e8eFDD MIMO\u7cfb\u7edf\uff0c\u901a\u8fc7\u5229\u7528\u4e0a\u884c\u94fe\u8defCSI\u6539\u5584\u4e0b\u884c\u94fe\u8defCSI\u83b7\u53d6\uff0c\u800c\u4e0d\u589e\u52a0\u989d\u5916\u5f00\u9500\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u6a21\u5757\u5316\u901a\u4fe1\u6846\u67b6\u4e2d\u6a21\u5757\u5206\u79bb\u8bbe\u8ba1\u5bfc\u81f4\u7684\u6027\u80fd\u6b21\u4f18\u548c\u5206\u5e03\u504f\u5dee\u95ee\u9898\uff0c\u4ee5\u6700\u5927\u5316\u7a7a\u95f4\u8d44\u6e90\u5229\u7528\u548c\u63d0\u9ad8\u7cfb\u7edf\u9891\u8c31\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e0a\u884c\u8f85\u52a9\u7684\u8054\u5408CE\u548cCSI\u53cd\u9988\u65b9\u6cd5\uff0c\u4f7f\u7528\u6df1\u5ea6\u8054\u5408\u6e90-\u4fe1\u9053\u7f16\u7801\uff08DJSCC\uff09\u67b6\u6784\u548c\u7aef\u5230\u7aef\u591a\u6a21\u5757\u8054\u5408\u8bad\u7ec3\uff0c\u501f\u52a9\u4e0a\u884c\u94fe\u8defCSI\u4f5c\u4e3a\u8f85\u52a9\u4fe1\u606f\u3002", "result": "\u901a\u8fc7\u6d88\u878d\u548c\u53ef\u4f38\u7f29\u6027\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e0a\u884cCSI\u4f5c\u4e3a\u8f85\u52a9\u4fe1\u606f\u7684\u6709\u6548\u6027\u548c\u7aef\u5230\u7aef\u8054\u5408\u8bad\u7ec3\u67b6\u6784\u7684\u5fc5\u8981\u6027\uff0c\u63d0\u9ad8\u4e86CSI\u91cd\u5efa\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u51cf\u8f7b\u4e86\u4f20\u7edf\u6846\u67b6\u4e0b\u7684\u6027\u80fd\u9000\u5316\uff0c\u5229\u7528\u90e8\u5206\u4fe1\u9053\u4e92\u6613\u6027\u6539\u5584\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2504.10839", "pdf": "https://arxiv.org/pdf/2504.10839", "abs": "https://arxiv.org/abs/2504.10839", "authors": ["Qiaosi Wang", "Xuhui Zhou", "Maarten Sap", "Jodi Forlizzi", "Hong Shen"], "title": "Rethinking Theory of Mind Benchmarks for LLMs: Towards A User-Centered Perspective", "categories": ["cs.HC", "cs.AI"], "comment": "7 pages, 1 figure, accepted to the HEAL@CHI 2025 Workshop", "summary": "The last couple of years have witnessed emerging research that appropriates\nTheory-of-Mind (ToM) tasks designed for humans to benchmark LLM's ToM\ncapabilities as an indication of LLM's social intelligence. However, this\napproach has a number of limitations. Drawing on existing psychology and AI\nliterature, we summarize the theoretical, methodological, and evaluation\nlimitations by pointing out that certain issues are inherently present in the\noriginal ToM tasks used to evaluate human's ToM, which continues to persist and\nexacerbated when appropriated to benchmark LLM's ToM. Taking a human-computer\ninteraction (HCI) perspective, these limitations prompt us to rethink the\ndefinition and criteria of ToM in ToM benchmarks in a more dynamic,\ninteractional approach that accounts for user preferences, needs, and\nexperiences with LLMs in such evaluations. We conclude by outlining potential\nopportunities and challenges towards this direction.", "AI": {"tldr": "\u672c\u6587\u6279\u8bc4\u4e86\u4f7f\u7528\u4eba\u7c7bToM\u4efb\u52a1\u8bc4\u4f30LLM\u793e\u4f1a\u667a\u80fd\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4eceHCI\u89c6\u89d2\u63d0\u51fa\u66f4\u52a8\u6001\u7684\u4ea4\u4e92\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u52a8\u673a\u662f\u9488\u5bf9\u5f53\u524dToM\u57fa\u51c6\u8bc4\u4f30LLM\u7684\u7406\u8bba\u3001\u65b9\u6cd5\u8bba\u548c\u8bc4\u4f30\u95ee\u9898\uff0c\u901a\u8fc7\u5fc3\u7406\u5b66\u548cAI\u6587\u732e\u8fdb\u884c\u603b\u7ed3\uff0c\u4ee5\u6539\u8fdb\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u65b9\u6cd5\u662f\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u5206\u6790ToM\u4efb\u52a1\u7684\u5c40\u9650\u6027\uff0c\u5e76\u91c7\u7528HCI\u89c6\u89d2\u91cd\u65b0\u5b9a\u4e49ToM\u57fa\u51c6\u3002", "result": "\u7ed3\u679c\u662f\u8bc6\u522b\u4e86\u8fd9\u4e9b\u5c40\u9650\u6027\uff0c\u5e76\u5efa\u8bae\u5728\u8bc4\u4f30\u4e2d\u8003\u8651\u7528\u6237\u504f\u597d\u3001\u9700\u6c42\u548c\u4f53\u9a8c\u3002", "conclusion": "\u7ed3\u8bba\u662f\u6982\u8ff0\u4e86\u671d\u52a8\u6001\u4ea4\u4e92\u65b9\u5411\u7684\u6f5c\u5728\u673a\u4f1a\u548c\u6311\u6218\u3002"}}
{"id": "2504.10542", "pdf": "https://arxiv.org/pdf/2504.10542", "abs": "https://arxiv.org/abs/2504.10542", "authors": ["Federico Tiblias", "Anna Schroeder", "Yue Zhang", "Mariami Gachechiladze", "Iryna Gurevych"], "title": "An Efficient Quantum Classifier Based on Hamiltonian Representations", "categories": ["quant-ph", "cs.ET", "cs.LG"], "comment": null, "summary": "Quantum machine learning (QML) is a discipline that seeks to transfer the\nadvantages of quantum computing to data-driven tasks. However, many studies\nrely on toy datasets or heavy feature reduction, raising concerns about their\nscalability. Progress is further hindered by hardware limitations and the\nsignificant costs of encoding dense vector representations on quantum devices.\nTo address these challenges, we propose an efficient approach called\nHamiltonian classifier that circumvents the costs associated with data encoding\nby mapping inputs to a finite set of Pauli strings and computing predictions as\ntheir expectation values. In addition, we introduce two classifier variants\nwith different scaling in terms of parameters and sample complexity. We\nevaluate our approach on text and image classification tasks, against\nwell-established classical and quantum models. The Hamiltonian classifier\ndelivers performance comparable to or better than these methods. Notably, our\nmethod achieves logarithmic complexity in both qubits and quantum gates, making\nit well-suited for large-scale, real-world applications. We make our\nimplementation available on GitHub.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHamiltonian classifier\u65b9\u6cd5\uff0c\u89e3\u51b3\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5e76\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7814\u7a76\u4f9d\u8d56\u73a9\u5177\u6570\u636e\u96c6\u6216\u7279\u5f81\u51cf\u5c11\uff0c\u5b58\u5728\u53ef\u6269\u5c55\u6027\u62c5\u5fe7\uff0c\u4e14\u53d7\u786c\u4ef6\u9650\u5236\u548c\u6570\u636e\u7f16\u7801\u6210\u672c\u5f71\u54cd\u3002", "method": "\u63d0\u51faHamiltonian classifier\uff0c\u901a\u8fc7\u5c06\u8f93\u5165\u6620\u5c04\u5230Pauli\u5b57\u7b26\u4e32\u5e76\u8ba1\u7b97\u671f\u671b\u503c\uff0c\u907f\u514d\u6570\u636e\u7f16\u7801\u6210\u672c\uff1b\u5f15\u5165\u4e24\u4e2a\u5206\u7c7b\u5668\u53d8\u4f53\u3002", "result": "\u5728\u6587\u672c\u548c\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0c\u6027\u80fd\u4e0e\u7ecf\u5178\u548c\u91cf\u5b50\u6a21\u578b\u76f8\u5f53\u6216\u66f4\u597d\uff1b\u590d\u6742\u5ea6\u4e3a\u5bf9\u6570\u7ea7\u522b\uff0c\u9002\u5408\u5927\u89c4\u6a21\u5e94\u7528\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u4e14\u9ad8\u6548\uff0c\u5e76\u63d0\u4f9b\u5f00\u6e90\u5b9e\u73b0\u3002"}}
{"id": "2504.10845", "pdf": "https://arxiv.org/pdf/2504.10845", "abs": "https://arxiv.org/abs/2504.10845", "authors": ["Phill Kyu Rhee"], "title": "Moving Beyond Next-Token Prediction: Transformers are Context-Sensitive Language Generators", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 2 figures", "summary": "Large Language Models (LLMs), powered by Transformers, have demonstrated\nhuman-like intelligence capabilities, yet their underlying mechanisms remain\npoorly understood. This paper presents a novel framework for interpreting LLMs\nas probabilistic left context-sensitive languages (CSLs) generators. We\nhypothesize that Transformers can be effectively decomposed into three\nfundamental components: context windows, attention mechanisms, and\nautoregressive generation frameworks. This decomposition allows for the\ndevelopment of more flexible and interpretable computational models, moving\nbeyond the traditional view of attention and autoregression as inseparable\nprocesses. We argue that next-token predictions can be understood as\nprobabilistic, dynamic approximations of left CSL production rules, providing\nan intuitive explanation for how simple token predictions can yield human-like\nintelligence outputs. Given that all CSLs are left context-sensitive\n(Penttonen, 1974), we conclude that Transformers stochastically approximate\nCSLs, which are widely recognized as models of human-like intelligence. This\ninterpretation bridges the gap between Formal Language Theory and the observed\ngenerative power of Transformers, laying a foundation for future advancements\nin generative AI theory and applications. Our novel perspective on Transformer\narchitectures will foster a deeper understanding of LLMs and their future\npotentials.", "AI": {"tldr": "This paper proposes a framework interpreting Large Language Models as probabilistic left context-sensitive language generators to better understand Transformer mechanisms.", "motivation": "To address the poor understanding of the underlying mechanisms of Large Language Models.", "method": "Decomposing Transformers into context windows, attention mechanisms, and autoregressive generation, interpreting next-token predictions as probabilistic CSL production rules.", "result": "Transformers stochastically approximate context-sensitive languages, bridging Formal Language Theory and LLM generative capabilities.", "conclusion": "Transformers model human-like intelligence through CSL approximation, fostering advancements in generative AI theory and applications."}}
{"id": "2504.10545", "pdf": "https://arxiv.org/pdf/2504.10545", "abs": "https://arxiv.org/abs/2504.10545", "authors": ["Yijun Liu"], "title": "Integrating Textual Embeddings from Contrastive Learning with Generative Recommender for Enhanced Personalization", "categories": ["cs.IR", "cs.LG"], "comment": "Code available at https://www.github.com/snapfinger/HSTU-BLaIR", "summary": "Recent advances in recommender systems have highlighted the complementary\nstrengths of generative modeling and pretrained language models. We propose a\nhybrid framework that augments the Hierarchical Sequential Transduction Unit\n(HSTU) generative recommender with BLaIR -- a contrastive text embedding model.\nThis integration enriches item representations with semantic signals from\ntextual metadata while preserving HSTU's powerful sequence modeling\ncapabilities.\n  We evaluate our method on two domains from the Amazon Reviews 2023 dataset,\ncomparing it against the original HSTU and a variant that incorporates\nembeddings from OpenAI's state-of-the-art text-embedding-3-large model. While\nthe OpenAI embedding model is likely trained on a substantially larger corpus\nwith significantly more parameters, our lightweight BLaIR-enhanced approach --\npretrained on domain-specific data -- consistently achieves better performance,\nhighlighting the effectiveness of contrastive text embeddings in\ncompute-efficient settings.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408HSTU\u751f\u6210\u63a8\u8350\u5668\u548cBLaIR\u5bf9\u6bd4\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u6df7\u5408\u6846\u67b6\uff0c\u63d0\u9ad8\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u6700\u8fd1\u63a8\u8350\u7cfb\u7edf\u7684\u8fdb\u5c55\u7a81\u51fa\u4e86\u751f\u6210\u6a21\u578b\u548c\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u65e8\u5728\u6574\u5408\u8fd9\u4e9b\u4f18\u52bf\u4ee5\u63d0\u5347\u63a8\u8350\u6548\u679c\u3002", "method": "\u65b9\u6cd5\u662f\u5c06BLaIR\u5bf9\u6bd4\u6587\u672c\u5d4c\u5165\u6a21\u578b\u589e\u5f3a\u5230HSTU\u4e2d\uff0c\u5e76\u5728Amazon Reviews 2023\u6570\u636e\u96c6\u7684\u4e24\u4e2a\u9886\u57df\u4e0a\u8bc4\u4f30\uff0c\u4e0e\u539fHSTU\u548cOpenAI\u7684text-embedding-3-large\u6a21\u578b\u6bd4\u8f83\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0cBLaIR\u589e\u5f3a\u7684\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u8bbe\u7f6e\u4e2d\u53d6\u5f97\u4e86\u6bd4\u539fHSTU\u548cOpenAI\u6a21\u578b\u66f4\u597d\u7684\u6027\u80fd\uff0c\u5c3d\u7ba1BLaIR\u662f\u57fa\u4e8e\u9886\u57df\u7279\u5b9a\u6570\u636e\u9884\u8bad\u7ec3\u7684\u8f7b\u91cf\u7ea7\u6a21\u578b\u3002", "conclusion": "\u8fd9\u7a81\u51fa\u4e86\u5bf9\u6bd4\u6587\u672c\u5d4c\u5165\u5728\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2504.10873", "pdf": "https://arxiv.org/pdf/2504.10873", "abs": "https://arxiv.org/abs/2504.10873", "authors": ["Tonko E. W. Bossen", "Andreas M\u00f8gelmose", "Ross Greer"], "title": "Can Vision-Language Models Understand and Interpret Dynamic Gestures from Pedestrians? Pilot Datasets and Exploration Towards Instructive Nonverbal Commands for Cooperative Autonomous Vehicles", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": null, "summary": "In autonomous driving, it is crucial to correctly interpret traffic gestures\n(TGs), such as those of an authority figure providing orders or instructions,\nor a pedestrian signaling the driver, to ensure a safe and pleasant traffic\nenvironment for all road users. This study investigates the capabilities of\nstate-of-the-art vision-language models (VLMs) in zero-shot interpretation,\nfocusing on their ability to caption and classify human gestures in traffic\ncontexts. We create and publicly share two custom datasets with varying formal\nand informal TGs, such as 'Stop', 'Reverse', 'Hail', etc. The datasets are\n\"Acted TG (ATG)\" and \"Instructive TG In-The-Wild (ITGI)\". They are annotated\nwith natural language, describing the pedestrian's body position and gesture.\nWe evaluate models using three methods utilizing expert-generated captions as\nbaseline and control: (1) caption similarity, (2) gesture classification, and\n(3) pose sequence reconstruction similarity. Results show that current VLMs\nstruggle with gesture understanding: sentence similarity averages below 0.59,\nand classification F1 scores reach only 0.14-0.39, well below the expert\nbaseline of 0.70. While pose reconstruction shows potential, it requires more\ndata and refined metrics to be reliable. Our findings reveal that although some\nSOTA VLMs can interpret zero-shot human traffic gestures, none are accurate and\nrobust enough to be trustworthy, emphasizing the need for further research in\nthis domain.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u4ea4\u901a\u624b\u52bf\u89e3\u91ca\u4e2d\u7684\u80fd\u529b\uff0c\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u6d4b\u8bd5\u5176\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u6b63\u786e\u89e3\u91ca\u4ea4\u901a\u624b\u52bf\u5bf9\u4e8e\u81ea\u52a8\u9a7e\u9a76\u7684\u5b89\u5168\u548c\u8212\u9002\u81f3\u5173\u91cd\u8981\uff0c\u5305\u62ec\u6743\u5a01\u6307\u4ee4\u6216\u884c\u4eba\u4fe1\u53f7\u3002", "method": "\u521b\u5efa\u4e86\u4e24\u4e2a\u6570\u636e\u96c6\uff08ATG\u548cITGI\uff09\uff0c\u4f7f\u7528\u4e13\u5bb6\u751f\u6210\u7684\u6807\u9898\u4f5c\u4e3a\u57fa\u51c6\uff0c\u901a\u8fc7\u6807\u9898\u76f8\u4f3c\u5ea6\u3001\u624b\u52bf\u5206\u7c7b\u548c\u59ff\u52bf\u5e8f\u5217\u91cd\u5efa\u76f8\u4f3c\u5ea6\u4e09\u79cd\u65b9\u6cd5\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5f53\u524dVLMs\u5728\u624b\u52bf\u7406\u89e3\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u53e5\u5b50\u76f8\u4f3c\u5ea6\u5e73\u5747\u4f4e\u4e8e0.59\uff0c\u5206\u7c7bF1\u5206\u6570\u4ec5\u4e3a0.14-0.39\uff0c\u8fdc\u4f4e\u4e8e\u4e13\u5bb6\u57fa\u51c60.70\uff1b\u59ff\u52bf\u91cd\u5efa\u6709\u6f5c\u529b\u4f46\u9700\u66f4\u591a\u6570\u636e\u548c\u6539\u8fdb\u3002", "conclusion": "\u7ed3\u8bba\u662f\u5f53\u524dSOTA VLMs\u65e0\u6cd5\u51c6\u786e\u53ef\u9760\u5730\u89e3\u91ca\u4ea4\u901a\u624b\u52bf\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u63d0\u5347\u5176\u9c81\u68d2\u6027\u3002"}}
{"id": "2504.10550", "pdf": "https://arxiv.org/pdf/2504.10550", "abs": "https://arxiv.org/abs/2504.10550", "authors": ["Daniel Kyselica", "Tom\u00e1\u0161 Hrob\u00e1r", "Ji\u0159\u00ed \u0160ilha", "Roman \u010eurikovi\u010d", "Marek \u0160uppa"], "title": "LCDC: Bridging Science and Machine Learning for Light Curve Analysis", "categories": ["astro-ph.IM", "astro-ph.EP", "cs.LG"], "comment": "13 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:2412.00544", "summary": "The characterization and analysis of light curves are vital for understanding\nthe physical and rotational properties of artificial space objects such as\nsatellites, rocket stages, and space debris. This paper introduces the Light\nCurve Dataset Creator (LCDC), a Python-based toolkit designed to facilitate the\npreprocessing, analysis, and machine learning applications of light curve data.\nLCDC enables seamless integration with publicly available datasets, such as the\nnewly introduced Mini Mega Tortora (MMT) database. Moreover, it offers data\nfiltering, transformation, as well as feature extraction tooling. To\ndemonstrate the toolkit's capabilities, we created the first standardized\ndataset for rocket body classification, RoBo6, which was used to train and\nevaluate several benchmark machine learning models, addressing the lack of\nreproducibility and comparability in recent studies. Furthermore, the toolkit\nenables advanced scientific analyses, such as surface characterization of the\nAtlas 2AS Centaur and the rotational dynamics of the Delta 4 rocket body, by\nstreamlining data preprocessing, feature extraction, and visualization. These\nuse cases highlight LCDC's potential to advance space debris characterization\nand promote sustainable space exploration. Additionally, they highlight the\ntoolkit's ability to enable AI-focused research within the space debris\ncommunity.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86Light Curve Dataset Creator (LCDC)\uff0c\u4e00\u4e2aPython\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u5904\u7406\u7a7a\u95f4\u7269\u4f53\u5149\u53d8\u66f2\u7ebf\u6570\u636e\uff0c\u5305\u62ec\u9884\u5904\u7406\u3001\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u5e94\u7528\uff0c\u5e76\u521b\u5efa\u4e86RoBo6\u6570\u636e\u96c6\u7528\u4e8e\u706b\u7bad\u4f53\u5206\u7c7b\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u4eba\u5de5\u7a7a\u95f4\u7269\u4f53\u7684\u7269\u7406\u548c\u65cb\u8f6c\u7279\u6027\uff0c\u5e76\u89e3\u51b3\u5149\u53d8\u66f2\u7ebf\u5206\u6790\u7814\u7a76\u4e2d\u518d\u73b0\u6027\u548c\u53ef\u6bd4\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1LCDC\u5de5\u5177\u5305\uff0c\u652f\u6301\u6570\u636e\u8fc7\u6ee4\u3001\u8f6c\u6362\u3001\u7279\u5f81\u63d0\u53d6\uff0c\u5e76\u4e0e\u516c\u5f00\u6570\u636e\u96c6\u96c6\u6210\uff1b\u521b\u5efaRoBo6\u6807\u51c6\u5316\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u6210\u529f\u521b\u5efaRoBo6\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u5e76\u8bc4\u4f30\u4e86\u591a\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff1b\u5bf9Atlas 2AS Centaur\u548cDelta 4\u706b\u7bad\u4f53\u8fdb\u884c\u4e86\u8868\u9762\u7279\u5f81\u548c\u65cb\u8f6c\u52a8\u529b\u5b66\u5206\u6790\u3002", "conclusion": "LCDC\u5de5\u5177\u5305\u63a8\u8fdb\u4e86\u7a7a\u95f4\u788e\u7247\u8868\u5f81\u7814\u7a76\uff0c\u4fc3\u8fdb\u53ef\u6301\u7eed\u7a7a\u95f4\u63a2\u7d22\uff0c\u5e76\u652f\u6301\u7a7a\u95f4\u788e\u7247\u793e\u533a\u7684AI\u7814\u7a76\u3002"}}
{"id": "2504.10878", "pdf": "https://arxiv.org/pdf/2504.10878", "abs": "https://arxiv.org/abs/2504.10878", "authors": ["Yilang Peng", "Sijia Qian", "Yingdan Lu", "Cuihua Shen"], "title": "Large Language Model-Informed Feature Discovery Improves Prediction and Interpretation of Credibility Perceptions of Visual Content", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.4.9; J.4"], "comment": "26 pages", "summary": "In today's visually dominated social media landscape, predicting the\nperceived credibility of visual content and understanding what drives human\njudgment are crucial for countering misinformation. However, these tasks are\nchallenging due to the diversity and richness of visual features. We introduce\na Large Language Model (LLM)-informed feature discovery framework that\nleverages multimodal LLMs, such as GPT-4o, to evaluate content credibility and\nexplain its reasoning. We extract and quantify interpretable features using\ntargeted prompts and integrate them into machine learning models to improve\ncredibility predictions. We tested this approach on 4,191 visual social media\nposts across eight topics in science, health, and politics, using credibility\nratings from 5,355 crowdsourced workers. Our method outperformed zero-shot\nGPT-based predictions by 13 percent in R2, and revealed key features like\ninformation concreteness and image format. We discuss the implications for\nmisinformation mitigation, visual credibility, and the role of LLMs in social\nscience.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4f7f\u7528LLM\u9884\u6d4b\u89c6\u89c9\u5185\u5bb9\u53ef\u4fe1\u5ea6\u5e76\u89e3\u91ca\u539f\u56e0\u7684\u6846\u67b6\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5e2e\u52a9\u5bf9\u6297\u9519\u8bef\u4fe1\u606f\u3002", "motivation": "\u5728\u89c6\u89c9\u4e3b\u5bfc\u7684\u793e\u4ea4\u5a92\u4f53\u4e2d\uff0c\u53cd\u5bf9\u9519\u8bef\u4fe1\u606f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u89c6\u89c9\u7279\u5f81\u7684\u591a\u6837\u6027\u4f7f\u9884\u6d4b\u53ef\u4fe1\u5ea6\u9762\u4e34\u6311\u6218\u3002", "method": "\u5f15\u5165LLM\u6307\u5bfc\u7684\u7279\u5f81\u53d1\u73b0\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001LLM\u5982GPT-4o\u901a\u8fc7\u9488\u5bf9\u6027\u63d0\u793a\u63d0\u53d6\u91cf\u5316\u7279\u5f81\uff0c\u5e76\u6574\u5408\u5230\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u8bc4\u4f30\u53ef\u4fe1\u5ea6\u3002", "result": "\u65b9\u6cd5\u5728R2\u4e0a\u6bd4\u96f6\u6837\u672cGPT\u9884\u6d4b\u9ad813%\uff0c\u8bc6\u522b\u51fa\u5173\u952e\u7279\u5f81\u5982\u4fe1\u606f\u5177\u4f53\u6027\u548c\u56fe\u50cf\u683c\u5f0f\uff0c\u57284191\u4e2a\u5e16\u5b50\u548c5355\u4e2a crowdfunded \u8bc4\u5206\u4e2d\u9a8c\u8bc1\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u8be5\u65b9\u6cd5\u5bf9\u51cf\u5c11\u9519\u8bef\u4fe1\u606f\u3001\u63d0\u5347\u89c6\u89c9\u53ef\u4fe1\u5ea6\u4ee5\u53caLLM\u5728\u793e\u4f1a\u79d1\u5b66\u4e2d\u4f5c\u7528\u7684\u542b\u4e49\u3002"}}
{"id": "2504.10553", "pdf": "https://arxiv.org/pdf/2504.10553", "abs": "https://arxiv.org/abs/2504.10553", "authors": ["Gon\u00e7alo Gon\u00e7alves", "Nikki Arendse", "Doogesh Kodi Ramanah", "Rados\u0142aw Wojtak"], "title": "Inferring the Hubble Constant Using Simulated Strongly Lensed Supernovae and Neural Network Ensembles", "categories": ["astro-ph.IM", "astro-ph.CO", "cs.LG"], "comment": "12 pages, 9 figures. To be submitted to the Open Journal of\n  Astrophysics", "summary": "Strongly lensed supernovae are a promising new probe to obtain independent\nmeasurements of the Hubble constant (${H_0}$). In this work, we employ\nsimulated gravitationally lensed Type Ia supernovae (glSNe Ia) to train our\nmachine learning (ML) pipeline to constrain $H_0$. We simulate image\ntime-series of glSNIa, as observed with the upcoming Nancy Grace Roman Space\nTelescope, that we employ for training an ensemble of five convolutional neural\nnetworks (CNNs). The outputs of this ensemble network are combined with a\nsimulation-based inference (SBI) framework to quantify the uncertainties on the\nnetwork predictions and infer full posteriors for the $H_0$ estimates. We\nillustrate that the combination of multiple glSN systems enhances constraint\nprecision, providing a $4.4\\%$ estimate of $H_0$ based on 100 simulated\nsystems, which is in agreement with the ground truth. This research highlights\nthe potential of leveraging the capabilities of ML with glSNe systems to obtain\na pipeline capable of fast and automated $H_0$ measurements.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u6a21\u62df\u7684\u91cd\u529b\u900f\u955cIa\u578b\u8d85\u65b0\u661f\u548c\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\u7ba1\u9053\uff0c\u4ee5\u5b9e\u73b0\u54c8\u52c3\u5e38\u6570H0\u7684\u7cbe\u786e\u4f30\u8ba1\uff1b\u4f7f\u7528100\u4e2a\u7cfb\u7edf\u8fbe\u52304.4%\u7684\u7cbe\u5ea6\uff0c\u4e0e\u771f\u5b9e\u503c\u4e00\u81f4\u3002", "motivation": "\u4e3a\u4e86\u83b7\u5f97\u54c8\u52c3\u5e38\u6570H0\u7684\u72ec\u7acb\u6d4b\u91cf\uff0c\u4f7f\u7528\u5f3a\u91cd\u529b\u900f\u955c\u8d85\u65b0\u661f\u4f5c\u4e3a\u65b0\u63a2\u9488\u3002", "method": "\u6a21\u62df\u91cd\u529b\u900f\u955cIa\u578b\u8d85\u65b0\u661f\u7684\u56fe\u50cf\u65f6\u95f4\u5e8f\u5217\uff0c\u4f7f\u7528Nancy Grace Roman Space\u671b\u8fdc\u955c\u6570\u636e\u8bad\u7ec3\u4e94\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u96c6\u6210\uff0c\u5e76\u7ed3\u5408\u57fa\u4e8e\u6a21\u62df\u7684\u63a8\u7406\u6846\u67b6\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u548c\u63a8\u65adH0\u540e\u9a8c\u5206\u5e03\u3002", "result": "\u4f7f\u7528100\u4e2a\u6a21\u62df\u7cfb\u7edf\uff0c\u83b7\u5f97\u4e0e\u771f\u5b9e\u503c\u4e00\u81f4\u7684H0\u4f30\u8ba1\uff0c\u7cbe\u5ea6\u4e3a4.4%\u3002", "conclusion": "\u7a81\u663e\u4e86\u673a\u5668\u5b66\u4e60\u4e0e\u91cd\u529b\u900f\u955c\u8d85\u65b0\u661f\u7ed3\u5408\u7684\u6f5c\u529b\uff0c\u53ef\u5b9e\u73b0\u5feb\u901f\u548c\u81ea\u52a8\u5316\u7684H0\u6d4b\u91cf\u3002"}}
{"id": "2504.10883", "pdf": "https://arxiv.org/pdf/2504.10883", "abs": "https://arxiv.org/abs/2504.10883", "authors": ["Karan Jain", "Mohammad Nayeem Teli"], "title": "Bringing together invertible UNets with invertible attention modules for memory-efficient diffusion models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diffusion models have recently gained state of the art performance on many\nimage generation tasks. However, most models require significant computational\nresources to achieve this. This becomes apparent in the application of medical\nimage synthesis due to the 3D nature of medical datasets like CT-scans, MRIs,\nelectron microscope, etc. In this paper we propose a novel architecture for a\nsingle GPU memory-efficient training for diffusion models for high dimensional\nmedical datasets. The proposed model is built by using an invertible UNet\narchitecture with invertible attention modules. This leads to the following two\ncontributions: 1. denoising diffusion models and thus enabling memory usage to\nbe independent of the dimensionality of the dataset, and 2. reducing the energy\nusage during training. While this new model can be applied to a multitude of\nimage generation tasks, we showcase its memory-efficiency on the 3D BraTS2020\ndataset leading to up to 15\\% decrease in peak memory consumption during\ntraining with comparable results to SOTA while maintaining the image quality.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u9006UNet\u548c\u6ce8\u610f\u529b\u6a21\u5757\u7684\u6269\u6563\u6a21\u578b\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u5355GPU\u9ad8\u6548\u8bad\u7ec3\u9ad8\u7ef4\u533b\u7597\u56fe\u50cf\uff0c\u5185\u5b58\u6d88\u8017\u51cf\u5c1115%\uff0c\u56fe\u50cf\u8d28\u91cf\u4e0eSOTA\u76f8\u5f53\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u56fe\u50cf\u751f\u6210\u4e2d\u6027\u80fd\u51fa\u8272\uff0c\u4f46\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\uff0c\u5c24\u5176\u57283D\u533b\u7597\u56fe\u50cf\u4e0a\uff0c\u56e0\u6b64\u9700\u8981\u5185\u5b58\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u53ef\u9006UNet\u67b6\u6784\u548c\u53ef\u9006\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u4f7f\u6269\u6563\u6a21\u578b\u7684\u5185\u5b58\u4f7f\u7528\u72ec\u7acb\u4e8e\u6570\u636e\u7ef4\u5ea6\u3002", "result": "\u5728BraTS2020\u6570\u636e\u96c6\u4e0a\uff0c\u5cf0\u503c\u5185\u5b58\u6d88\u8017\u51cf\u5c1115%\uff0c\u7ed3\u679c\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\uff0c\u56fe\u50cf\u8d28\u91cf\u4fdd\u6301\u4e00\u81f4\u3002", "conclusion": "\u8be5\u6a21\u578b\u53ef\u5e94\u7528\u4e8e\u591a\u79cd\u56fe\u50cf\u751f\u6210\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5185\u5b58\u548c\u80fd\u6e90\u6548\u7387\u3002"}}
{"id": "2504.10560", "pdf": "https://arxiv.org/pdf/2504.10560", "abs": "https://arxiv.org/abs/2504.10560", "authors": ["Yaroslav Gusev", "Vitaly Vanchurin"], "title": "Molecular Learning Dynamics", "categories": ["physics.chem-ph", "cs.LG"], "comment": "16 pages, 7 figures, 1 table", "summary": "We apply the physics-learning duality to molecular systems by complementing\nthe physical description of interacting particles with a dual learning\ndescription, where each particle is modeled as an agent minimizing a loss\nfunction. In the traditional physics framework, the equations of motion are\nderived from the Lagrangian function, while in the learning framework, the same\nequations emerge from learning dynamics driven by the agent loss function. The\nloss function depends on scalar quantities that describe invariant properties\nof all other agents or particles. To demonstrate this approach, we first infer\nthe loss functions of oxygen and hydrogen directly from a dataset generated by\nthe CP2K physics-based simulation of water molecules. We then employ the loss\nfunctions to develop a learning-based simulation of water molecules, which\nachieves comparable accuracy while being significantly more computationally\nefficient than standard physics-based simulations.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u7269\u7406-\u5b66\u4e60\u4e8c\u5143\u6027\u5e94\u7528\u4e8e\u5206\u5b50\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b66\u4e60\u65b9\u6cd5\u6a21\u62df\u6c34\u5206\u5b50\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u6a21\u62df\u3002", "motivation": "\u52a8\u673a\u662f\u7ed3\u5408\u7269\u7406\u63cf\u8ff0\u4e0e\u5b66\u4e60\u6846\u67b6\uff0c\u63d0\u9ad8\u5206\u5b50\u6a21\u62df\u7684\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4eceCP2K\u7269\u7406\u6a21\u62df\u6570\u636e\u63a8\u65ad\u6c27\u548c\u6c22\u7684\u635f\u5931\u51fd\u6570\uff0c\u5e76\u4f7f\u7528\u8fd9\u4e9b\u51fd\u6570\u8fdb\u884c\u57fa\u4e8e\u5b66\u4e60\u7684\u6a21\u62df\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5b66\u4e60-based\u6a21\u62df\u5728\u51c6\u786e\u6027\u4e0a\u4e0e\u7269\u7406\u6a21\u62df\u76f8\u5f53\uff0c\u4f46\u8ba1\u7b97\u6548\u7387\u663e\u8457\u66f4\u9ad8\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8fd9\u79cd\u7269\u7406-\u5b66\u4e60\u4e8c\u5143\u6027\u65b9\u6cd5\u5728\u5206\u5b50\u6a21\u62df\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u53ef\u7528\u4e8e\u66f4\u6709\u6548\u7684\u5e94\u7528\u3002"}}
{"id": "2504.10885", "pdf": "https://arxiv.org/pdf/2504.10885", "abs": "https://arxiv.org/abs/2504.10885", "authors": ["Zeyu Zhang", "Zijian Chen", "Zicheng Zhang", "Yuze Sun", "Yuan Tian", "Ziheng Jia", "Chunyi Li", "Xiaohong Liu", "Xiongkuo Min", "Guangtao Zhai"], "title": "PuzzleBench: A Fully Dynamic Evaluation Framework for Large Multimodal Models on Puzzle Solving", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large Multimodal Models (LMMs) have demonstrated impressive capabilities\nacross a wide range of multimodal tasks, achieving ever-increasing performance\non various evaluation benchmarks. However, existing benchmarks are typically\nstatic and often overlap with pre-training datasets, leading to fixed\ncomplexity constraints and substantial data contamination issues. Meanwhile,\nmanually annotated datasets are labor-intensive, time-consuming, and subject to\nhuman bias and inconsistency, leading to reliability and reproducibility\nissues. To address these problems, we propose a fully dynamic multimodal\nevaluation framework, named Open-ended Visual Puzzle Generation (OVPG), which\naims to generate fresh, diverse, and verifiable evaluation data automatically\nin puzzle-solving tasks. Specifically, the OVPG pipeline consists of a raw\nmaterial sampling module, a visual content generation module, and a puzzle rule\ndesign module, which ensures that each evaluation instance is primitive, highly\nrandomized, and uniquely solvable, enabling continual adaptation to the\nevolving capabilities of LMMs. Built upon OVPG, we construct PuzzleBench, a\ndynamic and scalable benchmark comprising 11,840 VQA samples. It features six\ncarefully designed puzzle tasks targeting three core LMM competencies, visual\nrecognition, logical reasoning, and context understanding. PuzzleBench differs\nfrom static benchmarks that quickly become outdated. It enables ongoing dataset\nrefreshing through OVPG and a rich set of open-ended puzzle designs, allowing\nseamless adaptation to the evolving capabilities of LMMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faOVPG\u6846\u67b6\uff0c\u7528\u4e8e\u52a8\u6001\u751f\u6210\u591a\u6a21\u6001\u6a21\u578b\u8bc4\u4f30\u6570\u636e\uff0c\u89e3\u51b3\u73b0\u6709\u57fa\u51c6\u7684\u9759\u6001\u548c\u6c61\u67d3\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u9759\u6001\u3001\u6613\u53d7\u6570\u636e\u6c61\u67d3\uff0c\u624b\u52a8\u6807\u6ce8\u8017\u65f6\u8d39\u529b\u4e14\u6613\u4ea7\u751f\u504f\u89c1\u548c\u4e00\u81f4\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faOVPG\u6846\u67b6\uff0c\u5305\u62ec\u539f\u6750\u6599\u91c7\u6837\u3001\u89c6\u89c9\u5185\u5bb9\u751f\u6210\u548c\u8c1c\u9898\u89c4\u5219\u8bbe\u8ba1\u6a21\u5757\uff0c\u5e76\u6784\u5efaPuzzleBench\u57fa\u51c6\uff0c\u5305\u542b11840\u4e2aVQA\u6837\u672c\u548c\u516d\u79cd\u8c1c\u9898\u4efb\u52a1\u3002", "result": "\u521b\u5efa\u4e86\u52a8\u6001\u3001\u53ef\u6269\u5c55\u7684PuzzleBench\u57fa\u51c6\uff0c\u9488\u5bf9\u89c6\u89c9\u8bc6\u522b\u3001\u903b\u8f91\u63a8\u7406\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "PuzzleBench\u901a\u8fc7\u6301\u7eed\u66f4\u65b0\u548c\u5f00\u653e\u8bbe\u8ba1\uff0c\u9002\u5e94\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u7684\u6f14\u8fdb\u3002"}}
{"id": "2504.10564", "pdf": "https://arxiv.org/pdf/2504.10564", "abs": "https://arxiv.org/abs/2504.10564", "authors": ["Julian Cremer", "Ross Irwin", "Alessandro Tibot", "Jon Paul Janet", "Simon Olsson", "Djork-Arn\u00e9 Clevert"], "title": "FLOWR: Flow Matching for Structure-Aware De Novo, Interaction- and Fragment-Based Ligand Generation", "categories": ["q-bio.QM", "cs.LG", "q-bio.BM"], "comment": null, "summary": "We introduce FLOWR, a novel structure-based framework for the generation and\noptimization of three-dimensional ligands. FLOWR integrates continuous and\ncategorical flow matching with equivariant optimal transport, enhanced by an\nefficient protein pocket conditioning. Alongside FLOWR, we present SPINDR, a\nthoroughly curated dataset comprising ligand-pocket co-crystal complexes\nspecifically designed to address existing data quality issues. Empirical\nevaluations demonstrate that FLOWR surpasses current state-of-the-art\ndiffusion- and flow-based methods in terms of PoseBusters-validity, pose\naccuracy, and interaction recovery, while offering a significant inference\nspeedup, achieving up to 70-fold faster performance. In addition, we introduce\nFLOWR.multi, a highly accurate multi-purpose model allowing for the targeted\nsampling of novel ligands that adhere to predefined interaction profiles and\nchemical substructures for fragment-based design without the need of\nre-training or any re-sampling strategies", "AI": {"tldr": "FLOWR \u662f\u4e00\u79cd\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u4e09\u7ef4\u914d\u4f53\u7684\u751f\u6210\u548c\u4f18\u5316\uff0c\u96c6\u6210\u4e86\u6d41\u5339\u914d\u3001\u6700\u4f18\u4f20\u8f93\u548c\u86cb\u767d\u8d28\u53e3\u888b\u6761\u4ef6\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6570\u636e\u8d28\u91cf\u95ee\u9898\uff0c\u5e76\u6539\u8fdb\u914d\u4f53\u751f\u6210\u65b9\u6cd5\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "FLOWR \u6574\u5408\u8fde\u7eed\u548c\u5206\u7c7b\u6d41\u5339\u914d\u3001\u7b49\u53d8\u6700\u4f18\u4f20\u8f93\uff0c\u5e76\u4f7f\u7528\u9ad8\u6548\u86cb\u767d\u8d28\u53e3\u888b\u6761\u4ef6\uff1b\u5f15\u5165 SPINDR \u6570\u636e\u96c6\u4f5c\u4e3a\u8bad\u7ec3\u57fa\u7840\u3002", "result": "\u5728\u6709\u6548\u6027\u3001\u4f4d\u59ff\u51c6\u786e\u6027\u548c\u4ea4\u4e92\u6062\u590d\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u9ad8 70 \u500d\uff1bFLOWR.multi \u652f\u6301\u65e0\u987b\u91cd\u65b0\u8bad\u7ec3\u7684\u9488\u5bf9\u6027\u914d\u4f53\u91c7\u6837\u3002", "conclusion": "FLOWR \u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u5feb\u3001\u66f4\u51c6\u786e\u7684\u591a\u529f\u80fd\u6846\u67b6\uff0c\u63d0\u5347\u4e86\u914d\u4f53\u8bbe\u8ba1\u5e94\u7528\u3002"}}
{"id": "2504.10886", "pdf": "https://arxiv.org/pdf/2504.10886", "abs": "https://arxiv.org/abs/2504.10886", "authors": ["Jiseon Kim", "Jea Kwon", "Luiz Felipe Vecchietti", "Alice Oh", "Meeyoung Cha"], "title": "Exploring Persona-dependent LLM Alignment for the Moral Machine Experiment", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "Accepted to ICLR 2025 Workshop - BiAlign (Bidirectional Human-AI\n  Alignment)", "summary": "Deploying large language models (LLMs) with agency in real-world applications\nraises critical questions about how these models will behave. In particular,\nhow will their decisions align with humans when faced with moral dilemmas? This\nstudy examines the alignment between LLM-driven decisions and human judgment in\nvarious contexts of the moral machine experiment, including personas reflecting\ndifferent sociodemographics. We find that the moral decisions of LLMs vary\nsubstantially by persona, showing greater shifts in moral decisions for\ncritical tasks than humans. Our data also indicate an interesting partisan\nsorting phenomenon, where political persona predominates the direction and\ndegree of LLM decisions. We discuss the ethical implications and risks\nassociated with deploying these models in applications that involve moral\ndecisions.", "AI": {"tldr": "\u672c\u7814\u7a76\u8c03\u67e5LLM\u5728\u9053\u5fb7\u56f0\u5883\u4e2d\u7684\u51b3\u7b56\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u5951\u5408\u5ea6\uff0c\u53d1\u73b0LLM\u51b3\u7b56\u53d7\u89d2\u8272\u5f71\u54cd\u8f83\u5927\uff0c\u5e76\u5728\u5173\u952e\u4efb\u52a1\u4e2d\u53d8\u5316\u66f4\u5267\u70c8\uff1b\u8fd8\u89c2\u5bdf\u5230\u653f\u6cbb\u89d2\u8272\u4e3b\u5bfc\u51b3\u7b56\u65b9\u5411\uff0c\u5e76\u8ba8\u8bba\u90e8\u7f72\u98ce\u9669\u3002", "motivation": "\u90e8\u7f72\u5177\u6709\u4ee3\u7406\u80fd\u529b\u7684LLM\u5230\u73b0\u5b9e\u5e94\u7528\u4e2d\u5f15\u53d1\u4e86\u5bf9\u5176\u884c\u4e3a\uff0c\u5c24\u5176\u662f\u9053\u5fb7\u51b3\u7b56\u7684\u62c5\u5fe7\u3002", "method": "\u4f7f\u7528\u9053\u5fb7\u673a\u5668\u5b9e\u9a8c\u7684\u5404\u79cd\u60c5\u5883\u548c\u4e0d\u540c\u793e\u4f1a\u4eba\u53e3\u7edf\u8ba1\u5b66\u7279\u5f81\u7684\u89d2\u8272\u6765\u68c0\u67e5LLM\u51b3\u7b56\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u5951\u5408\u5ea6\u3002", "result": "LLM\u7684\u9053\u5fb7\u51b3\u7b56\u6839\u636e\u89d2\u8272\u6709\u663e\u8457\u53d8\u5316\uff0c\u5728\u5173\u952e\u4efb\u52a1\u4e2d\u53d8\u5316\u5927\u4e8e\u4eba\u7c7b\uff1b\u5b58\u5728\u515a\u6d3e\u5206\u7c7b\u73b0\u8c61\uff0c\u5176\u4e2d\u653f\u6cbb\u89d2\u8272\u4e3b\u5bfc\u51b3\u7b56\u7684\u65b9\u5411\u548c\u7a0b\u5ea6\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u5728\u6d89\u53ca\u9053\u5fb7\u51b3\u7b56\u7684\u5e94\u7528\u4e2d\u90e8\u7f72LLM\u7684\u4f26\u7406\u542b\u4e49\u548c\u98ce\u9669\u3002"}}
{"id": "2504.10598", "pdf": "https://arxiv.org/pdf/2504.10598", "abs": "https://arxiv.org/abs/2504.10598", "authors": ["Omar Montasser", "Abhishek Shetty", "Nikita Zhivotovskiy"], "title": "Beyond Worst-Case Online Classification: VC-Based Regret Bounds for Relaxed Benchmarks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We revisit online binary classification by shifting the focus from competing\nwith the best-in-class binary loss to competing against relaxed benchmarks that\ncapture smoothed notions of optimality. Instead of measuring regret relative to\nthe exact minimal binary error -- a standard approach that leads to worst-case\nbounds tied to the Littlestone dimension -- we consider comparing with\npredictors that are robust to small input perturbations, perform well under\nGaussian smoothing, or maintain a prescribed output margin. Previous examples\nof this were primarily limited to the hinge loss. Our algorithms achieve regret\nguarantees that depend only on the VC dimension and the complexity of the\ninstance space (e.g., metric entropy), and notably, they incur only an\n$O(\\log(1/\\gamma))$ dependence on the generalized margin $\\gamma$. This stands\nin contrast to most existing regret bounds, which typically exhibit a\npolynomial dependence on $1/\\gamma$. We complement this with matching lower\nbounds. Our analysis connects recent ideas from adversarial robustness and\nsmoothed online learning.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u91cd\u65b0\u5ba1\u89c6\u5728\u7ebf\u4e8c\u5143\u5206\u7c7b\uff0c\u5c06\u9057\u61be\u5ea6\u7ade\u4e89\u4ece\u6700\u4f73\u4e8c\u5143\u635f\u5931\u8f6c\u5411\u677e\u5f1b\u57fa\u51c6\uff0c\u5982\u9c81\u68d2\u4e8e\u5c0f\u6270\u52a8\u6216Gaussian\u5e73\u6ed1\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u9057\u61be\u4fdd\u8bc1\u3002", "motivation": "\u52a8\u673a\u662f\u907f\u514d\u6807\u51c6\u65b9\u6cd5\u5bfc\u81f4\u7684\u4e0eLittlestone\u7ef4\u76f8\u5173\u7684\u7cdf\u7cd5\u754c\u9650\uff0c\u901a\u8fc7\u7ade\u4e89\u5e73\u6ed1\u7684\u6700\u4f18\u6027\u57fa\u51c6\u6765\u6539\u5584\u9057\u61be\u4fdd\u8bc1\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u8bbe\u8ba1\u7b97\u6cd5\uff0c\u5229\u7528\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u5e73\u6ed1\u5728\u7ebf\u5b66\u4e60\u7684\u601d\u60f3\uff0c\u6bd4\u8f83\u9c81\u68d2\u9884\u6d4b\u5668\u548c\u9ad8\u8fb9\u8ddd\u9884\u6d4b\u5668\u3002", "result": "\u7ed3\u679c\u662f\u9057\u61be\u4fdd\u8bc1\u4ec5\u4f9d\u8d56VC\u7ef4\u548c\u5b9e\u4f8b\u7a7a\u95f4\u590d\u6742\u6027\uff0c\u5bf9\u5e7f\u4e49\u8fb9\u8ddd\u03b3\u6709O(log(1/\u03b3))\u7684\u5bf9\u6570\u4f9d\u8d56\uff0c\u5e76\u6709\u5339\u914d\u7684\u4e0b\u754c\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8fd9\u79cd\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u597d\u7684\u9057\u61be\u754c\u9650\uff0c\u7a81\u51fa\u4e86\u677e\u5f1b\u57fa\u51c6\u7684\u4f18\u52bf\u3002"}}
{"id": "2504.10888", "pdf": "https://arxiv.org/pdf/2504.10888", "abs": "https://arxiv.org/abs/2504.10888", "authors": ["Jiahuan Long", "Wen Yao", "Tingsong Jiang", "Chao Ma"], "title": "CDUPatch: Color-Driven Universal Adversarial Patch Attack for Dual-Modal Visible-Infrared Detectors", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Adversarial patches are widely used to evaluate the robustness of object\ndetection systems in real-world scenarios. These patches were initially\ndesigned to deceive single-modal detectors (e.g., visible or infrared) and have\nrecently been extended to target visible-infrared dual-modal detectors.\nHowever, existing dual-modal adversarial patch attacks have limited attack\neffectiveness across diverse physical scenarios. To address this, we propose\nCDUPatch, a universal cross-modal patch attack against visible-infrared object\ndetectors across scales, views, and scenarios. Specifically, we observe that\ncolor variations lead to different levels of thermal absorption, resulting in\ntemperature differences in infrared imaging. Leveraging this property, we\npropose an RGB-to-infrared adapter that maps RGB patches to infrared patches,\nenabling unified optimization of cross-modal patches. By learning an optimal\ncolor distribution on the adversarial patch, we can manipulate its thermal\nresponse and generate an adversarial infrared texture. Additionally, we\nintroduce a multi-scale clipping strategy and construct a new visible-infrared\ndataset, MSDrone, which contains aerial vehicle images in varying scales and\nperspectives. These data augmentation strategies enhance the robustness of our\npatch in real-world conditions. Experiments on four benchmark datasets (e.g.,\nDroneVehicle, LLVIP, VisDrone, MSDrone) show that our method outperforms\nexisting patch attacks in the digital domain. Extensive physical tests further\nconfirm strong transferability across scales, views, and scenarios.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faCDUPatch\uff0c\u4e00\u79cd\u9488\u5bf9\u53ef\u89c1\u5149-\u7ea2\u5916\u53cc\u6a21\u6001\u7269\u4f53\u68c0\u6d4b\u5668\u7684\u901a\u7528\u8de8\u6a21\u6001\u5bf9\u6297\u8865\u4e01\u653b\u51fb\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u5728\u4e0d\u540c\u89c4\u6a21\u3001\u89c6\u89d2\u548c\u573a\u666f\u4e0b\u7684\u653b\u51fb\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u53cc\u6a21\u6001\u5bf9\u6297\u8865\u4e01\u653b\u51fb\u5728\u591a\u6837\u7269\u7406\u573a\u666f\u4e0b\u7684\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u63d0\u51faRGB-to-infrared\u9002\u914d\u5668\uff0c\u901a\u8fc7\u5b66\u4e60\u6700\u4f18\u989c\u8272\u5206\u5e03\u64cd\u7eb5\u70ed\u54cd\u5e94\uff0c\u7ed3\u5408\u591a\u5c3a\u5ea6\u88c1\u526a\u7b56\u7565\u548c\u65b0\u5efaMSDrone\u6570\u636e\u96c6\u589e\u5f3a\u9c81\u68d2\u6027\u3002", "result": "\u5728DroneVehicle\u3001LLVIP\u3001VisDrone\u548cMSDrone\u7b49\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u4e2d\uff0cCDUPatch\u5728\u6570\u5b57\u57df\u548c\u7269\u7406\u6d4b\u8bd5\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u653b\u51fb\uff0c\u663e\u793a\u51fa\u5f3a\u8f6c\u79fb\u6027\u3002", "conclusion": "CDUPatch\u5728\u4e0d\u540c\u89c4\u6a21\u3001\u89c6\u89d2\u548c\u573a\u666f\u4e0b\u5177\u6709\u9ad8\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\uff0c\u8bc1\u5b9e\u4e86\u5176\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2504.10620", "pdf": "https://arxiv.org/pdf/2504.10620", "abs": "https://arxiv.org/abs/2504.10620", "authors": ["Srivathsan Amruth"], "title": "SPreV", "categories": ["cs.GR", "cs.HC", "cs.LG", "stat.ML", "G.3"], "comment": "45 Pages, 7 Figures, 3 Tables, 9 Algorithms, Opensource", "summary": "SPREV, short for hyperSphere Reduced to two-dimensional Regular Polygon for\nVisualisation, is a novel dimensionality reduction technique developed to\naddress the challenges of reducing dimensions and visualizing labeled datasets\nthat exhibit a unique combination of three characteristics: small class size,\nhigh dimensionality, and low sample size. SPREV is designed not only to uncover\nbut also to visually represent hidden patterns within such datasets. Its\ndistinctive integration of geometric principles, adapted for discrete\ncomputational environments, makes it an indispensable tool in the modern data\nscience toolkit, enabling users to identify trends, extract insights, and\nnavigate complex data efficiently and effectively.", "AI": {"tldr": "SPREV \u662f\u4e00\u79cd\u65b0\u578b\u964d\u7ef4\u6280\u672f\uff0c\u7528\u4e8e\u5904\u7406\u5c0f\u7c7b\u5927\u5c0f\u3001\u9ad8\u7ef4\u5ea6\u548c\u4f4e\u6837\u672c\u91cf\u7684\u6807\u8bb0\u6570\u636e\u96c6\uff0c\u5e76\u53ef\u89c6\u5316\u9690\u85cf\u6a21\u5f0f\u3002", "motivation": "\u89e3\u51b3\u964d\u7ef4\u548c\u53ef\u89c6\u5316\u6311\u6218\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5c0f\u7c7b\u5927\u5c0f\u3001\u9ad8\u7ef4\u5ea6\u548c\u4f4e\u6837\u672c\u91cf\u7684\u6570\u636e\u96c6\u3002", "method": "\u6574\u5408\u51e0\u4f55\u539f\u5219\uff0c\u5e76\u9002\u5e94\u79bb\u6563\u8ba1\u7b97\u73af\u5883\u3002", "result": "\u7528\u6237\u80fd\u591f\u8bc6\u522b\u8d8b\u52bf\u3001\u63d0\u53d6\u6d1e\u89c1\uff0c\u5e76\u9ad8\u6548\u5bfc\u822a\u590d\u6742\u6570\u636e\u3002", "conclusion": "SPREV \u662f\u73b0\u4ee3\u6570\u636e\u79d1\u5b66\u5de5\u5177\u5305\u4e2d\u4e0d\u53ef\u6216\u7f3a\u7684\u5de5\u5177\u3002"}}
{"id": "2504.10898", "pdf": "https://arxiv.org/pdf/2504.10898", "abs": "https://arxiv.org/abs/2504.10898", "authors": ["Ahana Pradhan", "Jayant Haritsa"], "title": "Xpose: Bi-directional Engineering for Hidden Query Extraction", "categories": ["cs.DB", "cs.AI", "H.2.8"], "comment": null, "summary": "Query reverse engineering (QRE) aims to synthesize a SQL query to connect a\ngiven database and result instance. A recent variation of QRE is where an\nadditional input, an opaque executable containing a ground-truth query, is\nprovided, and the goal is to non-invasively extract this specific query through\nonly input-output examples. This variant, called Hidden Query Extraction (HQE),\nhas a spectrum of industrial use-cases including query recovery, database\nsecurity, and vendor migration. The reverse engineering (RE) tools developed\nfor HQE, which are based on database mutation and generation techniques, can\nonly extract flat queries with key-based equi joins and conjunctive arithmetic\nfilter predicates, making them limited wrt both query structure and query\noperators. In this paper, we present Xpose, a HQE solution that elevates the\nextraction scope to realistic complex queries, such as those found in the TPCH\nbenchmark. A two-pronged approach is taken: (1) The existing RE scope is\nsubstantially extended to incorporate union connectors, algebraic filter\npredicates, and disjunctions for both values and predicates. (2) The predictive\npower of LLMs is leveraged to convert business descriptions of the opaque\napplication into extraction guidance, representing ``forward engineering\" (FE).\nThe FE module recognizes common constructs, such as nesting of sub-queries,\nouter joins, and scalar functions. In essence, FE establishes the broad query\ncontours, while RE fleshes out the fine-grained details. We have evaluated\nXpose on (a) E-TPCH, a query suite comprising the complete TPCH benchmark\nextended with queries featuring unions, diverse join types, and sub-queries;\nand (b) the real-world STACK benchmark. The experimental results demonstrate\nthat its bi-directional engineering approach accurately extracts these complex\nqueries, representing a significant step forward with regard to HQE coverage.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86Xpose\u7cfb\u7edf\uff0c\u5b83\u7ed3\u5408\u9006\u5411\u548c\u6b63\u5411\u5de5\u7a0b\u4ece\u4e0d\u900f\u660e\u53ef\u6267\u884c\u6587\u4ef6\u4e2d\u63d0\u53d6\u590d\u6742SQL\u67e5\u8be2\uff0c\u63d0\u9ad8\u4e86\u9690\u85cf\u67e5\u8be2\u63d0\u53d6\u7684\u8986\u76d6\u8303\u56f4\u3002", "motivation": "\u73b0\u6709\u7684\u9690\u85cf\u67e5\u8be2\u63d0\u53d6\u5de5\u5177\u53ea\u80fd\u5904\u7406\u7b80\u5355\u67e5\u8be2\uff0c\u9650\u5236\u4e86\u67e5\u8be2\u7ed3\u6784\u548c\u64cd\u4f5c\u7b26\uff1b\u672c\u6587\u9488\u5bf9\u5de5\u4e1a\u5e94\u7528\u5982\u67e5\u8be2\u6062\u590d\u3001\u6570\u636e\u5e93\u5b89\u5168\u548c\u4f9b\u5e94\u5546\u8fc1\u79fb\u7684\u9700\u8981\uff0c\u63d0\u51fa\u6269\u5c55\u63d0\u53d6\u8303\u56f4\u3002", "method": "\u63d0\u51faXpose\u7cfb\u7edf\uff0c\u5305\u62ec\u6269\u5c55\u9006\u5411\u5de5\u7a0b\u4ee5\u652f\u6301\u8054\u5408\u3001\u4ee3\u6570\u8fc7\u6ee4\u548c\u6790\u53d6\uff0c\u4ee5\u53ca\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6b63\u5411\u5de5\u7a0b\u4ece\u4e1a\u52a1\u63cf\u8ff0\u83b7\u53d6\u6307\u5bfc\u3002", "result": "\u5728E-TPCH\u548cSTACK\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cXpose\u51c6\u786e\u63d0\u53d6\u4e86\u590d\u6742\u67e5\u8be2\uff0c\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "Xpose\u5728\u9690\u85cf\u67e5\u8be2\u63d0\u53d6\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u5c55\uff0c\u6269\u5c55\u4e86\u67e5\u8be2\u8986\u76d6\u8303\u56f4\u3002"}}
{"id": "2504.10903", "pdf": "https://arxiv.org/pdf/2504.10903", "abs": "https://arxiv.org/abs/2504.10903", "authors": ["Sicheng Feng", "Gongfan Fang", "Xinyin Ma", "Xinchao Wang"], "title": "Efficient Reasoning Models: A Survey", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reasoning models have demonstrated remarkable progress in solving complex and\nlogic-intensive tasks by generating extended Chain-of-Thoughts (CoTs) prior to\narriving at a final answer. Yet, the emergence of this \"slow-thinking\"\nparadigm, with numerous tokens generated in sequence, inevitably introduces\nsubstantial computational overhead. To this end, it highlights an urgent need\nfor effective acceleration. This survey aims to provide a comprehensive\noverview of recent advances in efficient reasoning. It categorizes existing\nworks into three key directions: (1) shorter - compressing lengthy CoTs into\nconcise yet effective reasoning chains; (2) smaller - developing compact\nlanguage models with strong reasoning capabilities through techniques such as\nknowledge distillation, other model compression techniques, and reinforcement\nlearning; and (3) faster - designing efficient decoding strategies to\naccelerate inference. A curated collection of papers discussed in this survey\nis available in our GitHub repository.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u6982\u8ff0\u4e86\u9ad8\u6548\u63a8\u7406\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5c06\u5de5\u4f5c\u5206\u4e3a\u7f29\u77ed\u63a8\u7406\u94fe\u3001\u5f00\u53d1\u5c0f\u578b\u6a21\u578b\u548c\u52a0\u901f\u89e3\u7801\u4e09\u7c7b\u3002", "motivation": "\u63a8\u7406\u6a21\u578b\u751f\u6210\u957f\u94fe\u5f0f\u601d\u8003\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u9700\u8981\u52a0\u901f\u65b9\u6cd5\u3002", "method": "\u5c06\u73b0\u6709\u5de5\u4f5c\u5206\u7c7b\u4e3a\uff1a(1) \u538b\u7f29\u63a8\u7406\u94fe\uff1b(2) \u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u7b49\u6280\u672f\u5f00\u53d1\u5c0f\u578b\u6a21\u578b\uff1b(3) \u8bbe\u8ba1\u9ad8\u6548\u89e3\u7801\u7b56\u7565\u3002", "result": "\u63d0\u4f9b\u4e86\u9ad8\u6548\u63a8\u7406\u7684\u5168\u9762\u6982\u8ff0\u548cGitHub\u4ed3\u5e93\u8d44\u6e90\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u9ad8\u6548\u63a8\u7406\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u603b\u7ed3\u4e86\u5f53\u524d\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2504.10653", "pdf": "https://arxiv.org/pdf/2504.10653", "abs": "https://arxiv.org/abs/2504.10653", "authors": ["Max Daniels"], "title": "On the Contractivity of Stochastic Interpolation Flow", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": "Proof of concept. I would be excited to chat about extensions!", "summary": "We investigate stochastic interpolation, a recently introduced framework for\nhigh dimensional sampling which bears many similarities to diffusion modeling.\nStochastic interpolation generates a data sample by first randomly initializing\na particle drawn from a simple base distribution, then simulating deterministic\nor stochastic dynamics such that in finite time the particle's distribution\nconverges to the target. We show that for a Gaussian base distribution and a\nstrongly log-concave target distribution, the stochastic interpolation flow map\nis Lipschitz with a sharp constant which matches that of Caffarelli's theorem\nfor optimal transport maps. We are further able to construct Lipschitz\ntransport maps between non-Gaussian distributions, generalizing some recent\nconstructions in the literature on transport methods for establishing\nfunctional inequalities. We discuss the practical implications of our theorem\nfor the sampling and estimation problems required by stochastic interpolation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u968f\u673a\u63d2\u503c\u6846\u67b6\u7528\u4e8e\u9ad8\u7ef4\u91c7\u6837\uff0c\u8bc1\u660e\u5176Lipschitz\u6027\u8d28\u5e76\u8ba8\u8bba\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u63a2\u7d22\u4e00\u79cd\u7c7b\u4f3c\u4e8e\u6269\u6563\u6a21\u578b\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u529f\u80fd\u4e0d\u7b49\u5f0f\u4ee5\u89e3\u51b3\u9ad8\u7ef4\u91c7\u6837\u95ee\u9898\u3002", "method": "\u8bc1\u660e\u9ad8\u65af\u57fa\u5206\u5e03\u548c\u5f3a\u5bf9\u6570\u51f9\u76ee\u6807\u5206\u5e03\u4e0b\u7684\u968f\u673a\u63d2\u503c\u6d41\u6620\u5c04Lipschitz\u6027\u8d28\uff0c\u5e76\u6784\u5efa\u975e\u9ad8\u65af\u5206\u5e03\u95f4\u7684Lipschitz\u4f20\u8f93\u6620\u5c04\u3002", "result": "\u968f\u673a\u63d2\u503c\u6d41\u6620\u5c04\u7684Lipschitz\u5e38\u6570\u4e0eCaffarelli\u5b9a\u7406\u5339\u914d\uff0c\u5e76\u63a8\u5e7f\u5230\u975e\u9ad8\u65af\u5206\u5e03\u3002", "conclusion": "\u4e3a\u968f\u673a\u63d2\u503c\u7684\u91c7\u6837\u548c\u4f30\u8ba1\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u9645\u542b\u4e49\u548c\u6f5c\u5728\u5e94\u7528\u3002"}}
{"id": "2504.10915", "pdf": "https://arxiv.org/pdf/2504.10915", "abs": "https://arxiv.org/abs/2504.10915", "authors": ["Rajesh Ranjan", "Shailja Gupta", "Surya Narayan Singh"], "title": "LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI Agent Ecosystems", "categories": ["cs.MA", "cs.AI", "cs.CY"], "comment": "4 Figures, 1 Table", "summary": "The rise of autonomous AI agents, capable of perceiving, reasoning, and\nacting independently, signals a profound shift in how digital ecosystems\noperate, govern, and evolve. As these agents proliferate beyond centralized\ninfrastructures, they expose foundational gaps in identity, accountability, and\nethical alignment. Three critical questions emerge: Identity: Who or what is\nthe agent? Accountability: Can its actions be verified, audited, and trusted?\nEthical Consensus: Can autonomous systems reliably align with human values and\nprevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered\nOrchestration for Knowledgeful Agents), a unified, systems-level architecture\nfor building ethically governed, interoperable AI agent ecosystems. LOKA\nintroduces a proposed Universal Agent Identity Layer (UAIL) for decentralized,\nverifiable identity; intent-centric communication protocols for semantic\ncoordination across diverse agents; and a Decentralized Ethical Consensus\nProtocol (DECP) that enables agents to make context-aware decisions grounded in\nshared ethical baselines. Anchored in emerging standards such as Decentralized\nIdentifiers (DIDs), Verifiable Credentials (VCs), and post-quantum\ncryptography, LOKA offers a scalable, future-resilient blueprint for\nmulti-agent AI governance. By embedding identity, trust, and ethics into the\nprotocol layer itself, LOKA establishes the foundation for a new era of\nresponsible, transparent, and autonomous AI ecosystems operating across digital\nand physical domains.", "AI": {"tldr": "LOKA \u534f\u8bae\u662f\u4e00\u79cd\u65b0\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u6784\u5efa\u9053\u5fb7\u6cbb\u7406\u7684 AI \u4ee3\u7406\u751f\u6001\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u8eab\u4efd\u3001\u8d23\u4efb\u548c\u4f26\u7406\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b AI \u4ee3\u7406\u7684\u5174\u8d77\uff0c\u6570\u5b57\u751f\u6001\u7cfb\u7edf\u4e2d\u5b58\u5728\u8eab\u4efd\u3001\u8d23\u4efb\u548c\u4f26\u7406\u4e00\u81f4\u6027\u7684\u57fa\u7840\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa LOKA \u534f\u8bae\uff0c\u5305\u62ec\u901a\u7528\u4ee3\u7406\u8eab\u4efd\u5c42\u3001\u610f\u56fe\u4e2d\u5fc3\u901a\u4fe1\u534f\u8bae\u548c\u53bb\u4e2d\u5fc3\u5316\u4f26\u7406\u5171\u8bc6\u534f\u8bae\uff0c\u4f7f\u7528\u53bb\u4e2d\u5fc3\u5316\u6807\u8bc6\u7b26\u3001\u53ef\u9a8c\u8bc1\u51ed\u8bc1\u548c\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u3001\u9762\u5411\u672a\u6765\u7684 AI \u6cbb\u7406\u84dd\u56fe\u3002", "conclusion": "\u901a\u8fc7\u5c06\u8eab\u4efd\u3001\u4fe1\u4efb\u548c\u4f26\u7406\u5d4c\u5165\u534f\u8bae\u5c42\uff0c\u5960\u5b9a\u4e86\u8d1f\u8d23\u3001\u900f\u660e\u548c\u81ea\u4e3b AI \u751f\u6001\u7cfb\u7edf\u7684\u57fa\u7840\u3002"}}
{"id": "2504.10662", "pdf": "https://arxiv.org/pdf/2504.10662", "abs": "https://arxiv.org/abs/2504.10662", "authors": ["Sina Elahimanesh", "Mohammadali Mohammadkhani", "Shohreh Kasaei"], "title": "Emotion Alignment: Discovering the Gap Between Social Media and Real-World Sentiments in Persian Tweets and Images", "categories": ["cs.HC", "cs.LG", "cs.SI"], "comment": null, "summary": "In contemporary society, widespread social media usage is evident in people's\ndaily lives. Nevertheless, disparities in emotional expressions between the\nreal world and online platforms can manifest. We comprehensively analyzed\nPersian community on X to explore this phenomenon. An innovative pipeline was\ndesigned to measure the similarity between emotions in the real world compared\nto social media. Accordingly, recent tweets and images of participants were\ngathered and analyzed using Transformers-based text and image sentiment\nanalysis modules. Each participant's friends also provided insights into the\ntheir real-world emotions. A distance criterion was used to compare real-world\nfeelings with virtual experiences. Our study encompassed N=105 participants,\n393 friends who contributed their perspectives, over 8,300 collected tweets,\nand 2,000 media images. Results indicated a 28.67% similarity between images\nand real-world emotions, while tweets exhibited a 75.88% alignment with\nreal-world feelings. Additionally, the statistical significance confirmed that\nthe observed disparities in sentiment proportions.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86\u6ce2\u65af\u793e\u533a\u5728X\u5e73\u53f0\u4e0a\u60c5\u611f\u8868\u8fbe\u4e0e\u73b0\u5b9e\u4e16\u754c\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u63a8\u6587\u76f8\u4f3c\u5ea6\u9ad8\u4e8e\u56fe\u50cf\u3002", "motivation": "\u63a2\u8ba8\u73b0\u5b9e\u4e16\u754c\u548c\u5728\u7ebf\u5e73\u53f0\u4e4b\u95f4\u60c5\u611f\u8868\u8fbe\u7684\u5dee\u5f02\u3002", "method": "\u8bbe\u8ba1\u7ba1\u9053\u4f7f\u7528Transformers-based\u6a21\u578b\u5206\u6790\u63a8\u6587\u548c\u56fe\u50cf\u60c5\u611f\uff0c\u7ed3\u5408\u670b\u53cb\u53cd\u9988\u53ca\u8ddd\u79bb\u6807\u51c6\u6bd4\u8f83\u3002", "result": "\u56fe\u50cf\u4e0e\u73b0\u5b9e\u60c5\u611f\u76f8\u4f3c\u5ea628.67%\uff0c\u63a8\u6587\u76f8\u4f3c\u5ea675.88%\uff0c\u5dee\u5f02\u5177\u6709\u7edf\u8ba1\u5b66\u610f\u4e49\u3002", "conclusion": "\u8bc1\u5b9e\u5728\u7ebf\u60c5\u611f\u8868\u8fbe\u4e0e\u73b0\u5b9e\u4e16\u754c\u5b58\u5728\u5dee\u5f02\uff0c\u63a8\u6587\u66f4\u63a5\u8fd1\u73b0\u5b9e\u60c5\u611f\u3002"}}
{"id": "2504.10669", "pdf": "https://arxiv.org/pdf/2504.10669", "abs": "https://arxiv.org/abs/2504.10669", "authors": ["Gokul Raju Govinda Raju", "Nikola Zubi\u0107", "Marco Cannici", "Davide Scaramuzza"], "title": "Perturbed State Space Feature Encoders for Optical Flow with Event Cameras", "categories": ["cs.CV", "cs.LG"], "comment": "10 pages, 4 figures, 4 tables. Equal contribution by Gokul Raju\n  Govinda Raju and Nikola Zubi\\'c", "summary": "With their motion-responsive nature, event-based cameras offer significant\nadvantages over traditional cameras for optical flow estimation. While deep\nlearning has improved upon traditional methods, current neural networks adopted\nfor event-based optical flow still face temporal and spatial reasoning\nlimitations. We propose Perturbed State Space Feature Encoders (P-SSE) for\nmulti-frame optical flow with event cameras to address these challenges. P-SSE\nadaptively processes spatiotemporal features with a large receptive field akin\nto Transformer-based methods, while maintaining the linear computational\ncomplexity characteristic of SSMs. However, the key innovation that enables the\nstate-of-the-art performance of our model lies in our perturbation technique\napplied to the state dynamics matrix governing the SSM system. This approach\nsignificantly improves the stability and performance of our model. We integrate\nP-SSE into a framework that leverages bi-directional flows and recurrent\nconnections, expanding the temporal context of flow prediction. Evaluations on\nDSEC-Flow and MVSEC datasets showcase P-SSE's superiority, with 8.48% and\n11.86% improvements in EPE performance, respectively.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faP-SSE\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e8b\u4ef6\u76f8\u673a\u5149\u5b66\u6d41\u4f30\u8ba1\uff0c\u901a\u8fc7\u6270\u52a8\u6280\u672f\u6539\u5584\u65f6\u7a7a\u63a8\u7406\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u795e\u7ecf\u7f51\u7edc\u5728\u4e8b\u4ef6\u76f8\u673a\u5149\u5b66\u6d41\u4f30\u8ba1\u4e2d\u7684\u65f6\u7a7a\u63a8\u7406\u9650\u5236\u3002", "method": "\u63d0\u51fa\u6270\u52a8\u72b6\u6001\u7a7a\u95f4\u7279\u5f81\u7f16\u7801\u5668(P-SSE)\uff0c\u5305\u62ec\u5bf9\u72b6\u6001\u52a8\u6001\u77e9\u9635\u7684\u6270\u52a8\u6280\u672f\uff0c\u5e76\u6574\u5408\u53cc\u5411\u6d41\u548c\u5faa\u73af\u8fde\u63a5\u6846\u67b6\u3002", "result": "\u5728DSEC-Flow\u548cMVSEC\u6570\u636e\u96c6\u4e0a\uff0cEPE\u6027\u80fd\u5206\u522b\u63d0\u9ad88.48%\u548c11.86%\u3002", "conclusion": "P-SSE\u5728\u4e8b\u4ef6\u76f8\u673a\u5149\u5b66\u6d41\u4f30\u8ba1\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002"}}
{"id": "2504.10948", "pdf": "https://arxiv.org/pdf/2504.10948", "abs": "https://arxiv.org/abs/2504.10948", "authors": ["Mohammad Matin Najafi", "Xianju Zhu", "Chrysanthi Kosyfaki", "Laks V. S. Lakshmanan", "Reynold Cheng"], "title": "BEACON: A Benchmark for Efficient and Accurate Counting of Subgraphs", "categories": ["cs.DS", "cs.AI", "cs.DB", "cs.SI"], "comment": null, "summary": "Subgraph counting the task of determining the number of instances of a query\npattern within a large graph lies at the heart of many critical applications,\nfrom analyzing financial networks and transportation systems to understanding\nbiological interactions. Despite decades of work yielding efficient algorithmic\n(AL) solutions and, more recently, machine learning (ML) approaches, a clear\ncomparative understanding is elusive. This gap stems from the absence of a\nunified evaluation framework, standardized datasets, and accessible ground\ntruths, all of which hinder systematic analysis and fair benchmarking. To\novercome these barriers, we introduce BEACON: a comprehensive benchmark\ndesigned to rigorously evaluate both AL and ML-based subgraph counting methods.\nBEACON provides a standardized dataset with verified ground truths, an\nintegrated evaluation environment, and a public leaderboard, enabling\nreproducible and transparent comparisons across diverse approaches. Our\nextensive experiments reveal that while AL methods excel in efficiently\ncounting subgraphs on very large graphs, they struggle with complex patterns\n(e.g., those exceeding six nodes). In contrast, ML methods are capable of\nhandling larger patterns but demand massive graph data inputs and often yield\nsuboptimal accuracy on small, dense graphs. These insights not only highlight\nthe unique strengths and limitations of each approach but also pave the way for\nfuture advancements in subgraph counting techniques. Overall, BEACON represents\na significant step towards unifying and accelerating research in subgraph\ncounting, encouraging innovative solutions and fostering a deeper understanding\nof the trade-offs between algorithmic and machine learning paradigms.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165BEACON\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5b50\u56fe\u8ba1\u6570\u4e2d\u7684\u7b97\u6cd5\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u63ed\u793a\u5176\u4f18\u7f3a\u70b9\uff0c\u4fc3\u8fdb\u7814\u7a76\u7edf\u4e00\u3002", "motivation": "\u5b50\u56fe\u8ba1\u6570\u4efb\u52a1\u7f3a\u4e4f\u7edf\u4e00\u6846\u67b6\u3001\u6807\u51c6\u5316\u6570\u636e\u96c6\u548cground truth\uff0c\u963b\u788d\u4e86\u7cfb\u7edf\u5206\u6790\u548c\u516c\u5e73\u6bd4\u8f83\u3002", "method": "\u5f15\u5165BEACON\uff0c\u63d0\u4f9b\u6807\u51c6\u5316\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u73af\u5883\u548c\u6392\u884c\u699c\uff0c\u8bc4\u4f30AL\u548cML\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793aAL\u65b9\u6cd5\u9ad8\u6548\u5904\u7406\u5927\u578b\u56fe\u4f46\u590d\u6742\u6a21\u5f0f\u56f0\u96be\uff0cML\u65b9\u6cd5\u80fd\u5904\u7406\u5927\u6a21\u5f0f\u4f46\u9700\u5927\u91cf\u6570\u636e\uff0c\u5728\u5c0f\u5bc6\u96c6\u56fe\u4e0a\u51c6\u786e\u6027\u4e0d\u8db3\u3002", "conclusion": "BEACON\u63a8\u52a8\u5b50\u56fe\u8ba1\u6570\u7814\u7a76\u7edf\u4e00\uff0c\u7a81\u51faAL\u548cML\u6743\u8861\uff0c\u9f13\u52b1\u672a\u6765\u521b\u65b0\u3002"}}
{"id": "2504.10961", "pdf": "https://arxiv.org/pdf/2504.10961", "abs": "https://arxiv.org/abs/2504.10961", "authors": ["Audrey Zhang", "Yifei Gao", "Wannapon Suraworachet", "Tanya Nazaretsky", "Mutlu Cukurova"], "title": "Evaluating Trust in AI, Human, and Co-produced Feedback Among Undergraduate Students", "categories": ["cs.HC", "cs.AI"], "comment": "35 pages, 6 figures. Under review at Assessment and Evaluation in\n  Higher Education", "summary": "As generative AI transforms educational feedback practices, understanding\nstudents' perceptions of different feedback providers becomes crucial for\neffective implementation. This study addresses a critical gap by comparing\nundergraduate students' trust in AI-generated, human-created, and human-AI\nco-produced feedback, informing how institutions can adapt feedback practices\nin this new era. Through a within-subject experiment with 91 participants, we\ninvestigated factors predicting students' ability to distinguish between\nfeedback types, perception of feedback quality, and potential biases to AI\ninvolvement. Findings revealed that students generally preferred AI and\nco-produced feedback over human feedback in terms of perceived usefulness and\nobjectivity. Only AI feedback suffered a decline in perceived genuineness when\nfeedback sources were revealed, while co-produced feedback maintained its\npositive perception. Educational AI experience improved students' ability to\nidentify AI feedback and increased their trust in all feedback types, while\ngeneral AI experience decreased perceived usefulness and credibility. Male\nstudents consistently rated all feedback types as less valuable than their\nfemale and non-binary counterparts. These insights inform evidence-based\nguidelines for integrating AI into higher education feedback systems while\naddressing trust concerns and fostering AI literacy among students.", "AI": {"tldr": "\u7814\u7a76\u663e\u793a\u5b66\u751f\u66f4\u504f\u597dAI\u548cAI-\u4eba\u7c7b\u5408\u4f5c\u53cd\u9988\uff0c\u57fa\u4e8e\u7ecf\u9a8c\u548c\u6027\u522b\u6709\u5dee\u5f02\uff0c\u4e3aAI\u5728\u6559\u80b2\u4e2d\u7684\u6574\u5408\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u6539\u53d8\u6559\u80b2\u53cd\u9988\u5b9e\u8df5\uff0c\u7406\u89e3\u5b66\u751f\u5bf9\u4e0d\u540c\u53cd\u9988\u63d0\u4f9b\u8005\u7684\u770b\u6cd5\u81f3\u5173\u91cd\u8981\uff0c\u672c\u7814\u7a76\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u752891\u540d\u53c2\u4e0e\u8005\u7684\u5185\u90e8\u53d7\u8bd5\u8005\u5b9e\u9a8c\uff0c\u8c03\u67e5\u5b66\u751f\u533a\u5206\u53cd\u9988\u7c7b\u578b\u7684\u80fd\u529b\u3001\u53cd\u9988\u8d28\u91cf\u611f\u77e5\u548c\u5bf9AI\u53c2\u4e0e\u7684\u504f\u89c1\u3002", "result": "\u5b66\u751f\u5728\u6709\u7528\u6027\u548c\u5ba2\u89c2\u6027\u4e0a\u66f4\u504f\u597dAI\u548c\u5408\u4f5c\u53cd\u9988\uff1b\u63ed\u793a\u6765\u6e90\u65f6AI\u53cd\u9988\u7684\u771f\u5b9e\u6027\u4e0b\u964d\uff1b\u6559\u80b2AI\u7ecf\u9a8c\u63d0\u5347\u8bc6\u522b\u548c\u4fe1\u4efb\uff1b\u4e00\u822cAI\u7ecf\u9a8c\u964d\u4f4e\u6709\u7528\u6027\u548c\u53ef\u4fe1\u5ea6\uff1b\u7537\u6027\u5b66\u751f\u5bf9\u6240\u6709\u53cd\u9988\u7684\u8bc4\u4ef7\u8f83\u4f4e\u3002", "conclusion": "\u8fd9\u4e9b\u6d1e\u89c1\u4e3a\u5c06AI\u6574\u5408\u5230\u9ad8\u7b49\u6559\u80b2\u53cd\u9988\u7cfb\u7edf\u4e2d\u63d0\u4f9b\u5faa\u8bc1\u6307\u5357\uff0c\u540c\u65f6\u89e3\u51b3\u4fe1\u4efb\u95ee\u9898\u5e76\u57f9\u517b\u5b66\u751f\u7684AI\u7d20\u517b\u3002"}}
{"id": "2504.10707", "pdf": "https://arxiv.org/pdf/2504.10707", "abs": "https://arxiv.org/abs/2504.10707", "authors": ["Haoyu Ji", "Yalan Song", "Tadd Bindas", "Chaopeng Shen", "Yuan Yang", "Ming Pan", "Jiangtao Liu", "Farshid Rahmani", "Ather Abbas", "Hylke Beck", "Yoshihide Wada", "Kathryn Lawson"], "title": "Distinct hydrologic response patterns and trends worldwide revealed by physics-embedded learning", "categories": ["physics.geo-ph", "cs.LG"], "comment": null, "summary": "To track rapid changes within our water sector, Global Water Models (GWMs)\nneed to realistically represent hydrologic systems' response patterns - such as\nbaseflow fraction - but are hindered by their limited ability to learn from\ndata. Here we introduce a high-resolution physics-embedded big-data-trained\nmodel as a breakthrough in reliably capturing characteristic hydrologic\nresponse patterns ('signatures') and their shifts. By realistically\nrepresenting the long-term water balance, the model revealed widespread shifts\n- up to ~20% over 20 years - in fundamental green-blue-water partitioning and\nbaseflow ratios worldwide. Shifts in these response patterns, previously\nconsidered static, contributed to increasing flood risks in northern\nmid-latitudes, heightening water supply stresses in southern subtropical\nregions, and declining freshwater inputs to many European estuaries, all with\necological implications. With more accurate simulations at monthly and daily\nscales than current operational systems, this next-generation model resolves\nlarge, nonlinear seasonal runoff responses to rainfall ('elasticity') and\nstreamflow flashiness in semi-arid and arid regions. These metrics highlight\nregions with management challenges due to large water supply variability and\nhigh climate sensitivity, but also provide tools to forecast seasonal water\navailability. This capability newly enables global-scale models to deliver\nreliable and locally relevant insights for water management.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f15\u5165\u4e00\u4e2a\u9ad8\u5206\u8fa8\u7387\u3001\u7269\u7406\u5d4c\u5165\u5f0f\u7684\u5927\u6570\u636e\u8bad\u7ec3\u6a21\u578b\uff0c\u7528\u4e8e\u6355\u83b7\u6c34\u6587\u54cd\u5e94\u6a21\u5f0f\u53ca\u5176\u53d8\u5316\uff0c\u63ed\u793a\u5168\u7403\u6c34\u8d44\u6e90\u5206\u914d\u7684\u91cd\u5927\u8f6c\u53d8\uff0c\u5e76\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u6a21\u62df\u7ed3\u679c\u3002", "motivation": "\u5168\u7403\u6c34\u6a21\u578b\u9700\u8981\u771f\u5b9e\u8868\u793a\u6c34\u6587\u7cfb\u7edf\u7684\u54cd\u5e94\u6a21\u5f0f\uff0c\u4f46\u53d7\u9650\u4e8e\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u7684\u80fd\u529b\uff0c\u65e0\u6cd5\u6709\u6548\u8ddf\u8e2a\u5feb\u901f\u53d8\u5316\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u9ad8\u5206\u8fa8\u7387\u3001\u7269\u7406\u5d4c\u5165\u5f0f\u7684\u5927\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u6a21\u578b\u63ed\u793a\u4e86\u5168\u7403\u57fa\u7840\u6d41\u6bd4\u548c\u7eff\u84dd\u6c34\u5206\u914d\u53d8\u5316\uff08\u9ad8\u8fbe20%\uff09\uff0c\u5bfc\u81f4\u6d2a\u6c34\u98ce\u9669\u589e\u52a0\u3001\u6c34\u4f9b\u7ed9\u538b\u529b\u5347\u9ad8\uff0c\u5e76\u63d0\u4f9b\u6bd4\u5f53\u524d\u7cfb\u7edf\u66f4\u51c6\u786e\u7684\u6708\u5ea6\u548c\u65e5\u5c3a\u5ea6\u6a21\u62df\u3002", "conclusion": "\u8fd9\u79cd\u6a21\u578b\u4f7f\u5168\u7403\u89c4\u6a21\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u53ef\u9760\u7684\u672c\u5730\u76f8\u5173\u6c34\u7ba1\u7406\u6d1e\u5bdf\uff0c\u5e2e\u52a9\u9884\u6d4b\u5b63\u8282\u6027\u6c34\u53ef\u7528\u6027\u548c\u7a81\u51fa\u7ba1\u7406\u6311\u6218\u533a\u57df\u3002"}}
{"id": "2504.10982", "pdf": "https://arxiv.org/pdf/2504.10982", "abs": "https://arxiv.org/abs/2504.10982", "authors": ["Yingjian Chen", "Feiyang Li", "Xingyu Song", "Tianxiao Li", "Issey Sudeka", "Irene Li"], "title": "Exploring the Role of KG-Based RAG in Japanese Medical Question Answering with Small-Scale LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages", "summary": "Large language models (LLMs) perform well in medical QA, but their\neffectiveness in Japanese contexts is limited due to privacy constraints that\nprevent the use of commercial models like GPT-4 in clinical settings. As a\nresult, recent efforts focus on instruction-tuning open-source LLMs, though the\npotential of combining them with retrieval-augmented generation (RAG) remains\nunderexplored. To bridge this gap, we are the first to explore a knowledge\ngraph-based (KG) RAG framework for Japanese medical QA small-scale open-source\nLLMs. Experimental results show that KG-based RAG has only a limited impact on\nJapanese medical QA using small-scale open-source LLMs. Further case studies\nreveal that the effectiveness of the RAG is sensitive to the quality and\nrelevance of the external retrieved content. These findings offer valuable\ninsights into the challenges and potential of applying RAG in Japanese medical\nQA, while also serving as a reference for other low-resource languages.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684RAG\u6846\u67b6\u5728\u65e5\u8bed\u533b\u7597\u95ee\u7b54\u4e2d\u4f7f\u7528\u5c0f\u578b\u5f00\u6e90LLM\u7684\u6548\u679c\uff0c\u53d1\u73b0\u5f71\u54cd\u6709\u9650\u3002", "motivation": "\u7531\u4e8e\u9690\u79c1\u9650\u5236\uff0c\u5546\u4e1aLLM\u5982GPT-4\u65e0\u6cd5\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u4f7f\u7528\uff0c\u5bfc\u81f4\u65e5\u8bed\u533b\u7597QA\u6548\u679c\u6709\u9650\uff0c\u4e14RAG\u7ed3\u5408\u6f5c\u529b\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u9996\u6b21\u5f00\u53d1\u5e76\u6d4b\u8bd5\u4e86\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684RAG\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u65e5\u8bed\u533b\u7597QA\u7684\u5c0f\u578b\u5f00\u6e90LLM\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aKG-based RAG\u5bf9\u65e5\u8bed\u533b\u7597QA\u7684\u5f71\u54cd\u6709\u9650\uff0c\u4e14\u5176\u6709\u6548\u6027\u4f9d\u8d56\u4e8e\u68c0\u7d22\u5185\u5bb9\u7684\u8d28\u91cf\u548c\u76f8\u5173\u6027\u3002", "conclusion": "\u4e3a\u65e5\u8bed\u533b\u7597QA\u4e2dRAG\u7684\u5e94\u7528\u63d0\u4f9b\u6311\u6218\u548c\u6f5c\u529b\u7684\u89c1\u89e3\uff0c\u5e76\u4e3a\u5176\u4ed6\u4f4e\u8d44\u6e90\u8bed\u8a00\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2504.10724", "pdf": "https://arxiv.org/pdf/2504.10724", "abs": "https://arxiv.org/abs/2504.10724", "authors": ["Avinash Kumar", "Shashank Nag", "Jason Clemons", "Lizy John", "Poulami Das"], "title": "HELIOS: Adaptive Model And Early-Exit Selection for Efficient LLM Inference Serving", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Deploying large language models (LLMs) presents critical challenges due to\nthe inherent trade-offs associated with key performance metrics, such as\nlatency, accuracy, and throughput. Typically, gains in one metric is\naccompanied with degradation in others. Early-Exit LLMs (EE-LLMs) efficiently\nnavigate this trade-off space by skipping some of the later model layers when\nit confidently finds an output token early, thus reducing latency without\nimpacting accuracy. However, as the early exits taken depend on the task and\nare unknown apriori to request processing, EE-LLMs conservatively load the\nentire model, limiting resource savings and throughput. Also, current\nframeworks statically select a model for a user task, limiting our ability to\nadapt to changing nature of the input queries.\n  We propose HELIOS to address these challenges. First, HELIOS shortlists a set\nof candidate LLMs, evaluates them using a subset of prompts, gathering\ntelemetry data in real-time. Second, HELIOS uses the early exit data from these\nevaluations to greedily load the selected model only up to a limited number of\nlayers. This approach yields memory savings which enables us to process more\nrequests at the same time, thereby improving throughput. Third, HELIOS monitors\nand periodically reassesses the performance of the candidate LLMs and if\nneeded, switches to another model that can service incoming queries more\nefficiently (such as using fewer layers without lowering accuracy). Our\nevaluations show that HELIOS achieves 1.48$\\times$ throughput, 1.10$\\times$\nenergy-efficiency, 1.39$\\times$ lower response time, and 3.7$\\times$\nimprovements in inference batch sizes compared to the baseline, when optimizing\nfor the respective service level objectives.", "AI": {"tldr": "HELIOS \u901a\u8fc7\u52a8\u6001\u7ba1\u7406\u65e9\u9000\u548c\u6a21\u578b\u9009\u62e9\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\uff0c\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u5ef6\u8fdf\u3001\u51c6\u786e\u6027\u548c\u541e\u5410\u91cf\u7684\u6743\u8861\uff0c\u65e9\u9000LLM\u867d\u6709\u6548\u4f46\u52a0\u8f7d\u4fdd\u5b88\u4e14\u65e0\u6cd5\u9002\u5e94\u67e5\u8be2\u53d8\u5316\u3002", "method": "\u63d0\u51faHELIOS\u6846\u67b6\uff1a\u77ed\u5217\u8868\u5019\u9009\u6a21\u578b\u5e76\u8bc4\u4f30\u3001\u57fa\u4e8e\u65e9\u9000\u6570\u636e\u8d2a\u5a6a\u52a0\u8f7d\u5c42\u6570\u3001\u76d1\u63a7\u5e76\u5207\u6362\u6a21\u578b\u4ee5\u9002\u5e94\u8f93\u5165\u3002", "result": "HELIOS \u5b9e\u73b01.48\u500d\u541e\u5410\u91cf\u30011.10\u500d\u80fd\u6548\u30011.39\u500d\u54cd\u5e94\u65f6\u95f4\u964d\u4f4e\u30013.7\u500d\u63a8\u7406\u6279\u91cf\u5927\u5c0f\u6539\u5584\u3002", "conclusion": "HELIOS \u6709\u6548\u89e3\u51b3\u90e8\u7f72\u6311\u6218\uff0c\u63d0\u9ad8\u6027\u80fd\u6307\u6807\u3002"}}
{"id": "2504.10733", "pdf": "https://arxiv.org/pdf/2504.10733", "abs": "https://arxiv.org/abs/2504.10733", "authors": ["Kien X. Nguyen", "Bao Bach", "Ilya Safro"], "title": "Cross-Problem Parameter Transfer in Quantum Approximate Optimization Algorithm: A Machine Learning Approach", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Quantum Approximate Optimization Algorithm (QAOA) is one of the most\npromising candidates to achieve the quantum advantage in solving combinatorial\noptimization problems. The process of finding a good set of variational\nparameters in the QAOA circuit has proven to be challenging due to multiple\nfactors, such as barren plateaus. As a result, there is growing interest in\nexploiting parameter transferability, where parameter sets optimized for one\nproblem instance are transferred to another that could be more complex either\nto estimate the solution or to serve as a warm start for further optimization.\nBut can we transfer parameters from one class of problems to another?\nLeveraging parameter sets learned from a well-studied class of problems could\nhelp navigate the less studied one, reducing optimization overhead and\nmitigating performance pitfalls. In this paper, we study whether pretrained\nQAOA parameters of MaxCut can be used as is or to warm start the Maximum\nIndependent Set (MIS) circuits. Specifically, we design machine learning models\nto find good donor candidates optimized on MaxCut and apply their parameters to\nMIS acceptors. Our experimental results show that such parameter transfer can\nsignificantly reduce the number of optimization iterations required while\nachieving comparable approximation ratios.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4eceMaxCut\u5230Maximum Independent Set (MIS)\u8f6c\u79fbQAOA\u53c2\u6570\uff0c\u5b9e\u9a8c\u663e\u793a\u8fd9\u53ef\u51cf\u5c11\u4f18\u5316\u8fed\u4ee3\u5e76\u4fdd\u6301\u53ef\u6bd4\u8fd1\u4f3c\u6bd4\u3002", "motivation": "QAOA\u53c2\u6570\u4f18\u5316\u56e0barren plateaus\u7b49\u56e0\u7d20\u56f0\u96be\uff0c\u53c2\u6570\u8f6c\u79fb\u53ef\u964d\u4f4e\u4f18\u5316\u5f00\u9500\uff0c\u4ece\u5df2\u7814\u7a76\u95ee\u9898\u8f6c\u79fb\u5230\u65b0\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7b5b\u9009MaxCut\u4f18\u5316\u7684\u53c2\u6570\u6350\u8d60\u8005\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8eMIS\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u53c2\u6570\u8f6c\u79fb\u663e\u8457\u51cf\u5c11\u4f18\u5316\u8fed\u4ee3\u6b21\u6570\uff0c\u540c\u65f6\u8fbe\u5230\u53ef\u6bd4\u7684\u8fd1\u4f3c\u6bd4\u3002", "conclusion": "\u53c2\u6570\u8f6c\u79fb\u4eceMaxCut\u5230MIS\u6709\u6548\uff0c\u53ef\u51cf\u5c11\u4f18\u5316\u5f00\u9500\u5e76\u7f13\u89e3\u6027\u80fd\u95ee\u9898\u3002"}}
{"id": "2504.10995", "pdf": "https://arxiv.org/pdf/2504.10995", "abs": "https://arxiv.org/abs/2504.10995", "authors": ["Chaoyang Wang", "Zeyu Zhang", "Long Teng", "Zijun Li", "Shichao Kan"], "title": "TMCIR: Token Merge Benefits Composed Image Retrieval", "categories": ["cs.CV", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2310.05473 by other authors", "summary": "Composed Image Retrieval (CIR) retrieves target images using a multi-modal\nquery that combines a reference image with text describing desired\nmodifications. The primary challenge is effectively fusing this visual and\ntextual information. Current cross-modal feature fusion approaches for CIR\nexhibit an inherent bias in intention interpretation. These methods tend to\ndisproportionately emphasize either the reference image features\n(visual-dominant fusion) or the textual modification intent (text-dominant\nfusion through image-to-text conversion). Such an imbalanced representation\noften fails to accurately capture and reflect the actual search intent of the\nuser in the retrieval results. To address this challenge, we propose TMCIR, a\nnovel framework that advances composed image retrieval through two key\ninnovations: 1) Intent-Aware Cross-Modal Alignment. We first fine-tune CLIP\nencoders contrastively using intent-reflecting pseudo-target images,\nsynthesized from reference images and textual descriptions via a diffusion\nmodel. This step enhances the encoder ability of text to capture nuanced\nintents in textual descriptions. 2) Adaptive Token Fusion. We further fine-tune\nall encoders contrastively by comparing adaptive token-fusion features with the\ntarget image. This mechanism dynamically balances visual and textual\nrepresentations within the contrastive learning pipeline, optimizing the\ncomposed feature for retrieval. Extensive experiments on Fashion-IQ and CIRR\ndatasets demonstrate that TMCIR significantly outperforms state-of-the-art\nmethods, particularly in capturing nuanced user intent.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTMCIR\u6846\u67b6\uff0c\u901a\u8fc7\u6539\u8fdb\u89c6\u89c9\u548c\u6587\u672c\u4fe1\u606f\u878d\u5408\uff0c\u63d0\u5347\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u6027\u80fd\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u4e2d\u8de8\u6a21\u6001\u878d\u5408\u65b9\u6cd5\u5b58\u5728\u7684\u504f\u5dee\u95ee\u9898\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u7528\u6237\u610f\u56fe\u3002", "method": "\u63d0\u51faTMCIR\u6846\u67b6\uff0c\u5305\u62ec\u610f\u56fe\u611f\u77e5\u8de8\u6a21\u6001\u5bf9\u9f50\uff08\u4f7f\u7528\u6269\u6563\u6a21\u578b\u5408\u6210\u4f2a\u76ee\u6807\u56fe\u50cf\u5fae\u8c03CLIP\u7f16\u7801\u5668\uff09\u548c\u81ea\u9002\u5e94\u6807\u8bb0\u878d\u5408\uff08\u5bf9\u6bd4\u5b66\u4e60\u52a8\u6001\u5e73\u8861\u89c6\u89c9\u548c\u6587\u672c\u8868\u793a\uff09\u3002", "result": "\u5728Fashion-IQ\u548cCIRR\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cTMCIR\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u6355\u6349\u7ec6\u5fae\u7528\u6237\u610f\u56fe\u65b9\u9762\u3002", "conclusion": "TMCIR\u6846\u67b6\u6709\u6548\u5e73\u8861\u89c6\u89c9\u548c\u6587\u672c\u8868\u793a\uff0c\u63d0\u9ad8\u4e86\u68c0\u7d22\u51c6\u786e\u6027\u3002"}}
{"id": "2504.11004", "pdf": "https://arxiv.org/pdf/2504.11004", "abs": "https://arxiv.org/abs/2504.11004", "authors": ["Jinwu Hu", "Wei Zhang", "Yufeng Wang", "Yu Hu", "Bin Xiao", "Mingkui Tan", "Qing Du"], "title": "Dynamic Compressing Prompts for Efficient Inference of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Under review (submited in 2024.11)", "summary": "Large Language Models (LLMs) have shown outstanding performance across a\nvariety of tasks, partly due to advanced prompting techniques. However, these\ntechniques often require lengthy prompts, which increase computational costs\nand can hinder performance because of the limited context windows of LLMs.\nWhile prompt compression is a straightforward solution, existing methods\nconfront the challenges of retaining essential information, adapting to context\nchanges, and remaining effective across different tasks. To tackle these\nissues, we propose a task-agnostic method called Dynamic Compressing Prompts\n(LLM-DCP). Our method reduces the number of prompt tokens while aiming to\npreserve the performance as much as possible. We model prompt compression as a\nMarkov Decision Process (MDP), enabling the DCP-Agent to sequentially remove\nredundant tokens by adapting to dynamic contexts and retaining crucial content.\nWe develop a reward function for training the DCP-Agent that balances the\ncompression rate, the quality of the LLM output, and the retention of key\ninformation. This allows for prompt token reduction without needing an external\nblack-box LLM. Inspired by the progressive difficulty adjustment in curriculum\nlearning, we introduce a Hierarchical Prompt Compression (HPC) training\nstrategy that gradually increases the compression difficulty, enabling the\nDCP-Agent to learn an effective compression method that maintains information\nintegrity. Experiments demonstrate that our method outperforms state-of-the-art\ntechniques, especially at higher compression rates. The code for our approach\nwill be available at https://github.com/Fhujinwu/DCP.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4efb\u52a1\u65e0\u5173\u7684\u63d0\u793a\u538b\u7f29\u65b9\u6cd5LLM-DCP\uff0c\u901a\u8fc7\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u51cf\u5c11\u63d0\u793a\u4ee4\u724c\uff0c\u540c\u65f6\u4fdd\u6301LLM\u6027\u80fd\u3002", "motivation": "LLM\u63d0\u793a\u6280\u672f\u9700\u957f\u63d0\u793a\uff0c\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u5e76\u53d7\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\uff1b\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\u96be\u4fdd\u7559\u5173\u952e\u4fe1\u606f\u3001\u9002\u5e94\u53d8\u5316\u548c\u8de8\u4efb\u52a1\u6709\u6548\u3002", "method": "\u63d0\u51faLLM-DCP\uff0c\u5c06\u538b\u7f29\u5efa\u6a21\u4e3aMDP\uff0c\u4f7f\u7528DCP-Agent\u79fb\u9664\u5197\u4f59\u4ee4\u724c\uff0c\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\u548c\u57fa\u4e8e\u8bfe\u7a0b\u5b66\u4e60\u7684HPC\u7b56\u7565\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u9ad8\u538b\u7f29\u7387\u4e0b\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u65b9\u6cd5\u6709\u6548\u51cf\u5c11\u63d0\u793a\u4ee4\u724c\u800c\u4e0d\u663e\u8457\u964d\u4f4e\u6027\u80fd\uff0c\u4ee3\u7801\u5c06\u5728GitHub\u4e0a\u516c\u5f00\u3002"}}
{"id": "2504.11008", "pdf": "https://arxiv.org/pdf/2504.11008", "abs": "https://arxiv.org/abs/2504.11008", "authors": ["Qinyue Tong", "Ziqian Lu", "Jun Liu", "Yangming Zheng", "Zheming Lu"], "title": "MediSee: Reasoning-based Pixel-level Perception in Medical Images", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 6 figures", "summary": "Despite remarkable advancements in pixel-level medical image perception,\nexisting methods are either limited to specific tasks or heavily rely on\naccurate bounding boxes or text labels as input prompts. However, the medical\nknowledge required for input is a huge obstacle for general public, which\ngreatly reduces the universality of these methods. Compared with these\ndomain-specialized auxiliary information, general users tend to rely on oral\nqueries that require logical reasoning. In this paper, we introduce a novel\nmedical vision task: Medical Reasoning Segmentation and Detection (MedSD),\nwhich aims to comprehend implicit queries about medical images and generate the\ncorresponding segmentation mask and bounding box for the target object. To\naccomplish this task, we first introduce a Multi-perspective, Logic-driven\nMedical Reasoning Segmentation and Detection (MLMR-SD) dataset, which\nencompasses a substantial collection of medical entity targets along with their\ncorresponding reasoning. Furthermore, we propose MediSee, an effective baseline\nmodel designed for medical reasoning segmentation and detection. The\nexperimental results indicate that the proposed method can effectively address\nMedSD with implicit colloquial queries and outperform traditional medical\nreferring segmentation methods.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u533b\u7597\u63a8\u7406\u5206\u5272\u548c\u68c0\u6d4b\u4efb\u52a1\uff0c\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\uff0c\u63d0\u51fa\u6570\u636e\u96c6\u548c\u57fa\u7ebf\u6a21\u578b\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4efb\u52a1\u7279\u5b9a\u6216\u4f9d\u8d56\u8fb9\u754c\u6846/\u6587\u672c\u6807\u7b7e\uff0c\u533b\u7597\u77e5\u8bc6\u95e8\u69db\u9ad8\uff0c\u7528\u6237\u66f4\u503e\u5411\u903b\u8f91\u63a8\u7406\u7684\u53e3\u5934\u67e5\u8be2\u3002", "method": "\u5f15\u5165MedSD\u4efb\u52a1\uff0c\u6784\u5efaMLMR-SD\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51faMediSee\u57fa\u7ebf\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u5904\u7406\u9690\u5f0f\u67e5\u8be2\uff0c\u5e76\u4f18\u4e8e\u4f20\u7edf\u533b\u7597\u5206\u5272\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u65b9\u6cd5\u63d0\u5347\u4e86\u533b\u7597\u56fe\u50cf\u5904\u7406\u7684\u901a\u7528\u6027\u548c\u6613\u7528\u6027\u3002"}}
{"id": "2504.11011", "pdf": "https://arxiv.org/pdf/2504.11011", "abs": "https://arxiv.org/abs/2504.11011", "authors": ["Francesca Pezzuti", "Ariane Mueller", "Sean MacAvaney", "Nicola Tonellotto"], "title": "Document Quality Scoring for Web Crawling", "categories": ["cs.IR", "cs.AI"], "comment": "Presented at WOWS2025", "summary": "The internet contains large amounts of low-quality content, yet users expect\nweb search engines to deliver high-quality, relevant results. The abundant\npresence of low-quality pages can negatively impact retrieval and crawling\nprocesses by wasting resources on these documents. Therefore, search engines\ncan greatly benefit from techniques that leverage efficient quality estimation\nmethods to mitigate these negative impacts. Quality scoring methods for web\npages are useful for many processes typical for web search systems, including\nstatic index pruning, index tiering, and crawling. Building on work by Chang et\nal.~\\cite{chang2024neural}, who proposed using neural estimators of semantic\nquality for static index pruning, we extend their approach and apply their\nneural quality scorers to assess the semantic quality of web pages in crawling\nprioritisation tasks. In our experimental analysis, we found that prioritising\nsemantically high-quality pages over low-quality ones can improve downstream\nsearch effectiveness. Our software contribution consists of a Docker container\nthat computes an effective quality score for a given web page, allowing the\nquality scorer to be easily included and used in other components of web search\nsystems.", "AI": {"tldr": "\u672c\u8bba\u6587\u6269\u5c55\u795e\u7ecf\u8d28\u91cf\u8bc4\u5206\u65b9\u6cd5\u5e94\u7528\u4e8e\u7f51\u7edc\u722c\u866b\u4f18\u5148\u7ea7\u8bbe\u7f6e\uff0c\u63d0\u9ad8\u641c\u7d22\u6548\u679c\uff0c\u5e76\u63d0\u4f9bDocker\u5bb9\u5668\u5de5\u5177\u3002", "motivation": "\u4e92\u8054\u7f51\u5b58\u5728\u5927\u91cf\u4f4e\u8d28\u91cf\u5185\u5bb9\uff0c\u6d6a\u8d39\u641c\u7d22\u5f15\u64ce\u8d44\u6e90\uff0c\u56e0\u6b64\u9700\u8981\u9ad8\u6548\u7684\u8d28\u91cf\u4f30\u8ba1\u65b9\u6cd5\u6765\u4f18\u5316\u68c0\u7d22\u548c\u722c\u53d6\u8fc7\u7a0b\u3002", "method": "\u57fa\u4e8eChang et al.\u7684\u5de5\u4f5c\uff0c\u6269\u5c55\u795e\u7ecf\u8d28\u91cf\u4f30\u8ba1\u5668\u7528\u4e8e\u722c\u866b\u4f18\u5148\u7ea7\u4efb\u52a1\u4e2d\u8bc4\u4f30\u7f51\u9875\u8bed\u4e49\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u4f18\u5148\u5904\u7406\u9ad8\u8d28\u91cf\u9875\u9762\u53ef\u63d0\u5347\u641c\u7d22\u6548\u679c\uff1b\u8d21\u732e\u4e86\u4e00\u4e2a\u8ba1\u7b97\u7f51\u9875\u8d28\u91cf\u5f97\u5206\u7684Docker\u5bb9\u5668\u3002", "conclusion": "\u8d28\u91cf\u8bc4\u5206\u65b9\u6cd5\u53ef\u663e\u8457\u6539\u5584\u641c\u7d22\u5f15\u64ce\u7684\u7d22\u5f15\u4fee\u526a\u3001\u5c42\u7ea7\u5316\u548c\u722c\u53d6\u7b49\u8fc7\u7a0b\u3002"}}
{"id": "2504.10757", "pdf": "https://arxiv.org/pdf/2504.10757", "abs": "https://arxiv.org/abs/2504.10757", "authors": ["Amirhosein Chahe", "Lifeng Zhou"], "title": "ReasonDrive: Efficient Visual Question Answering for Autonomous Vehicles with Reasoning-Enhanced Small Vision-Language Models", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Vision-language models (VLMs) show promise for autonomous driving but often\nlack transparent reasoning capabilities that are critical for safety. We\ninvestigate whether explicitly modeling reasoning during fine-tuning enhances\nVLM performance on driving decision tasks. Using GPT-4o, we generate structured\nreasoning chains for driving scenarios from the DriveLM benchmark with\ncategory-specific prompting strategies. We compare reasoning-based fine-tuning,\nanswer-only fine-tuning, and baseline instruction-tuned models across multiple\nsmall VLM families (Llama 3.2, Llava 1.5, and Qwen 2.5VL). Our results\ndemonstrate that reasoning-based fine-tuning consistently outperforms\nalternatives, with Llama3.2-11B-reason achieving the highest performance.\nModels fine-tuned with reasoning show substantial improvements in accuracy and\ntext generation quality, suggesting explicit reasoning enhances internal\nrepresentations for driving decisions. These findings highlight the importance\nof transparent decision processes in safety-critical domains and offer a\npromising direction for developing more interpretable autonomous driving\nsystems.", "AI": {"tldr": "\u663e\u5f0f\u63a8\u7406\u5fae\u8c03\u63d0\u5347\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u9a7e\u9a76\u51b3\u7b56\u4e2d\u7684\u6027\u80fd\uff0c\u4f7f\u7528GPT-4o\u751f\u6210\u63a8\u7406\u94fe\uff0c\u5e76\u8bc1\u660e\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7f3a\u4e4f\u900f\u660e\u63a8\u7406\u80fd\u529b\uff0c\u8fd9\u5bf9\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u589e\u5f3a\u63a8\u7406\u5efa\u6a21\u3002", "method": "\u4f7f\u7528GPT-4o\u751f\u6210\u7ed3\u6784\u5316\u63a8\u7406\u94fe\uff0c\u901a\u8fc7\u7c7b\u522b\u7279\u5b9a\u63d0\u793a\u7b56\u7565\u5728DriveLM\u57fa\u51c6\u4e0a\u5fae\u8c03Llama 3.2\u3001Llava 1.5\u548cQwen 2.5VL\u6a21\u578b\uff0c\u6bd4\u8f83\u63a8\u7406-based\u548c\u4ec5\u7b54\u6848\u5fae\u8c03\u3002", "result": "\u63a8\u7406-based\u5fae\u8c03 consistently \u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0cLlama3.2-11B-reason \u8868\u73b0\u6700\u4f73\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6587\u672c\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "\u5f3a\u8c03\u900f\u660e\u51b3\u7b56\u8fc7\u7a0b\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u5f00\u53d1\u66f4\u53ef\u89e3\u91ca\u7684\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2504.11014", "pdf": "https://arxiv.org/pdf/2504.11014", "abs": "https://arxiv.org/abs/2504.11014", "authors": ["Eunsoo Im", "Jung Kwon Lee", "Changhyun Jee"], "title": "GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*", "categories": ["cs.CV", "cs.AI"], "comment": "9pages, 1 supple", "summary": "The emerging trend in computer vision emphasizes developing universal models\ncapable of simultaneously addressing multiple diverse tasks. Such universality\ntypically requires joint training across multi-domain datasets to ensure\neffective generalization. However, monocular 3D object detection presents\nunique challenges in multi-domain training due to the scarcity of datasets\nannotated with accurate 3D ground-truth labels, especially beyond typical\nroad-based autonomous driving contexts. To address this challenge, we introduce\na novel weakly supervised framework leveraging pseudo-labels. Current\npretrained models often struggle to accurately detect pedestrians in non-road\nenvironments due to inherent dataset biases. Unlike generalized image-based 2D\nobject detection models, achieving similar generalization in monocular 3D\ndetection remains largely unexplored. In this paper, we propose GATE3D, a novel\nframework designed specifically for generalized monocular 3D object detection\nvia weak supervision. GATE3D effectively bridges domain gaps by employing\nconsistency losses between 2D and 3D predictions. Remarkably, our model\nachieves competitive performance on the KITTI benchmark as well as on an\nindoor-office dataset collected by us to evaluate the generalization\ncapabilities of our framework. Our results demonstrate that GATE3D\nsignificantly accelerates learning from limited annotated data through\neffective pre-training strategies, highlighting substantial potential for\nbroader impacts in robotics, augmented reality, and virtual reality\napplications. Project page: https://ies0411.github.io/GATE3D/", "AI": {"tldr": "\u672c\u6587\u5f15\u5165GATE3D\u6846\u67b6\uff0c\u901a\u8fc7\u5f31\u76d1\u7763\u5b66\u4e60\u5b9e\u73b0\u5355\u76ee3D\u7269\u4f53\u68c0\u6d4b\u7684\u6cdb\u5316\uff0c\u4f7f\u75282D\u548c3D\u9884\u6d4b\u4e00\u81f4\u6027\u635f\u5931\u6865\u63a5\u9886\u57df\u5dee\u8ddd\uff0c\u5728KITTI\u548c\u5ba4\u5185\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u901a\u7528\u6a21\u578b\u7684\u591a\u9886\u57df\u8bad\u7ec3\u6311\u6218\uff0c\u7279\u522b\u662f\u5355\u76ee3D\u7269\u4f53\u68c0\u6d4b\u6570\u636e\u96c6\u7a00\u7f3a\u548c\u504f\u7f6e\u95ee\u9898\uff0c\u5c24\u5176\u5728\u975e\u9053\u8def\u73af\u5883\u3002", "method": "\u65b9\u6cd5\u662f\u63d0\u51faGATE3D\u6846\u67b6\uff0c\u5229\u7528\u4f2a\u6807\u7b7e\u548c2D-3D\u9884\u6d4b\u4e00\u81f4\u6027\u635f\u5931\u6765\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u7ed3\u679c\u663e\u793aGATE3D\u5728KITTI\u57fa\u51c6\u548c\u5ba4\u5185\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u5e76\u52a0\u901f\u4e86\u4ece\u6709\u9650\u6807\u6ce8\u6570\u636e\u4e2d\u5b66\u4e60\u3002", "conclusion": "\u7ed3\u8bba\u662fGATE3D\u6709\u6548\u89e3\u51b3\u4e86\u68c0\u6d4b\u6311\u6218\uff0c\u5177\u6709\u5728\u673a\u5668\u4eba\u3001\u589e\u5f3a\u73b0\u5b9e\u548c\u865a\u62df\u73b0\u5b9e\u7b49\u9886\u57df\u7684\u5e7f\u6cdb\u6f5c\u529b\u3002"}}
{"id": "2504.10762", "pdf": "https://arxiv.org/pdf/2504.10762", "abs": "https://arxiv.org/abs/2504.10762", "authors": ["Qixu Chen", "Yeye He", "Raymond Chi-Wing Wong", "Weiwei Cui", "Song Ge", "Haidong Zhang", "Dongmei Zhang", "Surajit Chaudhuri"], "title": "Auto-Test: Learning Semantic-Domain Constraints for Unsupervised Error Detection in Tables", "categories": ["cs.DB", "cs.LG"], "comment": "full version of a paper accepted to SIGMOD 2025", "summary": "Data cleaning is a long-standing challenge in data management. While powerful\nlogic and statistical algorithms have been developed to detect and repair data\nerrors in tables, existing algorithms predominantly rely on domain-experts to\nfirst manually specify data-quality constraints specific to a given table,\nbefore data cleaning algorithms can be applied.\n  In this work, we propose a new class of data-quality constraints that we call\nSemantic-Domain Constraints, which can be reliably inferred and automatically\napplied to any tables, without requiring domain-experts to manually specify on\na per-table basis. We develop a principled framework to systematically learn\nsuch constraints from table corpora using large-scale statistical tests, which\ncan further be distilled into a core set of constraints using our optimization\nframework, with provable quality guarantees. Extensive evaluations show that\nthis new class of constraints can be used to both (1) directly detect errors on\nreal tables in the wild, and (2) augment existing expert-driven data-cleaning\ntechniques as a new class of complementary constraints.\n  Our extensively labeled benchmark dataset with 2400 real data columns, as\nwell as our code are available at https://github.com/qixuchen/AutoTest to\nfacilitate future research.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u8d28\u91cf\u7ea6\u675f\u2014\u2014\u8bed\u4e49\u57df\u7ea6\u675f\uff0c\u80fd\u591f\u81ea\u52a8\u63a8\u65ad\u548c\u5e94\u7528\uff0c\u800c\u4e0d\u9700\u9886\u57df\u4e13\u5bb6\u624b\u52a8\u6307\u5b9a\u3002", "motivation": "\u6570\u636e\u6e05\u6d17\u662f\u957f\u671f\u6311\u6218\uff0c\u73b0\u6709\u7684\u7b97\u6cd5\u4f9d\u8d56\u4e13\u5bb6\u624b\u52a8\u5b9a\u4e49\u7ea6\u675f\uff0c\u56e0\u6b64\u9700\u8981\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u89c4\u6a21\u7edf\u8ba1\u6d4b\u8bd5\u4ece\u8868\u683c\u8bed\u6599\u5e93\u5b66\u4e60\u7ea6\u675f\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u6846\u67b6\u63d0\u70bc\u6838\u5fc3\u7ea6\u675f\uff0c\u5177\u6709\u8d28\u91cf\u4fdd\u8bc1\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u8fd9\u79cd\u7ea6\u675f\u53ef\u68c0\u6d4b\u771f\u5b9e\u8868\u683c\u9519\u8bef\uff0c\u5e76\u589e\u5f3a\u73b0\u6709\u6570\u636e\u6e05\u6d17\u6280\u672f\uff1b\u8fd8\u63d0\u4f9b\u4e86\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4ee3\u7801\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u8bc1\u660e\u4e86\u81ea\u52a8\u7ea6\u675f\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u8d44\u6e90\u3002"}}
{"id": "2504.11020", "pdf": "https://arxiv.org/pdf/2504.11020", "abs": "https://arxiv.org/abs/2504.11020", "authors": ["Siddharth Mehrotra", "Ujwal Gadiraju", "Eva Bittner", "Folkert van Delden", "Catholijn M. Jonker", "Myrthe L. Tielman"], "title": "\"Even explanations will not help in trusting [this] fundamentally biased system\": A Predictive Policing Case-Study", "categories": ["cs.HC", "cs.AI"], "comment": "33rd ACM Conference on User Modeling, Adaptation and Personalization\n  (UMAP '25), June 16--19, 2025, New York City, NY, USA", "summary": "In today's society, where Artificial Intelligence (AI) has gained a vital\nrole, concerns regarding user's trust have garnered significant attention. The\nuse of AI systems in high-risk domains have often led users to either\nunder-trust it, potentially causing inadequate reliance or over-trust it,\nresulting in over-compliance. Therefore, users must maintain an appropriate\nlevel of trust. Past research has indicated that explanations provided by AI\nsystems can enhance user understanding of when to trust or not trust the\nsystem. However, the utility of presentation of different explanations forms\nstill remains to be explored especially in high-risk domains. Therefore, this\nstudy explores the impact of different explanation types (text, visual, and\nhybrid) and user expertise (retired police officers and lay users) on\nestablishing appropriate trust in AI-based predictive policing. While we\nobserved that the hybrid form of explanations increased the subjective trust in\nAI for expert users, it did not led to better decision-making. Furthermore, no\nform of explanations helped build appropriate trust. The findings of our study\nemphasize the importance of re-evaluating the use of explanations to build\n[appropriate] trust in AI based systems especially when the system's use is\nquestionable. Finally, we synthesize potential challenges and policy\nrecommendations based on our results to design for appropriate trust in\nhigh-risk based AI-based systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e0d\u540c\u89e3\u91ca\u5f62\u5f0f\uff08\u6587\u672c\u3001\u53ef\u89c6\u3001\u6df7\u5408\uff09\u548c\u7528\u6237\u4e13\u4e1a\u6027\u5bf9AI\u9884\u6d4b\u6027\u8b66\u52a1\u4fe1\u4efb\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6df7\u5408\u89e3\u91ca\u63d0\u5347\u4e13\u5bb6\u4e3b\u89c2\u4fe1\u4efb\u4f46\u672a\u6539\u5584\u51b3\u7b56\uff0c\u65e0\u89e3\u91ca\u5f62\u5f0f\u5e2e\u52a9\u5efa\u7acb\u9002\u5f53\u4fe1\u4efb\uff0c\u547c\u5401\u91cd\u65b0\u8bc4\u4f30\u89e3\u91ca\u5728AI\u4fe1\u4efb\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "AI\u5728\u9ad8\u98ce\u9669\u9886\u57df\u4fe1\u4efb\u95ee\u9898\u7a81\u51fa\uff0c\u7528\u6237\u53ef\u80fd\u8fc7\u5ea6\u6216\u4e0d\u8db3\u4fe1\u4efb\uff0c\u8fc7\u53bb\u7814\u7a76\u663e\u793a\u89e3\u91ca\u6709\u52a9\u4e8e\u7406\u89e3\u4fe1\u4efb\u65f6\u673a\uff0c\u4f46\u4e0d\u540c\u89e3\u91ca\u5f62\u5f0f\u7684\u5f71\u54cd\u5c24\u5176\u5728\u9ad8\u98ce\u9669\u9886\u57df\u4ecd\u9700\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u6587\u672c\u3001\u53ef\u89c6\u548c\u6df7\u5408\u89e3\u91ca\u5f62\u5f0f\uff0c\u4ee5\u53ca\u4e13\u5bb6\uff08\u9000\u4f11\u8b66\u5bdf\uff09\u548c\u975e\u4e13\u5bb6\u7528\u6237\uff0c\u5728AI\u9884\u6d4b\u6027\u8b66\u52a1\u4e2d\u5bf9\u4fe1\u4efb\u7684\u5f71\u54cd\u3002", "result": "\u6df7\u5408\u89e3\u91ca\u63d0\u9ad8\u4e86\u4e13\u5bb6\u7528\u6237\u7684\u4e3b\u89c2\u4fe1\u4efb\uff0c\u4f46\u672a\u6539\u5584\u51b3\u7b56\uff1b\u4efb\u4f55\u89e3\u91ca\u5f62\u5f0f\u5747\u672a\u5e2e\u52a9\u5efa\u7acb\u9002\u5f53\u4fe1\u4efb\u3002", "conclusion": "\u5f3a\u8c03\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u89e3\u91ca\u5728\u6784\u5efaAI\u9002\u5f53\u4fe1\u4efb\u4e2d\u7684\u4f5c\u7528\uff0c\u5c24\u5176\u5728\u6709\u7591\u95ee\u7684\u7cfb\u7edf\u4e2d\uff1b\u57fa\u4e8e\u7ed3\u679c\u63d0\u51fa\u6311\u6218\u548c\u653f\u7b56\u63a8\u8350\uff0c\u4ee5\u8bbe\u8ba1\u9ad8\u98ce\u9669AI\u7cfb\u7edf\u7684\u9002\u5f53\u4fe1\u4efb\u3002"}}
{"id": "2504.11038", "pdf": "https://arxiv.org/pdf/2504.11038", "abs": "https://arxiv.org/abs/2504.11038", "authors": ["Yudong Zhang", "Ruobing Xie", "Jiansheng Chen", "Xingwu Sun", "Zhanhui Kang", "Yu Wang"], "title": "QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by NAACL 2025 main", "summary": "In typical multimodal tasks, such as Visual Question Answering (VQA),\nadversarial attacks targeting a specific image and question can lead large\nvision-language models (LVLMs) to provide incorrect answers. However, it is\ncommon for a single image to be associated with multiple questions, and LVLMs\nmay still answer other questions correctly even for an adversarial image\nattacked by a specific question. To address this, we introduce the\nquery-agnostic visual attack (QAVA), which aims to create robust adversarial\nexamples that generate incorrect responses to unspecified and unknown\nquestions. Compared to traditional adversarial attacks focused on specific\nimages and questions, QAVA significantly enhances the effectiveness and\nefficiency of attacks on images when the question is unknown, achieving\nperformance comparable to attacks on known target questions. Our research\nbroadens the scope of visual adversarial attacks on LVLMs in practical\nsettings, uncovering previously overlooked vulnerabilities, particularly in the\ncontext of visual adversarial threats. The code is available at\nhttps://github.com/btzyd/qava.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f15\u5165QAVA\uff0c\u4e00\u79cd\u9488\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u67e5\u8be2\u65e0\u5173\u89c6\u89c9\u653b\u51fb\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u672a\u77e5\u95ee\u9898\u4e0b\u751f\u6210\u9519\u8bef\u54cd\u5e94\u3002", "motivation": "\u52a8\u673a\u662f\u4f20\u7edf\u653b\u51fb\u9488\u5bf9\u7279\u5b9a\u56fe\u50cf\u548c\u95ee\u9898\uff0c\u800c\u5b9e\u9645\u4e2d\u4e00\u4e2a\u56fe\u50cf\u53ef\u80fd\u5173\u8054\u591a\u4e2a\u95ee\u9898\uff0c\u6a21\u578b\u53ef\u80fd\u4ecd\u80fd\u6b63\u786e\u56de\u7b54\u5176\u4ed6\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u5bf9\u672a\u77e5\u95ee\u9898\u7684\u9c81\u68d2\u653b\u51fb\u6765\u63ed\u793a\u6a21\u578b\u7684\u6f0f\u6d1e\u3002", "method": "\u65b9\u6cd5\u662f\u63d0\u51faQAVA\uff0c\u8fd9\u662f\u4e00\u79cd\u67e5\u8be2\u65e0\u5173\u7684\u89c6\u89c9\u653b\u51fb\uff0c\u65e8\u5728\u521b\u5efa\u5bf9\u6297\u6837\u672c\uff0c\u4f7f\u6a21\u578b\u5bf9\u672a\u6307\u5b9a\u7684\u672a\u77e5\u95ee\u9898\u4ea7\u751f\u9519\u8bef\u54cd\u5e94\u3002", "result": "\u7ed3\u679c\u663e\u793aQAVA\u663e\u8457\u63d0\u9ad8\u4e86\u653b\u51fb\u7684\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u4e0e\u9488\u5bf9\u5df2\u77e5\u76ee\u6807\u95ee\u9898\u7684\u653b\u51fb\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8fd9\u9879\u7814\u7a76\u6269\u5c55\u4e86\u89c6\u89c9\u5bf9\u6297\u653b\u51fb\u7684\u8303\u56f4\uff0c\u63ed\u793a\u4e86\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u6a21\u578b\u7684\u5148\u524d\u672a\u88ab\u6ce8\u610f\u7684\u6f0f\u6d1e\u3002"}}
{"id": "2504.10793", "pdf": "https://arxiv.org/pdf/2504.10793", "abs": "https://arxiv.org/abs/2504.10793", "authors": ["Kuang Yuan", "Yifeng Wang", "Xiyuxing Zhang", "Chengyi Shen", "Swarun Kumar", "Justin Chan"], "title": "SonicSieve: Bringing Directional Speech Extraction to Smartphones Using Acoustic Microstructures", "categories": ["cs.SD", "cs.HC", "cs.LG", "eess.AS"], "comment": null, "summary": "Imagine placing your smartphone on a table in a noisy restaurant and clearly\ncapturing the voices of friends seated around you, or recording a lecturer's\nvoice with clarity in a reverberant auditorium. We introduce SonicSieve, the\nfirst intelligent directional speech extraction system for smartphones using a\nbio-inspired acoustic microstructure. Our passive design embeds directional\ncues onto incoming speech without any additional electronics. It attaches to\nthe in-line mic of low-cost wired earphones which can be attached to\nsmartphones. We present an end-to-end neural network that processes the raw\naudio mixtures in real-time on mobile devices. Our results show that SonicSieve\nachieves a signal quality improvement of 5.0 dB when focusing on a 30{\\deg}\nangular region. Additionally, the performance of our system based on only two\nmicrophones exceeds that of conventional 5-microphone arrays.", "AI": {"tldr": "SonicSieve\u662f\u4e00\u79cd\u667a\u80fd\u5b9a\u5411\u8bed\u97f3\u63d0\u53d6\u7cfb\u7edf\uff0c\u4f7f\u7528\u751f\u7269\u542f\u53d1\u58f0\u5b66\u5fae\u7ed3\u6784\u548c\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u667a\u80fd\u624b\u673a\u4e0a\u5b9e\u65f6\u63d0\u5347\u97f3\u9891\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3\u5728\u5608\u6742\u73af\u5883\uff08\u5982\u9910\u5385\u6216\u793c\u5802\uff09\u4e2d\u6e05\u6670\u6355\u83b7\u7279\u5b9a\u65b9\u5411\u58f0\u97f3\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u88ab\u52a8\u8bbe\u8ba1\u7684\u58f0\u5b66\u5fae\u7ed3\u6784\u5d4c\u5165\u5b9a\u5411\u7ebf\u7d22\uff0c\u5e76\u7ed3\u5408\u7aef\u5230\u7aef\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u539f\u59cb\u97f3\u9891\u6df7\u5408\uff0c\u4ec5\u9700\u4e24\u4e2a\u9ea6\u514b\u98ce\u3002", "result": "\u572830\u5ea6\u89d2\u533a\u57df\u4fe1\u53f7\u8d28\u91cf\u6539\u55845.0 dB\uff0c\u4e14\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u4e94\u9ea6\u514b\u98ce\u9635\u5217\u3002", "conclusion": "SonicSieve\u63d0\u4f9b\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684\u8bed\u97f3\u63d0\u53d6\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u79fb\u52a8\u8bbe\u5907\u573a\u666f\u3002"}}
{"id": "2504.10796", "pdf": "https://arxiv.org/pdf/2504.10796", "abs": "https://arxiv.org/abs/2504.10796", "authors": ["Lukas-Benedikt Fiechtner", "Jose Blanchet"], "title": "Wasserstein Distributionally Regret Optimization", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "Distributionally Robust Optimization (DRO) is a popular framework for\ndecision-making under uncertainty, but its adversarial nature can lead to\noverly conservative solutions. To address this, we study ex-ante\nDistributionally Robust Regret Optimization (DRRO), focusing on\nWasserstein-based ambiguity sets which are popular due to their links to\nregularization and machine learning. We provide a systematic analysis of\nWasserstein DRRO, paralleling known results for Wasserstein DRO. Under\nsmoothness and regularity conditions, we show that Wasserstein DRRO coincides\nwith Empirical Risk Minimization (ERM) up to first-order terms, and exactly so\nin convex quadratic settings. We revisit the Wasserstein DRRO newsvendor\nproblem, where the loss is the maximum of two linear functions of demand and\ndecision. Extending [25], we show that the regret can be computed by maximizing\ntwo one-dimensional concave functions. For more general loss functions\ninvolving the maximum of multiple linear terms in multivariate random variables\nand decision vectors, we prove that computing the regret and thus also the DRRO\npolicy is NP-hard. We then propose a convex relaxation for these more general\nWasserstein DRRO problems and demonstrate its strong empirical performance.\nFinally, we provide an upper bound on the optimality gap of our relaxation and\nshow it improves over recent alternatives.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faDRRO\u6846\u67b6\u4ee5\u51cf\u5c11DRO\u7684\u4fdd\u5b88\u6027\uff0c\u901a\u8fc7Wasserstein\u65b9\u6cd5\u5206\u6790\uff0c\u63d0\u4f9b\u8ba1\u7b97\u548c\u677e\u5f1b\u65b9\u6848\u3002", "motivation": "DRO\u7684\u5bf9\u6297\u6027\u53ef\u80fd\u5bfc\u81f4\u8fc7\u4e8e\u4fdd\u5b88\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u56e0\u6b64\u5f15\u5165DRRO\u4f18\u5316\u9057\u61be\u3002", "method": "\u7cfb\u7edf\u5206\u6790Wasserstein DRRO\uff0c\u5305\u62ec\u4e0eERM\u6bd4\u8f83\u3001newsvendor\u95ee\u9898\u6c42\u89e3\u3001NP-hard\u8bc1\u660e\u548c\u51f8\u677e\u5f1b\u65b9\u6cd5\u3002", "result": "\u8bc1\u660eDRRO\u5728\u5e73\u6ed1\u6761\u4ef6\u4e0b\u4e0eERM\u4e00\u81f4\uff0cregret\u8ba1\u7b97\u65b9\u6cd5\uff0cNP-hard\u7ed3\u679c\uff0c\u51f8\u677e\u5f1b\u6027\u80fd\u826f\u597d\uff0c\u5e76\u7ed9\u51fa\u4f18\u5316\u95f4\u9699\u4e0a\u754c\u3002", "conclusion": "\u63d0\u51fa\u7684\u677e\u5f1b\u65b9\u6cd5\u6709\u6548\uff0c\u5e76\u6539\u5584\u73b0\u6709\u65b9\u6cd5\u7684\u4e0a\u754c\u3002"}}
{"id": "2504.10808", "pdf": "https://arxiv.org/pdf/2504.10808", "abs": "https://arxiv.org/abs/2504.10808", "authors": ["Md Rakibul Hasan", "Shafin Rahman", "Md Zakir Hossain", "Aneesh Krishna", "Tom Gedeon"], "title": "Tabular foundation model to detect empathy from visual cues", "categories": ["cs.CV", "cs.HC", "cs.LG"], "comment": null, "summary": "Detecting empathy from video interactions is an emerging area of research.\nVideo datasets, however, are often released as extracted features (i.e.,\ntabular data) rather than raw footage due to privacy and ethical concerns.\nPrior research on such tabular datasets established tree-based classical\nmachine learning approaches as the best-performing models. Motivated by the\nrecent success of textual foundation models (i.e., large language models), we\nexplore the use of tabular foundation models in empathy detection from tabular\nvisual features. We experiment with two recent tabular foundation models $-$\nTabPFN v2 and TabICL $-$ through in-context learning and fine-tuning setups.\nOur experiments on a public human-robot interaction benchmark demonstrate a\nsignificant boost in cross-subject empathy detection accuracy over several\nstrong baselines (accuracy: $0.590 \\rightarrow 0.730$; AUC: $0.564 \\rightarrow\n0.669$). In addition to performance improvement, we contribute novel insights\nand an evaluation setup to ensure generalisation on unseen subjects in this\npublic benchmark. As the practice of releasing video features as tabular\ndatasets is likely to persist due to privacy constraints, our findings will be\nwidely applicable to future empathy detection video datasets as well.", "AI": {"tldr": "This paper uses tabular foundation models to improve empathy detection from video features, achieving significant accuracy gains.", "motivation": "Motivated by the success of textual foundation models and the common release of video data as tabular features due to privacy concerns.", "method": "Experimented with TabPFN v2 and TabICL using in-context learning and fine-tuning on a human-robot interaction benchmark.", "result": "Improved cross-subject empathy detection accuracy from 0.590 to 0.730 and AUC from 0.564 to 0.669, with enhanced generalization.", "conclusion": "Findings are applicable to future empathy detection datasets released as tabular data due to privacy constraints."}}
{"id": "2504.11082", "pdf": "https://arxiv.org/pdf/2504.11082", "abs": "https://arxiv.org/abs/2504.11082", "authors": ["Efthymios Georgiou", "Vassilis Katsouros", "Yannis Avrithis", "Alexandros Potamianos"], "title": "DeepMLF: Multimodal language model with learnable tokens for deep fusion in sentiment analysis", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "While multimodal fusion has been extensively studied in Multimodal Sentiment\nAnalysis (MSA), the role of fusion depth and multimodal capacity allocation\nremains underexplored. In this work, we position fusion depth, scalability, and\ndedicated multimodal capacity as primary factors for effective fusion. We\nintroduce DeepMLF, a novel multimodal language model (LM) with learnable tokens\ntailored toward deep fusion. DeepMLF leverages an audiovisual encoder and a\npretrained decoder LM augmented with multimodal information across its layers.\nWe append learnable tokens to the LM that: 1) capture modality interactions in\na controlled fashion and 2) preserve independent information flow for each\nmodality. These fusion tokens gather linguistic information via causal\nself-attention in LM Blocks and integrate with audiovisual information through\ncross-attention MM Blocks. Serving as dedicated multimodal capacity, this\ndesign enables progressive fusion across multiple layers, providing depth in\nthe fusion process. Our training recipe combines modality-specific losses and\nlanguage modelling loss, with the decoder LM tasked to predict ground truth\npolarity. Across three MSA benchmarks with varying dataset characteristics,\nDeepMLF achieves state-of-the-art performance. Our results confirm that deeper\nfusion leads to better performance, with optimal fusion depths (5-7) exceeding\nthose of existing approaches. Additionally, our analysis on the number of\nfusion tokens reveals that small token sets ($\\sim$20) achieve optimal\nperformance. We examine the importance of representation learning order (fusion\ncurriculum) through audiovisual encoder initialization experiments. Our\nablation studies demonstrate the superiority of the proposed fusion design and\ngating while providing a holistic examination of DeepMLF's scalability to LLMs,\nand the impact of each training objective and embedding regularization.", "AI": {"tldr": "\u63d0\u51faDeepMLF\u6a21\u578b\uff0c\u6539\u8fdb\u4e86\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u7684\u878d\u5408\u6df1\u5ea6\u548c\u5bb9\u91cf\u5206\u914d\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u63a2\u8ba8\u878d\u5408\u6df1\u5ea6\u548c\u591a\u6a21\u6001\u5bb9\u91cf\u5206\u914d\u7684\u4f5c\u7528\uff0c\u8fd9\u4e9b\u65b9\u9762\u5728\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u5f15\u5165DeepMLF\uff0c\u4f7f\u7528\u97f3\u89c6\u9891\u7f16\u7801\u5668\u548c\u9884\u8bad\u7ec3\u89e3\u7801\u5668\u8bed\u8a00\u6a21\u578b\uff0c\u6dfb\u52a0\u53ef\u5b66\u4e60\u6807\u8bb0\u8fdb\u884c\u6df1\u5ea6\u878d\u5408\uff0c\u5e76\u7ed3\u5408\u7279\u5b9a\u635f\u5931\u51fd\u6570\u8bad\u7ec3\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u6700\u4f18\u878d\u5408\u6df1\u5ea6\u4e3a5-7\uff0c\u5c11\u91cf\u6807\u8bb0\uff08\u7ea620\u4e2a\uff09\u5373\u53ef\u6700\u4f73\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u8bbe\u8ba1\u4f18\u52bf\u3002", "conclusion": "\u66f4\u6df1\u878d\u5408\u5e26\u6765\u66f4\u597d\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u878d\u5408\u8bbe\u8ba1\u548c\u95e8\u63a7\u673a\u5236\u7684\u4f18\u8d8a\u6027\uff0c\u5e76\u5206\u6790\u4e86\u53ef\u6269\u5c55\u6027\u548c\u8bad\u7ec3\u76ee\u6807\u7684\u5f71\u54cd\u3002"}}
{"id": "2504.11083", "pdf": "https://arxiv.org/pdf/2504.11083", "abs": "https://arxiv.org/abs/2504.11083", "authors": ["Peng Du", "Shuolei Wang", "Shicheng Li", "Jinjing Shi"], "title": "QAMA: Quantum annealing multi-head attention operator with classical deep learning framework", "categories": ["quant-ph", "cs.AI"], "comment": null, "summary": "As large language models scale up, the conventional attention mechanism faces\ncritical challenges of exponential growth in memory consumption and energy\ncosts. Quantum annealing computing, with its inherent advantages in\ncomputational efficiency and low energy consumption, offers an innovative\ndirection for constructing novel deep learning architectures. This study\nproposes the first Quantum Annealing-based Multi-head Attention (QAMA)\nmechanism, achieving seamless compatibility with classical attention\narchitectures through quadratic unconstrained binary optimization (QUBO)\nmodeling of forward propagation and energy-based backpropagation. The method\ninnovatively leverages the quantum bit interaction characteristics of Ising\nmodels to optimize the conventional $O(n^2)$ spatiotemporal complexity into\nlinear resource consumption. Integrated with the optical computing advantages\nof coherent Ising machines (CIM), the system maintains millisecond-level\nreal-time responsiveness while significantly reducing energy consumption. Our\nkey contributions include: Theoretical proofs establish QAMA mathematical\nequivalence to classical attention mechanisms; Dual optimization of multi-head\nspecificity and long-range information capture via QUBO constraints; Explicit\ngradient proofs for the Ising energy equation are utilized to implement\ngradient conduction as the only path in the computational graph as a layer;\nProposed soft selection mechanism overcoming traditional binary attention\nlimitations to approximate continuous weights. Experiments on QBoson CPQC\nquantum computer show QAMA achieves comparable accuracy to classical operators\nwhile reducing inference time to millisecond level and improving solution\nquality. This work pioneers architectural-level integration of quantum\ncomputing and deep learning, applicable to any attention-based model, driving\nparadigm innovation in AI foundational computing.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u91cf\u5b50\u9000\u706b\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236QAMA\uff0c\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u548c\u80fd\u8017\uff0c\u4e0e\u7ecf\u5178\u6ce8\u610f\u529b\u517c\u5bb9\u3002", "motivation": "\u4f20\u7edf\u6ce8\u610f\u529b\u673a\u5236\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5185\u5b58\u548c\u80fd\u91cf\u6d88\u8017\u6025\u5267\u589e\u52a0\uff0c\u91cf\u5b50\u9000\u706b\u63d0\u4f9b\u9ad8\u6548\u4f4e\u8017\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528QUBO\u5efa\u6a21\u548cIsing\u6a21\u578b\u4f18\u5316\u6ce8\u610f\u529b\u8ba1\u7b97\uff0c\u5b9e\u73b0\u4eceO(n^2)\u5230\u7ebf\u6027\u7684\u65f6\u7a7a\u590d\u6742\u5ea6\u3002", "result": "\u5b9e\u9a8c\u663e\u793aQAMA\u51c6\u786e\u7387\u4e0e\u7ecf\u5178\u76f8\u5f53\uff0c\u63a8\u7406\u65f6\u95f4\u51cf\u81f3\u6beb\u79d2\u7ea7\uff0c\u80fd\u8017\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "\u5f00\u521b\u91cf\u5b50\u8ba1\u7b97\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6574\u5408\uff0c\u53ef\u5e94\u7528\u4e8e\u4efb\u4f55\u6ce8\u610f\u529b\u6a21\u578b\uff0c\u63a8\u52a8AI\u8ba1\u7b97\u8303\u5f0f\u521b\u65b0\u3002"}}
{"id": "2504.11091", "pdf": "https://arxiv.org/pdf/2504.11091", "abs": "https://arxiv.org/abs/2504.11091", "authors": ["Maximilian G. Schuh", "Joshua Hesse", "Stephan A. Sieber"], "title": "AI-guided Antibiotic Discovery Pipeline from Target Selection to Compound Identification", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "comment": "12 pages, preprint", "summary": "Antibiotic resistance presents a growing global health crisis, demanding new\ntherapeutic strategies that target novel bacterial mechanisms. Recent advances\nin protein structure prediction and machine learning-driven molecule generation\noffer a promising opportunity to accelerate drug discovery. However, practical\nguidance on selecting and integrating these models into real-world pipelines\nremains limited. In this study, we develop an end-to-end, artificial\nintelligence-guided antibiotic discovery pipeline that spans target\nidentification to compound realization. We leverage structure-based clustering\nacross predicted proteomes of multiple pathogens to identify conserved,\nessential, and non-human-homologous targets. We then systematically evaluate\nsix leading 3D-structure-aware generative models$\\unicode{x2014}$spanning\ndiffusion, autoregressive, graph neural network, and language model\narchitectures$\\unicode{x2014}$on their usability, chemical validity, and\nbiological relevance. Rigorous post-processing filters and commercial analogue\nsearches reduce over 100 000 generated compounds to a focused, synthesizable\nset. Our results highlight DeepBlock and TamGen as top performers across\ndiverse criteria, while also revealing critical trade-offs between model\ncomplexity, usability, and output quality. This work provides a comparative\nbenchmark and blueprint for deploying artificial intelligence in early-stage\nantibiotic development.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1AI\u6307\u5bfc\u7684\u6297\u751f\u7d20\u53d1\u73b0\u7ba1\u9053\uff0c\u4ece\u76ee\u6807\u8bc6\u522b\u5230\u5316\u5408\u7269\u5b9e\u73b0\uff0c\u8bc4\u4f30\u591a\u79cd\u751f\u6210\u6a21\u578b\uff0c\u7a81\u51faDeepBlock\u548cTamGen\u7684\u6027\u80fd\u3002", "motivation": "\u6297\u751f\u7d20\u8010\u836f\u6027\u662f\u5168\u7403\u5065\u5eb7\u5371\u673a\uff0c\u9700\u8981\u65b0\u7597\u6cd5\uff1bAI\u548c\u673a\u5668\u5b66\u4e60\u8fdb\u5c55\u63d0\u4f9b\u673a\u4f1a\uff0c\u4f46\u6574\u5408\u6307\u5bfc\u6709\u9650\u3002", "method": "\u5f00\u53d1\u7aef\u5230\u7aefAI\u7ba1\u9053\uff1b\u4f7f\u7528\u7ed3\u6784-based\u805a\u7c7b\u8bc6\u522b\u76ee\u6807\uff1b\u8bc4\u4f30\u516d\u79cd3D\u7ed3\u6784aware\u751f\u6210\u6a21\u578b\uff08\u5305\u62ec\u6269\u6563\u3001\u81ea\u56de\u5f52\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u8bed\u8a00\u6a21\u578b\uff09\uff1b\u540e\u5904\u7406\u8fc7\u6ee4\u548c\u5546\u4e1a\u7c7b\u4f3c\u7269\u641c\u7d22\u3002", "result": "DeepBlock\u548cTamGen\u8868\u73b0\u6700\u4f73\uff1b\u63ed\u793a\u6a21\u578b\u590d\u6742\u6027\u3001\u53ef\u7528\u6027\u548c\u8f93\u51fa\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "\u63d0\u4f9b\u6bd4\u8f83\u57fa\u51c6\u548c\u84dd\u56fe\uff0c\u7528\u4e8eAI\u5728\u65e9\u671f\u6297\u751f\u7d20\u5f00\u53d1\u4e2d\u7684\u90e8\u7f72\u3002"}}
{"id": "2504.11109", "pdf": "https://arxiv.org/pdf/2504.11109", "abs": "https://arxiv.org/abs/2504.11109", "authors": ["Linus Jern", "Valter Uotila", "Cong Yu", "Bo Zhao"], "title": "Fine-Tuning Large Language Models on Quantum Optimization Problems for Circuit Generation", "categories": ["quant-ph", "cs.AI"], "comment": "12 pages, 8 figures, 3 tables", "summary": "Large language models (LLM) have achieved remarkable outcomes in addressing\ncomplex problems, including math, coding, and analyzing large amounts of\nscientific reports. Yet few works have explored the potential of LLM in quantum\ncomputing. The most challenging problem is how to leverage LLMs to\nautomatically generate quantum circuits at a large scale. In this paper, we\naddress such a challenge by fine-tuning LLMs and injecting the domain-specific\nknowledge of quantum computing. In particular, we investigate the mechanisms to\ngenerate training data sets and construct the end-to-end pipeline to fine-tune\npre-trained LLMs that produce parameterized quantum circuits for optimization\nproblems. We have prepared 14,000 quantum circuits covering a substantial part\nof the quantum optimization landscape: 12 optimization problem instances and\ntheir optimized QAOA, VQE, and adaptive VQE circuits. The fine-tuned LLMs can\nconstruct syntactically correct parametrized quantum circuits in the most\nrecent OpenQASM 3.0. We have evaluated the quality of the parameters by\ncomparing them to the optimized expectation values and distributions. Our\nevaluation shows that the fine-tuned LLM outperforms state-of-the-art models\nand that the parameters are better than random. The LLM-generated parametrized\ncircuits and initial parameters can be used as a starting point for further\noptimization, \\emph{e.g.,} templates in quantum machine learning and the\nbenchmark for compilers and hardware.", "AI": {"tldr": "\u672c\u8bba\u6587\u901a\u8fc7\u5fae\u8c03LLM\u81ea\u52a8\u751f\u6210\u91cf\u5b50\u7535\u8def\uff0c\u8986\u76d6\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u663e\u793a\u51fa\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "LLM\u5728\u6570\u5b66\u3001\u7f16\u7801\u548c\u79d1\u5b66\u62a5\u544a\u5206\u6790\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u91cf\u5b50\u8ba1\u7b97\u9886\u57df\u5c24\u5176\u662f\u5927\u89c4\u6a21\u81ea\u52a8\u751f\u6210\u91cf\u5b50\u7535\u8def\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u751f\u621014,000\u4e2a\u91cf\u5b50\u7535\u8def\u6570\u636e\u96c6\uff0c\u6784\u5efa\u7aef\u5230\u7aef\u7ba1\u9053\u5fae\u8c03\u9884\u8bad\u7ec3LLM\uff0c\u6ce8\u5165\u91cf\u5b50\u8ba1\u7b97\u77e5\u8bc6\uff0c\u751f\u6210\u7b26\u5408OpenQASM 3.0\u7684\u53c2\u6570\u5316\u7535\u8def\u3002", "result": "\u5fae\u8c03LLM\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u7684\u7535\u8def\uff0c\u53c2\u6570\u4f18\u4e8e\u968f\u673a\u548c\u73b0\u6709\u6a21\u578b\uff0c\u53ef\u4f5c\u4e3a\u8fdb\u4e00\u6b65\u4f18\u5316\u7684\u8d77\u70b9\u3002", "conclusion": "\u751f\u6210\u7684\u7535\u8def\u548c\u53c2\u6570\u53ef\u4f5c\u4e3a\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u677f\u3001\u7f16\u8bd1\u5668\u57fa\u51c6\u548c\u786c\u4ef6\u6d4b\u8bd5\u7684\u8d77\u70b9\u3002"}}
{"id": "2504.10958", "pdf": "https://arxiv.org/pdf/2504.10958", "abs": "https://arxiv.org/abs/2504.10958", "authors": ["Alexander K\u00f6hler", "Michael Breu\u00df"], "title": "Recognition of Geometrical Shapes by Dictionary Learning", "categories": ["cs.CV", "cs.LG", "00A69, 68U05, 68T05"], "comment": "6 pages, 4 figures, ACDSA 2025 conference", "summary": "Dictionary learning is a versatile method to produce an overcomplete set of\nvectors, called atoms, to represent a given input with only a few atoms. In the\nliterature, it has been used primarily for tasks that explore its powerful\nrepresentation capabilities, such as for image reconstruction. In this work, we\npresent a first approach to make dictionary learning work for shape\nrecognition, considering specifically geometrical shapes. As we demonstrate,\nthe choice of the underlying optimization method has a significant impact on\nrecognition quality. Experimental results confirm that dictionary learning may\nbe an interesting method for shape recognition tasks.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5c06\u5b57\u5178\u5b66\u4e60\u5e94\u7528\u4e8e\u51e0\u4f55\u5f62\u72b6\u8bc6\u522b\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u5316\u65b9\u6cd5\u5bf9\u8bc6\u522b\u8d28\u91cf\u6709\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u6269\u5c55\u5b57\u5178\u5b66\u4e60\u4ece\u56fe\u50cf\u91cd\u5efa\u5230\u5f62\u72b6\u8bc6\u522b\u4efb\u52a1\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5b57\u5178\u5b66\u4e60\u7684\u5f62\u72b6\u8bc6\u522b\u65b9\u6cd5\uff0c\u5e76\u63a2\u8ba8\u4e0d\u540c\u4f18\u5316\u65b9\u6cd5\u7684 impact\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u5b9e\u5b57\u5178\u5b66\u4e60\u5bf9\u5f62\u72b6\u8bc6\u522b\u6709\u6548\uff0c\u4e14\u4f18\u5316\u65b9\u6cd5\u9009\u62e9\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u5b57\u5178\u5b66\u4e60\u53ef\u80fd\u662f\u4e00\u79cd\u6709\u8da3\u7684\u5f62\u72b6\u8bc6\u522b\u65b9\u6cd5\u3002"}}
{"id": "2504.10973", "pdf": "https://arxiv.org/pdf/2504.10973", "abs": "https://arxiv.org/abs/2504.10973", "authors": ["Tomasz M. Rutkowski", "Stanis\u0142aw Nar\u0119bski", "Mihoko Otake-Matsuura", "Tomasz Komendzi\u0144ski"], "title": "Early Detection of Cognitive Impairment in Elderly using a Passive FPVS-EEG BCI and Machine Learning -- Extended Version", "categories": ["q-bio.NC", "cs.HC", "cs.LG", "J.3"], "comment": "4 pages, 4 figures, exteded version of an abstract accepted for a\n  poster presentation at the 47th Annual International Conference of the IEEE\n  Engineering in Medicine and Biology Society (EMBC2025), Copenhagen, Denmark,\n  July 14-17, 2025", "summary": "Early dementia diagnosis requires biomarkers sensitive to both structural and\nfunctional brain changes. While structural neuroimaging biomarkers have\nprogressed significantly, objective functional biomarkers of early cognitive\ndecline remain a critical unmet need. Current cognitive assessments often rely\non behavioral responses, making them susceptible to factors like effort,\npractice effects, and educational background, thereby hindering early and\naccurate detection. This work introduces a novel approach, leveraging a\nlightweight convolutional neural network (CNN) to infer cognitive impairment\nlevels directly from electroencephalography (EEG) data. Critically, this method\nemploys a passive fast periodic visual stimulation (FPVS) paradigm, eliminating\nthe need for explicit behavioral responses or task comprehension from the\nparticipant. This passive approach provides an objective measure of working\nmemory function, independent of confounding factors inherent in active\ncognitive tasks, and offers a promising new avenue for early and unbiased\ndetection of cognitive decline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u8f7b\u91cf\u7ea7CNN\u4eceEEG\u6570\u636e\u4e2d\u63a8\u65ad\u8ba4\u77e5\u969c\u788d\u7684\u65b0\u65b9\u6cd5\uff0c\u91c7\u7528\u88ab\u52a8FPVS\u8303\u5f0f\uff0c\u5b9e\u73b0\u65e0\u884c\u4e3a\u54cd\u5e94\u7684\u5ba2\u89c2\u8bc4\u4f30\u3002", "motivation": "\u65e9\u671f\u75f4\u5446\u8bca\u65ad\u9700\u8981\u654f\u611f\u7684\u529f\u80fd\u8111\u53d8\u5316\u751f\u7269\u6807\u5fd7\u7269\uff0c\u4f46\u5f53\u524d\u884c\u4e3a\u8bc4\u4f30\u6613\u53d7\u52aa\u529b\u3001\u7ec3\u4e60\u6548\u5e94\u548c\u6559\u80b2\u80cc\u666f\u5f71\u54cd\uff0c\u5bfc\u81f4\u65e9\u671f\u68c0\u6d4b\u56f0\u96be\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5206\u6790EEG\u6570\u636e\uff0c\u7ed3\u5408\u88ab\u52a8\u5feb\u901f\u5468\u671f\u89c6\u89c9\u523a\u6fc0\u8303\u5f0f\uff0c\u4e0d\u4f9d\u8d56\u53c2\u4e0e\u8005\u7684\u884c\u4e3a\u54cd\u5e94\u6216\u4efb\u52a1\u7406\u89e3\u3002", "result": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u72ec\u7acb\u4e8e\u6df7\u6742\u56e0\u7d20\u7684\u5ba2\u89c2\u5de5\u4f5c\u8bb0\u5fc6\u529f\u80fd\u6d4b\u91cf\uff0c\u6709\u671b\u5b9e\u73b0\u65e9\u671f\u8ba4\u77e5\u8870\u9000\u7684\u65e0\u504f\u68c0\u6d4b\u3002", "conclusion": "\u88ab\u52a8\u65b9\u6cd5\u4e3a\u65e9\u671f\u75f4\u5446\u8bca\u65ad\u5f00\u8f9f\u65b0\u9014\u5f84\uff0c\u63d0\u4f9b\u53ef\u9760\u7684\u8ba4\u77e5\u529f\u80fd\u8bc4\u4f30\u3002"}}
{"id": "2504.11160", "pdf": "https://arxiv.org/pdf/2504.11160", "abs": "https://arxiv.org/abs/2504.11160", "authors": ["Haohan Chen", "Hongjia Liu", "Shiyong Lan", "Wenwu Wang", "Yixin Qiao", "Yao Li", "Guonan Deng"], "title": "DMAGaze: Gaze Estimation Based on Feature Disentanglement and Multi-Scale Attention", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Gaze estimation, which predicts gaze direction, commonly faces the challenge\nof interference from complex gaze-irrelevant information in face images. In\nthis work, we propose DMAGaze, a novel gaze estimation framework that exploits\ninformation from facial images in three aspects: gaze-relevant global features\n(disentangled from facial image), local eye features (extracted from cropped\neye patch), and head pose estimation features, to improve overall performance.\nFirstly, we design a new continuous mask-based Disentangler to accurately\ndisentangle gaze-relevant and gaze-irrelevant information in facial images by\nachieving the dual-branch disentanglement goal through separately\nreconstructing the eye and non-eye regions. Furthermore, we introduce a new\ncascaded attention module named Multi-Scale Global Local Attention Module\n(MS-GLAM). Through a customized cascaded attention structure, it effectively\nfocuses on global and local information at multiple scales, further enhancing\nthe information from the Disentangler. Finally, the global gaze-relevant\nfeatures disentangled by the upper face branch, combined with head pose and\nlocal eye features, are passed through the detection head for high-precision\ngaze estimation. Our proposed DMAGaze has been extensively validated on two\nmainstream public datasets, achieving state-of-the-art performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDMAGaze\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u548c\u6ce8\u610f\u529b\u673a\u5236\u6539\u5584\u6ce8\u89c6\u4f30\u8ba1\uff0c\u5173\u6ce8\u76f8\u5173\u7279\u5f81\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u9762\u90e8\u56fe\u50cf\u4e2d\u590d\u6742\u4e0d\u76f8\u5173\u4fe1\u606f\u5e72\u6270\u7684\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u8fde\u7eed\u63a9\u7801\u89e3\u8026\u5668\u5206\u79bb\u6ce8\u89c6\u76f8\u5173\u4fe1\u606f\uff0c\u5f15\u5165\u591a\u5c3a\u5ea6\u5168\u5c40\u5c40\u90e8\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5e76\u7ed3\u5408\u5934\u90e8\u59ff\u52bf\u548c\u5c40\u90e8\u773c\u775b\u7279\u5f81\u8fdb\u884c\u9ad8\u7cbe\u5ea6\u4f30\u8ba1\u3002", "result": "\u5728\u4e24\u4e2a\u4e3b\u6d41\u516c\u5171\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u53d6\u5f97\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "DMAGaze\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u6ce8\u89c6\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2504.11053", "pdf": "https://arxiv.org/pdf/2504.11053", "abs": "https://arxiv.org/abs/2504.11053", "authors": ["Karthik Shivashankar", "Rafael Capilla", "Maren Maritsdatter Kruke", "Mili Orucevic", "Antonio Martini"], "title": "QualiTagger: Automating software quality detection in issue trackers", "categories": ["cs.SE", "cs.LG"], "comment": "IN Review ASE journal", "summary": "A systems quality is a major concern for development teams when it evolve.\nUnderstanding the effects of a loss of quality in the codebase is crucial to\navoid side effects like the appearance of technical debt. Although the\nidentification of these qualities in software requirements described in natural\nlanguage has been investigated, most of the results are often not applicable in\npractice, and rely on having been validated on small datasets and limited\namount of projects. For many years, machine learning (ML) techniques have been\nproved as a valid technique to identify and tag terms described in natural\nlanguage. In order to advance previous works, in this research we use cutting\nedge models like Transformers, together with a vast dataset mined and curated\nfrom GitHub, to identify what text is usually associated with different quality\nproperties. We also study the distribution of such qualities in issue trackers\nfrom openly accessible software repositories, and we evaluate our approach both\nwith students from a software engineering course and with its application to\nrecognize security labels in industry.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528Transformer\u6a21\u578b\u548cGitHub\u6570\u636e\u96c6\u8bc6\u522b\u8f6f\u4ef6\u8d28\u91cf\u5c5e\u6027\u6587\u672c\uff0c\u5e76\u8bc4\u4f30\u5176\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u8f6f\u4ef6\u8d28\u91cf\u4e0b\u964d\u53ef\u80fd\u5bfc\u81f4\u6280\u672f\u503a\u52a1\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u4e0d\u5b9e\u7528\u4e14\u6570\u636e\u96c6\u6709\u9650\u3002", "method": "\u91c7\u7528Transformer\u7b49\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4eceGitHub\u6316\u6398\u5927\u6570\u636e\u96c6\uff0c\u8bc6\u522b\u81ea\u7136\u8bed\u8a00\u4e2d\u8d28\u91cf\u5c5e\u6027\u6587\u672c\uff0c\u5e76\u901a\u8fc7\u5b66\u751f\u548c\u5de5\u4e1a\u573a\u666f\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u4e86\u8d28\u91cf\u5c5e\u6027\u5728\u95ee\u9898\u8ddf\u8e2a\u5668\u4e2d\u7684\u5206\u5e03\uff0c\u5e76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u5728\u8bc6\u522b\u5b89\u5168\u6807\u7b7e\u7b49\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6539\u8fdb\u4e86\u8d28\u91cf\u5c5e\u6027\u8bc6\u522b\u6280\u672f\uff0c\u4f7f\u5176\u66f4\u9002\u7528\u4e8e\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u3002"}}
{"id": "2504.11168", "pdf": "https://arxiv.org/pdf/2504.11168", "abs": "https://arxiv.org/abs/2504.11168", "authors": ["William Hackett", "Lewis Birch", "Stefan Trawicki", "Neeraj Suri", "Peter Garraghan"], "title": "Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails", "categories": ["cs.CR", "cs.AI", "cs.LG", "I.2.7"], "comment": "12 pages, 5 figures, 6 tables", "summary": "Large Language Models (LLMs) guardrail systems are designed to protect\nagainst prompt injection and jailbreak attacks. However, they remain vulnerable\nto evasion techniques. We demonstrate two approaches for bypassing LLM prompt\ninjection and jailbreak detection systems via traditional character injection\nmethods and algorithmic Adversarial Machine Learning (AML) evasion techniques.\nThrough testing against six prominent protection systems, including Microsoft's\nAzure Prompt Shield and Meta's Prompt Guard, we show that both methods can be\nused to evade detection while maintaining adversarial utility achieving in some\ninstances up to 100% evasion success. Furthermore, we demonstrate that\nadversaries can enhance Attack Success Rates (ASR) against black-box targets by\nleveraging word importance ranking computed by offline white-box models. Our\nfindings reveal vulnerabilities within current LLM protection mechanisms and\nhighlight the need for more robust guardrail systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u5b57\u7b26\u6ce8\u5165\u548c\u5bf9\u6297\u673a\u5668\u5b66\u4e60\u6280\u672f\u7ed5\u8fc7LLM\u9632\u62a4\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe100%\u7684\u89c4\u907f\u6210\u529f\u7387\uff0c\u5e76\u5f3a\u8c03\u4e86\u9700\u8981\u66f4\u5f3a\u5927\u7684\u9632\u62a4\u673a\u5236\u3002", "motivation": "\u63ed\u793a\u5f53\u524dLLM\u9632\u62a4\u673a\u5236\u5728\u9762\u5bf9\u63d0\u793a\u6ce8\u5165\u548c\u8d8a\u72f1\u653b\u51fb\u65f6\u7684\u6f0f\u6d1e\uff0c\u4ee5\u7a81\u51fa\u5176\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u4f20\u7edf\u5b57\u7b26\u6ce8\u5165\u65b9\u6cd5\u548c\u7b97\u6cd5\u5bf9\u6297\u673a\u5668\u5b66\u4e60(AML)\u89c4\u907f\u6280\u672f\uff0c\u5bf9\u5305\u62ecMicrosoft\u7684Azure Prompt Shield\u548cMeta\u7684Prompt Guard\u5728\u5185\u7684\u516d\u79cd\u4e3b\u8981\u9632\u62a4\u7cfb\u7edf\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86100%\u7684\u89c4\u907f\u6210\u529f\u7387\uff0c\u5e76\u901a\u8fc7\u5229\u7528\u767d\u76d2\u6a21\u578b\u8ba1\u7b97\u7684\u5355\u8bcd\u91cd\u8981\u6027\u6392\u540d\u6765\u63d0\u9ad8\u5bf9\u9ed1\u76d2\u76ee\u6807\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "conclusion": "\u7a81\u663e\u4e86\u5f53\u524dLLM\u9632\u62a4\u673a\u5236\u7684\u8106\u5f31\u6027\uff0c\u5e76\u6307\u51fa\u9700\u8981\u5f00\u53d1\u66f4\u7a33\u5065\u7684\u9632\u62a4\u7cfb\u7edf\u3002"}}
{"id": "2504.11067", "pdf": "https://arxiv.org/pdf/2504.11067", "abs": "https://arxiv.org/abs/2504.11067", "authors": ["Sebastian Baunsgaard", "Matthias Boehm"], "title": "Morphing-based Compression for Data-centric ML Pipelines", "categories": ["cs.DB", "cs.DC", "cs.LG"], "comment": "20 pages, 28 figures, 4 tables", "summary": "Data-centric ML pipelines extend traditional machine learning (ML) pipelines\n-- of feature transformations and ML model training -- by outer loops for data\ncleaning, augmentation, and feature engineering to create high-quality input\ndata. Existing lossless matrix compression applies lightweight compression\nschemes to numeric matrices and performs linear algebra operations such as\nmatrix-vector multiplications directly on the compressed representation but\nstruggles to efficiently rediscover structural data redundancy. Compressed\noperations are effective at fitting data in available memory, reducing I/O\nacross the storage-memory-cache hierarchy, and improving instruction\nparallelism. The applied data cleaning, augmentation, and feature\ntransformations provide a rich source of information about data characteristics\nsuch as distinct items, column sparsity, and column correlations. In this\npaper, we introduce BWARE -- an extension of AWARE for workload-aware lossless\nmatrix compression -- that pushes compression through feature transformations\nand engineering to leverage information about structural transformations.\nBesides compressed feature transformations, we introduce a novel technique for\nlightweight morphing of a compressed representation into workload-optimized\ncompressed representations without decompression. BWARE shows substantial\nend-to-end runtime improvements, reducing the execution time for training\ndata-centric ML pipelines from days to hours.", "AI": {"tldr": "BWARE \u6269\u5c55 AWARE \u7684\u5de5\u4f5c\u8d1f\u8f7d\u611f\u77e5\u65e0\u635f\u77e9\u9635\u538b\u7f29\uff0c\u7528\u4e8e\u6570\u636e\u4e2d\u5fc3 ML \u7ba1\u9053\uff0c\u901a\u8fc7\u7279\u5f81\u8f6c\u6362\u548c\u538b\u7f29\u5f62\u6001\u8f6c\u6362\u663e\u8457\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u91cd\u65b0\u53d1\u73b0\u7ed3\u6784\u6570\u636e\u5197\u4f59\uff0c\u800c\u6570\u636e\u6e05\u6d17\u3001\u589e\u5f3a\u548c\u7279\u5f81\u5de5\u7a0b\u63d0\u4f9b\u4e86\u6570\u636e\u7279\u6027\u7684\u4fe1\u606f\uff0c\u53ef\u7528\u4e8e\u4f18\u5316\u538b\u7f29\u3002", "method": "\u5f15\u5165 BWARE\uff0c\u5c06\u538b\u7f29\u63a8\u9001\u5230\u7279\u5f81\u8f6c\u6362\u548c\u5de5\u7a0b\u4e2d\uff0c\u5e76\u5f00\u53d1\u4e00\u79cd\u65b0\u578b\u6280\u672f\uff0c\u5728\u4e0d\u89e3\u538b\u7684\u60c5\u51b5\u4e0b\u5c06\u538b\u7f29\u8868\u793a\u5f62\u6001\u5316\u4e3a\u5de5\u4f5c\u8d1f\u8f7d\u4f18\u5316\u7684\u8868\u793a\u3002", "result": "BWARE \u663e\u8457\u6539\u5584\u7aef\u5230\u7aef\u8fd0\u884c\u65f6\u6027\u80fd\uff0c\u5c06\u6570\u636e\u4e2d\u5fc3 ML \u7ba1\u9053\u7684\u8bad\u7ec3\u65f6\u95f4\u4ece\u5929\u51cf\u5c11\u5230\u5c0f\u65f6\u3002", "conclusion": "BWARE \u63d0\u5347\u4e86\u6570\u636e\u4e2d\u5fc3 ML \u7ba1\u9053\u7684\u6548\u7387\uff0c\u5c55\u793a\u4e86\u901a\u8fc7\u5229\u7528\u7ed3\u6784\u4fe1\u606f\u4f18\u5316\u538b\u7f29\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.11169", "pdf": "https://arxiv.org/pdf/2504.11169", "abs": "https://arxiv.org/abs/2504.11169", "authors": ["Laura De Grazia", "Pol Pastells", "Mauro V\u00e1zquez Chas", "Desmond Elliott", "Danae S\u00e1nchez Villegas", "Mireia Farr\u00fas", "Mariona Taul\u00e9"], "title": "MuSeD: A Multimodal Spanish Dataset for Sexism Detection in Social Media Videos", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Sexism is generally defined as prejudice and discrimination based on sex or\ngender, affecting every sector of society, from social institutions to\nrelationships and individual behavior. Social media platforms amplify the\nimpact of sexism by conveying discriminatory content not only through text but\nalso across multiple modalities, highlighting the critical need for a\nmultimodal approach to the analysis of sexism online. With the rise of social\nmedia platforms where users share short videos, sexism is increasingly\nspreading through video content. Automatically detecting sexism in videos is a\nchallenging task, as it requires analyzing the combination of verbal, audio,\nand visual elements to identify sexist content. In this study, (1) we introduce\nMuSeD, a new Multimodal Spanish dataset for Sexism Detection consisting of\n$\\approx$ 11 hours of videos extracted from TikTok and BitChute; (2) we propose\nan innovative annotation framework for analyzing the contribution of textual\nand multimodal labels in the classification of sexist and non-sexist content;\nand (3) we evaluate a range of large language models (LLMs) and multimodal LLMs\non the task of sexism detection. We find that visual information plays a key\nrole in labeling sexist content for both humans and models. Models effectively\ndetect explicit sexism; however, they struggle with implicit cases, such as\nstereotypes, instances where annotators also show low agreement. This\nhighlights the inherent difficulty of the task, as identifying implicit sexism\ndepends on the social and cultural context.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165MuSeD\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u6ce8\u91ca\u6846\u67b6\uff0c\u5e76\u8bc4\u4f30LLM\u5728\u591a\u6a21\u6001\u6027\u522b\u6b67\u89c6\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u89c6\u89c9\u4fe1\u606f\u91cd\u8981\uff0c\u4f46\u9690\u6027\u6b67\u89c6\u68c0\u6d4b\u56f0\u96be\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u89c6\u9891\u4e2d\u6027\u522b\u6b67\u89c6\u4f20\u64ad\u9700\u8981\u591a\u6a21\u6001\u5206\u6790\uff0c\u4ee5\u5e94\u5bf9\u6587\u672c\u3001\u97f3\u9891\u548c\u89c6\u89c9\u5143\u7d20\u7684\u7ed3\u5408\u3002", "method": "\u5f15\u5165\u7ea611\u5c0f\u65f6\u7684MuSeD\u897f\u73ed\u7259\u8bed\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u6587\u672c\u548c\u591a\u6a21\u6001\u6807\u7b7e\u6ce8\u91ca\u6846\u67b6\uff0c\u5e76\u8bc4\u4f30\u5404\u79cdLLM\u548c\u591a\u6a21\u6001LLM\u3002", "result": "\u89c6\u89c9\u4fe1\u606f\u5728\u68c0\u6d4b\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff1b\u6a21\u578b\u5bf9\u663e\u6027\u6027\u522b\u6b67\u89c6\u68c0\u6d4b\u8f83\u597d\uff0c\u4f46\u5bf9\u9690\u6027\u6b67\u89c6\u548c\u523b\u677f\u5370\u8c61 struggled\uff1b\u6ce8\u91ca\u8005\u5bf9\u9690\u6027\u6848\u4f8b\u4e00\u81f4\u6027\u4f4e\u3002", "conclusion": "\u8bc6\u522b\u9690\u6027\u6027\u522b\u6b67\u89c6\u56e0\u793e\u4f1a\u6587\u5316\u80cc\u666f\u800c\u5177\u6709\u6311\u6218\u6027\uff0c\u7a81\u663e\u4efb\u52a1\u7684\u590d\u6742\u6027\u3002"}}
{"id": "2504.11076", "pdf": "https://arxiv.org/pdf/2504.11076", "abs": "https://arxiv.org/abs/2504.11076", "authors": ["Tom Hochsprung", "Jakob Runge", "Andreas Gerhardus"], "title": "Using Time Structure to Estimate Causal Effects", "categories": ["stat.ME", "cs.LG", "62M10", "G.3"], "comment": "25 pages main paper, 25 pages Appendix, 50 pages in total, 3 tables,\n  7 figures", "summary": "There exist several approaches for estimating causal effects in time series\nwhen latent confounding is present. Many of these approaches rely on additional\nauxiliary observed variables or time series such as instruments, negative\ncontrols or time series that satisfy the front- or backdoor criterion in\ncertain graphs. In this paper, we present a novel approach for estimating\ndirect (and via Wright's path rule total) causal effects in a time series setup\nwhich does not rely on additional auxiliary observed variables or time series.\nThis approach assumes that the underlying time series is a Structural Vector\nAutoregressive (SVAR) process and estimates direct causal effects by solving\ncertain linear equation systems made up of different covariances and model\nparameters. We state sufficient graphical criteria in terms of the so-called\nfull time graph under which these linear equations systems are uniquely\nsolvable and under which their solutions contain the to-be-identified direct\ncausal effects as components. We also state sufficient lag-based criteria under\nwhich the previously mentioned graphical conditions are satisfied and, thus,\nunder which direct causal effects are identifiable. Several numerical\nexperiments underline the correctness and applicability of our results.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u4f9d\u8d56\u8f85\u52a9\u53d8\u91cf\u7684\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u65b9\u6cd5\uff0c\u57fa\u4e8e\u7ed3\u6784\u5411\u91cf\u81ea\u56de\u5f52\uff08SVAR\uff09\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u8f85\u52a9\u53d8\u91cf\u5982\u5de5\u5177\u53d8\u91cf\u6216\u63a7\u5236\u53d8\u91cf\uff0c\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u4e0d\u9700\u8981\u8fd9\u4e9b\u53d8\u91cf\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u5047\u8bbe\u65f6\u95f4\u5e8f\u5217\u4e3aSVAR\u8fc7\u7a0b\uff0c\u901a\u8fc7\u6c42\u89e3\u7ebf\u6027\u65b9\u7a0b\u7ec4\uff08\u4f7f\u7528\u534f\u65b9\u5dee\u548c\u6a21\u578b\u53c2\u6570\uff09\u6765\u4f30\u8ba1\u76f4\u63a5\u56e0\u679c\u6548\u5e94\uff0c\u5e76\u7ed9\u51fa\u56fe\u5f62\u548c\u6ede\u540e-based \u6807\u51c6\u786e\u4fdd\u53ef\u8bc6\u522b\u6027\u3002", "result": "\u7ed9\u51fa\u4e86\u5145\u5206\u6761\u4ef6\u786e\u4fdd\u65b9\u7a0b\u7ec4\u552f\u4e00\u53ef\u89e3\u548c\u56e0\u679c\u6548\u5e94\u53ef\u8bc6\u522b\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6b63\u786e\u6027\u548c\u9002\u7528\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u6709\u6548\uff0c\u80fd\u591f\u8bc6\u522b\u76f4\u63a5\uff08\u548c\u603b\uff09\u56e0\u679c\u6548\u5e94\u3002"}}
{"id": "2504.11171", "pdf": "https://arxiv.org/pdf/2504.11171", "abs": "https://arxiv.org/abs/2504.11171", "authors": ["Johannes Jakubik", "Felix Yang", "Benedikt Blumenstiel", "Erik Scheurer", "Rocco Sedona", "Stefano Maurogiovanni", "Jente Bosmans", "Nikolaos Dionelis", "Valerio Marsocci", "Niklas Kopp", "Rahul Ramachandran", "Paolo Fraccaro", "Thomas Brunschwiler", "Gabriele Cavallaro", "Juan Bernabe-Moreno", "Nicolas Long\u00e9p\u00e9"], "title": "TerraMind: Large-Scale Generative Multimodality for Earth Observation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We present TerraMind, the first any-to-any generative, multimodal foundation\nmodel for Earth observation (EO). Unlike other multimodal models, TerraMind is\npretrained on dual-scale representations combining both token-level and\npixel-level data across modalities. On a token level, TerraMind encodes\nhigh-level contextual information to learn cross-modal relationships, while on\na pixel level, TerraMind leverages fine-grained representations to capture\ncritical spatial nuances. We pretrained TerraMind on nine geospatial modalities\nof a global, large-scale dataset. In this paper, we demonstrate that (i)\nTerraMind's dual-scale early fusion approach unlocks a range of zero-shot and\nfew-shot applications for Earth observation, (ii) TerraMind introduces\n\"Thinking-in-Modalities\" (TiM) -- the capability of generating additional\nartificial data during finetuning and inference to improve the model output --\nand (iii) TerraMind achieves beyond state-of-the-art performance in\ncommunity-standard benchmarks for EO like PANGAEA. The pretraining dataset, the\nmodel weights, and our code is open-sourced under a permissive license.", "AI": {"tldr": "TerraMind \u662f\u7b2c\u4e00\u4e2a\u7528\u4e8e\u5730\u7403\u89c2\u6d4b\u7684\u4efb\u610f\u5230\u4efb\u610f\u751f\u6210\u5f0f\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u53cc\u5c3a\u5ea6\u8868\u793a\u7ed3\u5408 token \u7ea7\u548c pixel \u7ea7\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u7684\u6027\u80fd\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u73b0\u6709\u591a\u6a21\u6001\u6a21\u578b\u5728\u5904\u7406\u8de8\u6a21\u6001\u5173\u7cfb\u548c\u7a7a\u95f4\u7ec6\u5fae\u5dee\u522b\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u63d0\u5347\u5730\u7403\u89c2\u6d4b\u4efb\u52a1\u7684\u751f\u6210\u80fd\u529b\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5728\u5168\u7403\u5927\u89c4\u6a21\u6570\u636e\u96c6\u7684\u4e5d\u79cd\u5730\u7406\u7a7a\u95f4\u6a21\u6001\u4e0a\u9884\u8bad\u7ec3 TerraMind\uff0c\u4f7f\u7528\u53cc\u5c3a\u5ea6\u65e9\u878d\u5408\u65b9\u6cd5\u548c 'Thinking-in-Modalities' (TiM) \u673a\u5236\u751f\u6210\u989d\u5916\u6570\u636e\u3002", "result": "\u7ed3\u679c\u663e\u793a TerraMind \u5b9e\u73b0\u4e86\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5e94\u7528\uff0c\u652f\u6301 TiM \u673a\u5236\uff0c\u5e76\u5728 PANGAEA \u7b49\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u7684\u6027\u80fd\u3002", "conclusion": "\u7ed3\u8bba\u662f TerraMind \u7684\u53cc\u5c3a\u5ea6\u65b9\u6cd5\u6709\u6548\uff0c\u5e76\u901a\u8fc7\u5f00\u6e90\u9884\u8bad\u7ec3\u6570\u636e\u96c6\u3001\u6a21\u578b\u6743\u91cd\u548c\u4ee3\u7801\u4fc3\u8fdb\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2504.11079", "pdf": "https://arxiv.org/pdf/2504.11079", "abs": "https://arxiv.org/abs/2504.11079", "authors": ["Karthik Shivashankar", "Ghadi S. Al Hajj", "Antonio Martini"], "title": "Scalability and Maintainability Challenges and Solutions in Machine Learning: Systematic Literature Review", "categories": ["cs.SE", "cs.LG"], "comment": "Minor Revision ACM Computing Survey", "summary": "This systematic literature review examines the critical challenges and\nsolutions related to scalability and maintainability in Machine Learning (ML)\nsystems. As ML applications become increasingly complex and widespread across\nindustries, the need to balance system scalability with long-term\nmaintainability has emerged as a significant concern. This review synthesizes\ncurrent research and practices addressing these dual challenges across the\nentire ML life-cycle, from data engineering to model deployment in production.\nWe analyzed 124 papers to identify and categorize 41 maintainability challenges\nand 13 scalability challenges, along with their corresponding solutions. Our\nfindings reveal intricate inter dependencies between scalability and\nmaintainability, where improvements in one often impact the other.\n  The review is structured around six primary research questions, examining\nmaintainability and scalability challenges in data engineering, model\nengineering, and ML system development. We explore how these challenges\nmanifest differently across various stages of the ML life-cycle.\n  This comprehensive overview offers valuable insights for both researchers and\npractitioners in the field of ML systems. It aims to guide future research\ndirections, inform best practices, and contribute to the development of more\nrobust, efficient, and sustainable ML applications across various domains.", "AI": {"tldr": "\u672c\u7bc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u63a2\u8ba8\u4e86\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u53ef\u6269\u5c55\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u7684\u6311\u6218\u4e0e\u89e3\u51b3\u65b9\u6848\uff0c\u5206\u6790\u4e86124\u7bc7\u8bba\u6587\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u5e94\u7528\u7684\u590d\u6742\u6027\u548c\u5e7f\u6cdb\u5e94\u7528\u4e0d\u65ad\u589e\u52a0\uff0c\u5e73\u8861\u7cfb\u7edf\u53ef\u6269\u5c55\u6027\u548c\u957f\u671f\u53ef\u7ef4\u62a4\u6027\u7684\u9700\u6c42\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790\u4e86124\u7bc7\u8bba\u6587\uff0c\u8bc6\u522b\u5e76\u5206\u7c7b\u4e8641\u4e2a\u53ef\u7ef4\u62a4\u6027\u6311\u6218\u548c13\u4e2a\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u5e76\u56f4\u7ed5\u516d\u4e2a\u4e3b\u8981\u7814\u7a76\u95ee\u9898\u6784\u5efa\u7ed3\u6784\u3002", "result": "\u53d1\u73b0\u53ef\u6269\u5c55\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u4e4b\u95f4\u5b58\u5728\u590d\u6742\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u63d0\u4f9b\u4e86\u6311\u6218\u548c\u89e3\u51b3\u65b9\u6848\u7684\u5206\u7c7b\u3002", "conclusion": "\u4e3a\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u5b9d\u8d35\u89c1\u89e3\uff0c\u6307\u5bfc\u672a\u6765\u7814\u7a76\u65b9\u5411\u3001\u544a\u77e5\u6700\u4f73\u5b9e\u8df5\uff0c\u5e76\u4fc3\u8fdb\u66f4\u7a33\u5065\u3001\u9ad8\u6548\u548c\u53ef\u6301\u7eed\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\u5f00\u53d1\u3002"}}
{"id": "2504.11182", "pdf": "https://arxiv.org/pdf/2504.11182", "abs": "https://arxiv.org/abs/2504.11182", "authors": ["Liangbo Ning", "Wenqi Fan", "Qing Li"], "title": "Exploring Backdoor Attack and Defense for LLM-empowered Recommendations", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The fusion of Large Language Models (LLMs) with recommender systems (RecSys)\nhas dramatically advanced personalized recommendations and drawn extensive\nattention. Despite the impressive progress, the safety of LLM-based RecSys\nagainst backdoor attacks remains largely under-explored. In this paper, we\nraise a new problem: Can a backdoor with a specific trigger be injected into\nLLM-based Recsys, leading to the manipulation of the recommendation responses\nwhen the backdoor trigger is appended to an item's title? To investigate the\nvulnerabilities of LLM-based RecSys under backdoor attacks, we propose a new\nattack framework termed Backdoor Injection Poisoning for RecSys (BadRec).\nBadRec perturbs the items' titles with triggers and employs several fake users\nto interact with these items, effectively poisoning the training set and\ninjecting backdoors into LLM-based RecSys. Comprehensive experiments reveal\nthat poisoning just 1% of the training data with adversarial examples is\nsufficient to successfully implant backdoors, enabling manipulation of\nrecommendations. To further mitigate such a security threat, we propose a\nuniversal defense strategy called Poison Scanner (P-Scanner). Specifically, we\nintroduce an LLM-based poison scanner to detect the poisoned items by\nleveraging the powerful language understanding and rich knowledge of LLMs. A\ntrigger augmentation agent is employed to generate diverse synthetic triggers\nto guide the poison scanner in learning domain-specific knowledge of the\npoisoned item detection task. Extensive experiments on three real-world\ndatasets validate the effectiveness of the proposed P-Scanner.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8LLM-based\u63a8\u8350\u7cfb\u7edf\u7684\u540e\u95e8\u653b\u51fb\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51faBadRec\u653b\u51fb\u6846\u67b6\u548cP-Scanner\u9632\u5fa1\u7b56\u7565\u3002", "motivation": "\u52a8\u673a\u662f\u63ed\u793aLLM-based\u63a8\u8350\u7cfb\u7edf\u5bf9\u540e\u95e8\u653b\u51fb\u7684\u6613\u611f\u6027\uff0c\u8fd9\u65b9\u9762\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u65b9\u6cd5\u5305\u62ecBadRec\u6846\u67b6\uff0c\u901a\u8fc7\u6270\u52a8\u7269\u54c1\u6807\u9898\u548c\u5047\u7528\u6237\u4ea4\u4e92\u6ce8\u5165\u540e\u95e8\uff1bP-Scanner\u4f7f\u7528LLM-based\u626b\u63cf\u5668\u548c\u89e6\u53d1\u5668\u589e\u5f3a\u4ee3\u7406\u68c0\u6d4b\u4e2d\u6bd2\u7269\u54c1\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u6bd2\u5bb31%\u7684\u8bad\u7ec3\u6570\u636e\u5373\u53ef\u6210\u529f\u6ce8\u5165\u540e\u95e8\uff1bP-Scanner\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6709\u6548\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8bc1\u660e\u4e86\u7cfb\u7edf\u6f0f\u6d1e\u5e76\u9a8c\u8bc1\u4e86\u9632\u5fa1\u7b56\u7565\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2504.11085", "pdf": "https://arxiv.org/pdf/2504.11085", "abs": "https://arxiv.org/abs/2504.11085", "authors": ["Karthik Shivashankar", "Antonio Martini"], "title": "TD-Suite: All Batteries Included Framework for Technical Debt Classification", "categories": ["cs.SE", "cs.LG"], "comment": "In submission", "summary": "Recognizing that technical debt is a persistent and significant challenge\nrequiring sophisticated management tools, TD-Suite offers a comprehensive\nsoftware framework specifically engineered to automate the complex task of its\nclassification within software projects. It leverages the advanced natural\nlanguage understanding of state-of-the-art transformer models to analyze\ntextual artifacts, such as developer discussions in issue reports, where subtle\nindicators of debt often lie hidden.\n  TD-Suite provides a seamless end-to-end pipeline, managing everything from\ninitial data ingestion and rigorous preprocessing to model training, thorough\nevaluation, and final inference. This allows it to support both straightforward\nbinary classification (debt or no debt) and more valuable, identifying specific\ncategories like code, design, or documentation debt, thus enabling more\ntargeted management strategies.\n  To ensure the generated models are robust and perform reliably on real-world,\noften imbalanced, datasets, TD-Suite incorporates critical training\nmethodologies: k-fold cross-validation assesses generalization capability,\nearly stopping mechanisms prevent overfitting to the training data, and class\nweighting strategies effectively address skewed data distributions. Beyond core\nfunctionality, and acknowledging the growing importance of sustainability, the\nframework integrates tracking and reporting of carbon emissions associated with\nthe computationally intensive model training process.\n  It also features a user-friendly Gradio web interface in a Docker container\nsetup, simplifying model interaction, evaluation, and inference.", "AI": {"tldr": "TD-Suite \u662f\u4e00\u4e2a\u8f6f\u4ef6\u6846\u67b6\uff0c\u4f7f\u7528 transformer \u6a21\u578b\u81ea\u52a8\u5206\u7c7b\u8f6f\u4ef6\u9879\u76ee\u4e2d\u7684\u6280\u672f\u503a\u52a1\uff0c\u5305\u62ec\u4e8c\u5143\u5206\u7c7b\u548c\u7c7b\u522b\u5206\u7c7b\uff0c\u5e76\u5177\u6709\u9c81\u68d2\u8bad\u7ec3\u548c\u53ef\u6301\u7eed\u6027\u8ddf\u8e2a\u529f\u80fd\u3002", "motivation": "\u89e3\u51b3\u8f6f\u4ef6\u9879\u76ee\u4e2d\u6280\u672f\u503a\u52a1\u7684\u6301\u4e45\u6311\u6218\uff0c\u901a\u8fc7\u63d0\u4f9b\u81ea\u52a8\u5206\u7c7b\u5de5\u5177\u3002", "method": "\u5229\u7528 transformer \u6a21\u578b\u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff0c\u5206\u6790\u6587\u672c\u5de5\u4ef6\uff1b\u7aef\u5230\u7aef\u7ba1\u9053\u5305\u62ec\u6570\u636e\u6444\u53d6\u3001\u9884\u5904\u7406\u3001\u6a21\u578b\u8bad\u7ec3\uff08\u4f7f\u7528 k \u6298\u4ea4\u53c9\u9a8c\u8bc1\u3001\u63d0\u524d\u505c\u6b62\u3001\u7c7b\u6743\u91cd\u8c03\u6574\uff09\u3001\u8bc4\u4f30\u548c\u63a8\u7406\uff1b\u5e76\u63d0\u4f9b\u7528\u6237\u53cb\u597d\u7684 Gradio web \u63a5\u53e3\u3002", "result": "\u5b9e\u73b0\u6280\u672f\u503a\u52a1\u7c7b\u522b\u7684\u51c6\u786e\u5206\u7c7b\uff0c\u5904\u7406\u4e0d\u5e73\u8861\u6570\u636e\u96c6\uff0c\u5e76\u8ddf\u8e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u78b3\u6392\u653e\u3002", "conclusion": "TD-Suite \u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u3001\u6613\u7528\u7684\u6280\u672f\u503a\u52a1\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u5347\u8f6f\u4ef6\u5f00\u53d1\u5b9e\u8df5\u3002"}}
{"id": "2504.11186", "pdf": "https://arxiv.org/pdf/2504.11186", "abs": "https://arxiv.org/abs/2504.11186", "authors": ["Minjie Zou", "Sahana Srinivasan", "Thaddaeus Wai Soon Lo", "Ke Zou", "Gabriel Dawei Yang", "Xuguang Ai", "Hyunjae Kim", "Maxwell Singer", "Fares Antaki", "Kelvin Li", "Robert Chang", "Marcus Tan", "David Ziyou Chen", "Dianbo Liu", "Qingyu Chen", "Yih Chung Tham"], "title": "Benchmarking Next-Generation Reasoning-Focused Large Language Models in Ophthalmology: A Head-to-Head Evaluation on 5,888 Items", "categories": ["cs.CL", "cs.AI"], "comment": "83 pages, 6 figures, 3 tables, 9 supplementary figures, 7\n  supplementary tables", "summary": "Recent advances in reasoning-focused large language models (LLMs) mark a\nshift from general LLMs toward models designed for complex decision-making, a\ncrucial aspect in medicine. However, their performance in specialized domains\nlike ophthalmology remains underexplored. This study comprehensively evaluated\nand compared the accuracy and reasoning capabilities of four newly developed\nreasoning-focused LLMs, namely DeepSeek-R1, OpenAI o1, o3-mini, and Gemini 2.0\nFlash-Thinking. Each model was assessed using 5,888 multiple-choice\nophthalmology exam questions from the MedMCQA dataset in zero-shot setting.\nQuantitative evaluation included accuracy, Macro-F1, and five text-generation\nmetrics (ROUGE-L, METEOR, BERTScore, BARTScore, and AlignScore), computed\nagainst ground-truth reasonings. Average inference time was recorded for a\nsubset of 100 randomly selected questions. Additionally, two board-certified\nophthalmologists qualitatively assessed clarity, completeness, and reasoning\nstructure of responses to differential diagnosis questions.O1 (0.902) and\nDeepSeek-R1 (0.888) achieved the highest accuracy, with o1 also leading in\nMacro-F1 (0.900). The performance of models across the text-generation metrics\nvaried: O3-mini excelled in ROUGE-L (0.151), o1 in METEOR (0.232), DeepSeek-R1\nand o3-mini tied for BERTScore (0.673), DeepSeek-R1 (-4.105) and Gemini 2.0\nFlash-Thinking (-4.127) performed best in BARTScore, while o3-mini (0.181) and\no1 (0.176) led AlignScore. Inference time across the models varied, with\nDeepSeek-R1 being slowest (40.4 seconds) and Gemini 2.0 Flash-Thinking fastest\n(6.7 seconds). Qualitative evaluation revealed that DeepSeek-R1 and Gemini 2.0\nFlash-Thinking tended to provide detailed and comprehensive intermediate\nreasoning, whereas o1 and o3-mini displayed concise and summarized\njustifications.", "AI": {"tldr": "This study evaluates four reasoning-focused LLMs on ophthalmology exam questions, comparing accuracy, reasoning, and efficiency.", "motivation": "To explore the underexplored performance of reasoning-focused LLMs in specialized medical domains like ophthalmology, despite advances in complex decision-making.", "method": "Evaluated four LLMs using 5,888 multiple-choice questions from MedMCQA in zero-shot setting, with metrics including accuracy, Macro-F1, text-generation scores, inference time, and qualitative assessment by ophthalmologists.", "result": "O1 and DeepSeek-R1 had highest accuracy; models varied in metrics like ROUGE-L and inference time; qualitative results showed differences in reasoning detail.", "conclusion": "Reasoning-focused LLMs show promise in medical applications with trade-offs in accuracy, efficiency, and reasoning quality."}}
{"id": "2504.11128", "pdf": "https://arxiv.org/pdf/2504.11128", "abs": "https://arxiv.org/abs/2504.11128", "authors": ["P. Tomkiewicz", "J. Jaworski", "P. Zielonka", "A. Wilinski"], "title": "K-means Enhanced Density Gradient Analysis for Urban and Transport Metrics Using Multi-Modal Satellite Imagery", "categories": ["cs.CV", "cs.LG", "eess.IV", "I.4.6, I.4.7, I.4.3"], "comment": "16 pages, 6 figures", "summary": "This paper presents a novel computational approach for evaluating urban\nmetrics through density gradient analysis using multi-modal satellite imagery,\nwith applications including public transport and other urban systems. By\ncombining optical and Synthetic Aperture Radar (SAR) data, we develop a method\nto segment urban areas, identify urban centers, and quantify density gradients.\nOur approach calculates two key metrics: the density gradient coefficient\n($\\alpha$) and the minimum effective distance (LD) at which density reaches a\ntarget threshold. We further employ machine learning techniques, specifically\nK-means clustering, to objectively identify uniform and high-variability\nregions within density gradient plots. We demonstrate that these metrics\nprovide an effective screening tool for public transport analyses by revealing\nthe underlying urban structure. Through comparative analysis of two\nrepresentative cities with contrasting urban morphologies (monocentric vs\npolycentric), we establish relationships between density gradient\ncharacteristics and public transport network topologies. Cities with clear\ndensity peaks in their gradient plots indicate distinct urban centers requiring\ndifferent transport strategies than those with more uniform density\ndistributions. This methodology offers urban planners a cost-effective,\nglobally applicable approach to preliminary public transport assessment using\nfreely available satellite data. The complete implementation, with additional\nexamples and documentation, is available in an open-source repository under the\nMIT license at https://github.com/nexri/Satellite-Imagery-Urban-Analysis.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u591a\u6a21\u6001\u536b\u661f\u56fe\u50cf\u8fdb\u884c\u5bc6\u5ea6\u68af\u5ea6\u5206\u6790\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u57ce\u5e02\u6307\u6807\u548c\u516c\u5171\u4ea4\u901a\u7cfb\u7edf\u3002", "motivation": "\u4e3a\u4e86\u63d0\u4f9b\u4e00\u79cd\u6210\u672c\u6548\u76ca\u9ad8\u3001\u5168\u7403\u9002\u7528\u7684\u5de5\u5177\uff0c\u4f7f\u7528\u514d\u8d39\u536b\u661f\u6570\u636e\u6765\u521d\u6b65\u8bc4\u4f30\u516c\u5171\u4ea4\u901a\u548c\u57ce\u5e02\u7ed3\u6784\u3002", "method": "\u7ed3\u5408\u5149\u5b66\u548cSAR\u6570\u636e\uff0c\u5206\u5272\u57ce\u5e02\u533a\u57df\uff0c\u8bc6\u522b\u4e2d\u5fc3\uff0c\u91cf\u5316\u5bc6\u5ea6\u68af\u5ea6\uff0c\u8ba1\u7b97\u03b1\u548cLD\u6307\u6807\uff0c\u5e76\u4f7f\u7528K-means\u805a\u7c7b\u5206\u6790\u5bc6\u5ea6\u68af\u5ea6\u56fe\u3002", "result": "\u901a\u8fc7\u6bd4\u8f83\u5355\u4e2d\u5fc3\u548c\u591a\u4e2d\u5fc3\u57ce\u5e02\uff0c\u5efa\u7acb\u5bc6\u5ea6\u68af\u5ea6\u4e0e\u516c\u5171\u4ea4\u901a\u7f51\u7edc\u5173\u7cfb\u7684\u8bc1\u636e\uff0c\u8bc1\u660e\u6307\u6807\u4f5c\u4e3a\u7b5b\u9009\u5de5\u5177\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u57ce\u5e02\u89c4\u5212\u8005\u63d0\u4f9b\u7ecf\u6d4e\u6709\u6548\u7684\u5f00\u6e90\u5de5\u5177\uff0c\u652f\u6301\u5168\u7403\u516c\u5171\u4ea4\u901a\u8bc4\u4f30\u3002"}}
{"id": "2504.11150", "pdf": "https://arxiv.org/pdf/2504.11150", "abs": "https://arxiv.org/abs/2504.11150", "authors": ["Mahir Gulzar", "Yar Muhammad", "Naveed Muhammad"], "title": "GC-GAT: Multimodal Vehicular Trajectory Prediction using Graph Goal Conditioning and Cross-context Attention", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Predicting future trajectories of surrounding vehicles heavily relies on what\ncontextual information is given to a motion prediction model. The context\nitself can be static (lanes, regulatory elements, etc) or dynamic (traffic\nparticipants). This paper presents a lane graph-based motion prediction model\nthat first predicts graph-based goal proposals and later fuses them with cross\nattention over multiple contextual elements. We follow the famous\nencoder-interactor-decoder architecture where the encoder encodes scene context\nusing lightweight Gated Recurrent Units, the interactor applies cross-context\nattention over encoded scene features and graph goal proposals, and the decoder\nregresses multimodal trajectories via Laplacian Mixture Density Network from\nthe aggregated encodings. Using cross-attention over graph-based goal proposals\ngives robust trajectory estimates since the model learns to attend to future\ngoal-relevant scene elements for the intended agent. We evaluate our work on\nnuScenes motion prediction dataset, achieving state-of-the-art results.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8f66\u9053\u56fe\u7684\u8fd0\u52a8\u9884\u6d4b\u6a21\u578b\uff0c\u4f7f\u7528\u7f16\u7801\u5668-\u4ea4\u4e92\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u5728nuScenes\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u6a21\u578b\u9700\u6709\u6548\u5229\u7528\u9759\u6001\uff08\u5982\u8f66\u9053\uff09\u548c\u52a8\u6001\uff08\u5982\u4ea4\u901a\u53c2\u4e0e\u8005\uff09\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "method": "\u6a21\u578b\u91c7\u7528encoder-interactor-decoder\u67b6\u6784\uff1aencoder\u7528\u8f7b\u91cf\u7ea7\u95e8\u63a7\u5faa\u73af\u5355\u5143\u7f16\u7801\u573a\u666f\u4e0a\u4e0b\u6587\uff0cinteractor\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u878d\u5408\u7279\u5f81\u548c\u56fe-based\u76ee\u6807\u63d0\u6848\uff0cdecoder\u7528\u62c9\u666e\u62c9\u65af\u6df7\u5408\u5bc6\u5ea6\u7f51\u7edc\u56de\u5f52\u591a\u6a21\u6001\u8f68\u8ff9\u3002", "result": "\u5728nuScenes\u8fd0\u52a8\u9884\u6d4b\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6a21\u578b\u5b66\u4f1a\u5173\u6ce8\u672a\u6765\u76ee\u6807\u76f8\u5173\u7684\u573a\u666f\u5143\u7d20\uff0c\u63d0\u5347\u4e86\u8f68\u8ff9\u4f30\u8ba1\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2504.11245", "pdf": "https://arxiv.org/pdf/2504.11245", "abs": "https://arxiv.org/abs/2504.11245", "authors": ["Laixin Xie", "Ying Zhang", "Xiyuan Wang", "Shiyi Liu", "Shenghan Gao", "Xingxing Xing", "Wei Wan", "Haipeng Zhang", "Quan Li"], "title": "Influence Maximization in Temporal Social Networks with a Cold-Start Problem: A Supervised Approach", "categories": ["cs.SI", "cs.AI"], "comment": "Accepted by ICWSM 2025", "summary": "Influence Maximization (IM) in temporal graphs focuses on identifying\ninfluential \"seeds\" that are pivotal for maximizing network expansion. We\nadvocate defining these seeds through Influence Propagation Paths (IPPs), which\nis essential for scaling up the network. Our focus lies in efficiently labeling\nIPPs and accurately predicting these seeds, while addressing the\noften-overlooked cold-start issue prevalent in temporal networks. Our strategy\nintroduces a motif-based labeling method and a tensorized Temporal Graph\nNetwork (TGN) tailored for multi-relational temporal graphs, bolstering\nprediction accuracy and computational efficiency. Moreover, we augment\ncold-start nodes with new neighbors from historical data sharing similar IPPs.\nThe recommendation system within an online team-based gaming environment\npresents subtle impact on the social network, forming multi-relational (i.e.,\nweak and strong) temporal graphs for our empirical IM study. We conduct offline\nexperiments to assess prediction accuracy and model training efficiency,\ncomplemented by online A/B testing to validate practical network growth and the\neffectiveness in addressing the cold-start issue.", "AI": {"tldr": "\u672c\u8bba\u6587\u9488\u5bf9\u65f6\u95f4\u56fe\u4e2d\u7684\u5f71\u54cd\u6700\u5927\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u5f71\u54cd\u4f20\u64ad\u8def\u5f84\u7684\u79cd\u5b50\u9009\u62e9\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u901a\u8fc7\u5f71\u54cd\u4f20\u64ad\u8def\u5f84\u5b9a\u4e49\u79cd\u5b50\u4ee5\u6269\u5927\u7f51\u7edc\u89c4\u6a21\uff0c\u5e76\u89e3\u51b3\u65f6\u95f4\u7f51\u7edc\u4e2d\u5e38\u89c1\u7684\u51b7\u542f\u52a8\u95ee\u9898\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u4e3b\u9898\u7684\u6807\u8bb0\u65b9\u6cd5\u548c\u5f20\u91cf\u5316\u65f6\u95f4\u56fe\u7f51\u7edc\uff08TGN\uff09\uff0c\u5e76\u4f7f\u7528\u5386\u53f2\u6570\u636e\u4e3a\u51b7\u542f\u52a8\u8282\u70b9\u6dfb\u52a0\u65b0\u90bb\u5c45\u3002", "result": "\u79bb\u7ebf\u5b9e\u9a8c\u663e\u793a\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u8bad\u7ec3\u6548\u7387\u7684\u63d0\u5347\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5b9e\u9645\u7f51\u7edc\u589e\u957f\u548c\u51b7\u542f\u52a8\u95ee\u9898\u7684\u6709\u6548\u89e3\u51b3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5f71\u54cd\u6700\u5927\u5316\u7684\u6027\u80fd\uff0c\u5e76\u6709\u6548\u5904\u7406\u4e86\u51b7\u542f\u52a8\u95ee\u9898\u3002"}}
{"id": "2504.11246", "pdf": "https://arxiv.org/pdf/2504.11246", "abs": "https://arxiv.org/abs/2504.11246", "authors": ["Davoud Shariat Panah", "Alessandro N Franciosi", "Cormac McCarthy", "Andrew Hines"], "title": "Respiratory Inhaler Sound Event Classification Using Self-Supervised Learning", "categories": ["eess.AS", "cs.AI", "cs.LG"], "comment": "Accepted at the IEEE EMBC 2025 Conference", "summary": "Asthma is a chronic respiratory condition that affects millions of people\nworldwide. While this condition can be managed by administering controller\nmedications through handheld inhalers, clinical studies have shown low\nadherence to the correct inhaler usage technique. Consequently, many patients\nmay not receive the full benefit of their medication. Automated classification\nof inhaler sounds has recently been studied to assess medication adherence.\nHowever, the existing classification models were typically trained using data\nfrom specific inhaler types, and their ability to generalize to sounds from\ndifferent inhalers remains unexplored. In this study, we adapted the wav2vec\n2.0 self-supervised learning model for inhaler sound classification by\npre-training and fine-tuning this model on inhaler sounds. The proposed model\nshows a balanced accuracy of 98% on a dataset collected using a dry powder\ninhaler and smartwatch device. The results also demonstrate that re-finetuning\nthis model on minimal data from a target inhaler is a promising approach to\nadapting a generic inhaler sound classification model to a different inhaler\ndevice and audio capture hardware. This is the first study in the field to\ndemonstrate the potential of smartwatches as assistive technologies for the\npersonalized monitoring of inhaler adherence using machine learning models.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528wav2vec 2.0\u6a21\u578b\u6539\u8fdb\u5438\u5165\u5668\u58f0\u97f3\u5206\u7c7b\uff0c\u63d0\u9ad8\u54ee\u5598\u836f\u7269\u4f9d\u4ece\u6027\u76d1\u6d4b\uff0c\u51c6\u786e\u7387\u8fbe98%\u3002", "motivation": "\u54ee\u5598\u60a3\u8005\u5438\u5165\u5668\u4f7f\u7528\u4f9d\u4ece\u6027\u4f4e\uff0c\u73b0\u6709\u7684\u5206\u7c7b\u6a21\u578b\u65e0\u6cd5\u6cdb\u5316\u5230\u4e0d\u540c\u5438\u5165\u5668\u7c7b\u578b\u3002", "method": "\u901a\u8fc7\u9884\u8bad\u7ec3\u548c\u5fae\u8c03wav2vec 2.0\u6a21\u578b\u6765\u5904\u7406\u5438\u5165\u5668\u58f0\u97f3\u6570\u636e\u3002", "result": "\u6a21\u578b\u5728\u5e72\u7c89\u5438\u5165\u5668\u6570\u636e\u96c6\u4e0a\u8fbe\u523098%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff0c\u5e76\u8bc1\u660e\u4e86\u4f7f\u7528\u5c11\u91cf\u6570\u636e\u91cd\u65b0\u5fae\u8c03\u7684\u9002\u5e94\u6027\u3002", "conclusion": "\u667a\u80fd\u624b\u8868\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u6709\u6f5c\u529b\u7528\u4e8e\u4e2a\u6027\u5316\u5438\u5165\u5668\u4f9d\u4ece\u6027\u76d1\u6d4b\uff0c\u8fd9\u662f\u8be5\u9886\u57df\u7684\u9996\u6b21\u7814\u7a76\u3002"}}
{"id": "2504.11170", "pdf": "https://arxiv.org/pdf/2504.11170", "abs": "https://arxiv.org/abs/2504.11170", "authors": ["Taewook Kang", "Bum-Jae You", "Juyoun Park", "Yisoo Lee"], "title": "A Real-time Anomaly Detection Method for Robots based on a Flexible and Sparse Latent Space", "categories": ["cs.RO", "cs.LG"], "comment": "20 pages, 11 figures", "summary": "The growing demand for robots to operate effectively in diverse environments\nnecessitates the need for robust real-time anomaly detection techniques during\nrobotic operations. However, deep learning-based models in robotics face\nsignificant challenges due to limited training data and highly noisy signal\nfeatures. In this paper, we present Sparse Masked Autoregressive Flow-based\nAdversarial AutoEncoders model to address these problems. This approach\nintegrates Masked Autoregressive Flow model into Adversarial AutoEncoders to\nconstruct a flexible latent space and utilize Sparse autoencoder to efficiently\nfocus on important features, even in scenarios with limited feature space. Our\nexperiments demonstrate that the proposed model achieves a 4.96% to 9.75%\nhigher area under the receiver operating characteristic curve for\npick-and-place robotic operations with randomly placed cans, compared to\nexisting state-of-the-art methods. Notably, it showed up to 19.67% better\nperformance in scenarios involving collisions with lightweight objects.\nAdditionally, unlike the existing state-of-the-art model, our model performs\ninferences within 1 millisecond, ensuring real-time anomaly detection. These\ncapabilities make our model highly applicable to machine learning-based robotic\nsafety systems in dynamic environments. The code will be made publicly\navailable after acceptance.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210Masked Autoregressive Flow\u548cSparse autoencoder\u7684Adversarial AutoEncoders\u6a21\u578b\uff0c\u7528\u4e8e\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u5b9e\u65f6\u5f02\u5e38\u68c0\u6d4b\uff0c\u63d0\u9ad8\u4e86\u6027\u80fd\u548c\u5b9e\u65f6\u6027\u3002", "motivation": "\u673a\u5668\u4eba\u9700\u8981\u5728\u591a\u6837\u73af\u5883\u4e2d\u6709\u6548\u64cd\u4f5c\uff0c\u4f46\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9762\u4e34\u8bad\u7ec3\u6570\u636e\u6709\u9650\u548c\u566a\u58f0\u7279\u5f81\u5927\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faSparse Masked Autoregressive Flow-based Adversarial AutoEncoders\u6a21\u578b\uff0c\u5c06Masked Autoregressive Flow\u96c6\u6210\u5230Adversarial AutoEncoders\u4e2d\uff0c\u5e76\u4f7f\u7528Sparse autoencoder\u5173\u6ce8\u91cd\u8981\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cROC\u66f2\u7ebf\u9762\u79ef\u63d0\u9ad8\u4e864.96%\u81f39.75%\uff0c\u78b0\u649e\u573a\u666f\u6027\u80fd\u63d0\u534719.67%\uff0c\u63a8\u7406\u65f6\u95f4\u5c0f\u4e8e1\u6beb\u79d2\u3002", "conclusion": "\u8be5\u6a21\u578b\u9002\u7528\u4e8e\u52a8\u6001\u73af\u5883\u4e0b\u7684\u673a\u5668\u4eba\u5b89\u5168\u7cfb\u7edf\uff0c\u4ee3\u7801\u5c06\u516c\u5f00\u3002"}}
{"id": "2504.11212", "pdf": "https://arxiv.org/pdf/2504.11212", "abs": "https://arxiv.org/abs/2504.11212", "authors": ["Samuel Weidemaier", "Florine Hartwig", "Josua Sassen", "Sergio Conti", "Mirela Ben-Chen", "Martin Rumpf"], "title": "SDFs from Unoriented Point Clouds using Neural Variational Heat Distances", "categories": ["math.NA", "cs.LG", "cs.NA", "65K10, 68T07, 65D18, 49J45"], "comment": "14 pages, 16 figures, 4 tables", "summary": "We propose a novel variational approach for computing neural Signed Distance\nFields (SDF) from unoriented point clouds. To this end, we replace the commonly\nused eikonal equation with the heat method, carrying over to the neural domain\nwhat has long been standard practice for computing distances on discrete\nsurfaces. This yields two convex optimization problems for whose solution we\nemploy neural networks: We first compute a neural approximation of the\ngradients of the unsigned distance field through a small time step of heat flow\nwith weighted point cloud densities as initial data. Then we use it to compute\na neural approximation of the SDF. We prove that the underlying variational\nproblems are well-posed. Through numerical experiments, we demonstrate that our\nmethod provides state-of-the-art surface reconstruction and consistent SDF\ngradients. Furthermore, we show in a proof-of-concept that it is accurate\nenough for solving a PDE on the zero-level set.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u53d8\u5206\u65b9\u6cd5\uff0c\u4f7f\u7528\u70ed\u65b9\u6cd5\u4ee3\u66ffeikonal\u65b9\u7a0b\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u4ece\u65e0\u5411\u70b9\u4e91\u8ba1\u7b97\u7b26\u53f7\u8ddd\u79bb\u573a\uff08SDF\uff09\uff0c\u5e76\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u52a8\u673a\u662f\u5c06\u70ed\u65b9\u6cd5\u4ece\u79bb\u6563\u8868\u9762\u6269\u5c55\u5230\u795e\u7ecf\u9886\u57df\uff0c\u4ee5\u6539\u8fdb\u4ece\u70b9\u4e91\u8ba1\u7b97SDF\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u4e24\u4e2a\u51f8\u4f18\u5316\u95ee\u9898\uff1a\u5148\u901a\u8fc7\u70ed\u6d41\u8fd1\u4f3c\u65e0\u7b26\u53f7\u8ddd\u79bb\u573a\u7684\u68af\u5ea6\uff0c\u7136\u540e\u8ba1\u7b97SDF\u3002", "result": "\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u8868\u9762\u91cd\u5efa\u3001\u4e00\u81f4\u7684SDF\u68af\u5ea6\uff0c\u5e76\u53ef\u7528\u4e8e\u96f6\u6c34\u5e73\u96c6\u4e0a\u6c42\u89e3PDE\u3002", "conclusion": "\u7ed3\u8bba\u662f\u53d8\u5206\u95ee\u9898\u826f\u5b9a\u4e49\uff0c\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2504.11227", "pdf": "https://arxiv.org/pdf/2504.11227", "abs": "https://arxiv.org/abs/2504.11227", "authors": ["Run Wang", "Gamze Islamoglu", "Andrea Belano", "Viviane Potocnik", "Francesco Conti", "Angelo Garofalo", "Luca Benini"], "title": "VEXP: A Low-Cost RISC-V ISA Extension for Accelerated Softmax Computation in Transformers", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "While Transformers are dominated by Floating-Point (FP)\nMatrix-Multiplications, their aggressive acceleration through dedicated\nhardware or many-core programmable systems has shifted the performance\nbottleneck to non-linear functions like Softmax. Accelerating Softmax is\nchallenging due to its non-pointwise, non-linear nature, with exponentiation as\nthe most demanding step. To address this, we design a custom arithmetic block\nfor Bfloat16 exponentiation leveraging a novel approximation algorithm based on\nSchraudolph's method, and we integrate it into the Floating-Point Unit (FPU) of\nthe RISC-V cores of a compute cluster, through custom Instruction Set\nArchitecture (ISA) extensions, with a negligible area overhead of 1\\%. By\noptimizing the software kernels to leverage the extension, we execute Softmax\nwith 162.7$\\times$ less latency and 74.3$\\times$ less energy compared to the\nbaseline cluster, achieving an 8.2$\\times$ performance improvement and\n4.1$\\times$ higher energy efficiency for the FlashAttention-2 kernel in GPT-2\nconfiguration. Moreover, the proposed approach enables a multi-cluster system\nto efficiently execute end-to-end inference of pre-trained Transformer models,\nsuch as GPT-2, GPT-3 and ViT, achieving up to 5.8$\\times$ and 3.6$\\times$\nreduction in latency and energy consumption, respectively, without requiring\nre-training and with negligible accuracy loss.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u81ea\u5b9a\u4e49\u786c\u4ef6\u52a0\u901fTransformer\u4e2d\u7684Softmax\u51fd\u6570\uff0c\u4f7f\u7528\u8fd1\u4f3c\u7b97\u6cd5\u5b9e\u73b0\u663e\u8457\u7684\u6027\u80fd\u548c\u80fd\u91cf\u6548\u7387\u63d0\u5347\u3002", "motivation": "Transformer\u6a21\u578b\u4e2d\uff0c\u6027\u80fd\u74f6\u9888\u4ece\u6d6e\u70b9\u77e9\u9635\u4e58\u6cd5\u8f6c\u79fb\u5230\u975e\u7ebf\u6027\u51fd\u6570\u5982Softmax\u7684\u6307\u6570\u8fd0\u7b97\uff0c\u9700\u8981\u9ad8\u6548\u52a0\u901f\u3002", "method": "\u8bbe\u8ba1Bfloat16\u6307\u6570\u8fd0\u7b97\u81ea\u5b9a\u4e49\u7b97\u672f\u5757\uff0c\u57fa\u4e8eSchraudolph\u65b9\u6cd5\u8fd1\u4f3c\uff0c\u96c6\u6210\u5230RISC-V\u6838\u5fc3FPU\u4e2d\uff0c\u5e76\u901a\u8fc7\u81ea\u5b9a\u4e49ISA\u6269\u5c55\u548c\u8f6f\u4ef6\u4f18\u5316\u3002", "result": "Softmax\u5ef6\u8fdf\u51cf\u5c11162.7\u500d\u3001\u80fd\u91cf\u6d88\u8017\u51cf\u5c1174.3\u500d\uff1bFlashAttention-2\u6027\u80fd\u63d0\u53478.2\u500d\u3001\u80fd\u91cf\u6548\u7387\u63d0\u9ad84.1\u500d\uff1b\u7aef\u5230\u7aef\u63a8\u7406\u5ef6\u8fdf\u548c\u80fd\u91cf\u6d88\u8017\u51cf\u5c11\u9ad8\u8fbe5.8\u500d\u548c3.6\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u4ec5\u5fae\u5c0f\u7cbe\u5ea6\u635f\u5931\uff0c\u5373\u53ef\u9ad8\u6548\u6267\u884cTransformer\u6a21\u578b\u63a8\u7406\u3002"}}
{"id": "2504.11268", "pdf": "https://arxiv.org/pdf/2504.11268", "abs": "https://arxiv.org/abs/2504.11268", "authors": ["Juan Garcia Giraldo", "Nikolaos Dimitriadis", "Ke Wang", "Pascal Frossard"], "title": "Single-Input Multi-Output Model Merging: Leveraging Foundation Models for Dense Multi-Task Learning", "categories": ["cs.CV", "cs.AI"], "comment": "22 pages, 6 figures", "summary": "Model merging is a flexible and computationally tractable approach to merge\nsingle-task checkpoints into a multi-task model. Prior work has solely focused\non constrained multi-task settings where there is a one-to-one mapping between\na sample and a task, overlooking the paradigm where multiple tasks may operate\non the same sample, e.g., scene understanding. In this paper, we focus on the\nmulti-task setting with single-input-multiple-outputs (SIMO) and show that it\nqualitatively differs from the single-input-single-output model merging\nsettings studied in the literature due to the existence of task-specific\ndecoders and diverse loss objectives. We identify that existing model merging\nmethods lead to significant performance degradation, primarily due to\nrepresentation misalignment between the merged encoder and task-specific\ndecoders. We propose two simple and efficient fixes for the SIMO setting to\nre-align the feature representation after merging. Compared to joint\nfine-tuning, our approach is computationally effective and flexible, and sheds\nlight into identifying task relationships in an offline manner. Experiments on\nNYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) task\narithmetic suffices to enable multi-task capabilities; however, the\nrepresentations generated by the merged encoder has to be re-aligned with the\ntask-specific heads; (2) the proposed architecture rivals traditional\nmulti-task learning in performance but requires fewer samples and training\nsteps by leveraging the existence of task-specific models.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u5728\u5355\u8f93\u5165\u591a\u8f93\u51fa\uff08SIMO\uff09\u591a\u4efb\u52a1\u8bbe\u7f6e\u4e0b\u6539\u8fdb\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b80\u5355\u4fee\u590d\u89e3\u51b3\u8868\u793a\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u9ad8\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u4ec5\u5173\u6ce8\u5355\u8f93\u5165\u5355\u8f93\u51fa\u8bbe\u7f6e\uff0c\u5ffd\u7565SIMO\u573a\u666f\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u9488\u5bf9\u4efb\u52a1\u7279\u5b9a\u89e3\u7801\u5668\u548c\u635f\u5931\u76ee\u6807\u8fdb\u884c\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u7b80\u5355\u9ad8\u6548\u7684\u4fee\u590d\u65b9\u6cd5\uff0c\u7528\u4e8e\u5408\u5e76\u540e\u91cd\u65b0\u5bf9\u9f50\u7279\u5f81\u8868\u793a\uff0c\u4ee5\u9002\u5e94SIMO\u591a\u4efb\u52a1\u73af\u5883\u3002", "result": "\u5b9e\u9a8c\u5728NYUv2\u3001Cityscapes\u548cTaskonomy\u6570\u636e\u96c6\u4e0a\u663e\u793a\uff0c\u4efb\u52a1\u7b97\u672f\u7ed3\u5408\u8868\u793a\u5bf9\u9f50\u53ef\u5b9e\u73b0\u591a\u4efb\u52a1\u80fd\u529b\uff0c\u4e0e\u4f20\u7edf\u591a\u4efb\u52a1\u5b66\u4e60\u6027\u80fd\u76f8\u5f53\uff0c\u4f46\u4f7f\u7528\u66f4\u5c11\u6837\u672c\u548c\u8bad\u7ec3\u6b65\u9aa4\u3002", "conclusion": "\u6a21\u578b\u5408\u5e76\u5728SIMO\u8bbe\u7f6e\u4e0b\u901a\u8fc7\u8868\u793a\u5bf9\u9f50\u53ef\u9ad8\u6548\u5b9e\u73b0\u591a\u4efb\u52a1\u5b66\u4e60\uff0c\u63ed\u793a\u4efb\u52a1\u5173\u7cfb\u5e76\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u3002"}}
{"id": "2504.11305", "pdf": "https://arxiv.org/pdf/2504.11305", "abs": "https://arxiv.org/abs/2504.11305", "authors": ["Jincheng Kang", "Yi Cen", "Yigang Cen", "Ke Wang", "Yuhan Liu"], "title": "CFIS-YOLO: A Lightweight Multi-Scale Fusion Network for Edge-Deployable Wood Defect Detection", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 11 figures", "summary": "Wood defect detection is critical for ensuring quality control in the wood\nprocessing industry. However, current industrial applications face two major\nchallenges: traditional methods are costly, subjective, and labor-intensive,\nwhile mainstream deep learning models often struggle to balance detection\naccuracy and computational efficiency for edge deployment. To address these\nissues, this study proposes CFIS-YOLO, a lightweight object detection model\noptimized for edge devices. The model introduces an enhanced C2f structure, a\ndynamic feature recombination module, and a novel loss function that\nincorporates auxiliary bounding boxes and angular constraints. These\ninnovations improve multi-scale feature fusion and small object localization\nwhile significantly reducing computational overhead. Evaluated on a public wood\ndefect dataset, CFIS-YOLO achieves a mean Average Precision (mAP@0.5) of\n77.5\\%, outperforming the baseline YOLOv10s by 4 percentage points. On SOPHON\nBM1684X edge devices, CFIS-YOLO delivers 135 FPS, reduces power consumption to\n17.3\\% of the original implementation, and incurs only a 0.5 percentage point\ndrop in mAP. These results demonstrate that CFIS-YOLO is a practical and\neffective solution for real-world wood defect detection in resource-constrained\nenvironments.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faCFIS-YOLO\u6a21\u578b\uff0c\u7528\u4e8e\u6728\u5934\u7f3a\u9677\u68c0\u6d4b\uff0c\u4f18\u5316\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u4e3b\u89c2\u4e14\u52b3\u52a8\u5bc6\u96c6\uff0c\u4ee5\u53ca\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8fb9\u7f18\u90e8\u7f72\u65f6\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u5e73\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51faCFIS-YOLO\u6a21\u578b\uff0c\u5305\u62ec\u589e\u5f3aC2f\u7ed3\u6784\u3001\u52a8\u6001\u7279\u5f81\u91cd\u7ec4\u6a21\u5757\u548c\u65b0\u578b\u635f\u5931\u51fd\u6570\uff0c\u63d0\u9ad8\u591a\u5c3a\u5ea6\u7279\u5f81\u878d\u5408\u548c\u5c0f\u76ee\u6807\u5b9a\u4f4d\u3002", "result": "\u5728\u516c\u5171\u6570\u636e\u96c6\u4e0amAP@0.5\u8fbe77.5%\uff0c\u6bd4YOLOv10s\u9ad84%\uff1b\u5728SOPHON BM1684X\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5e27\u7387135 FPS\uff0c\u529f\u8017\u964d\u81f317.3%\uff0cmAP\u4ec5\u4e0b\u964d0.5%\u3002", "conclusion": "CFIS-YOLO\u662f\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u6728\u5934\u7f3a\u9677\u68c0\u6d4b\u7684\u5b9e\u7528\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.11247", "pdf": "https://arxiv.org/pdf/2504.11247", "abs": "https://arxiv.org/abs/2504.11247", "authors": ["Fikrican \u00d6zg\u00fcr", "Ren\u00e9 Zurbr\u00fcgg", "Suryansh Kumar"], "title": "Next-Future: Sample-Efficient Policy Learning for Robotic-Arm Tasks", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "10 pages, 9 figures, 6 tables", "summary": "Hindsight Experience Replay (HER) is widely regarded as the state-of-the-art\nalgorithm for achieving sample-efficient multi-goal reinforcement learning (RL)\nin robotic manipulation tasks with binary rewards. HER facilitates learning\nfrom failed attempts by replaying trajectories with redefined goals. However,\nit relies on a heuristic-based replay method that lacks a principled framework.\nTo address this limitation, we introduce a novel replay strategy,\n\"Next-Future\", which focuses on rewarding single-step transitions. This\napproach significantly enhances sample efficiency and accuracy in learning\nmulti-goal Markov decision processes (MDPs), particularly under stringent\naccuracy requirements -- a critical aspect for performing complex and precise\nrobotic-arm tasks. We demonstrate the efficacy of our method by highlighting\nhow single-step learning enables improved value approximation within the\nmulti-goal RL framework. The performance of the proposed replay strategy is\nevaluated across eight challenging robotic manipulation tasks, using ten random\nseeds for training. Our results indicate substantial improvements in sample\nefficiency for seven out of eight tasks and higher success rates in six tasks.\nFurthermore, real-world experiments validate the practical feasibility of the\nlearned policies, demonstrating the potential of \"Next-Future\" in solving\ncomplex robotic-arm tasks.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165'Next-Future'\u91cd\u653e\u7b56\u7565\uff0c\u6539\u8fdbHER\u5728\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6837\u672c\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u3002", "motivation": "HER\u4f9d\u8d56\u542f\u53d1\u5f0f\u91cd\u653e\u65b9\u6cd5\u7f3a\u4e4f\u539f\u5219\u6846\u67b6\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u65b0\u7b56\u7565\u6765\u63d0\u5347\u5b66\u4e60\u6548\u7387\u3002", "method": "\u63d0\u51fa'Next-Future'\u7b56\u7565\uff0c\u4e13\u6ce8\u4e8e\u5956\u52b1\u5355\u6b65\u8f6c\u6362\uff0c\u4ee5\u63d0\u9ad8\u591a\u76ee\u6807MDP\u7684\u5b66\u4e60\u3002", "result": "\u5728\u516b\u4e2a\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0c\u4e03\u4e2a\u4efb\u52a1\u6837\u672c\u6548\u7387\u63d0\u5347\uff0c\u516d\u4e2a\u4efb\u52a1\u6210\u529f\u7387\u66f4\u9ad8\uff1b\u5b9e\u4e16\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b56\u7565\u7684\u53ef\u884c\u6027\u3002", "conclusion": "'Next-Future'\u7b56\u7565\u5728\u590d\u6742\u673a\u5668\u4eba\u81c2\u4efb\u52a1\u4e2d\u663e\u793a\u6f5c\u529b\uff0c\u63d0\u9ad8\u4e86\u4ef7\u503c\u903c\u8fd1\u548c\u6027\u80fd\u3002"}}
{"id": "2504.11249", "pdf": "https://arxiv.org/pdf/2504.11249", "abs": "https://arxiv.org/abs/2504.11249", "authors": ["Luke Evans", "Octavian-Vlad Murad", "Lars Dingeldein", "Pilar Cossio", "Roberto Covino", "Marina Meila"], "title": "Cryo-em images are intrinsically low dimensional", "categories": ["q-bio.QM", "cs.CV", "cs.LG", "q-bio.BM", "stat.ML"], "comment": null, "summary": "Simulation-based inference provides a powerful framework for cryo-electron\nmicroscopy, employing neural networks in methods like CryoSBI to infer\nbiomolecular conformations via learned latent representations. This latent\nspace represents a rich opportunity, encoding valuable information about the\nphysical system and the inference process. Harnessing this potential hinges on\nunderstanding the underlying geometric structure of these representations. We\ninvestigate this structure by applying manifold learning techniques to CryoSBI\nrepresentations of hemagglutinin (simulated and experimental). We reveal that\nthese high-dimensional data inherently populate low-dimensional, smooth\nmanifolds, with simulated data effectively covering the experimental\ncounterpart. By characterizing the manifold's geometry using Diffusion Maps and\nidentifying its principal axes of variation via coordinate interpretation\nmethods, we establish a direct link between the latent structure and key\nphysical parameters. Discovering this intrinsic low-dimensionality and\ninterpretable geometric organization not only validates the CryoSBI approach\nbut enables us to learn more from the data structure and provides opportunities\nfor improving future inference strategies by exploiting this revealed manifold\ngeometry.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6d41\u5f62\u5b66\u4e60\u5206\u6790CryoSBI\u7684\u6f5c\u5728\u8868\u793a\uff0c\u53d1\u73b0\u5176\u4e3a\u4f4e\u7ef4\u5e73\u6ed1\u6d41\u5f62\uff0c\u4e0e\u7269\u7406\u53c2\u6570\u76f8\u5173\u8054\uff0c\u9a8c\u8bc1\u5e76\u6539\u8fdb\u51b7\u51bb\u7535\u5b50\u663e\u5fae\u955c\u63a8\u65ad\u65b9\u6cd5\u3002", "motivation": "CryoSBI\u6f5c\u5728\u7a7a\u95f4\u5305\u542b\u7269\u7406\u7cfb\u7edf\u548c\u63a8\u65ad\u8fc7\u7a0b\u7684\u5b9d\u8d35\u4fe1\u606f\uff0c\u9700\u8981\u7406\u89e3\u5176\u51e0\u4f55\u7ed3\u6784\u4ee5\u5145\u5206\u53d1\u6325\u6f5c\u529b\u3002", "method": "\u5e94\u7528\u6d41\u5f62\u5b66\u4e60\u6280\u672f\uff08\u5982Diffusion Maps\uff09\u5230CryoSBI\u7684\u8840\u51dd\u7d20\u6a21\u62df\u548c\u5b9e\u9a8c\u6570\u636e\u4e0a\uff0c\u8868\u5f81\u6d41\u5f62\u51e0\u4f55\u5e76\u8bc6\u522b\u4e3b\u53d8\u5316\u8f74\u3002", "result": "\u6570\u636e\u586b\u5145\u4f4e\u7ef4\u5e73\u6ed1\u6d41\u5f62\uff0c\u6a21\u62df\u6570\u636e\u8986\u76d6\u5b9e\u9a8c\u6570\u636e\uff0c\u5e76\u5efa\u7acb\u6f5c\u5728\u7ed3\u6784\u4e0e\u5173\u952e\u7269\u7406\u53c2\u6570\u7684\u76f4\u63a5\u8054\u7cfb\u3002", "conclusion": "\u53d1\u73b0\u7684\u4f4e\u7ef4\u6027\u548c\u53ef\u89e3\u91ca\u6027\u9a8c\u8bc1\u4e86CryoSBI\u65b9\u6cd5\uff0c\u5e76\u4e3a\u4ece\u6570\u636e\u7ed3\u6784\u4e2d\u5b66\u4e60\u548c\u4f18\u5316\u672a\u6765\u63a8\u65ad\u7b56\u7565\u63d0\u4f9b\u673a\u4f1a\u3002"}}
{"id": "2504.11335", "pdf": "https://arxiv.org/pdf/2504.11335", "abs": "https://arxiv.org/abs/2504.11335", "authors": ["Gopichand Bandarupalli"], "title": "Code Reborn AI-Driven Legacy Systems Modernization from COBOL to Java", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "This study investigates AI-driven modernization of legacy COBOL code into\nJava, addressing a critical challenge in aging software systems. Leveraging the\nLegacy COBOL 2024 Corpus -- 50,000 COBOL files from public and enterprise\nsources -- Java parses the code, AI suggests upgrades, and React visualizes\ngains. Achieving 93% accuracy, complexity drops 35% (from 18 to 11.7) and\ncoupling 33% (from 8 to 5.4), surpassing manual efforts (75%) and rule-based\ntools (82%). The approach offers a scalable path to rejuvenate COBOL systems,\nvital for industries like banking and insurance.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528AI\u5c06\u9057\u7559COBOL\u4ee3\u7801\u73b0\u4ee3\u5316\u4e3aJava\uff0c\u5b9e\u73b093%\u51c6\u786e\u7387\u548c\u663e\u8457\u6548\u7387\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u8001\u5316\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u7279\u522b\u662f\u5c06COBOL\u4ee3\u7801\u5347\u7ea7\u4e3aJava\uff0c\u5bf9\u94f6\u884c\u548c\u4fdd\u9669\u7b49\u884c\u4e1a\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5229\u7528Legacy COBOL 2024 Corpus\uff0850,000\u4e2aCOBOL\u6587\u4ef6\uff09\uff0c\u901a\u8fc7Java\u89e3\u6790\u4ee3\u7801\u3001AI\u5efa\u8bae\u5347\u7ea7\u3001React\u53ef\u89c6\u5316\u6536\u76ca\u3002", "result": "\u5b9e\u73b093%\u51c6\u786e\u7387\uff0c\u590d\u6742\u5ea6\u964d\u4f4e35%\uff08\u4ece18\u523011.7\uff09\uff0c\u8026\u5408\u5ea6\u964d\u4f4e33%\uff08\u4ece8\u52305.4\uff09\uff0c\u4f18\u4e8e\u624b\u52a8\u65b9\u6cd5\uff0875%\uff09\u548c\u57fa\u4e8e\u89c4\u5219\u5de5\u5177\uff0882%\uff09\u3002", "conclusion": "\u63d0\u4f9b\u53ef\u6269\u5c55\u8def\u5f84\u6765\u632f\u5174COBOL\u7cfb\u7edf\uff0c\u52a9\u529b\u884c\u4e1a\u73b0\u4ee3\u5316\u3002"}}
{"id": "2504.11258", "pdf": "https://arxiv.org/pdf/2504.11258", "abs": "https://arxiv.org/abs/2504.11258", "authors": ["Liam Welsh", "Udit Grover", "Sebastian Jaimungal"], "title": "Multi-Agent Reinforcement Learning for Greenhouse Gas Offset Credit Markets", "categories": ["q-fin.MF", "cs.LG"], "comment": null, "summary": "Climate change is a major threat to the future of humanity, and its impacts\nare being intensified by excess man-made greenhouse gas emissions. One method\ngovernments can employ to control these emissions is to provide firms with\nemission limits and penalize any excess emissions above the limit. Excess\nemissions may also be offset by firms who choose to invest in carbon reducing\nand capturing projects. These projects generate offset credits which can be\nsubmitted to a regulating agency to offset a firm's excess emissions, or they\ncan be traded with other firms. In this work, we characterize the finite-agent\nNash equilibrium for offset credit markets. As computing Nash equilibria is an\nNP-hard problem, we utilize the modern reinforcement learning technique\nNash-DQN to efficiently estimate the market's Nash equilibria. We demonstrate\nnot only the validity of employing reinforcement learning methods applied to\nclimate themed financial markets, but also the significant financial savings\nemitting firms may achieve when abiding by the Nash equilibria through\nnumerical experiments.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u62b5\u6d88\u4fe1\u7528\u5e02\u573a\u63a7\u5236\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u7684Nash\u5747\u8861\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5Nash-DQN\u4f30\u8ba1\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u8d22\u52a1\u8282\u7ea6\u6f5c\u529b\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u5a01\u80c1\u4eba\u7c7b\u672a\u6765\uff0c\u4eba\u4e3a\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u52a0\u5267\uff0c\u653f\u5e9c\u53ef\u901a\u8fc7\u6392\u653e\u9650\u989d\u548c\u60e9\u7f5a\u63aa\u65bd\u63a7\u5236\u6392\u653e\uff0c\u9f13\u52b1\u4f01\u4e1a\u6295\u8d44\u78b3\u51cf\u6392\u9879\u76ee\u4ee5\u751f\u6210\u62b5\u6d88\u4fe1\u7528\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6280\u672fNash-DQN\u9ad8\u6548\u4f30\u8ba1\u6709\u9650\u4ee3\u7406Nash\u5747\u8861\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u6c14\u5019\u91d1\u878d\u5e02\u573a\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53ca\u4f01\u4e1a\u9075\u5b88Nash\u5747\u8861\u65f6\u53ef\u5b9e\u73b0\u7684\u663e\u8457\u8d22\u52a1\u8282\u7ea6\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u53ef\u6709\u6548\u5e94\u7528\u4e8e\u6c14\u5019\u4e3b\u9898\u91d1\u878d\u5e02\u573a\uff0c\u5e2e\u52a9\u4f01\u4e1a\u5b9e\u73b0\u8d22\u52a1\u5229\u76ca\u3002"}}
{"id": "2504.11299", "pdf": "https://arxiv.org/pdf/2504.11299", "abs": "https://arxiv.org/abs/2504.11299", "authors": ["Peter Matthew Jacobs", "Foad Namjoo", "Jeff M. Phillips"], "title": "Efficient and Stable Multi-Dimensional Kolmogorov-Smirnov Distance", "categories": ["stat.CO", "cs.CG", "cs.LG"], "comment": "21 pages, Primary: stat.CO. Secondary: cs.CG, cs.LG", "summary": "We revisit extending the Kolmogorov-Smirnov distance between probability\ndistributions to the multidimensional setting and make new arguments about the\nproper way to approach this generalization. Our proposed formulation maximizes\nthe difference over orthogonal dominating rectangular ranges (d-sided\nrectangles in R^d), and is an integral probability metric. We also prove that\nthe distance between a distribution and a sample from the distribution\nconverges to 0 as the sample size grows, and bound this rate. Moreover, we show\nthat one can, up to this same approximation error, compute the distance\nefficiently in 4 or fewer dimensions; specifically the runtime is near-linear\nin the size of the sample needed for that error. With this, we derive a\ndelta-precision two-sample hypothesis test using this distance. Finally, we\nshow these metric and approximation properties do not hold for other popular\nvariants.", "AI": {"tldr": "\u672c\u8bba\u6587\u91cd\u65b0\u5ba1\u89c6\u591a\u7ef4Kolmogorov-Smirnov\u8ddd\u79bb\u7684\u6269\u5c55\uff0c\u63d0\u51fa\u65b0\u516c\u5f0f\u5e76\u8bc1\u660e\u5176\u6536\u655b\u6027\u3001\u8ba1\u7b97\u6548\u7387\u548c\u5047\u8bbe\u68c0\u9a8c\u3002", "motivation": "\u63a2\u8ba8\u6b63\u786e\u6269\u5c55Kolmogorov-Smirnov\u8ddd\u79bb\u5230\u591a\u7ef4\u7a7a\u95f4\u7684\u9002\u5f53\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6700\u5927\u5316\u6b63\u4ea4\u4e3b\u5bfc\u77e9\u5f62\u8303\u56f4\u5dee\u7684\u79ef\u5206\u6982\u7387\u5ea6\u91cf\uff0c\u8bc1\u660e\u8ddd\u79bb\u6536\u655b\u3001\u754c\u5b9a\u6536\u655b\u7387\u3001\u57284\u7ef4\u5185\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\uff0c\u5e76\u5bfc\u51fa\u4e00\u4e2a\u5047\u8bbe\u68c0\u9a8c\u3002", "result": "\u8bc1\u660e\u5206\u5e03\u4e0e\u6837\u672c\u8ddd\u79bb\u968f\u6837\u672c\u5927\u5c0f\u6536\u655b\u52300\uff0c\u7ed9\u51fa\u6536\u655b\u7387\u754c\uff1b\u5b9e\u73b0\u4e86\u9ad8\u6548\u8ba1\u7b97\u548c\u5047\u8bbe\u68c0\u9a8c\uff1b\u5176\u4ed6\u53d8\u4f53\u4e0d\u5177\u5907\u8fd9\u4e9b\u6027\u8d28\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5408\u9002\u7684\u591a\u7ef4\u6269\u5c55\uff0c\u5177\u6709\u826f\u597d\u7684\u5ea6\u91cf\u548c\u8fd1\u4f3c\u6027\u80fd\u3002"}}
{"id": "2504.11338", "pdf": "https://arxiv.org/pdf/2504.11338", "abs": "https://arxiv.org/abs/2504.11338", "authors": ["Alexandre Savi Fayam Mbala Mouen", "Jerry Lacmou Zeutouo", "Vianney Kengne Tchendji"], "title": "Transformer-Based Model for Cold Start Mitigation in FaaS Architecture", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Serverless architectures, particularly the Function as a Service (FaaS)\nmodel, have become a cornerstone of modern cloud computing due to their ability\nto simplify resource management and enhance application deployment agility.\nHowever, a significant challenge remains: the cold start problem. This\nphenomenon occurs when an idle FaaS function is invoked, requiring a full\ninitialization process, which increases latency and degrades user experience.\nExisting solutions for cold start mitigation are limited in terms of invocation\npattern generalization and implementation complexity. In this study, we propose\nan innovative approach leveraging Transformer models to mitigate the impact of\ncold starts in FaaS architectures. Our solution excels in accurately modeling\nfunction initialization delays and optimizing serverless system performance.\nExperimental evaluation using a public dataset provided by Azure demonstrates a\nsignificant reduction in cold start times, reaching up to 79\\% compared to\nconventional methods.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4f7f\u7528Transformer\u6a21\u578b\u7f13\u89e3FaaS\u4e2d\u7684\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u53ef\u51cf\u5c11\u9ad8\u8fbe79%\u7684\u542f\u52a8\u65f6\u95f4\u3002", "motivation": "\u89e3\u51b3\u670d\u52a1\u5668less\u67b6\u6784\u4e2d\u51b7\u542f\u52a8\u95ee\u9898\u5bfc\u81f4\u7684\u5ef6\u8fdf\u548c\u7528\u6237\u4f53\u9a8c\u4e0b\u964d\uff0c\u4ee5\u53ca\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5728\u8c03\u7528\u6a21\u5f0f\u6cdb\u5316\u548c\u5b9e\u73b0\u590d\u6742\u5ea6\u4e0a\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528Transformer\u6a21\u578b\u5efa\u6a21\u51fd\u6570\u521d\u59cb\u5316\u5ef6\u8fdf\u5e76\u4f18\u5316\u670d\u52a1\u5668less\u7cfb\u7edf\u6027\u80fd\u7684\u521b\u65b0\u65b9\u6cd5\u3002", "result": "\u4f7f\u7528Azure\u516c\u5171\u6570\u636e\u96c6\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u663e\u793a\u51b7\u542f\u52a8\u65f6\u95f4\u6bd4\u4f20\u7edf\u65b9\u6cd5\u51cf\u5c11\u9ad8\u8fbe79%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u51b7\u542f\u52a8\u5f71\u54cd\uff0c\u63d0\u9ad8\u4e86FaaS\u67b6\u6784\u7684\u6027\u80fd\u3002"}}
{"id": "2504.11302", "pdf": "https://arxiv.org/pdf/2504.11302", "abs": "https://arxiv.org/abs/2504.11302", "authors": ["Hari Nathan"], "title": "Limits of Discrete Energy of Families of Increasing Sets", "categories": ["math.CA", "cs.LG", "math.MG"], "comment": null, "summary": "The Hausdorff dimension of a set can be detected using the Riesz energy.\nHere, we consider situations where a sequence of points, $\\{x_n\\}$, ``fills\nin'' a set $E \\subset \\mathbb{R}^d$ in an appropriate sense and investigate the\ndegree to which the discrete analog to the Riesz energy of these sets can be\nused to bound the Hausdorff dimension of $E$. We also discuss applications to\ndata science and Erd\\H{o}s/Falconer type problems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4f7f\u7528Riesz\u80fd\u91cf\u548c\u70b9\u5e8f\u5217\u586b\u5145\u6765\u4f30\u8ba1\u96c6\u5408\u7684Hausdorff\u7ef4\u6570\uff0c\u5e76\u5e94\u7528\u4e8e\u6570\u636e\u79d1\u5b66\u548cErd\u0151s/Falconer\u95ee\u9898\u3002", "motivation": "\u52a8\u673a\u662f\u5229\u7528Riesz\u80fd\u91cf\u68c0\u6d4bHausdorff\u7ef4\u6570\uff0c\u5e76\u7814\u7a76\u79bb\u6563\u6a21\u62df\u5728\u586b\u5145\u96c6\u5408\u65f6\u7684\u754c\u5b9a\u6f5c\u529b\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5206\u6790\u70b9\u5e8f\u5217\u586b\u5145\u96c6\u5408E\uff0c\u5e76\u4f7f\u7528\u79bb\u6563Riesz\u80fd\u91cf\u7684\u6a21\u62df\u6765\u8c03\u67e5\u7ef4\u6570\u754c\u5b9a\u3002", "result": "\u7ed3\u679c\u663e\u793a\u8fd9\u79cd\u65b9\u6cd5\u53ef\u7528\u4e8e\u754c\u5b9aHausdorff\u7ef4\u6570\uff0c\u5e76\u6269\u5c55\u5230\u6570\u636e\u79d1\u5b66\u548c\u76f8\u5173\u6570\u5b66\u95ee\u9898\u3002", "conclusion": "\u7ed3\u8bba\u662f\u79bb\u6563Riesz\u80fd\u91cf\u5728\u7ef4\u6570\u4f30\u8ba1\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2504.11304", "pdf": "https://arxiv.org/pdf/2504.11304", "abs": "https://arxiv.org/abs/2504.11304", "authors": ["Aditya Kulkarni", "Carlos Soto"], "title": "Differentially Private Geodesic and Linear Regression", "categories": ["stat.ML", "cs.LG"], "comment": "16 pages, 7 figures", "summary": "In statistical applications it has become increasingly common to encounter\ndata structures that live on non-linear spaces such as manifolds. Classical\nlinear regression, one of the most fundamental methodologies of statistical\nlearning, captures the relationship between an independent variable and a\nresponse variable which both are assumed to live in Euclidean space. Thus,\ngeodesic regression emerged as an extension where the response variable lives\non a Riemannian manifold. The parameters of geodesic regression, as with linear\nregression, capture the relationship of sensitive data and hence one should\nconsider the privacy protection practices of said parameters. We consider\nreleasing Differentially Private (DP) parameters of geodesic regression via the\nK-Norm Gradient (KNG) mechanism for Riemannian manifolds. We derive theoretical\nbounds for the sensitivity of the parameters showing they are tied to their\nrespective Jacobi fields and hence the curvature of the space. This\ncorroborates recent findings of differential privacy for the Fr\\'echet mean. We\ndemonstrate the efficacy of our methodology on the sphere,\n$\\mbS^2\\subset\\mbR^3$ and, since it is general to Riemannian manifolds, the\nmanifold of Euclidean space which simplifies geodesic regression to a case of\nlinear regression. Our methodology is general to any Riemannian manifold and\nthus it is suitable for data in domains such as medical imaging and computer\nvision.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u6269\u5c55\u4e86\u5fae\u5206\u9690\u79c1\u5230\u9ece\u66fc\u6d41\u5f62\u4e0a\u7684\u6d4b\u5730\u56de\u5f52\uff0c\u63d0\u4f9b\u654f\u611f\u5ea6\u754c\u548c\u5e94\u7528\u793a\u8303\u3002", "motivation": "\u52a8\u673a\u662f\u5904\u7406\u975e\u7ebf\u6027\u7a7a\u95f4\u6570\u636e\u65f6\u9700\u8981\u9690\u79c1\u4fdd\u62a4\uff0c\u7ecf\u5178\u7ebf\u6027\u56de\u5f52\u4e0d\u9002\u7528\u3002", "method": "\u65b9\u6cd5\u662f\u901a\u8fc7K-\u8303\u6570\u68af\u5ea6\u673a\u5236\u5728\u9ece\u66fc\u6d41\u5f62\u4e0a\u53d1\u5e03DP\u53c2\u6570\uff0c\u5e76\u63a8\u5bfc\u4e0e\u96c5\u53ef\u6bd4\u573a\u76f8\u5173\u7684\u654f\u611f\u5ea6\u754c\u3002", "result": "\u7ed3\u679c\uff1a\u5bfc\u51fa\u4e86\u654f\u611f\u5ea6\u7406\u8bba\u754c\uff0c\u5e76\u5728\u7403\u9762S^2\u548c\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u7ed3\u8bba\uff1a\u8be5\u65b9\u6cd5\u901a\u7528\u4e8e\u4efb\u4f55\u9ece\u66fc\u6d41\u5f62\uff0c\u9002\u7528\u4e8e\u533b\u7597\u6210\u50cf\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u7b49\u9886\u57df\u3002"}}
{"id": "2504.11318", "pdf": "https://arxiv.org/pdf/2504.11318", "abs": "https://arxiv.org/abs/2504.11318", "authors": ["Vishnu Iyer"], "title": "Mildly-Interacting Fermionic Unitaries are Efficiently Learnable", "categories": ["quant-ph", "cs.DS", "cs.LG"], "comment": "30 pages, 4 figures", "summary": "Recent work has shown that one can efficiently learn fermionic Gaussian\nunitaries, also commonly known as nearest-neighbor matchcircuits or\nnon-interacting fermionic unitaries. However, one could ask a similar question\nabout unitaries that are near Gaussian: for example, unitaries prepared with a\nsmall number of non-Gaussian circuit elements. These operators find\nsignificance in quantum chemistry and many-body physics, yet no algorithm\nexists to learn them.\n  We give the first such result by devising an algorithm which makes queries to\na $n$-mode fermionic unitary $U$ prepared by at most $O(t)$ non-Gaussian gates\nand returns a circuit approximating $U$ to diamond distance $\\varepsilon$ in\ntime $\\textrm{poly}(n,2^t,1/\\varepsilon)$. This resolves a central open\nquestion of Mele and Herasymenko under the strongest distance metric. In fact,\nour algorithm is much more general: we define a property of unitary Gaussianity\nknown as unitary Gaussian dimension and show that our algorithm can learn\n$n$-mode unitaries of Gaussian dimension at least $2n - O(t)$ in time\n$\\textrm{poly}(n,2^t,1/\\varepsilon)$. Indeed, this class subsumes unitaries\nprepared by at most $O(t)$ non-Gaussian gates but also includes several\nunitaries that require up to $2^{O(t)}$ non-Gaussian gates to construct.\n  In addition, we give a $\\textrm{poly}(n,1/\\varepsilon)$-time algorithm to\ndistinguish whether an $n$-mode unitary is of Gaussian dimension at least $k$\nor $\\varepsilon$-far from all such unitaries in Frobenius distance, promised\nthat one is the case. Along the way, we prove structural results about\nnear-Gaussian fermionic unitaries that are likely to be of independent\ninterest.", "AI": {"tldr": "\u8bba\u6587\u5f00\u53d1\u7b97\u6cd5\u5b66\u4e60\u8fd1\u4f3c\u9ad8\u65af fermionic \u5355\u5143\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u591a\u9879\u5f0f\uff0c\u5e76\u89e3\u51b3\u5f00\u653e\u95ee\u9898\u3002", "motivation": "\u9ad8\u65af\u5355\u5143\u5b66\u4e60\u5df2\u6709\u7b97\u6cd5\uff0c\u4f46\u8fd1\u4f3c\u9ad8\u65af\u5355\u5143\uff08\u5982\u5c11\u91cf\u975e\u9ad8\u65af\u95e8\u51c6\u5907\uff09\u65e0\u7b97\u6cd5\uff0c\u4e14\u5728\u91cf\u5b50\u5316\u5b66\u548c\u591a\u4f53\u7269\u7406\u4e2d\u91cd\u8981\u3002", "method": "\u7b97\u6cd5\u67e5\u8be2 n \u6a21\u5355\u5143\uff0c\u8fd4\u56de diamond \u8ddd\u79bb \u03b5 \u5185\u8fd1\u4f3c\u7535\u8def\uff0c\u590d\u6742\u5ea6 poly(n, 2^t, 1/\u03b5)\uff0c\u9002\u7528\u4e8e Gaussian dimension \u81f3\u5c11 2n - O(t) \u7684\u5355\u5143\u3002", "result": "\u9996\u6b21\u7ed9\u51fa\u5b66\u4e60\u7b97\u6cd5\uff0c\u89e3\u51b3 Mele \u548c Herasymenko \u95ee\u9898\uff1b\u63d0\u4f9b\u591a\u9879\u5f0f\u65f6\u95f4\u533a\u5206\u7b97\u6cd5\u3002", "conclusion": "\u7b97\u6cd5\u66f4\u901a\u7528\uff0c\u6db5\u76d6\u66f4\u5e7f\u5355\u5143\u7c7b\uff0c\u5e76\u8bc1\u660e\u7ed3\u6784\u7ed3\u679c\u3002"}}
{"id": "2504.11349", "pdf": "https://arxiv.org/pdf/2504.11349", "abs": "https://arxiv.org/abs/2504.11349", "authors": ["Yuezhe Yang", "Boyu Yang", "Yaqian Wang", "Yang He", "Xingbo Dong", "Zhe Jin"], "title": "Explicit and Implicit Representations in AI-based 3D Reconstruction for Radiology: A systematic literature review", "categories": ["cs.CV", "cs.AI", "cs.GR", "68T45", "I.4.5"], "comment": "43 pages, 5 figures, submit to Medical Image Analysis", "summary": "The demand for high-quality medical imaging in clinical practice and assisted\ndiagnosis has made 3D reconstruction in radiological imaging a key research\nfocus. Artificial intelligence (AI) has emerged as a promising approach to\nenhancing reconstruction accuracy while reducing acquisition and processing\ntime, thereby minimizing patient radiation exposure and discomfort and\nultimately benefiting clinical diagnosis. This review explores state-of-the-art\nAI-based 3D reconstruction algorithms in radiological imaging, categorizing\nthem into explicit and implicit approaches based on their underlying\nprinciples. Explicit methods include point-based, volume-based, and Gaussian\nrepresentations, while implicit methods encompass implicit prior embedding and\nneural radiance fields. Additionally, we examine commonly used evaluation\nmetrics and benchmark datasets. Finally, we discuss the current state of\ndevelopment, key challenges, and future research directions in this evolving\nfield. Our project available on: https://github.com/Bean-Young/AI4Med.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u63a2\u8ba8\u4e86\u57fa\u4e8eAI\u7684\u653e\u5c04\u5b66\u6210\u50cf3D\u91cd\u5efa\u7b97\u6cd5\uff0c\u5c06\u5176\u5206\u7c7b\u4e3a\u663e\u5f0f\u548c\u9690\u5f0f\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u8bc4\u4f30\u6307\u6807\u3001\u6570\u636e\u96c6\u3001\u5f53\u524d\u72b6\u6001\u3001\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u9ad8\u54c1\u8d28\u533b\u7597\u6210\u50cf\u7684\u9700\u6c42\u63a8\u52a8AI\u7528\u4e8e\u63d0\u9ad8\u91cd\u5efa\u51c6\u786e\u6027\u3001\u51cf\u5c11\u65f6\u95f4\u548c\u8f90\u5c04\u66b4\u9732\u3002", "method": "\u5206\u7c7bAI\u65b9\u6cd5\u4e3a\u663e\u5f0f\uff08\u70b9\u3001\u4f53\u79ef\u3001Gaussian\u8868\u793a\uff09\u548c\u9690\u5f0f\uff08\u9690\u5f0f\u5148\u9a8c\u5d4c\u5165\u3001\u795e\u7ecf\u8f90\u5c04\u573a\uff09\uff0c\u5e76\u5ba1\u67e5\u8bc4\u4f30\u6307\u6807\u548c\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "\u8ba8\u8bba\u4e86\u5f53\u524d\u53d1\u5c55\u72b6\u6001\u3001\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "AI\u5728\u533b\u7597\u6210\u50cf\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u9879\u76ee\u4ee3\u7801\u53ef\u5728GitHub\u4e0a\u83b7\u53d6\u3002"}}
{"id": "2504.11415", "pdf": "https://arxiv.org/pdf/2504.11415", "abs": "https://arxiv.org/abs/2504.11415", "authors": ["Nikolette Pedersen", "Regitze Sydendal", "Andreas Wulff", "Ralf Raumanns", "Eike Petersen", "Veronika Cheplygina"], "title": "Robustness and sex differences in skin cancer detection: logistic regression vs CNNs", "categories": ["cs.CV", "cs.LG"], "comment": "16 pages (excluding appendix), 2 figures (excluding appendix),\n  submitted to MIUA 2025 conference (response pending)", "summary": "Deep learning has been reported to achieve high performances in the detection\nof skin cancer, yet many challenges regarding the reproducibility of results\nand biases remain. This study is a replication (different data, same analysis)\nof a study on Alzheimer's disease [28] which studied robustness of logistic\nregression (LR) and convolutional neural networks (CNN) across patient sexes.\nWe explore sex bias in skin cancer detection, using the PAD-UFES-20 dataset\nwith LR trained on handcrafted features reflecting dermatological guidelines\n(ABCDE and the 7-point checklist), and a pre-trained ResNet-50 model. We\nevaluate these models in alignment with [28]: across multiple training datasets\nwith varied sex composition to determine their robustness. Our results show\nthat both the LR and the CNN were robust to the sex distributions, but the\nresults also revealed that the CNN had a significantly higher accuracy (ACC)\nand area under the receiver operating characteristics (AUROC) for male patients\nthan for female patients. We hope these findings to contribute to the growing\nfield of investigating potential bias in popular medical machine learning\nmethods. The data and relevant scripts to reproduce our results can be found in\nour Github.", "AI": {"tldr": "\u672c\u7814\u7a76\u590d\u5236\u4e86[28]\u7814\u7a76\uff0c\u63a2\u8ba8\u76ae\u80a4\u764c\u68c0\u6d4b\u4e2d\u6027\u522b\u504f\u7f6e\uff0c\u53d1\u73b0CNN\u5728\u7537\u6027\u60a3\u8005\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u76ae\u80a4\u764c\u68c0\u6d4b\u4e2d\u6027\u80fd\u9ad8\uff0c\u4f46\u5b58\u5728\u53ef\u91cd\u590d\u6027\u548c\u504f\u7f6e\u95ee\u9898\uff0c\u56e0\u6b64\u590d\u5236[28]\u7814\u7a76\u4ee5\u8bc4\u4f30\u6027\u522b\u504f\u7f6e\u3002", "method": "\u4f7f\u7528PAD-UFES-20\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u903b\u8f91\u56de\u5f52\uff08LR\uff09\u57fa\u4e8e\u624b\u5de5\u7279\u5f81\uff08ABCDE\u548c7\u70b9\u68c0\u67e5\u8868\uff09\u548cResNet-50 CNN\u6a21\u578b\uff0c\u5728\u4e0d\u540c\u6027\u522b\u5206\u5e03\u4e0b\u8bc4\u4f30\u9c81\u68d2\u6027\u3002", "result": "LR\u548cCNN\u5bf9\u6027\u522b\u5206\u5e03\u9c81\u68d2\uff0c\u4f46CNN\u5728\u7537\u6027\u60a3\u8005\u7684\u51c6\u786e\u6027\u548cAUROC\u663e\u8457\u9ad8\u4e8e\u5973\u6027\u60a3\u8005\u3002", "conclusion": "\u5e0c\u671b\u4e3a\u8c03\u67e5\u533b\u7597\u673a\u5668\u5b66\u4e60\u504f\u7f6e\u8d21\u732e\u529b\u91cf\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u91cd\u590d\u7684\u6570\u636e\u548c\u811a\u672c\u3002"}}
{"id": "2504.11358", "pdf": "https://arxiv.org/pdf/2504.11358", "abs": "https://arxiv.org/abs/2504.11358", "authors": ["Yupei Liu", "Yuqi Jia", "Jinyuan Jia", "Dawn Song", "Neil Zhenqiang Gong"], "title": "DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks", "categories": ["cs.CR", "cs.AI"], "comment": "To appear in IEEE Symposium on Security and Privacy, 2025", "summary": "LLM-integrated applications and agents are vulnerable to prompt injection\nattacks, where an attacker injects prompts into their inputs to induce\nattacker-desired outputs. A detection method aims to determine whether a given\ninput is contaminated by an injected prompt. However, existing detection\nmethods have limited effectiveness against state-of-the-art attacks, let alone\nadaptive ones. In this work, we propose DataSentinel, a game-theoretic method\nto detect prompt injection attacks. Specifically, DataSentinel fine-tunes an\nLLM to detect inputs contaminated with injected prompts that are strategically\nadapted to evade detection. We formulate this as a minimax optimization\nproblem, with the objective of fine-tuning the LLM to detect strong adaptive\nattacks. Furthermore, we propose a gradient-based method to solve the minimax\noptimization problem by alternating between the inner max and outer min\nproblems. Our evaluation results on multiple benchmark datasets and LLMs show\nthat DataSentinel effectively detects both existing and adaptive prompt\ninjection attacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDataSentinel\uff0c\u4e00\u79cd\u57fa\u4e8e\u6e38\u620f\u7406\u8bba\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4bLLM\u4e2d\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002", "motivation": "LLM\u96c6\u6210\u5e94\u7528\u6613\u53d7\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u73b0\u6709\u7684\u68c0\u6d4b\u65b9\u6cd5\u5bf9\u5148\u8fdb\u548c\u9002\u5e94\u6027\u653b\u51fb\u65e0\u6548\u3002", "method": "\u63d0\u51faDataSentinel\uff0c\u901a\u8fc7\u5fae\u8c03LLM\u5e76\u4f7f\u7528minimax\u4f18\u5316\u548c\u68af\u5ea6\u65b9\u6cd5\u6765\u68c0\u6d4b\u9002\u5e94\u6027\u653b\u51fb\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548cLLM\u4e0a\uff0cDataSentinel\u6709\u6548\u68c0\u6d4b\u73b0\u6709\u548c\u9002\u5e94\u6027\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002", "conclusion": "DataSentinel\u4e3a\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.11426", "pdf": "https://arxiv.org/pdf/2504.11426", "abs": "https://arxiv.org/abs/2504.11426", "authors": ["Xue Zhang", "Songming Zhang", "Yunlong Liang", "Fandong Meng", "Yufeng Chen", "Jinan Xu", "Jie Zhou"], "title": "A Dual-Space Framework for General Knowledge Distillation of Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "19 pages, 9 figures, 11 tables, under review. Code is available at:\n  https://github.com/songmzhang/DSKDv2. arXiv admin note: text overlap with\n  arXiv:2406.17328", "summary": "Knowledge distillation (KD) is a promising solution to compress large\nlanguage models (LLMs) by transferring their knowledge to smaller models.\nDuring this process, white-box KD methods usually minimize the distance between\nthe output distributions of the teacher model and the student model to transfer\nmore information. However, we reveal that the current white-box KD framework\nexhibits two limitations: a) bridging probability distributions from different\noutput spaces will limit the similarity between the teacher model and the\nstudent model; b) this framework cannot be applied to LLMs with different\nvocabularies. One of the root causes for these limitations is that the\ndistributions from the teacher and the student for KD are output by different\nprediction heads, which yield distributions in different output spaces and\ndimensions. Therefore, in this paper, we propose a dual-space knowledge\ndistillation (DSKD) framework that unifies the prediction heads of the teacher\nand the student models for KD. Specifically, we first introduce two projectors\nwith ideal initialization to project the teacher/student hidden states into the\nstudent/teacher representation spaces. After this, the hidden states from\ndifferent models can share the same head and unify the output spaces of the\ndistributions. Furthermore, we develop an exact token alignment (ETA) algorithm\nto align the same tokens in two differently-tokenized sequences. Based on the\nabove, our DSKD framework is a general KD framework that supports both\noff-policy and on-policy KD, and KD between any two LLMs regardless of their\nvocabularies. Extensive experiments on instruction-following, mathematical\nreasoning, and code generation benchmarks show that DSKD significantly\noutperforms existing methods based on the current white-box KD framework and\nsurpasses other cross-tokenizer KD methods for LLMs with different\nvocabularies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u53cc\u7a7a\u95f4\u77e5\u8bc6\u84b8\u998f\u6846\u67b6DSKD\uff0c\u89e3\u51b3\u4f20\u7edf\u767d\u76d2KD\u5728\u4e0d\u540c\u8f93\u51fa\u7a7a\u95f4\u548c\u8bcd\u6c47\u8868\u4e0b\u7684\u9650\u5236\uff0c\u5b9e\u9a8c\u663e\u793a\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u767d\u76d2KD\u6846\u67b6\u5b58\u5728\u8f93\u51fa\u7a7a\u95f4\u4e0d\u4e00\u81f4\u548c\u65e0\u6cd5\u5904\u7406\u4e0d\u540c\u8bcd\u6c47\u8868\u7684\u95ee\u9898\uff0c\u6839\u56e0\u662f\u6559\u5e08\u548c\u5b66\u751f\u6a21\u578b\u4f7f\u7528\u4e0d\u540c\u9884\u6d4b\u5934\u3002", "method": "\u63d0\u51faDSKD\u6846\u67b6\uff0c\u4f7f\u7528\u4e24\u4e2a\u6295\u5f71\u5668\u7edf\u4e00\u9690\u85cf\u72b6\u6001\u7a7a\u95f4\uff0c\u5e76\u5f00\u53d1\u7cbe\u786e\u6807\u8bb0\u5bf9\u9f50\u7b97\u6cd5ETA\uff0c\u652f\u6301\u4efb\u610fLLM\u95f4\u7684\u79bb\u7ebf\u548c\u5728\u7ebf\u77e5\u8bc6\u84b8\u998f\u3002", "result": "\u5b9e\u9a8c\u5728\u6307\u4ee4\u9075\u5faa\u3001\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u663e\u793a\uff0cDSKD\u4f18\u4e8e\u73b0\u6709\u767d\u76d2KD\u65b9\u6cd5\uff0c\u5e76\u5728\u4e0d\u540c\u8bcd\u6c47\u8868\u573a\u666f\u4e0b\u8d85\u8d8a\u5176\u4ed6\u8de8\u6807\u8bb0\u5668KD\u65b9\u6cd5\u3002", "conclusion": "DSKD\u662f\u4e00\u79cd\u901a\u7528\u6846\u67b6\uff0c\u53ef\u5904\u7406\u4efb\u610f\u8bcd\u6c47\u8868\u548c\u8f93\u51fa\u7a7a\u95f4\u7684LLM\u77e5\u8bc6\u84b8\u998f\uff0c\u63d0\u5347\u538b\u7f29\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2504.11431", "pdf": "https://arxiv.org/pdf/2504.11431", "abs": "https://arxiv.org/abs/2504.11431", "authors": ["Maria Teleki", "Xiangjue Dong", "Haoran Liu", "James Caverlee"], "title": "Masculine Defaults via Gendered Discourse in Podcasts and Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "cs.SI"], "comment": "To appear in ICWSM 2025", "summary": "Masculine defaults are widely recognized as a significant type of gender\nbias, but they are often unseen as they are under-researched. Masculine\ndefaults involve three key parts: (i) the cultural context, (ii) the masculine\ncharacteristics or behaviors, and (iii) the reward for, or simply acceptance\nof, those masculine characteristics or behaviors. In this work, we study\ndiscourse-based masculine defaults, and propose a twofold framework for (i) the\nlarge-scale discovery and analysis of gendered discourse words in spoken\ncontent via our Gendered Discourse Correlation Framework (GDCF); and (ii) the\nmeasurement of the gender bias associated with these gendered discourse words\nin LLMs via our Discourse Word-Embedding Association Test (D-WEAT). We focus\nour study on podcasts, a popular and growing form of social media, analyzing\n15,117 podcast episodes. We analyze correlations between gender and discourse\nwords -- discovered via LDA and BERTopic -- to automatically form gendered\ndiscourse word lists. We then study the prevalence of these gendered discourse\nwords in domain-specific contexts, and find that gendered discourse-based\nmasculine defaults exist in the domains of business, technology/politics, and\nvideo games. Next, we study the representation of these gendered discourse\nwords from a state-of-the-art LLM embedding model from OpenAI, and find that\nthe masculine discourse words have a more stable and robust representation than\nthe feminine discourse words, which may result in better system performance on\ndownstream tasks for men. Hence, men are rewarded for their discourse patterns\nwith better system performance by one of the state-of-the-art language models\n-- and this embedding disparity is a representational harm and a masculine\ndefault.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u8bdd\u8bed\u4e2d\u7684\u7537\u6027\u9ed8\u8ba4\u504f\u5dee\uff0c\u4f7f\u7528\u64ad\u5ba2\u6570\u636e\u548cLLM\uff0c\u53d1\u73b0\u6027\u522b\u504f\u5dee\u95ee\u9898\u3002", "motivation": "\u7537\u6027\u9ed8\u8ba4\u504f\u5dee\u88ab\u4f4e\u4f30\u4e14\u7814\u7a76\u4e0d\u8db3\uff0c\u5305\u62ec\u6587\u5316\u80cc\u666f\u3001\u7537\u6027\u7279\u5f81\u548c\u5956\u52b1\uff0c\u672c\u6587\u65e8\u5728\u63ed\u793a\u5176\u5f71\u54cd\u3002", "method": "\u63d0\u51faGDCF\u6846\u67b6\u901a\u8fc7LDA\u548cBERTopic\u5206\u679015,117\u4e2a\u64ad\u5ba2\u5267\u96c6\u53d1\u73b0\u6027\u522b\u5316\u8bdd\u8bed\u8bcd\uff0c\u5e76\u4f7f\u7528D-WEAT\u6d4b\u91cfLLM\u4e2d\u7684\u6027\u522b\u504f\u5dee\u3002", "result": "\u5728\u5546\u4e1a\u3001\u6280\u672f/\u653f\u6cbb\u548c\u89c6\u9891\u6e38\u620f\u9886\u57df\u5b58\u5728\u6027\u522b\u5316\u8bdd\u8bed\uff1b\u7537\u6027\u8bdd\u8bed\u8bcd\u5728LLM\u4e2d\u8868\u793a\u66f4\u7a33\u5b9a\uff0c\u5bfc\u81f4\u7537\u6027\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u8fd9\u79cd\u5d4c\u5165\u5dee\u5f02\u662f\u4e00\u79cd\u8868\u5f81\u6027\u4f24\u5bb3\uff0c\u5e76\u4f53\u73b0\u4e86\u7537\u6027\u9ed8\u8ba4\u504f\u5dee\u3002"}}
{"id": "2504.11369", "pdf": "https://arxiv.org/pdf/2504.11369", "abs": "https://arxiv.org/abs/2504.11369", "authors": ["Lucio La Cava", "Andrea Tagarelli"], "title": "OpenTuringBench: An Open-Model-based Benchmark and Framework for Machine-Generated Text Detection and Attribution", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "physics.soc-ph"], "comment": "Under review with ARR", "summary": "Open Large Language Models (OLLMs) are increasingly leveraged in generative\nAI applications, posing new challenges for detecting their outputs. We propose\nOpenTuringBench, a new benchmark based on OLLMs, designed to train and evaluate\nmachine-generated text detectors on the Turing Test and Authorship Attribution\nproblems. OpenTuringBench focuses on a representative set of OLLMs, and\nfeatures a number of challenging evaluation tasks, including\nhuman/machine-manipulated texts, out-of-domain texts, and texts from previously\nunseen models. We also provide OTBDetector, a contrastive learning framework to\ndetect and attribute OLLM-based machine-generated texts. Results highlight the\nrelevance and varying degrees of difficulty of the OpenTuringBench tasks, with\nour detector achieving remarkable capabilities across the various tasks and\noutperforming most existing detectors. Resources are available on the\nOpenTuringBench Hugging Face repository at\nhttps://huggingface.co/datasets/MLNTeam-Unical/OpenTuringBench", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faOpenTuringBench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u68c0\u6d4b\u5f00\u653e\u5927\u578b\u8bed\u8a00\u6a21\u578b(OLLMs)\u751f\u6210\u6587\u672c\u7684\u6a21\u578b\uff0c\u5e76\u5f15\u5165OTBDetector\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "OLLMs\u5728\u751f\u6210AI\u5e94\u7528\u4e2d\u65e5\u76ca\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5e26\u6765\u4e86\u68c0\u6d4b\u5176\u8f93\u51fa\u7684\u65b0\u6311\u6218\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eOLLMs\u7684OpenTuringBench\u57fa\u51c6\u548cOTBDetector\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u56fe\u7075\u6d4b\u8bd5\u548c\u4f5c\u8005\u5f52\u5c5e\u95ee\u9898\u3002", "result": "OTBDetector\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u5927\u591a\u6570\u73b0\u6709\u68c0\u6d4b\u5668\uff0c\u5e76\u7a81\u663e\u57fa\u51c6\u4efb\u52a1\u7684\u76f8\u5173\u6027\u548c\u96be\u5ea6\u3002", "conclusion": "\u8bc1\u660e\u4e86OpenTuringBench\u548cOTBDetector\u7684\u6709\u6548\u6027\uff0c\u8d44\u6e90\u53ef\u5728Hugging Face\u4ed3\u5e93\u83b7\u53d6\u3002"}}
{"id": "2504.11436", "pdf": "https://arxiv.org/pdf/2504.11436", "abs": "https://arxiv.org/abs/2504.11436", "authors": ["Eleanor Wiske Dillon", "Sonia Jaffe", "Nicole Immorlica", "Christopher T. Stanton"], "title": "Shifting Work Patterns with Generative AI", "categories": ["econ.GN", "cs.LG", "q-fin.EC"], "comment": null, "summary": "We present evidence on how generative AI changes the work patterns of\nknowledge workers using data from a 6-month-long, cross-industry, randomized\nfield experiment. Half of the 6,000 workers in the study received access to a\ngenerative AI tool integrated into the applications they already used for\nemails, document creation, and meetings. We find that access to the AI tool\nduring the first year of its release primarily impacted behaviors that could be\nchanged independently and not behaviors that required coordination to change:\nworkers who used the tool spent 3 fewer hours, or 25% less time on email each\nweek (intent to treat estimate is 1.4 hours) and seemed to complete documents\nmoderately faster, but did not significantly change time spent in meetings.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u968f\u673a\u5b9e\u9a8c\u53d1\u73b0\uff0c\u751f\u6210\u5f0fAI\u5de5\u5177\u51cf\u5c11\u4e86\u77e5\u8bc6\u5de5\u4f5c\u8005\u5728\u90ae\u4ef6\u548c\u6587\u6863\u4e0a\u7684\u65f6\u95f4\uff0c\u4f46\u672a\u663e\u8457\u5f71\u54cd\u4f1a\u8bae\u65f6\u95f4\u3002", "motivation": "\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5982\u4f55\u6539\u53d8\u77e5\u8bc6\u5de5\u4f5c\u8005\u7684\u5de5\u4f5c\u6a21\u5f0f\u3002", "method": "\u91c7\u75286\u4e2a\u6708\u8de8\u884c\u4e1a\u968f\u673a\u573a\u5b9e\u9a8c\uff0c\u6d89\u53ca6000\u540d\u5de5\u4eba\uff0c\u4e00\u534a\u6709AI\u5de5\u5177\u8bbf\u95ee\uff0cAI\u6574\u5408\u5230\u90ae\u4ef6\u3001\u6587\u6863\u548c\u4f1a\u8bae\u5e94\u7528\u4e2d\u3002", "result": "\u4f7f\u7528AI\u5de5\u5177\u7684\u5de5\u4eba\u6bcf\u5468\u90ae\u4ef6\u65f6\u95f4\u51cf\u5c111.4\u5c0f\u65f6\uff0825%\uff09\uff0c\u6587\u6863\u5b8c\u6210\u66f4\u5feb\uff0c\u4f46\u4f1a\u8bae\u65f6\u95f4\u65e0\u663e\u8457\u53d8\u5316\u3002", "conclusion": "AI\u4e3b\u8981\u5f71\u54cd\u72ec\u7acb\u53ef\u6539\u53d8\u7684\u884c\u4e3a\uff0c\u800c\u975e\u9700\u8981\u534f\u8c03\u7684\u884c\u4e3a\u3002"}}
{"id": "2504.11442", "pdf": "https://arxiv.org/pdf/2504.11442", "abs": "https://arxiv.org/abs/2504.11442", "authors": ["Leon Guertler", "Bobby Cheng", "Simon Yu", "Bo Liu", "Leshem Choshen", "Cheston Tan"], "title": "TextArena", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "comment": "work in progress; 5 pages, 3 figures", "summary": "TextArena is an open-source collection of competitive text-based games for\ntraining and evaluation of agentic behavior in Large Language Models (LLMs). It\nspans 57+ unique environments (including single-player, two-player, and\nmulti-player setups) and allows for easy evaluation of model capabilities via\nan online-play system (against humans and other submitted models) with\nreal-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social\nskills such as negotiation, theory of mind, and deception, creating a gap that\nTextArena addresses. Designed with research, community and extensibility in\nmind, TextArena emphasizes ease of adding new games, adapting the framework,\ntesting models, playing against the models, and training models. Detailed\ndocumentation of environments, games, leaderboard, and examples are available\non https://github.com/LeonGuertler/TextArena and https://www.textarena.ai/.", "AI": {"tldr": "TextArena \u662f\u4e00\u4e2a\u5f00\u6e90\u6587\u672c\u6e38\u620f\u96c6\u5408\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u884c\u4e3a\uff0c\u5305\u62ec57+\u4e2a\u73af\u5883\uff0c\u652f\u6301\u5728\u7ebf\u5bf9\u6218\u548cTrueSkill\u8bc4\u5206\u3002", "motivation": "\u4f20\u7edf\u57fa\u51c6\u6d4b\u8bd5\u5f88\u5c11\u8bc4\u4f30\u52a8\u6001\u793e\u4ea4\u6280\u80fd\u5982\u8c08\u5224\u3001\u7406\u8bba\u5fc3\u667a\u548c\u6b3a\u9a97\uff0c\u56e0\u6b64\u9700\u8981TextArena\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u5305\u542b\u5355\u4eba\u3001\u53cc\u4eba\u3001\u591a\u4eba\u73af\u5883\u7684\u6e38\u620f\u6846\u67b6\uff0c\u652f\u6301\u5728\u7ebf\u5bf9\u6218\u7cfb\u7edf\u3001TrueSkill\u8bc4\u5206\uff0c\u5e76\u5f3a\u8c03\u6613\u6269\u5c55\u548c\u793e\u533a\u4f7f\u7528\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6613\u4e8e\u8bc4\u4f30\u6a21\u578b\u80fd\u529b\u7684\u5e73\u53f0\uff0c\u5177\u6709\u5728\u7ebf\u6392\u884c\u699c\u548c\u8be6\u7ec6\u6587\u6863\uff0c\u4fc3\u8fdb\u4e86LLM\u793e\u4ea4\u6280\u80fd\u7684\u6d4b\u8bd5\u3002", "conclusion": "TextArena \u65e8\u5728\u652f\u6301\u7814\u7a76\u548c\u793e\u533a\u6269\u5c55\uff0c\u63d0\u4f9b\u6e38\u620f\u73af\u5883\u3001\u6392\u884c\u699c\u548c\u793a\u4f8b\u7684\u6587\u6863\uff0c\u53ef\u901a\u8fc7GitHub\u548c\u7f51\u7ad9\u8bbf\u95ee\u3002"}}
{"id": "2504.11443", "pdf": "https://arxiv.org/pdf/2504.11443", "abs": "https://arxiv.org/abs/2504.11443", "authors": ["Eleanor Wiske Dillon", "Sonia Jaffe", "Sida Peng", "Alexia Cambon"], "title": "Early Impacts of M365 Copilot", "categories": ["econ.GN", "cs.LG", "q-fin.EC"], "comment": null, "summary": "Advances in generative AI have rapidly expanded the potential of computers to\nperform or assist in a wide array of tasks traditionally performed by humans.\nWe analyze a large, real-world randomized experiment of over 6,000 workers at\n56 firms to present some of the earliest evidence on how these technologies are\nchanging the way knowledge workers do their jobs. We find substantial time\nsavings on common core tasks across a wide range of industries and occupations:\nworkers who make use of this technology spent half an hour less reading email\neach week and completed documents 12% faster. Despite the newness of the\ntechnology, nearly 40% of workers who were given access to the tool used it\nregularly in their work throughout the 6-month study.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u901a\u8fc7\u968f\u673a\u5b9e\u9a8c\u663e\u793a\uff0c\u751f\u6210\u5f0fAI\u5e2e\u52a9\u77e5\u8bc6\u5de5\u4f5c\u8005\u8282\u7701\u65f6\u95f4\uff0c\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u63a2\u7a76\u751f\u6210\u5f0fAI\u5feb\u901f\u53d1\u5c55\u5bf9\u4eba\u7c7b\u5de5\u4f5c\u65b9\u5f0f\u7684\u5f71\u54cd\u3002", "method": "\u5bf956\u5bb6\u516c\u53f8\u7684\u8d85\u8fc76000\u540d\u5458\u5de5\u8fdb\u884c\u5927\u578b\u771f\u5b9e\u4e16\u754c\u968f\u673a\u5b9e\u9a8c\u5206\u6790\u3002", "result": "\u4f7f\u7528AI\u540e\uff0c\u5458\u5de5\u6bcf\u5468\u9605\u8bfb\u90ae\u4ef6\u8282\u770130\u5206\u949f\uff0c\u6587\u6863\u5b8c\u6210\u901f\u5ea6\u63d0\u9ad812%\uff1b\u8fd140%\u7684\u5458\u5de5\u57286\u4e2a\u6708\u5185\u5b9a\u671f\u4f7f\u7528\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u663e\u8457\u63d0\u5347\u4e86\u5de5\u4f5c\u6548\u7387\uff0c\u5e76\u663e\u793a\u51fa\u8f83\u9ad8\u7684\u91c7\u7528\u7387\u3002"}}
{"id": "2504.11389", "pdf": "https://arxiv.org/pdf/2504.11389", "abs": "https://arxiv.org/abs/2504.11389", "authors": ["Kevin Xie", "Amirmojtaba Sabour", "Jiahui Huang", "Despoina Paschalidou", "Greg Klar", "Umar Iqbal", "Sanja Fidler", "Xiaohui Zeng"], "title": "VideoPanda: Video Panoramic Diffusion with Multi-view Attention", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "Project website at\n  https://research-staging.nvidia.com/labs/toronto-ai/VideoPanda/", "summary": "High resolution panoramic video content is paramount for immersive\nexperiences in Virtual Reality, but is non-trivial to collect as it requires\nspecialized equipment and intricate camera setups. In this work, we introduce\nVideoPanda, a novel approach for synthesizing 360$^\\circ$ videos conditioned on\ntext or single-view video data. VideoPanda leverages multi-view attention\nlayers to augment a video diffusion model, enabling it to generate consistent\nmulti-view videos that can be combined into immersive panoramic content.\nVideoPanda is trained jointly using two conditions: text-only and single-view\nvideo, and supports autoregressive generation of long-videos. To overcome the\ncomputational burden of multi-view video generation, we randomly subsample the\nduration and camera views used during training and show that the model is able\nto gracefully generalize to generating more frames during inference. Extensive\nevaluations on both real-world and synthetic video datasets demonstrate that\nVideoPanda generates more realistic and coherent 360$^\\circ$ panoramas across\nall input conditions compared to existing methods. Visit the project website at\nhttps://research-staging.nvidia.com/labs/toronto-ai/VideoPanda/ for results.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVideoPanda\u65b9\u6cd5\uff0c\u901a\u8fc7\u6587\u672c\u6216\u5355\u89c6\u56fe\u89c6\u9891\u5408\u6210\u9ad8\u8d28\u91cf360\u5ea6\u5168\u666f\u89c6\u9891\u3002", "motivation": "\u9ad8\u5206\u8fa8\u7387\u5168\u666f\u89c6\u9891\u91c7\u96c6\u56f0\u96be\uff0c\u9700\u8981\u4e13\u7528\u8bbe\u5907\uff0c\u672c\u6587\u65e8\u5728\u7b80\u5316\u5408\u6210\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u591a\u89c6\u56fe\u6ce8\u610f\u529b\u5c42\u589e\u5f3a\u89c6\u9891\u6269\u6563\u6a21\u578b\uff0c\u8054\u5408\u8bad\u7ec3\u6587\u672c\u548c\u5355\u89c6\u56fe\u6761\u4ef6\uff0c\u652f\u6301\u81ea\u56de\u5f52\u957f\u89c6\u9891\u751f\u6210\uff0c\u5e76\u901a\u8fc7\u968f\u673a\u91c7\u6837\u51cf\u5c11\u8ba1\u7b97\u8d1f\u62c5\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u751f\u6210\u66f4\u771f\u5b9e\u3001\u66f4\u8fde\u8d2f\u7684360\u5ea6\u5168\u666f\u89c6\u9891\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "VideoPanda\u6709\u6548\u63d0\u5347\u4e86360\u5ea6\u89c6\u9891\u5408\u6210\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002"}}
{"id": "2504.11406", "pdf": "https://arxiv.org/pdf/2504.11406", "abs": "https://arxiv.org/abs/2504.11406", "authors": ["Felipe Crispim Salvagnini", "Jancarlo F. Gomes", "Cid A. N. Santos", "Silvio Jamil F. Guimar\u00e3es", "Alexandre X. Falc\u00e3o"], "title": "Multi-level Cellular Automata for FLIM networks", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The necessity of abundant annotated data and complex network architectures\npresents a significant challenge in deep-learning Salient Object Detection\n(deep SOD) and across the broader deep-learning landscape. This challenge is\nparticularly acute in medical applications in developing countries with limited\ncomputational resources. Combining modern and classical techniques offers a\npath to maintaining competitive performance while enabling practical\napplications. Feature Learning from Image Markers (FLIM) methodology empowers\nexperts to design convolutional encoders through user-drawn markers, with\nfilters learned directly from these annotations. Recent findings demonstrate\nthat coupling a FLIM encoder with an adaptive decoder creates a flyweight\nnetwork suitable for SOD, requiring significantly fewer parameters than\nlightweight models and eliminating the need for backpropagation. Cellular\nAutomata (CA) methods have proven successful in data-scarce scenarios but\nrequire proper initialization -- typically through user input, priors, or\nrandomness. We propose a practical intersection of these approaches: using FLIM\nnetworks to initialize CA states with expert knowledge without requiring user\ninteraction for each image. By decoding features from each level of a FLIM\nnetwork, we can initialize multiple CAs simultaneously, creating a multi-level\nframework. Our method leverages the hierarchical knowledge encoded across\ndifferent network layers, merging multiple saliency maps into a high-quality\nfinal output that functions as a CA ensemble. Benchmarks across two challenging\nmedical datasets demonstrate the competitiveness of our multi-level CA approach\ncompared to established models in the deep SOD literature.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408FLIM\u548cCA\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u8d44\u6e90\u6709\u9650\u7684\u533b\u7597\u5e94\u7528\u4e2d\u8fdb\u884c\u663e\u8457\u5bf9\u8c61\u68c0\u6d4b\uff0c\u51cf\u5c11\u4e86\u5bf9\u6807\u6ce8\u6570\u636e\u548c\u590d\u6742\u7f51\u7edc\u7684\u9700\u6c42\u3002", "motivation": "\u6df1\u5c42\u5b66\u4e60\u663e\u8457\u5bf9\u8c61\u68c0\u6d4b\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u548c\u590d\u6742\u7f51\u7edc\u67b6\u6784\uff0c\u5c24\u5176\u5728\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u7684\u53d1\u5c55\u4e2d\u56fd\u5bb6\u533b\u7597\u5e94\u7528\u4e2d\uff0c\u8fd9\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u7ed3\u5408\u73b0\u4ee3\u548c\u7ecf\u5178\u6280\u672f\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u6027\u80fd\u548c\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4f7f\u7528FLIM\u7f51\u7edc\u521d\u59cb\u5316CA\u72b6\u6001\uff0c\u901a\u8fc7\u4eceFLIM\u7f51\u7edc\u4e0d\u540c\u5c42\u89e3\u7801\u7279\u5f81\u6765\u540c\u65f6\u521d\u59cb\u5316\u591a\u4e2aCA\uff0c\u5f62\u6210\u591a\u5c42\u6846\u67b6\uff0c\u5e76\u5408\u5e76\u591a\u4e2a\u663e\u8457\u6027\u56fe\u751f\u6210\u6700\u7ec8\u8f93\u51fa\u3002", "result": "\u5728\u4e24\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u533b\u7597\u6570\u636e\u96c6\u4e0a\u7684\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u8be5\u591a\u5c42CA\u65b9\u6cd5\u4e0e\u73b0\u6709\u6df1\u5c42SOD\u6a21\u578b\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\uff0c\u4f7f\u7528\u66f4\u5c11\u53c2\u6570\u4e14\u65e0\u9700\u53cd\u5411\u4f20\u64ad\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bc1\u660e\u4e86\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\uff0c\u4f7f\u7528\u4e13\u5bb6\u77e5\u8bc6\u521d\u59cb\u5316CA\u53ef\u4ee5\u83b7\u5f97\u9ad8\u8d28\u91cf\u7684\u663e\u8457\u5bf9\u8c61\u68c0\u6d4b\u7ed3\u679c\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u53ef\u5b9e\u8df5\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.11423", "pdf": "https://arxiv.org/pdf/2504.11423", "abs": "https://arxiv.org/abs/2504.11423", "authors": ["Dazhong Shen", "Guanglu Song", "Yi Zhang", "Bingqi Ma", "Lujundong Li", "Dongzhi Jiang", "Zhuofan Zong", "Yu Liu"], "title": "ADT: Tuning Diffusion Models with Adversarial Supervision", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diffusion models have achieved outstanding image generation by reversing a\nforward noising process to approximate true data distributions. During\ntraining, these models predict diffusion scores from noised versions of true\nsamples in a single forward pass, while inference requires iterative denoising\nstarting from white noise. This training-inference divergences hinder the\nalignment between inference and training data distributions, due to potential\nprediction biases and cumulative error accumulation. To address this problem,\nwe propose an intuitive but effective fine-tuning framework, called Adversarial\nDiffusion Tuning (ADT), by stimulating the inference process during\noptimization and aligning the final outputs with training data by adversarial\nsupervision. Specifically, to achieve robust adversarial training, ADT features\na siamese-network discriminator with a fixed pre-trained backbone and\nlightweight trainable parameters, incorporates an image-to-image sampling\nstrategy to smooth discriminative difficulties, and preserves the original\ndiffusion loss to prevent discriminator hacking. In addition, we carefully\nconstrain the backward-flowing path for back-propagating gradients along the\ninference path without incurring memory overload or gradient explosion.\nFinally, extensive experiments on Stable Diffusion models (v1.5, XL, and v3),\ndemonstrate that ADT significantly improves both distribution alignment and\nimage quality.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faAdversarial Diffusion Tuning (ADT)\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u7ec6\u8c03\u6269\u6563\u6a21\u578b\uff0c\u6539\u5584\u8bad\u7ec3\u548c\u63a8\u7406\u5206\u5e03\u5bf9\u9f50\u95ee\u9898\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u5206\u6b67\u5bfc\u81f4\u9884\u6d4b\u504f\u5dee\u548c\u7d2f\u79ef\u9519\u8bef\uff0c\u963b\u788d\u6570\u636e\u5206\u5e03\u5bf9\u9f50\u3002", "method": "\u63d0\u51faADT\u6846\u67b6\uff0c\u4f7f\u7528siamese-network\u9274\u522b\u5668\u3001image-to-image\u91c7\u6837\u7b56\u7565\u3001\u4fdd\u7559\u539f\u59cbdiffusion loss\uff0c\u5e76\u7ea6\u675f\u68af\u5ea6\u56de\u4f20\u8def\u5f84\u3002", "result": "\u5728Stable Diffusion\u6a21\u578b\uff08v1.5\u3001XL\u3001v3\uff09\u4e0a\u7684\u5b9e\u9a8c\u663e\u793aADT\u663e\u8457\u63d0\u5347\u5206\u5e03\u5bf9\u9f50\u548c\u56fe\u50cf\u8d28\u91cf\u3002", "conclusion": "ADT\u901a\u8fc7\u523a\u6fc0\u63a8\u7406\u8fc7\u7a0b\u548c\u5bf9\u6297\u76d1\u7763\u6709\u6548\u6539\u5584\u6269\u6563\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2504.11440", "pdf": "https://arxiv.org/pdf/2504.11440", "abs": "https://arxiv.org/abs/2504.11440", "authors": ["Lennart Sch\u00e4permeier"], "title": "Greedy Restart Schedules: A Baseline for Dynamic Algorithm Selection on Numerical Black-box Optimization Problems", "categories": ["math.OC", "cs.AI"], "comment": "Author version. Accepted as full paper to be presented at the GECCO\n  2025 conference, July 14-18, M\\'alaga, Spain. (DOI 10.1145/3712256.3726408)", "summary": "In many optimization domains, there are multiple different solvers that\ncontribute to the overall state-of-the-art, each performing better on some, and\nworse on other types of problem instances. Meta-algorithmic approaches, such as\ninstance-based algorithm selection, configuration and scheduling, aim to close\nthis gap by extracting the most performance possible from a set of\n(configurable) optimizers. In this context, the best performing individual\nalgorithms are often hand-crafted hybrid heuristics which perform many restarts\nof fast local optimization approaches. However, data-driven techniques to\ncreate optimized restart schedules have not yet been extensively studied.\n  Here, we present a simple scheduling approach that iteratively selects the\nalgorithm performing best on the distribution of unsolved training problems at\ntime of selection, resulting in a problem-independent solver schedule. We\ndemonstrate our approach using well-known optimizers from numerical black-box\noptimization on the BBOB testbed, bridging much of the gap between single and\nvirtual best solver from the original portfolio across various evaluation\nprotocols. Our greedy restart schedule presents a powerful baseline for more\ncomplex dynamic algorithm selection models.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8d2a\u5a6a\u91cd\u542f\u8c03\u5ea6\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u9009\u62e9\u6700\u4f73\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4f18\u5316\u6027\u80fd\uff0c\u5e76\u5728BBOB\u6d4b\u8bd5\u53f0\u4e0a\u63a5\u8fd1\u865a\u62df\u6700\u4f73\u6c42\u89e3\u5668\u3002", "motivation": "\u4f18\u5316\u9886\u57df\u5b58\u5728\u591a\u79cd\u6c42\u89e3\u5668\uff0c\u5404\u6709\u4f18\u52a3\uff0c\u5143\u7b97\u6cd5\u65b9\u6cd5\u65e8\u5728\u901a\u8fc7\u7b97\u6cd5\u9009\u62e9\u548c\u8c03\u5ea6\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u6570\u636e\u9a71\u52a8\u7684\u91cd\u542f\u8c03\u5ea6\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u7b80\u5355\u8c03\u5ea6\u65b9\u6cd5\uff0c\u8fed\u4ee3\u9009\u62e9\u5728\u672a\u89e3\u51b3\u95ee\u9898\u5206\u5e03\u4e0a\u8868\u73b0\u6700\u597d\u7684\u7b97\u6cd5\uff0c\u5f62\u6210\u95ee\u9898\u65e0\u5173\u7684\u8d2a\u5a6a\u91cd\u542f\u8c03\u5ea6\u3002", "result": "\u5728BBOB\u6d4b\u8bd5\u53f0\u4e0a\uff0c\u4f7f\u7528\u6570\u503c\u9ed1\u7bb1\u4f18\u5316\u6c42\u89e3\u5668\uff0c\u663e\u8457\u7f29\u5c0f\u5355\u4e00\u548c\u865a\u62df\u6700\u4f73\u6c42\u89e3\u5668\u5dee\u8ddd\uff0c\u5728\u591a\u79cd\u8bc4\u4f30\u534f\u8bae\u4e0b\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u66f4\u590d\u6742\u7684\u52a8\u6001\u7b97\u6cd5\u9009\u62e9\u6a21\u578b\u63d0\u4f9b\u5f3a\u5927\u57fa\u7ebf\u3002"}}
{"id": "2504.11456", "pdf": "https://arxiv.org/pdf/2504.11456", "abs": "https://arxiv.org/abs/2504.11456", "authors": ["Zhiwei He", "Tian Liang", "Jiahao Xu", "Qiuzhi Liu", "Xingyu Chen", "Yue Wang", "Linfeng Song", "Dian Yu", "Zhenwen Liang", "Wenxuan Wang", "Zhuosheng Zhang", "Rui Wang", "Zhaopeng Tu", "Haitao Mi", "Dong Yu"], "title": "DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and Verifiable Mathematical Dataset for Advancing Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "WIP", "summary": "The capacity for complex mathematical reasoning is a key benchmark for\nartificial intelligence. While reinforcement learning (RL) applied to LLMs\nshows promise, progress is significantly hindered by the lack of large-scale\ntraining data that is sufficiently challenging, possesses verifiable answer\nformats suitable for RL, and is free from contamination with evaluation\nbenchmarks. To address these limitations, we introduce DeepMath-103K, a new,\nlarge-scale dataset comprising approximately 103K mathematical problems,\nspecifically designed to train advanced reasoning models via RL. DeepMath-103K\nis curated through a rigorous pipeline involving source analysis, stringent\ndecontamination against numerous benchmarks, and filtering for high difficulty\n(primarily Levels 5-9), significantly exceeding existing open resources in\nchallenge. Each problem includes a verifiable final answer, enabling rule-based\nRL, and three distinct R1-generated solutions suitable for diverse training\nparadigms like supervised fine-tuning or distillation. Spanning a wide range of\nmathematical topics, DeepMath-103K promotes the development of generalizable\nreasoning. We demonstrate that models trained on DeepMath-103K achieve\nsignificant improvements on challenging mathematical benchmarks, validating its\neffectiveness. We release DeepMath-103K publicly to facilitate community\nprogress in building more capable AI reasoning systems:\nhttps://github.com/zwhe99/DeepMath.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f15\u5165DeepMath-103K\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3AI\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\uff0c\u5e94\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u8fdb\u5c55\u7f13\u6162\uff0c\u4e3b\u8981\u662f\u7531\u4e8e\u7f3a\u4e4f\u5927\u89c4\u6a21\u3001\u5177\u6709\u6311\u6218\u6027\u3001\u53ef\u9a8c\u8bc1\u7b54\u6848\u683c\u5f0f\u4e14\u65e0\u8bc4\u4f30\u57fa\u51c6\u6c61\u67d3\u7684\u8bad\u7ec3\u6570\u636e\u3002", "method": "\u901a\u8fc7\u6765\u6e90\u5206\u6790\u3001\u4e25\u683c\u53bb\u6c61\u67d3\u5904\u7406\u3001\u9ad8\u96be\u5ea6\u95ee\u9898\u8fc7\u6ee4\uff08\u4e3b\u89815-9\u7ea7\uff09\u3001\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7b54\u6848\u548c\u4e09\u79cdR1\u751f\u6210\u89e3\u51b3\u65b9\u6848\u7684\u7ba1\u9053\u6765\u6784\u5efa\u6570\u636e\u96c6\u3002", "result": "\u5728DeepMath-103K\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u6570\u636e\u96c6\u516c\u5f00\u53d1\u5e03\uff0c\u4ee5\u4fc3\u8fdb\u793e\u533a\u6784\u5efa\u66f4\u5f3aAI\u63a8\u7406\u7cfb\u7edf\u3002"}}
