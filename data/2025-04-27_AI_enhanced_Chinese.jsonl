{"id": "2504.16937", "pdf": "https://arxiv.org/pdf/2504.16937", "abs": "https://arxiv.org/abs/2504.16937", "authors": ["Ariel S. Kapusta", "David Jin", "Peter M. Teague", "Robert A. Houston", "Jonathan B. Elliott", "Grace Y. Park", "Shelby S. Holdren"], "title": "A Framework for the Assurance of AI-Enabled Systems", "categories": ["cs.AI"], "comment": "12 pages, 2 figures, published in conference proceedings of SPIE\n  Defense and Commercial Sensing conference on Assurance and Security for\n  AI-enabled Systems 2025", "summary": "The United States Department of Defense (DOD) looks to accelerate the\ndevelopment and deployment of AI capabilities across a wide spectrum of defense\napplications to maintain strategic advantages. However, many common features of\nAI algorithms that make them powerful, such as capacity for learning,\nlarge-scale data ingestion, and problem-solving, raise new technical, security,\nand ethical challenges. These challenges may hinder adoption due to uncertainty\nin development, testing, assurance, processes, and requirements.\nTrustworthiness through assurance is essential to achieve the expected value\nfrom AI.\n  This paper proposes a claims-based framework for risk management and\nassurance of AI systems that addresses the competing needs for faster\ndeployment, successful adoption, and rigorous evaluation. This framework\nsupports programs across all acquisition pathways provide grounds for\nsufficient confidence that an AI-enabled system (AIES) meets its intended\nmission goals without introducing unacceptable risks throughout its lifecycle.\nThe paper's contributions are a framework process for AI assurance, a set of\nrelevant definitions to enable constructive conversations on the topic of AI\nassurance, and a discussion of important considerations in AI assurance. The\nframework aims to provide the DOD a robust yet efficient mechanism for swiftly\nfielding effective AI capabilities without overlooking critical risks or\nundermining stakeholder trust.", "AI": {"tldr": "This paper proposes a claims-based framework for AI assurance in the DOD to balance rapid deployment with risk management.", "motivation": "The DOD aims to accelerate AI development but faces challenges like technical, security, and ethical issues that hinder adoption, necessitating trustworthiness.", "method": "Proposes a claims-based framework including a process for AI assurance, relevant definitions, and key considerations.", "result": "Provides a mechanism for faster AI deployment with rigorous evaluation and risk management, ensuring mission goals are met without unacceptable risks.", "conclusion": "The framework offers an efficient way for the DOD to field AI capabilities while maintaining trust and minimizing risks."}}
{"id": "2504.16938", "pdf": "https://arxiv.org/pdf/2504.16938", "abs": "https://arxiv.org/abs/2504.16938", "authors": ["Lucas Carr", "Nicholas Leisegang", "Thomas Meyer", "Sergei Obiedkov"], "title": "Rational Inference in Formal Concept Analysis", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Defeasible conditionals are a form of non-monotonic inference which enable\nthe expression of statements like \"if $\\phi$ then normally $\\psi$\". The KLM\nframework defines a semantics for the propositional case of defeasible\nconditionals by construction of a preference ordering over possible worlds. The\npattern of reasoning induced by these semantics is characterised by consequence\nrelations satisfying certain desirable properties of non-monotonic reasoning.\nIn FCA, implications are used to describe dependencies between attributes.\nHowever, these implications are unsuitable to reason with erroneous data or\ndata prone to exceptions. Until recently, the topic of non-monotonic inference\nin FCA has remained largely uninvestigated. In this paper, we provide a\nconstruction of the KLM framework for defeasible reasoning in FCA and show that\nthis construction remains faithful to the principle of non-monotonic inference\ndescribed in the original framework. We present an additional argument that,\nwhile remaining consistent with the original ideas around non-monotonic\nreasoning, the defeasible reasoning we propose in FCA offers a more contextual\nview on inference, providing the ability for more relevant conclusions to be\ndrawn when compared to the propositional case.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5c06KLM\u6846\u67b6\u7684\u975e\u5355\u8c03\u63a8\u7406\u5e94\u7528\u4e8e\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\uff0c\u4ee5\u5904\u7406\u5f02\u5e38\u6570\u636e\uff0c\u5e76\u8bc1\u660e\u5176\u5fe0\u5b9e\u4e8e\u539f\u6846\u67b6\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u4e0a\u4e0b\u6587\u5316\u7684\u63a8\u7406\u3002", "motivation": "\u6807\u51c6FCA\u4e2d\u7684\u8574\u6db5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u9519\u8bef\u6216\u5f02\u5e38\u6570\u636e\uff0c\u975e\u5355\u8c03\u63a8\u7406\u5728FCA\u4e2d\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u56e0\u6b64\u9700\u8981\u5f15\u5165KLM\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5728FCA\u4e2d\u6784\u5efaKLM\u6846\u67b6\u7684\u7ed3\u6784\u3002", "result": "\u8be5\u6784\u5efa\u5fe0\u5b9e\u4e8e\u539fKLM\u6846\u67b6\u7684\u539f\u5219\uff0c\u5e76\u5728FCA\u4e2d\u5b9e\u73b0\u66f4\u4e0a\u4e0b\u6587\u5316\u7684\u63a8\u7406\uff0c\u5141\u8bb8\u5f97\u51fa\u66f4\u76f8\u5173\u7684\u7ed3\u8bba\u3002", "conclusion": "FCA\u4e2d\u7684\u975e\u5355\u8c03\u63a8\u7406\u6bd4\u547d\u9898\u903b\u8f91\u66f4\u9002\u5408\u5904\u7406\u5b9e\u9645\u5f02\u5e38\uff0c\u63d0\u4f9b\u66f4\u76f8\u5173\u548c\u4e0a\u4e0b\u6587\u5316\u7684\u63a8\u7406\u7ed3\u679c\u3002"}}
{"id": "2504.16939", "pdf": "https://arxiv.org/pdf/2504.16939", "abs": "https://arxiv.org/abs/2504.16939", "authors": ["Emre Can Acikgoz", "Cheng Qian", "Hongru Wang", "Vardhan Dongre", "Xiusi Chen", "Heng Ji", "Dilek Hakkani-T\u00fcr", "Gokhan Tur"], "title": "A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have propelled conversational\nAI from traditional dialogue systems into sophisticated agents capable of\nautonomous actions, contextual awareness, and multi-turn interactions with\nusers. Yet, fundamental questions about their capabilities, limitations, and\npaths forward remain open. This survey paper presents a desideratum for\nnext-generation Conversational Agents - what has been achieved, what challenges\npersist, and what must be done for more scalable systems that approach\nhuman-level intelligence. To that end, we systematically analyze LLM-driven\nConversational Agents by organizing their capabilities into three primary\ndimensions: (i) Reasoning - logical, systematic thinking inspired by human\nintelligence for decision making, (ii) Monitor - encompassing self-awareness\nand user interaction monitoring, and (iii) Control - focusing on tool\nutilization and policy following. Building upon this, we introduce a novel\ntaxonomy by classifying recent work on Conversational Agents around our\nproposed desideratum. We identify critical research gaps and outline key\ndirections, including realistic evaluations, long-term multi-turn reasoning\nskills, self-evolution capabilities, collaborative and multi-agent task\ncompletion, personalization, and proactivity. This work aims to provide a\nstructured foundation, highlight existing limitations, and offer insights into\npotential future research directions for Conversational Agents, ultimately\nadvancing progress toward Artificial General Intelligence (AGI). We maintain a\ncurated repository of papers at:\nhttps://github.com/emrecanacikgoz/awesome-conversational-agents.", "AI": {"tldr": "This survey paper analyzes LLM-driven Conversational Agents, organizing capabilities into reasoning, monitoring, and control dimensions, and identifies future research directions.", "motivation": "To address open questions about capabilities, limitations, and paths forward for Conversational Agents, aiming to advance towards human-level intelligence and AGI.", "method": "Systematically analyzing agents by defining three dimensions (Reasoning, Monitor, Control), introducing a taxonomy, classifying recent work, and identifying research gaps.", "result": "Identified critical gaps and key directions including realistic evaluations, long-term reasoning, self-evolution, collaborative tasks, personalization, and proactivity.", "conclusion": "Provides a structured foundation, highlights limitations, and offers insights for advancing towards AGI."}}
{"id": "2504.17006", "pdf": "https://arxiv.org/pdf/2504.17006", "abs": "https://arxiv.org/abs/2504.17006", "authors": ["Jalal Arabneydi", "Saiful Islam", "Srijita Das", "Sai Krishna Gottipati", "William Duguay", "Cloderic Mars", "Matthew E. Taylor", "Matthew Guzdial", "Antoine Fagette", "Younes Zerouali"], "title": "A Systematic Approach to Design Real-World Human-in-the-Loop Deep Reinforcement Learning: Salient Features, Challenges and Trade-offs", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": "This is a result of the collaboration by JACOBB, AMII(Alberta Machine\n  Intelligence Institute), Thales and AI Redefined (AIR) in 2021-2023", "summary": "With the growing popularity of deep reinforcement learning (DRL),\nhuman-in-the-loop (HITL) approach has the potential to revolutionize the way we\napproach decision-making problems and create new opportunities for human-AI\ncollaboration. In this article, we introduce a novel multi-layered hierarchical\nHITL DRL algorithm that comprises three types of learning: self learning,\nimitation learning and transfer learning. In addition, we consider three forms\nof human inputs: reward, action and demonstration. Furthermore, we discuss main\nchallenges, trade-offs and advantages of HITL in solving complex problems and\nhow human information can be integrated in the AI solution systematically. To\nverify our technical results, we present a real-world unmanned aerial vehicles\n(UAV) problem wherein a number of enemy drones attack a restricted area. The\nobjective is to design a scalable HITL DRL algorithm for ally drones to\nneutralize the enemy drones before they reach the area. To this end, we first\nimplement our solution using an award-winning open-source HITL software called\nCogment. We then demonstrate several interesting results such as (a) HITL leads\nto faster training and higher performance, (b) advice acts as a guiding\ndirection for gradient methods and lowers variance, and (c) the amount of\nadvice should neither be too large nor too small to avoid over-training and\nunder-training. Finally, we illustrate the role of human-AI cooperation in\nsolving two real-world complex scenarios, i.e., overloaded and decoy attacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u591a\u5c42\u7ea7\u4eba\u673a\u4ea4\u4e92\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u65e0\u4eba\u673a\u573a\u666f\u9a8c\u8bc1\u5176\u5728\u51b3\u7b56\u95ee\u9898\u4e2d\u7684\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6d41\u884c\uff0c\u4eba\u673a\u4ea4\u4e92\u65b9\u6cd5\u53ef\u9769\u65b0\u51b3\u7b56\u65b9\u5f0f\u5e76\u4fc3\u8fdb\u4eba\u673a\u5408\u4f5c\u3002", "method": "\u63d0\u51fa\u65b0\u578b\u591a\u5c42\u7ea7\u5206\u5c42\u4eba\u673a\u4ea4\u4e92DRL\u7b97\u6cd5\uff0c\u5305\u62ec\u81ea\u5b66\u4e60\u3001\u6a21\u4eff\u5b66\u4e60\u548c\u8f6c\u79fb\u5b66\u4e60\uff0c\u5e76\u6574\u5408\u5956\u52b1\u3001\u52a8\u4f5c\u548c\u6f14\u793a\u4e09\u79cd\u4eba\u7c7b\u8f93\u5165\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u4eba\u673a\u4ea4\u4e92\u52a0\u901f\u8bad\u7ec3\u3001\u63d0\u5347\u6027\u80fd\uff0c\u5efa\u8bae\u4f5c\u4e3a\u68af\u5ea6\u6307\u5bfc\u964d\u4f4e\u65b9\u5dee\uff0c\u5efa\u8bae\u91cf\u9700\u9002\u4e2d\u907f\u514d\u8fc7\u62df\u5408\u6216\u6b20\u62df\u5408\u3002", "conclusion": "\u8ba8\u8bba\u4eba\u673a\u4ea4\u4e92\u5728\u590d\u6742\u95ee\u9898\u4e2d\u7684\u6311\u6218\u3001\u6743\u8861\u548c\u4f18\u52bf\uff0c\u5e76\u5c55\u793a\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u4eba\u673a\u5408\u4f5c\u7684\u4f5c\u7528\u3002"}}
{"id": "2504.16961", "pdf": "https://arxiv.org/pdf/2504.16961", "abs": "https://arxiv.org/abs/2504.16961", "authors": ["Binon Teji", "Swarup Roy"], "title": "A Novel Graph Transformer Framework for Gene Regulatory Network Inference", "categories": ["cs.LG", "cs.ET", "q-bio.GN", "q-bio.MN", "q-bio.QM"], "comment": null, "summary": "The inference of gene regulatory networks (GRNs) is a foundational stride\ntowards deciphering the fundamentals of complex biological systems. Inferring a\npossible regulatory link between two genes can be formulated as a link\nprediction problem. Inference of GRNs via gene coexpression profiling data may\nnot always reflect true biological interactions, as its susceptibility to noise\nand misrepresenting true biological regulatory relationships. Most GRN\ninference methods face several challenges in the network reconstruction phase.\nTherefore, it is important to encode gene expression values, leverege the prior\nknowledge gained from the available inferred network structures and positional\ninformations of the input network nodes towards inferring a better and more\nconfident GRN network reconstruction. In this paper, we explore the integration\nof multiple inferred networks to enhance the inference of Gene Regulatory\nNetworks (GRNs). Primarily, we employ autoencoder embeddings to capture gene\nexpression patterns directly from raw data, preserving intricate biological\nsignals. Then, we embed the prior knowledge from GRN structures transforming\nthem into a text-like representation using random walks, which are then encoded\nwith a masked language model, BERT, to generate global embeddings for each gene\nacross all networks. Additionally, we embed the positional encodings of the\ninput gene networks to better identify the position of each unique gene within\nthe graph. These embeddings are integrated into graph transformer-based model,\ntermed GT-GRN, for GRN inference. The GT-GRN model effectively utilizes the\ntopological structure of the ground truth network while incorporating the\nenriched encoded information. Experimental results demonstrate that GT-GRN\nsignificantly outperforms existing GRN inference methods, achieving superior\naccuracy and highlighting the robustness of our approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGT-GRN\u6a21\u578b\uff0c\u4f7f\u7528\u5d4c\u5165\u6280\u672f\u548c\u56fe\u53d8\u6362\u5668\u6539\u8fdb\u57fa\u56e0\u8c03\u63a7\u7f51\u7edc\u63a8\u65ad\u3002", "motivation": "\u73b0\u6709GRN\u63a8\u65ad\u65b9\u6cd5\u6613\u53d7\u566a\u58f0\u5f71\u54cd\uff0c\u9700\u6574\u5408\u591a\u7f51\u7edc\u5148\u9a8c\u77e5\u8bc6\u548c\u4f4d\u7f6e\u4fe1\u606f\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u81ea\u7f16\u7801\u5668\u5d4c\u5165\u57fa\u56e0\u8868\u8fbe\uff0cBERT\u7f16\u7801GRN\u7ed3\u6784\u548c\u4f4d\u7f6e\u4fe1\u606f\uff0c\u6574\u5408\u5230\u56fe\u53d8\u6362\u5668\u6a21\u578bGT-GRN\u4e2d\u3002", "result": "\u5b9e\u9a8c\u663e\u793aGT-GRN\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5229\u7528\u7f51\u7edc\u62d3\u6251\u548c\u4fe1\u606f\u7f16\u7801\uff0c\u63d0\u5347GRN\u63a8\u65ad\u6027\u80fd\u3002"}}
{"id": "2504.17118", "pdf": "https://arxiv.org/pdf/2504.17118", "abs": "https://arxiv.org/abs/2504.17118", "authors": ["Apurva Patil", "Kyle Morgenstein", "Luis Sentis", "Takashi Tanaka"], "title": "Path Integral Methods for Synthesizing and Preventing Stealthy Attacks in Nonlinear Cyber-Physical Systems", "categories": ["eess.SY", "cs.IT", "cs.SY", "math.IT"], "comment": null, "summary": "This paper studies the synthesis and mitigation of stealthy attacks in\nnonlinear cyber-physical systems (CPS). To quantify stealthiness, we employ the\nKullback-Leibler (KL) divergence, a measure rooted in hypothesis testing and\ndetection theory, which captures the trade-off between an attacker's desire to\nremain stealthy and her goal of degrading system performance. First, we\nsynthesize the worst-case stealthy attack in nonlinear CPS using the path\nintegral approach. Second, we consider how a controller can mitigate the impact\nof such stealthy attacks by formulating a minimax KL control problem, yielding\na zero-sum game between the attacker and the controller. Again, we leverage a\npath integral-based solution that computes saddle-point policies for both\nplayers through Monte Carlo simulations. We validate our approach using\nunicycle navigation and cruise control problems, demonstrating how an attacker\ncan covertly drive the system into unsafe regions, and how the controller can\nadapt her policy to combat the worst-case attacks.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u975e\u7ebf\u6027\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u4e2d\u9690\u79d8\u653b\u51fb\u7684\u5408\u6210\u548c\u7f13\u89e3\uff0c\u4f7f\u7528KL\u6563\u5ea6\u91cf\u5316\u9690\u79d8\u6027\uff0c\u901a\u8fc7\u8def\u5f84\u79ef\u5206\u65b9\u6cd5\u548c\u6700\u5c0f\u6700\u5927\u63a7\u5236\u95ee\u9898\u9a8c\u8bc1\u3002", "motivation": "\u91cf\u5316\u653b\u51fb\u8005\u5728\u4fdd\u6301\u9690\u79d8\u6027\u548c\u7834\u574f\u7cfb\u7edf\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4f7f\u7528KL\u6563\u5ea6\u6355\u6349\u8fd9\u79cdtrade-off\u3002", "method": "\u9996\u5148\u7528\u8def\u5f84\u79ef\u5206\u65b9\u6cd5\u5408\u6210\u6700\u574f\u60c5\u51b5\u9690\u79d8\u653b\u51fb\uff1b\u5176\u6b21\u5236\u5b9a\u6700\u5c0f\u6700\u5927KL\u63a7\u5236\u95ee\u9898\uff0c\u6c42\u89e3\u96f6\u548c\u535a\u5f08\uff0c\u901a\u8fc7\u8def\u5f84\u79ef\u5206\u548c\u8499\u7279\u5361\u6d1b\u6a21\u62df\u8ba1\u7b97\u7b56\u7565\u3002", "result": "\u5728unicycle\u5bfc\u822a\u548c\u5de1\u822a\u63a7\u5236\u95ee\u9898\u4e2d\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u653b\u51fb\u8005\u9690\u79d8\u9a71\u52a8\u7cfb\u7edf\u8fdb\u5165\u4e0d\u5b89\u5168\u533a\u57df\uff0c\u4ee5\u53ca\u63a7\u5236\u5668\u9002\u5e94\u5bf9\u6297\u6700\u574f\u653b\u51fb\u3002", "conclusion": "\u65b9\u6cd5\u6709\u6548\uff0c\u63d0\u4f9b\u5bf9\u6297\u9690\u79d8\u653b\u51fb\u7684\u6846\u67b6\u3002"}}
{"id": "2504.17017", "pdf": "https://arxiv.org/pdf/2504.17017", "abs": "https://arxiv.org/abs/2504.17017", "authors": ["Balaji Rao", "William Eiers", "Carlo Lipizzi"], "title": "Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification", "categories": ["cs.AI", "cs.FL", "cs.LG", "cs.LO"], "comment": "Accepted to the Proceedings of the 19th Conference on Neurosymbolic\n  Learning and Reasoning (NeSy 2025)", "summary": "Formally verifying properties of software code has been a highly desirable\ntask, especially with the emergence of LLM-generated code. In the same vein,\nthey provide an interesting avenue for the exploration of formal verification\nand mechanistic interpretability. Since the introduction of code-specific\nmodels, despite their successes in generating code in Lean4 and Isabelle, the\ntask of generalized theorem proving still remains far from being fully solved\nand will be a benchmark for reasoning capability in LLMs. In this work, we\nintroduce a framework that generates whole proofs in a formal language to be\nused within systems that utilize the power of built-in tactics and\noff-the-shelf automated theorem provers. Our framework includes 3 components:\ngenerating natural language statements of the code to be verified, an LLM that\ngenerates formal proofs for the given statement, and a module employing\nheuristics for building the final proof. To train the LLM, we employ a 2-stage\nfine-tuning process, where we first use SFT-based training to enable the model\nto generate syntactically correct Isabelle code and then RL-based training that\nencourages the model to generate proofs verified by a theorem prover. We\nvalidate our framework using the miniF2F-test benchmark and the Isabelle proof\nassistant and design a use case to verify the correctness of the AWS S3 bucket\naccess policy code. We also curate a dataset based on the\nFVEL\\textsubscript{\\textnormal{ER}} dataset for future training tasks.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u4f7f\u7528LLM\u751f\u6210\u5f62\u5f0f\u5316\u8bc1\u660e\u6765\u9a8c\u8bc1\u8f6f\u4ef6\u4ee3\u7801\uff0c\u7279\u522b\u662fLLM\u751f\u6210\u7684\u4ee3\u7801\u3002", "motivation": "\u52a8\u673a\u662fLLM\u751f\u6210\u4ee3\u7801\u7684\u5174\u8d77\u589e\u52a0\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\u9700\u6c42\uff0c\u4e14\u5b9a\u7406\u8bc1\u660e\u662f\u8bc4\u4f30LLM\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4e00\u4e2a\u6846\u67b6\uff1a\u751f\u6210\u81ea\u7136\u8bed\u8a00\u8bed\u53e5\u3001LLM\u751f\u6210\u5f62\u5f0f\u5316\u8bc1\u660e\u3001\u542f\u53d1\u5f0f\u6a21\u5757\u6784\u5efa\u8bc1\u660e\u3002\u8bad\u7ec3\u91c7\u7528SFT\u786e\u4fdd\u8bed\u6cd5\u6b63\u786e\uff0c\u7136\u540eRL\u786e\u4fdd\u8bc1\u660e\u53ef\u9a8c\u8bc1\u3002", "result": "\u7ed3\u679c\u5728miniF2F-test\u57fa\u51c6\u548cIsabelle\u4e0a\u9a8c\u8bc1\uff0c\u5e76\u5e94\u7528\u4e8eAWS S3\u8bbf\u95ee\u653f\u7b56\u7528\u4f8b\uff0c\u8fd8\u6574\u7406\u4e86\u57fa\u4e8eFVEL_ER\u7684\u6570\u636e\u96c6\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8be5\u6846\u67b6\u63d0\u5347\u4e86LLM\u5728\u5f62\u5f0f\u5316\u8bc1\u660e\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6570\u636e\u96c6\u3002"}}
{"id": "2504.16968", "pdf": "https://arxiv.org/pdf/2504.16968", "abs": "https://arxiv.org/abs/2504.16968", "authors": ["Jun Wu", "Jiangtao Wen", "Yuxing Han"], "title": "Backslash: Rate Constrained Optimized Training of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapid advancement of large-language models (LLMs) has driven extensive\nresearch into parameter compression after training has been completed, yet\ncompression during the training phase remains largely unexplored. In this work,\nwe introduce Rate-Constrained Training (Backslash), a novel training-time\ncompression approach based on rate-distortion optimization (RDO). Backslash\nenables a flexible trade-off between model accuracy and complexity,\nsignificantly reducing parameter redundancy while preserving performance.\nExperiments in various architectures and tasks demonstrate that Backslash can\nreduce memory usage by 60\\% - 90\\% without accuracy loss and provides\nsignificant compression gain compared to compression after training. Moreover,\nBackslash proves to be highly versatile: it enhances generalization with small\nLagrange multipliers, improves model robustness to pruning (maintaining\naccuracy even at 80\\% pruning rates), and enables network simplification for\naccelerated inference on edge devices.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aBackslash\u7684\u8bad\u7ec3\u65f6\u538b\u7f29\u65b9\u6cd5\uff0c\u4f7f\u7528\u7387\u5931\u771f\u4f18\u5316\uff08RDO\uff09\uff0c\u5728\u4e0d\u635f\u5931\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u51cf\u5c1160%-90%\u7684\u5185\u5b58\u4f7f\u7528\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u540e\u538b\u7f29\u7814\u7a76\u5e7f\u6cdb\uff0c\u4f46\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u538b\u7f29\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51faRate-Constrained Training\uff08Backslash\uff09\u65b9\u6cd5\uff0c\u57fa\u4e8e\u7387\u5931\u771f\u4f18\u5316\uff0c\u5141\u8bb8\u5728\u6a21\u578b\u51c6\u786e\u6027\u548c\u590d\u6742\u5ea6\u4e4b\u95f4\u7075\u6d3b\u6743\u8861\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5185\u5b58\u4f7f\u7528\u51cf\u5c1160%-90%\u65e0\u51c6\u786e\u6027\u635f\u5931\uff0c\u6bd4\u8bad\u7ec3\u540e\u538b\u7f29\u66f4\u6709\u6548\uff1b\u8fd8\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3001\u6297\u526a\u679d\u9c81\u68d2\u6027\uff0c\u5e76\u52a0\u901f\u8fb9\u7f18\u8bbe\u5907\u63a8\u7406\u3002", "conclusion": "Backslash\u65b9\u6cd5\u9ad8\u5ea6\u901a\u7528\uff0c\u53ef\u6539\u5584\u6a21\u578b\u6027\u80fd\u3001\u589e\u5f3a\u9c81\u68d2\u6027\u548c\u7b80\u5316\u7f51\u7edc\u3002"}}
{"id": "2504.17128", "pdf": "https://arxiv.org/pdf/2504.17128", "abs": "https://arxiv.org/abs/2504.17128", "authors": ["Seyed Yousef Soltanian", "Wenlong Zhang"], "title": "PACE: A Framework for Learning and Control in Linear Incomplete-Information Differential Games", "categories": ["eess.SY", "cs.LG", "cs.MA", "cs.SY", "93C41, 49N70, 49N90, 91A27"], "comment": "Accepted to 7th Annual Conference on Learning for Dynamics and\n  Control (L4DC) 2025. Camera-ready version using the official PMLR template.\n  The full version including appendix and proofs", "summary": "In this paper, we address the problem of a two-player linear quadratic\ndifferential game with incomplete information, a scenario commonly encountered\nin multi-agent control, human-robot interaction (HRI), and approximation\nmethods for solving general-sum differential games. While solutions to such\nlinear differential games are typically obtained through coupled Riccati\nequations, the complexity increases when agents have incomplete information,\nparticularly when neither is aware of the other's cost function. To tackle this\nchallenge, we propose a model-based Peer-Aware Cost Estimation (PACE) framework\nfor learning the cost parameters of the other agent. In PACE, each agent treats\nits peer as a learning agent rather than a stationary optimal agent, models\ntheir learning dynamics, and leverages this dynamic to infer the cost function\nparameters of the other agent. This approach enables agents to infer each\nother's objective function in real time based solely on their previous state\nobservations and dynamically adapt their control policies. Furthermore, we\nprovide a theoretical guarantee for the convergence of parameter estimation and\nthe stability of system states in PACE. Additionally, in our numerical studies,\nwe demonstrate how modeling the learning dynamics of the other agent benefits\nPACE, compared to approaches that approximate the other agent as having\ncomplete information, particularly in terms of stability and convergence speed.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faPACE\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u4e0d\u5b8c\u5168\u4fe1\u606f\u4e0b\u7684\u4e24\u73a9\u5bb6\u7ebf\u6027\u4e8c\u6b21\u5fae\u5206\u6e38\u620f\uff0c\u5b9e\u73b0\u5b9e\u65f6\u6210\u672c\u53c2\u6570\u4f30\u8ba1\u548c\u63a7\u5236\u7b56\u7565\u9002\u5e94\u3002", "motivation": "\u89e3\u51b3\u4ee3\u7406\u4e0d\u5b8c\u5168\u4fe1\u606f\u95ee\u9898\uff0c\u5c24\u5176\u662f\u4e0d\u77e5\u9053\u5bf9\u65b9\u6210\u672c\u51fd\u6570\u7684\u6311\u6218\uff0c\u5e38\u89c1\u4e8e\u591a\u4ee3\u7406\u63a7\u5236\u3001\u4eba\u673a\u4ea4\u4e92\u548c\u4e00\u822c\u548c\u5fae\u5206\u6e38\u620f\u7684\u8fd1\u4f3c\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u7684PACE\u6846\u67b6\uff0c\u6bcf\u4e2a\u4ee3\u7406\u5c06\u5bf9\u7b49\u65b9\u89c6\u4e3a\u5b66\u4e60\u4ee3\u7406\uff0c\u5efa\u6a21\u5176\u5b66\u4e60\u52a8\u6001\uff0c\u5e76\u7528\u4e8e\u63a8\u65ad\u6210\u672c\u51fd\u6570\u53c2\u6570\u3002", "result": "\u63d0\u4f9b\u53c2\u6570\u4f30\u8ba1\u6536\u655b\u548c\u7cfb\u7edf\u72b6\u6001\u7a33\u5b9a\u7684\u7406\u8bba\u4fdd\u8bc1\uff1b\u6570\u503c\u7814\u7a76\u663e\u793a\uff0c\u4e0e\u5047\u8bbe\u5b8c\u5168\u4fe1\u606f\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0cPACE\u5728\u7a33\u5b9a\u6027\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "PACE\u6846\u67b6\u5141\u8bb8\u4ee3\u7406\u57fa\u4e8e\u89c2\u5bdf\u5b9e\u65f6\u63a8\u65ad\u5bf9\u65b9\u76ee\u6807\u5e76\u52a8\u6001\u9002\u5e94\u63a7\u5236\u7b56\u7565\uff0c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2504.17087", "pdf": "https://arxiv.org/pdf/2504.17087", "abs": "https://arxiv.org/abs/2504.17087", "authors": ["Yuran Li", "Jama Hussein Mohamud", "Chongren Sun", "Di Wu", "Benoit Boulet"], "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments", "categories": ["cs.AI"], "comment": "12 pages, 5 figures, 6 tables", "summary": "Large language models (LLMs) are being widely applied across various fields,\nbut as tasks become more complex, evaluating their responses is increasingly\nchallenging. Compared to human evaluators, the use of LLMs to support\nperformance evaluation offers a more efficient alternative. However, most\nstudies focus mainly on aligning LLMs' judgments with human preferences,\noverlooking the existence of biases and mistakes in human judgment.\nFurthermore, how to select suitable LLM judgments given multiple potential LLM\nresponses remains underexplored. To address these two aforementioned issues, we\npropose a three-stage meta-judge selection pipeline: 1) developing a\ncomprehensive rubric with GPT-4 and human experts, 2) using three advanced LLM\nagents to score judgments, and 3) applying a threshold to filter out\nlow-scoring judgments. Compared to methods using a single LLM as both judge and\nmeta-judge, our pipeline introduces multi-agent collaboration and a more\ncomprehensive rubric. Experimental results on the JudgeBench dataset show about\n15.55\\% improvement compared to raw judgments and about 8.37\\% improvement over\nthe single-agent baseline. Our work demonstrates the potential of LLMs as\nmeta-judges and lays the foundation for future research on constructing\npreference datasets for LLM-as-a-judge reinforcement learning.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e09\u9636\u6bb5\u5143\u5224\u65ad\u9009\u62e9\u7ba1\u9053\uff0c\u4f7f\u7528\u591a\u4ee3\u7406LLM\u6539\u8fdbLLM\u8bc4\u4f30\u5224\u65ad\u9009\u62e9\uff0c\u5b9e\u9a8c\u663e\u793a\u663e\u8457\u6539\u8fdb\u3002", "motivation": "LLM\u4efb\u52a1\u590d\u6742\uff0c\u8bc4\u4f30\u6311\u6218\u5927\uff1b\u4eba\u7c7b\u8bc4\u4f30\u6548\u7387\u4f4e\u4e14\u6709\u504f\u5dee\uff1b\u73b0\u6709\u7814\u7a76\u5ffd\u7565\u504f\u5dee\u548c\u5224\u65ad\u9009\u62e9\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u7ba1\u9053\uff1a1) \u4e0eGPT-4\u548c\u4e13\u5bb6\u5f00\u53d1\u8bc4\u5206\u6807\u51c6\uff0c2) \u4f7f\u7528\u4e09\u4e2aLLM\u4ee3\u7406\u8bc4\u5206\uff0c3) \u9608\u503c\u8fc7\u6ee4\u4f4e\u5206\u5224\u65ad\uff0c\u5f15\u5165\u591a\u4ee3\u7406\u534f\u4f5c\u3002", "result": "\u5728JudgeBench\u6570\u636e\u96c6\u4e0a\uff0c\u6539\u8fdb15.55%\u6bd4\u539f\u59cb\u5224\u65ad\uff0c8.37%\u6bd4\u5355\u4ee3\u7406\u57fa\u7ebf\u3002", "conclusion": "\u8bc1\u660eLLM\u4f5c\u4e3a\u5143\u5224\u65ad\u6f5c\u529b\uff0c\u5e76\u4e3aLLM\u5224\u65ad\u5f3a\u5316\u5b66\u4e60\u504f\u597d\u6570\u636e\u96c6\u7814\u7a76\u5960\u57fa\u3002"}}
{"id": "2504.16970", "pdf": "https://arxiv.org/pdf/2504.16970", "abs": "https://arxiv.org/abs/2504.16970", "authors": ["Yin Wang", "Chunlin Gong", "Xiang Wu", "Hanleran Zhang"], "title": "STFM: A Spatio-Temporal Information Fusion Model Based on Phase Space Reconstruction for Sea Surface Temperature Prediction", "categories": ["cs.LG"], "comment": "19 pages, 14 figures", "summary": "The sea surface temperature (SST), a key environmental parameter, is crucial\nto optimizing production planning, making its accurate prediction a vital\nresearch topic. However, the inherent nonlinearity of the marine dynamic system\npresents significant challenges. Current forecasting methods mainly include\nphysics-based numerical simulations and data-driven machine learning\napproaches. The former, while describing SST evolution through differential\nequations, suffers from high computational complexity and limited\napplicability, whereas the latter, despite its computational benefits, requires\nlarge datasets and faces interpretability challenges. This study presents a\nprediction framework based solely on data-driven techniques. Using phase space\nreconstruction, we construct initial-delay attractor pairs with a mathematical\nhomeomorphism and design a Spatio-Temporal Fusion Mapping (STFM) to uncover\ntheir intrinsic connections. Unlike conventional models, our method captures\nSST dynamics efficiently through phase space reconstruction and achieves high\nprediction accuracy with minimal training data in comparative tests", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684SST\u9884\u6d4b\u6846\u67b6\uff0c\u4f7f\u7528\u76f8\u7a7a\u95f4\u91cd\u6784\u548cSTFM\u65b9\u6cd5\uff0c\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "SST\u9884\u6d4b\u5bf9\u751f\u4ea7\u89c4\u5212\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6d77\u6d0b\u7cfb\u7edf\u975e\u7ebf\u6027\u6311\u6218\u5927\uff0c\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u6216\u6570\u636e\u9700\u6c42\u9ad8\u3002", "method": "\u901a\u8fc7\u76f8\u7a7a\u95f4\u91cd\u6784\u6784\u5efa\u5438\u5f15\u5b50\u5bf9\uff0c\u5e76\u8bbe\u8ba1STFM\u63ed\u793aSST\u52a8\u6001\u3002", "result": "\u65b9\u6cd5\u9ad8\u6548\uff0c\u9700\u5c11\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u5728\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u8bc1\u660e\u5728SST\u9884\u6d4b\u4e2d\u6709\u6548\u4e14\u4f18\u8d8a\u3002"}}
{"id": "2504.17129", "pdf": "https://arxiv.org/pdf/2504.17129", "abs": "https://arxiv.org/abs/2504.17129", "authors": ["Seyed Yousef Soltanian", "Wenlong Zhang"], "title": "Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference", "categories": ["eess.SY", "cs.AI", "cs.GT", "cs.RO", "cs.SY", "93C41, 49N70, 49N90, 91A27"], "comment": null, "summary": "Human-robot interactions can be modeled as incomplete-information general-sum\ndynamic games since the objective functions of both agents are not explicitly\nknown to each other. However, solving for equilibrium policies for such games\npresents a major challenge, especially if the games involve nonlinear\nunderlying dynamics. To simplify the problem, existing work often assumes that\none agent is an expert with complete information about its peer, which can lead\nto biased estimates and failures in coordination. To address this challenge, we\npropose a nonlinear peer-aware cost estimation (N-PACE) algorithm for\ngeneral-sum dynamic games. In N-PACE, using iterative linear quadratic (LQ)\napproximation of the nonlinear general-sum game, each agent explicitly models\nthe learning dynamics of its peer agent while inferring their objective\nfunctions, leading to unbiased fast learning in inferring the unknown objective\nfunction of the peer agent, which is critical for task completion and safety\nassurance. Additionally, we demonstrate how N-PACE enables \\textbf{intent\ncommunication} in such multi-agent systems by explicitly modeling the peer's\nlearning dynamics.", "AI": {"tldr": "This paper proposes the N-PACE algorithm for human-robot interactions in incomplete-information games, enabling fast, unbiased learning of peer objectives and intent communication.", "motivation": "To address challenges in solving equilibrium policies for incomplete-information general-sum dynamic games with nonlinear dynamics, as existing methods assume complete information, leading to biased estimates and coordination failures.", "method": "Proposes the N-PACE algorithm, which uses iterative linear quadratic approximation to model the peer's learning dynamics and infer their objective functions.", "result": "Achieves unbiased fast learning of peer objectives, improves task completion and safety, and enables intent communication in multi-agent systems.", "conclusion": "N-PACE enhances coordination and safety in human-robot interactions by explicitly modeling peer learning dynamics, reducing biases from incomplete information."}}
{"id": "2504.17179", "pdf": "https://arxiv.org/pdf/2504.17179", "abs": "https://arxiv.org/abs/2504.17179", "authors": ["Mohammad Zarei", "Melanie A Jutras", "Eliana Evans", "Mike Tan", "Omid Aaramoon"], "title": "AUTHENTICATION: Identifying Rare Failure Modes in Autonomous Vehicle Perception Systems using Adversarially Guided Diffusion Models", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.RO", "68T45, 68T05 68T45, 68T05 68T45, 68T05", "I.2.6; I.2.10; I.4.8"], "comment": "8 pages, 10 figures. Accepted to IEEE Conference on Artificial\n  Intelligence (CAI), 2025", "summary": "Autonomous Vehicles (AVs) rely on artificial intelligence (AI) to accurately\ndetect objects and interpret their surroundings. However, even when trained\nusing millions of miles of real-world data, AVs are often unable to detect rare\nfailure modes (RFMs). The problem of RFMs is commonly referred to as the\n\"long-tail challenge\", due to the distribution of data including many instances\nthat are very rarely seen. In this paper, we present a novel approach that\nutilizes advanced generative and explainable AI techniques to aid in\nunderstanding RFMs. Our methods can be used to enhance the robustness and\nreliability of AVs when combined with both downstream model training and\ntesting. We extract segmentation masks for objects of interest (e.g., cars) and\ninvert them to create environmental masks. These masks, combined with carefully\ncrafted text prompts, are fed into a custom diffusion model. We leverage the\nStable Diffusion inpainting model guided by adversarial noise optimization to\ngenerate images containing diverse environments designed to evade object\ndetection models and expose vulnerabilities in AI systems. Finally, we produce\nnatural language descriptions of the generated RFMs that can guide developers\nand policymakers to improve the safety and reliability of AV systems.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u751f\u6210AI\u6280\u672f\u6a21\u62df\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u7a00\u6709\u6545\u969c\u6a21\u5f0f\uff0c\u63d0\u9ad8\u5176\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u8bad\u7ec3\u540e\u4ecd\u96be\u4ee5\u68c0\u6d4b\u7a00\u6709\u6545\u969c\u6a21\u5f0f\uff0c\u5bfc\u81f4\u957f\u5c3e\u6311\u6218\uff0c\u9700\u8981\u63d0\u5347\u5176\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u63d0\u53d6\u5bf9\u8c61\u5206\u5272\u63a9\u7801\uff0c\u521b\u5efa\u73af\u5883\u63a9\u7801\uff0c\u7ed3\u5408\u6587\u672c\u63d0\u793a\u548cStable Diffusion\u6a21\u578b\u751f\u6210\u89c4\u907f\u68c0\u6d4b\u56fe\u50cf\uff0c\u5e76\u4ea7\u751f\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u3002", "result": "\u751f\u6210\u56fe\u50cf\u66b4\u9732AI\u6f0f\u6d1e\uff0c\u63d0\u9ad8\u8f66\u8f86\u9c81\u68d2\u6027\uff0c\u5e76\u6307\u5bfc\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u589e\u5f3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u8f85\u52a9\u5f00\u53d1\u8005\u4e0e\u653f\u7b56\u5236\u5b9a\u8005\u6539\u8fdb\u3002"}}
{"id": "2504.16972", "pdf": "https://arxiv.org/pdf/2504.16972", "abs": "https://arxiv.org/abs/2504.16972", "authors": ["Hossein Ahmadi", "Sajjad Emdadi Mahdimahalleh", "Arman Farahat", "Banafsheh Saffari"], "title": "Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.SP"], "comment": null, "summary": "The rapid growth of unlabeled time-series data in domains such as wireless\ncommunications, radar, biomedical engineering, and the Internet of Things (IoT)\nhas driven advancements in unsupervised learning. This review synthesizes\nrecent progress in applying autoencoders and vision transformers for\nunsupervised signal analysis, focusing on their architectures, applications,\nand emerging trends. We explore how these models enable feature extraction,\nanomaly detection, and classification across diverse signal types, including\nelectrocardiograms, radar waveforms, and IoT sensor data. The review highlights\nthe strengths of hybrid architectures and self-supervised learning, while\nidentifying challenges in interpretability, scalability, and domain\ngeneralization. By bridging methodological innovations and practical\napplications, this work offers a roadmap for developing robust, adaptive models\nfor signal intelligence.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u56de\u987e\u4e86\u5728\u65e0\u76d1\u7763\u4fe1\u53f7\u5206\u6790\u4e2d\u5e94\u7528\u81ea\u7f16\u7801\u5668\u548c\u89c6\u89c9\u53d8\u538b\u5668\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u6db5\u76d6\u67b6\u6784\u3001\u5e94\u7528\u548c\u8d8b\u52bf\u3002", "motivation": "\u672a\u6807\u8bb0\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u5feb\u901f\u589e\u957f\u63a8\u52a8\u4e86\u65e0\u76d1\u7763\u5b66\u4e60\u7684\u53d1\u5c55\uff0c\u7279\u522b\u662f\u5728\u65e0\u7ebf\u901a\u4fe1\u3001\u96f7\u8fbe\u3001\u751f\u7269\u533b\u5b66\u5de5\u7a0b\u548c\u7269\u8054\u7f51\u9886\u57df\u3002", "method": "\u901a\u8fc7\u5408\u6210\u81ea\u7f16\u7801\u5668\u548c\u89c6\u89c9\u53d8\u538b\u5668\u7684\u67b6\u6784\u3001\u5e94\u7528\u548c\u65b0\u5174\u8d8b\u52bf\uff0c\u63a2\u8ba8\u5176\u5728\u4fe1\u53f7\u5206\u6790\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u6a21\u578b\u5b9e\u73b0\u4e86\u7279\u5f81\u63d0\u53d6\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u5206\u7c7b\uff0c\u7a81\u51fa\u4e86\u6df7\u5408\u67b6\u6784\u548c\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u4f18\u52bf\uff0c\u4f46\u9762\u4e34\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9886\u57df\u6cdb\u5316\u6311\u6218\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6865\u63a5\u65b9\u6cd5\u521b\u65b0\u4e0e\u5b9e\u9645\u5e94\u7528\u7684\u8def\u7ebf\u56fe\uff0c\u4ee5\u5f00\u53d1\u7a33\u5065\u7684\u81ea\u9002\u5e94\u4fe1\u53f7\u667a\u80fd\u6a21\u578b\u3002"}}
{"id": "2504.17139", "pdf": "https://arxiv.org/pdf/2504.17139", "abs": "https://arxiv.org/abs/2504.17139", "authors": ["Keyan Miao", "Liqun Zhao", "Han Wang", "Konstantinos Gatsis", "Antonis Papachristodoulou"], "title": "Opt-ODENet: A Neural ODE Framework with Differentiable QP Layers for Safe and Stable Control Design (longer version)", "categories": ["eess.SY", "cs.SY"], "comment": "19 pages", "summary": "Designing controllers that achieve task objectives while ensuring safety is a\nkey challenge in control systems. This work introduces Opt-ODENet, a Neural ODE\nframework with a differentiable Quadratic Programming (QP) optimization layer\nto enforce constraints as hard requirements. Eliminating the reliance on\nnominal controllers or large datasets, our framework solves the optimal control\nproblem directly using Neural ODEs. Stability and convergence are ensured\nthrough Control Lyapunov Functions (CLFs) in the loss function, while Control\nBarrier Functions (CBFs) embedded in the QP layer enforce real-time safety. By\nintegrating the differentiable QP layer with Neural ODEs, we demonstrate\ncompatibility with the adjoint method for gradient computation, enabling the\nlearning of the CBF class-$\\mathcal{K}$ function and control network\nparameters. Experiments validate its effectiveness in balancing safety and\nperformance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa Opt-ODENet \u6846\u67b6\uff0c\u4f7f\u7528 Neural ODE \u548c\u53ef\u5fae\u5206 QP \u5c42\u5f3a\u5236\u7ea6\u675f\uff0c\u786e\u4fdd\u63a7\u5236\u7cfb\u7edf\u7684\u5b89\u5168\u548c\u6027\u80fd\u5e73\u8861\u3002", "motivation": "\u89e3\u51b3\u63a7\u5236\u7cfb\u7edf\u4e2d\u8bbe\u8ba1\u65e2\u5b9e\u73b0\u4efb\u52a1\u76ee\u6807\u53c8\u786e\u4fdd\u5b89\u5168\u7684\u63a7\u5236\u5668\u6311\u6218\uff0c\u65e0\u9700\u4f9d\u8d56\u540d\u4e49\u63a7\u5236\u5668\u6216\u5927\u578b\u6570\u636e\u96c6\u3002", "method": "\u5f15\u5165 Opt-ODENet \u6846\u67b6\uff0c\u5c06\u53ef\u5fae\u5206\u4e8c\u6b21\u89c4\u5212 (QP) \u4f18\u5316\u5c42\u4e0e Neural ODE \u7ed3\u5408\uff0c\u4f7f\u7528\u63a7\u5236\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570 (CLFs) \u786e\u4fdd\u7a33\u5b9a\u6027\u548c\u6536\u655b\u6027\uff0c\u5e76\u901a\u8fc7\u63a7\u5236\u5c4f\u969c\u51fd\u6570 (CBFs) \u5728 QP \u5c42\u5f3a\u5236\u5b9e\u65f6\u5b89\u5168\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u5728\u5e73\u8861\u5b89\u5168\u6027\u548c\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u96c6\u6210\u53ef\u5fae\u5206 QP \u548c Neural ODE\uff0c\u5b9e\u73b0\u5b89\u5168\u63a7\u5236\u95ee\u9898\u7684\u76f4\u63a5\u6c42\u89e3\uff0c\u5e76\u652f\u6301\u4f34\u968f\u65b9\u6cd5\u8fdb\u884c\u68af\u5ea6\u8ba1\u7b97\u3002"}}
{"id": "2504.17282", "pdf": "https://arxiv.org/pdf/2504.17282", "abs": "https://arxiv.org/abs/2504.17282", "authors": ["Lynn Cherif", "Flemming Kondrup", "David Venuto", "Ankit Anand", "Doina Precup", "Khimya Khetarpal"], "title": "Cracking the Code of Action: a Generative Approach to Affordances for Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Agents that can autonomously navigate the web through a graphical user\ninterface (GUI) using a unified action space (e.g., mouse and keyboard actions)\ncan require very large amounts of domain-specific expert demonstrations to\nachieve good performance. Low sample efficiency is often exacerbated in\nsparse-reward and large-action-space environments, such as a web GUI, where\nonly a few actions are relevant in any given situation. In this work, we\nconsider the low-data regime, with limited or no access to expert behavior. To\nenable sample-efficient learning, we explore the effect of constraining the\naction space through $\\textit{intent-based affordances}$ -- i.e., considering\nin any situation only the subset of actions that achieve a desired outcome. We\npropose $\\textbf{Code as Generative Affordances}$ $(\\textbf{$\\texttt{CoGA}$})$,\na method that leverages pre-trained vision-language models (VLMs) to generate\ncode that determines affordable actions through implicit intent-completion\nfunctions and using a fully-automated program generation and verification\npipeline. These programs are then used in-the-loop of a reinforcement learning\nagent to return a set of affordances given a pixel observation. By greatly\nreducing the number of actions that an agent must consider, we demonstrate on a\nwide range of tasks in the MiniWob++ benchmark that: $\\textbf{1)}$\n$\\texttt{CoGA}$ is orders of magnitude more sample efficient than its RL agent,\n$\\textbf{2)}$ $\\texttt{CoGA}$'s programs can generalize within a family of\ntasks, and $\\textbf{3)}$ $\\texttt{CoGA}$ performs better or on par compared\nwith behavior cloning when a small number of expert demonstrations is\navailable.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faCoGA\u65b9\u6cd5\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u7ea6\u675f\u52a8\u4f5c\u7a7a\u95f4\uff0c\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u7f51\u9875GUI\u4efb\u52a1\u4e2d\u7684\u6837\u672c\u6548\u7387\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u4f4e\u6570\u636e\u73af\u5883\u4e0b\u4ee3\u7406\u6837\u672c\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u5c24\u5176\u5728\u7a00\u758f\u5956\u52b1\u548c\u5927\u578b\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u3002", "method": "\u65b9\u6cd5\u662fCoGA\uff0c\u5229\u7528VLMs\u751f\u6210\u4ee3\u7801\u901a\u8fc7\u610f\u56fe\u5b8c\u6210\u51fd\u6570\u548c\u81ea\u52a8\u5316\u7ba1\u9053\uff0c\u786e\u5b9a\u53ef\u8d1f\u62c5\u52a8\u4f5c\u96c6\u3002", "result": "\u7ed3\u679c\u663e\u793aCoGA\u6837\u672c\u6548\u7387\u9ad8\u51fa\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u80fd\u6cdb\u5316\uff0c\u5e76\u5728\u5c11\u91cf\u4e13\u5bb6\u6f14\u793a\u65f6\u6027\u80fd\u4f18\u4e8e\u6216\u76f8\u5f53\u4e8e\u662f\u884c\u4e3a\u514b\u9686\u3002", "conclusion": "\u7ed3\u8bba\u662fCoGA\u662f\u4e00\u79cd\u6709\u6548\u7684\u6837\u672c\u9ad8\u6548\u5b66\u4e60\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u7ea6\u675f\u52a8\u4f5c\u7a7a\u95f4\u7684\u76ca\u5904\u3002"}}
{"id": "2504.16980", "pdf": "https://arxiv.org/pdf/2504.16980", "abs": "https://arxiv.org/abs/2504.16980", "authors": ["Pratyush Maini", "Sachin Goyal", "Dylan Sam", "Alex Robey", "Yash Savani", "Yiding Jiang", "Andy Zou", "Zacharcy C. Lipton", "J. Zico Kolter"], "title": "Safety Pretraining: Toward the Next Generation of Safe AI", "categories": ["cs.LG"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in high-stakes\nsettings, the risk of generating harmful or toxic content remains a central\nchallenge. Post-hoc alignment methods are brittle: once unsafe patterns are\nlearned during pretraining, they are hard to remove. We present a data-centric\npretraining framework that builds safety into the model from the start. Our\ncontributions include: (i) a safety classifier trained on 10,000 GPT-4 labeled\nexamples, used to filter 600B tokens; (ii) the largest synthetic safety dataset\nto date (100B tokens) generated via recontextualization of harmful web data;\n(iii) RefuseWeb and Moral Education datasets that convert harmful prompts into\nrefusal dialogues and web-style educational material; (iv) Harmfulness-Tag\nannotations injected during pretraining to flag unsafe content and steer away\ninference from harmful generations; and (v) safety evaluations measuring base\nmodel behavior before instruction tuning. Our safety-pretrained models reduce\nattack success rates from 38.8% to 8.4% with no performance degradation on\nstandard LLM safety benchmarks.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u6570\u636e\u4e2d\u5fc3\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u4ece\u4e00\u5f00\u59cb\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u51cf\u5c11\u6709\u5bb3\u8f93\u51fa\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u7684\u98ce\u9669\uff0c\u56e0\u4e3a\u4e8b\u540e\u5bf9\u9f50\u65b9\u6cd5\u4e0d\u7a33\u5b9a\u3002", "method": "\u5305\u62ec\u8bad\u7ec3\u5b89\u5168\u5206\u7c7b\u5668\u8fc7\u6ee4\u6570\u636e\u3001\u751f\u6210\u5408\u6210\u5b89\u5168\u6570\u636e\u96c6\u3001\u521b\u5efa\u7279\u5b9a\u6570\u636e\u96c6\u5e76\u6ce8\u5165\u6807\u8bb0\u4ee5\u5f15\u5bfc\u6a21\u578b\u3002", "result": "\u5c06\u653b\u51fb\u6210\u529f\u7387\u4ece38.8%\u964d\u81f38.4%\uff0c\u65e0\u6027\u80fd\u9000\u5316\u3002", "conclusion": "\u5b89\u5168\u9884\u8bad\u7ec3\u65b9\u6cd5\u6709\u6548\u964d\u4f4e\u6709\u5bb3\u751f\u6210\u98ce\u9669\u3002"}}
{"id": "2504.17211", "pdf": "https://arxiv.org/pdf/2504.17211", "abs": "https://arxiv.org/abs/2504.17211", "authors": ["Abdallah Alalem Albustami", "Ahmad F. Taha"], "title": "Breaking the Flow and the Bank: Stealthy Cyberattacks on Water Network Hydraulics", "categories": ["eess.SY", "cs.CR", "cs.SY"], "comment": null, "summary": "As water distribution networks (WDNs) become increasingly connected with\ndigital infrastructures, they face greater exposure to cyberattacks that\nthreaten their operational integrity. Stealthy False Data Injection Attacks\n(SFDIAs) are particularly concerning, as they manipulate sensor data to\ncompromise system operations while avoiding detection. While existing studies\nhave focused on either detection methods or specific attack formulations, the\nrelationship between attack sophistication, system knowledge requirements, and\nachievable impact remains unexplored. This paper presents a systematic analysis\nof sensor attacks against WDNs, investigating different combinations of\nphysical constraints, state monitoring requirements, and intrusion detection\nevasion conditions. We propose several attack formulations that range from\ntailored strategies satisfying both physical and detection constraints to\nsimpler measurement manipulations. The proposed attacks are simple and local --\nrequiring knowledge only of targeted sensors and their hydraulic connections --\nmaking them scalable and practical. Through case studies on Net1 and Net3\nbenchmark networks, we demonstrate how these attacks can persistently increase\noperational costs and alter water flows while remaining undetected by\nmonitoring systems for extended periods. The analysis provides utilities with\ninsights for vulnerability assessment and motivates the development of\nprotection strategies that combine physical and statistical security\nmechanisms.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u6c34\u5206\u914d\u7f51\u7edc\u9762\u5bf9\u9690\u853d\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\u7684\u7cfb\u7edf\u6027\u98ce\u9669\uff0c\u63d0\u51fa\u7b80\u5355\u53ef\u6269\u5c55\u7684\u653b\u51fb\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u672a\u63a2\u7d22\u653b\u51fb\u590d\u6742\u6027\u3001\u7cfb\u7edf\u77e5\u8bc6\u8981\u6c42\u4e0e\u5f71\u54cd\u95f4\u7684\u5173\u7cfb\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u591a\u79cd\u653b\u51fb\u5f62\u5f0f\uff0c\u7ed3\u5408\u7269\u7406\u7ea6\u675f\u548c\u68c0\u6d4b\u89c4\u907f\u6761\u4ef6\uff0c\u901a\u8fc7Net1\u548cNet3\u57fa\u51c6\u7f51\u7edc\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u653b\u51fb\u53ef\u6301\u4e45\u589e\u52a0\u8fd0\u8425\u6210\u672c\u3001\u6539\u53d8\u6c34\u6d41\u800c\u4e0d\u88ab\u68c0\u6d4b\u3002", "conclusion": "\u4e3a\u6f0f\u6d1e\u8bc4\u4f30\u63d0\u4f9b\u6d1e\u5bdf\uff0c\u5e76\u63a8\u52a8\u5f00\u53d1\u7ed3\u5408\u7269\u7406\u548c\u7edf\u8ba1\u5b89\u5168\u673a\u5236\u7684\u4fdd\u62a4\u7b56\u7565\u3002"}}
{"id": "2504.17295", "pdf": "https://arxiv.org/pdf/2504.17295", "abs": "https://arxiv.org/abs/2504.17295", "authors": ["Shahrzad Khayatbashi", "Viktor Sj\u00f6lind", "Anders Gran\u00e5ker", "Amin Jalali"], "title": "AI-Enhanced Business Process Automation: A Case Study in the Insurance Domain Using Object-Centric Process Mining", "categories": ["cs.AI"], "comment": null, "summary": "Recent advancements in Artificial Intelligence (AI), particularly Large\nLanguage Models (LLMs), have enhanced organizations' ability to reengineer\nbusiness processes by automating knowledge-intensive tasks. This automation\ndrives digital transformation, often through gradual transitions that improve\nprocess efficiency and effectiveness. To fully assess the impact of such\nautomation, a data-driven analysis approach is needed - one that examines how\ntraditional and AI-enhanced process variants coexist during this transition.\nObject-Centric Process Mining (OCPM) has emerged as a valuable method that\nenables such analysis, yet real-world case studies are still needed to\ndemonstrate its applicability. This paper presents a case study from the\ninsurance sector, where an LLM was deployed in production to automate the\nidentification of claim parts, a task previously performed manually and\nidentified as a bottleneck for scalability. To evaluate this transformation, we\napply OCPM to assess the impact of AI-driven automation on process scalability.\nOur findings indicate that while LLMs significantly enhance operational\ncapacity, they also introduce new process dynamics that require further\nrefinement. This study also demonstrates the practical application of OCPM in a\nreal-world setting, highlighting its advantages and limitations.", "AI": {"tldr": "\u672c\u8bba\u6587\u901a\u8fc7\u5bf9\u8c61\u4e2d\u5fc3\u8fc7\u7a0b\u6316\u6398\uff08OCPM\uff09\u5206\u6790\u4e86\u5728\u4fdd\u9669\u884c\u4e1a\u4e2d\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u5316\u7d22\u8d54\u90e8\u5206\u8bc6\u522b\u7684\u5f71\u54cd\uff0c\u5c55\u793a\u4e86\u5176\u63d0\u5347\u53ef\u4f38\u7f29\u6027\u4f46\u4e5f\u5f15\u5165\u65b0\u52a8\u6001\u7684\u4f18\u52bf\u548c\u5c40\u9650\u3002", "motivation": "\u8bc4\u4f30AI\u81ea\u52a8\u5316\u5982\u4f55\u5f71\u54cd\u4e1a\u52a1\u8fc7\u7a0b\u6570\u5b57\u8f6c\u578b\uff0c\u7279\u522b\u662f\u4f20\u7edf\u548cAI\u589e\u5f3a\u8fc7\u7a0b\u7684\u5171\u5b58\uff0c\u9700\u8981\u6570\u636e\u9a71\u52a8\u5206\u6790\u3002", "method": "\u91c7\u7528OCPM\u65b9\u6cd5\uff0c\u5728\u4fdd\u9669\u6848\u4f8b\u4e2d\u90e8\u7f72LLM\u81ea\u52a8\u5316\u7d22\u8d54\u8bc6\u522b\u4efb\u52a1\u3002", "result": "LLM\u663e\u8457\u63d0\u5347\u64cd\u4f5c\u5bb9\u91cf\uff0c\u4f46\u5f15\u5165\u65b0\u8fc7\u7a0b\u52a8\u6001\u9700\u4f18\u5316\uff1bOCPM\u8bc1\u660e\u4e86\u5176\u5b9e\u7528\u6027\u53ca\u5176\u9650\u5236\u3002", "conclusion": "\u7a81\u663eOCPM\u5728AI\u9a71\u52a8\u8fc7\u7a0b\u5206\u6790\u4e2d\u7684\u4f18\u52bf\u548c\u6311\u6218\u3002"}}
{"id": "2504.17004", "pdf": "https://arxiv.org/pdf/2504.17004", "abs": "https://arxiv.org/abs/2504.17004", "authors": ["Amin Karbasi", "Omar Montasser", "John Sous", "Grigoris Velegkas"], "title": "(Im)possibility of Automated Hallucination Detection in Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Is automated hallucination detection possible? In this work, we introduce a\ntheoretical framework to analyze the feasibility of automatically detecting\nhallucinations produced by large language models (LLMs). Inspired by the\nclassical Gold-Angluin framework for language identification and its recent\nadaptation to language generation by Kleinberg and Mullainathan, we investigate\nwhether an algorithm, trained on examples drawn from an unknown target language\n$K$ (selected from a countable collection) and given access to an LLM, can\nreliably determine whether the LLM's outputs are correct or constitute\nhallucinations.\n  First, we establish an equivalence between hallucination detection and the\nclassical task of language identification. We prove that any hallucination\ndetection method can be converted into a language identification method, and\nconversely, algorithms solving language identification can be adapted for\nhallucination detection. Given the inherent difficulty of language\nidentification, this implies that hallucination detection is fundamentally\nimpossible for most language collections if the detector is trained using only\ncorrect examples from the target language.\n  Second, we show that the use of expert-labeled feedback, i.e., training the\ndetector with both positive examples (correct statements) and negative examples\n(explicitly labeled incorrect statements), dramatically changes this\nconclusion. Under this enriched training regime, automated hallucination\ndetection becomes possible for all countable language collections.\n  These results highlight the essential role of expert-labeled examples in\ntraining hallucination detectors and provide theoretical support for\nfeedback-based methods, such as reinforcement learning with human feedback\n(RLHF), which have proven critical for reliable LLM deployment.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5206\u6790\u4e86\u662f\u5426\u53ef\u80fd\u81ea\u52a8\u68c0\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5e7b\u89c9\uff0c\u53d1\u73b0\u6ca1\u6709\u4e13\u5bb6\u53cd\u9988\u65f6\u4e0d\u53ef\u80fd\uff0c\u4f46\u6709\u53cd\u9988\u65f6\u53ef\u80fd\uff0c\u5e76\u652f\u6301RLHF\u7b49\u65b9\u6cd5\u3002", "motivation": "\u53d7Gold-Angluin\u6846\u67b6\u542f\u53d1\uff0c\u63a2\u8ba8\u81ea\u52a8\u68c0\u6d4bLLMs\u5e7b\u89c9\u7684\u53ef\u884c\u6027\u3002", "method": "\u5f15\u5165\u7406\u8bba\u6846\u67b6\uff0c\u5efa\u7acb\u5e7b\u89c9\u68c0\u6d4b\u4e0e\u8bed\u8a00\u8bc6\u522b\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u7814\u7a76\u4e13\u5bb6\u6807\u8bb0\u53cd\u9988\u7684\u5f71\u54cd\u3002", "result": "\u6ca1\u6709\u4e13\u5bb6\u6807\u8bb0\u53cd\u9988\u65f6\uff0c\u5e7b\u89c9\u68c0\u6d4b\u5728\u5927\u591a\u6570\u8bed\u8a00\u96c6\u5408\u4e2d\u4e0d\u53ef\u80fd\uff1b\u6709\u53cd\u9988\u65f6\uff0c\u5bf9\u6240\u6709\u53ef\u6570\u8bed\u8a00\u96c6\u5408\u6210\u4e3a\u53ef\u80fd\u3002", "conclusion": "\u5f3a\u8c03\u4e13\u5bb6\u6807\u8bb0\u793a\u4f8b\u5728\u8bad\u7ec3\u5e7b\u89c9\u68c0\u6d4b\u5668\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u4e3a\u53cd\u9988-based \u65b9\u6cd5\u5982RLHF\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2504.17347", "pdf": "https://arxiv.org/pdf/2504.17347", "abs": "https://arxiv.org/abs/2504.17347", "authors": ["Sribalaji C. Anand"], "title": "Analysis and Mitigation of Data injection Attacks against Data-Driven Control", "categories": ["eess.SY", "cs.SY"], "comment": "Under review for publication", "summary": "This paper investigates the impact of false data injection attacks on\ndata-driven control systems. Specifically, we consider an adversary injecting\nfalse data into the sensor channels during the learning phase. When the\noperator seeks to learn a stable state-feedback controller, we propose an\nattack strategy capable of misleading the operator into learning an unstable\nfeedback gain. We also investigate the effects of constant-bias injection\nattacks on data-driven linear quadratic regulation (LQR). Finally, we explore\npotential mitigation strategies and support our findings with numerical\nexamples.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\u5bf9\u6570\u636e\u9a71\u52a8\u63a7\u5236\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u653b\u51fb\u53ef\u5bfc\u81f4\u5b66\u4e60\u4e0d\u7a33\u5b9a\u63a7\u5236\u5668\uff0c\u5e76\u63a2\u8ba8\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u6570\u636e\u9a71\u52a8\u63a7\u5236\u7cfb\u7edf\u4e2d\u5b89\u5168\u95ee\u9898\uff0c\u9632\u6b62\u653b\u51fb\u8005\u5728\u5b66\u4e60\u9636\u6bb5\u6ce8\u5165\u865a\u5047\u6570\u636e\u5bfc\u81f4\u63a7\u5236\u5668\u4e0d\u7a33\u5b9a\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u63d0\u51fa\u653b\u51fb\u7b56\u7565\u8bef\u5bfc\u5b66\u4e60\u4e0d\u7a33\u5b9a\u53cd\u9988\u589e\u76ca\uff0c\u7814\u7a76\u5e38\u91cf\u504f\u5dee\u6ce8\u5165\u5bf9\u6570\u636e\u9a71\u52a8LQR\u7684\u5f71\u54cd\uff0c\u5e76\u63a2\u7d22\u7f13\u89e3\u7b56\u7565\uff0c\u4f7f\u7528\u6570\u503c\u4f8b\u5b50\u652f\u6301\u3002", "result": "\u7ed3\u679c\u663e\u793a\u653b\u51fb\u53ef\u5bfc\u81f4\u4e0d\u7a33\u5b9a\u63a7\u5236\u5668\u548cLQR\u6027\u80fd\u4e0b\u964d\uff0c\u6570\u503c\u4f8b\u5b50\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u53d1\u73b0\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u9632\u8303\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5efa\u8bae\u91c7\u7528\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2504.17356", "pdf": "https://arxiv.org/pdf/2504.17356", "abs": "https://arxiv.org/abs/2504.17356", "authors": ["Weiliang Zhang", "Xiaohan Huang", "Yi Du", "Ziyue Qiao", "Qingqing Long", "Zhen Meng", "Yuanchun Zhou", "Meng Xiao"], "title": "Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": "20 pages, keywords: Automated Feature Engineering, Tabular Dataset,\n  Multi-Agent Reinforcement Learning, Feature Selection", "summary": "Feature selection aims to preprocess the target dataset, find an optimal and\nmost streamlined feature subset, and enhance the downstream machine learning\ntask. Among filter, wrapper, and embedded-based approaches, the reinforcement\nlearning (RL)-based subspace exploration strategy provides a novel objective\noptimization-directed perspective and promising performance. Nevertheless, even\nwith improved performance, current reinforcement learning approaches face\nchallenges similar to conventional methods when dealing with complex datasets.\nThese challenges stem from the inefficient paradigm of using one agent per\nfeature and the inherent complexities present in the datasets. This observation\nmotivates us to investigate and address the above issue and propose a novel\napproach, namely HRLFS. Our methodology initially employs a Large Language\nModel (LLM)-based hybrid state extractor to capture each feature's mathematical\nand semantic characteristics. Based on this information, features are\nclustered, facilitating the construction of hierarchical agents for each\ncluster and sub-cluster. Extensive experiments demonstrate the efficiency,\nscalability, and robustness of our approach. Compared to contemporary or the\none-feature-one-agent RL-based approaches, HRLFS improves the downstream ML\nperformance with iterative feature subspace exploration while accelerating\ntotal run time by reducing the number of agents involved.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faHRLFS\u65b9\u6cd5\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f18\u5316\u7279\u5f81\u9009\u62e9\uff0c\u63d0\u9ad8\u673a\u5668\u5b66\u4e60\u6027\u80fd\u5e76\u52a0\u901f\u8fd0\u884c\u3002", "motivation": "\u5f53\u524dRL-based\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\uff0c\u5982\u6bcf\u4e2a\u7279\u5f81\u4e00\u4e2a\u4ee3\u7406\u548c\u6570\u636e\u96c6\u590d\u6742\u6027\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "HRLFS\u4f7f\u7528LLM-based\u6df7\u5408\u72b6\u6001\u63d0\u53d6\u5668\u6355\u83b7\u7279\u5f81\u7279\u6027\uff0c\u8fdb\u884c\u805a\u7c7b\u5e76\u6784\u5efa\u5206\u5c42\u4ee3\u7406\u63a2\u7d22\u7279\u5f81\u5b50\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eHRLFS\u63d0\u5347\u4e0b\u6e38ML\u6027\u80fd\uff0c\u51cf\u5c11\u4ee3\u7406\u6570\u91cf\uff0c\u52a0\u901f\u8fd0\u884c\u65f6\u95f4\uff0c\u5e76\u5c55\u793a\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "HRLFS\u4f18\u4e8e\u73b0\u6709RL\u65b9\u6cd5\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2504.17028", "pdf": "https://arxiv.org/pdf/2504.17028", "abs": "https://arxiv.org/abs/2504.17028", "authors": ["Iman Khadir", "Shane Stevenson", "Henry Li", "Kyle Krick", "Abram Burrows", "David Hall", "Stan Posey", "Samuel S. P. Shen"], "title": "Democracy of AI Numerical Weather Models: An Example of Global Forecasting with FourCastNetv2 Made by a University Research Lab Using GPU", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": "12 pages, 8 figures", "summary": "This paper demonstrates the feasibility of democratizing AI-driven global\nweather forecasting models among university research groups by leveraging\nGraphics Processing Units (GPUs) and freely available AI models, such as\nNVIDIA's FourCastNetv2. FourCastNetv2 is an NVIDIA's advanced neural network\nfor weather prediction and is trained on a 73-channel subset of the European\nCentre for Medium-Range Weather Forecasts (ECMWF) Reanalysis v5 (ERA5) dataset\nat single levels and different pressure levels. Although the training\nspecifications for FourCastNetv2 are not released to the public, the training\ndocumentation of the model's first generation, FourCastNet, is available to all\nusers. The training had 64 A100 GPUs and took 16 hours to complete. Although\nNVIDIA's models offer significant reductions in both time and cost compared to\ntraditional Numerical Weather Prediction (NWP), reproducing published\nforecasting results presents ongoing challenges for resource-constrained\nuniversity research groups with limited GPU availability. We demonstrate both\n(i) leveraging FourCastNetv2 to create predictions through the designated\napplication programming interface (API) and (ii) utilizing NVIDIA hardware to\ntrain the original FourCastNet model. Further, this paper demonstrates the\ncapabilities and limitations of NVIDIA A100's for resource-limited research\ngroups in universities. We also explore data management, training efficiency,\nand model validation, highlighting the advantages and challenges of using\nlimited high-performance computing resources. Consequently, this paper and its\ncorresponding GitHub materials may serve as an initial guide for other\nuniversity research groups and courses related to machine learning, climate\nscience, and data science to develop research and education programs on AI\nweather forecasting, and hence help democratize the AI NWP in the digital\neconomy.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7GPU\u548cNVIDIA\u7684FourCastNetv2\u7b49\u514d\u8d39AI\u6a21\u578b\uff0c\u4f7fAI\u9a71\u52a8\u7684\u5168\u7403\u5929\u6c14\u9884\u62a5\u5728\u5927\u5b66\u7814\u7a76\u7fa4\u4f53\u4e2d\u5b9e\u73b0\u6c11\u4e3b\u5316\u3002", "motivation": "\u89e3\u51b3\u8d44\u6e90\u53d7\u9650\u5927\u5b66\u7fa4\u4f53\u590d\u5236\u5929\u6c14\u9884\u62a5\u7ed3\u679c\u7684\u6311\u6218\uff0c\u5e76\u4fc3\u8fdbAI\u6570\u503c\u5929\u6c14\u9884\u62a5\uff08NWP\uff09\u7684\u6c11\u4e3b\u5316\u3002", "method": "\u5229\u7528FourCastNetv2 API\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u4f7f\u7528NVIDIA\u786c\u4ef6\u8bad\u7ec3FourCastNet\u6a21\u578b\uff1b\u63a2\u8ba8\u6570\u636e\u7ba1\u7406\u3001\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u9a8c\u8bc1\u3002", "result": "\u8bc1\u660e\u4e86\u4f7f\u7528\u6709\u9650GPU\u8d44\u6e90\u7684\u53ef\u884c\u6027\uff0c\u7a81\u51fa\u4e86NVIDIA A100\u7684\u80fd\u529b\u3001\u9650\u5236\u4ee5\u53ca\u4f18\u52bf\u4e0e\u6311\u6218\u3002", "conclusion": "\u53ef\u4f5c\u4e3a\u6307\u5357\uff0c\u5e2e\u52a9\u5176\u4ed6\u5927\u5b66\u7fa4\u4f53\u5f00\u53d1AI\u5929\u6c14\u9884\u62a5\u7a0b\u5e8f\uff0c\u4fc3\u8fdbAI NWP\u5728\u6570\u5b57\u7ecf\u6d4e\u4e2d\u7684\u666e\u53ca\u3002"}}
{"id": "2504.17406", "pdf": "https://arxiv.org/pdf/2504.17406", "abs": "https://arxiv.org/abs/2504.17406", "authors": ["Marco Peruzzo", "Giacomo Baggio", "Francesco Ticozzi"], "title": "Finding Conditions for Target Controllability under Christmas Trees", "categories": ["eess.SY", "cs.SY"], "comment": "Submitted at the Conference on Decision and Control 2025", "summary": "This paper presents new graph-theoretic conditions for structural target\ncontrollability of directed networks. After reviewing existing conditions and\nhighlighting some gaps in the literature, we introduce a new class of network\nsystems, named Christmas trees, which generalizes trees and cacti. We then\nestablish a graph-theoretic characterization of sets of nodes that are\nstructurally target controllable for a simple subclass of Christmas trees. Our\ncharacterization applies to general network systems by considering spanning\nsubgraphs of Christmas tree class and allows us to uncover target controllable\nsets that existing criteria fail to identify.", "AI": {"tldr": "\u672c\u8bba\u6587\u901a\u8fc7\u5f15\u5165Christmas trees\u7f51\u7edc\u7c7b\uff0c\u63d0\u51fa\u65b0\u7684\u56fe\u8bba\u6761\u4ef6\u6765\u6539\u8fdb\u5b9a\u5411\u7f51\u7edc\u7684\u7ed3\u6784\u76ee\u6807\u53ef\u63a7\u6027\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u6761\u4ef6\u5b58\u5728\u7a7a\u767d\uff0c\u65e0\u6cd5\u5b8c\u5168\u8bc6\u522b\u76ee\u6807\u53ef\u63a7\u8282\u70b9\u96c6\u3002", "method": "\u5f15\u5165Christmas trees\u7c7b\uff0c\u5e76\u4e3a\u5176\u5b9e\u9a8c\u5b50\u7c7b\u5efa\u7acb\u56fe\u8bba\u7279\u5f81\uff0c\u7136\u540e\u6269\u5c55\u5230\u4e00\u822c\u7f51\u7edc\u7684\u751f\u6210\u5b50\u56fe\u3002", "result": "\u53d1\u73b0\u4e86\u73b0\u6709\u6807\u51c6\u65e0\u6cd5\u8bc6\u522b\u7684\u76ee\u6807\u53ef\u63a7\u96c6\uff0c\u5e76\u63d0\u4f9b\u4e86\u65b0\u7684\u8868\u5f81\u65b9\u6cd5\u3002", "conclusion": "\u65b0\u7684\u6761\u4ef6\u63d0\u5347\u4e86\u7ed3\u6784\u76ee\u6807\u53ef\u63a7\u6027\u7684\u5206\u6790\u80fd\u529b\u3002"}}
{"id": "2504.17402", "pdf": "https://arxiv.org/pdf/2504.17402", "abs": "https://arxiv.org/abs/2504.17402", "authors": ["Anna Sofia Lippolis", "Mohammad Javad Saeedizade", "Robin Keskisarkka", "Aldo Gangemi", "Eva Blomqvist", "Andrea Giovanni Nuzzolese"], "title": "Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown significant potential for ontology\nengineering. However, it is still unclear to what extent they are applicable to\nthe task of domain-specific ontology generation. In this study, we explore the\napplication of LLMs for automated ontology generation and evaluate their\nperformance across different domains. Specifically, we investigate the\ngeneralizability of two state-of-the-art LLMs, DeepSeek and o1-preview, both\nequipped with reasoning capabilities, by generating ontologies from a set of\ncompetency questions (CQs) and related user stories. Our experimental setup\ncomprises six distinct domains carried out in existing ontology engineering\nprojects and a total of 95 curated CQs designed to test the models' reasoning\nfor ontology engineering. Our findings show that with both LLMs, the\nperformance of the experiments is remarkably consistent across all domains,\nindicating that these methods are capable of generalizing ontology generation\ntasks irrespective of the domain. These results highlight the potential of\nLLM-based approaches in achieving scalable and domain-agnostic ontology\nconstruction and lay the groundwork for further research into enhancing\nautomated reasoning and knowledge representation techniques.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30LLM\u5728\u9886\u57df\u7279\u5b9a\u672c\u4f53\u751f\u6210\u4e2d\u7684\u901a\u7528\u6027\uff0c\u5b9e\u9a8c\u663e\u793aDeepSeek\u548co1-preview\u6a21\u578b\u5728\u4e0d\u540c\u9886\u57df\u6027\u80fd\u4e00\u81f4\u3002", "motivation": "\u63a2\u8ba8LLM\u5728\u9886\u57df\u7279\u5b9a\u672c\u4f53\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u9002\u7528\u7a0b\u5ea6\uff0c\u56e0\u4e3a\u5176\u6f5c\u529b\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u4f7f\u7528DeepSeek\u548co1-preview\u6a21\u578b\uff0c\u4ece95\u4e2acompetency questions\u548cuser stories\u751f\u6210\u672c\u4f53\uff0c\u6d89\u53ca6\u4e2a\u4e0d\u540c\u9886\u57df\u3002", "result": "\u4e24\u4e2aLLM\u5728\u6240\u6709\u9886\u57df\u7684\u6027\u80fd\u9ad8\u5ea6\u4e00\u81f4\uff0c\u8bc1\u660e\u5176\u901a\u7528\u5316\u80fd\u529b\u3002", "conclusion": "\u5f3a\u8c03LLM\u53ef\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u9886\u57df\u65e0\u5173\u672c\u4f53\u6784\u5efa\uff0c\u5e76\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u81ea\u52a8\u63a8\u7406\u548c\u77e5\u8bc6\u8868\u793a\u6280\u672f\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2504.17058", "pdf": "https://arxiv.org/pdf/2504.17058", "abs": "https://arxiv.org/abs/2504.17058", "authors": ["Rahul Vishwakarma"], "title": "Statistical Guarantees in Synthetic Data through Conformal Adversarial Generation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The generation of high-quality synthetic data presents significant challenges\nin machine learning research, particularly regarding statistical fidelity and\nuncertainty quantification. Existing generative models produce compelling\nsynthetic samples but lack rigorous statistical guarantees about their relation\nto the underlying data distribution, limiting their applicability in critical\ndomains requiring robust error bounds. We address this fundamental limitation\nby presenting a novel framework that incorporates conformal prediction\nmethodologies into Generative Adversarial Networks (GANs). By integrating\nmultiple conformal prediction paradigms including Inductive Conformal\nPrediction (ICP), Mondrian Conformal Prediction, Cross-Conformal Prediction,\nand Venn-Abers Predictors, we establish distribution-free uncertainty\nquantification in generated samples. This approach, termed Conformalized GAN\n(cGAN), demonstrates enhanced calibration properties while maintaining the\ngenerative power of traditional GANs, producing synthetic data with provable\nstatistical guarantees. We provide rigorous mathematical proofs establishing\nfinite-sample validity guarantees and asymptotic efficiency properties,\nenabling the reliable application of synthetic data in high-stakes domains\nincluding healthcare, finance, and autonomous systems.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faConformalized GAN\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408conformal prediction\u65b9\u6cd5\uff0c\u63d0\u4f9b\u5408\u6210\u6570\u636e\u7684\u7edf\u8ba1\u4fdd\u8bc1\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u6a21\u578b\u7f3a\u4e4f\u4e25\u683c\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u9650\u5236\u4e86\u5728\u5173\u952e\u9886\u57df\u5982\u533b\u7597\u548c\u91d1\u878d\u7684\u5e94\u7528\u3002", "method": "\u5c06Inductive Conformal Prediction\u3001Mondrian Conformal Prediction\u7b49\u65b9\u6cd5\u6574\u5408\u5230GAN\u4e2d\uff0c\u5f62\u6210Conformalized GAN (cGAN)\u3002", "result": "cGAN\u63d0\u9ad8\u4e86\u5408\u6210\u6570\u636e\u7684\u6821\u51c6\u6027\u80fd\u548c\u7edf\u8ba1\u4fdd\u771f\u5ea6\uff0c\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u6709\u9650\u6837\u672c\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\u786e\u4fdd\u6e10\u8fdb\u6548\u7387\uff0c\u652f\u6301\u5728\u9ad8\u98ce\u9669\u9886\u57df\u53ef\u9760\u5e94\u7528\u3002"}}
{"id": "2504.17418", "pdf": "https://arxiv.org/pdf/2504.17418", "abs": "https://arxiv.org/abs/2504.17418", "authors": ["Phillip Pitschi", "Simon Sagmeister", "Sven Goblirsch", "Markus Lienkamp", "Boris Lohmann"], "title": "Longitudinal Control for Autonomous Racing with Combustion Engine Vehicles", "categories": ["eess.SY", "cs.RO", "cs.SY"], "comment": "8 pages, 9 Figures", "summary": "Usually, a controller for path- or trajectory tracking is employed in\nautonomous driving. Typically, these controllers generate high-level commands\nlike longitudinal acceleration or force. However, vehicles with combustion\nengines expect different actuation inputs. This paper proposes a longitudinal\ncontrol concept that translates high-level trajectory-tracking commands to the\nrequired low-level vehicle commands such as throttle, brake pressure and a\ndesired gear. We chose a modular structure to easily integrate different\ntrajectory-tracking control algorithms and vehicles. The proposed control\nconcept enables a close tracking of the high-level control command. An\nanti-lock braking system, traction control, and brake warmup control also\nensure a safe operation during real-world tests. We provide experimental\nvalidation of our concept using real world data with longitudinal accelerations\nreaching up to $25 \\, \\frac{\\mathrm{m}}{\\mathrm{s}^2}$. The experiments were\nconducted using the EAV24 racecar during the first event of the Abu Dhabi\nAutonomous Racing League on the Yas Marina Formula 1 Circuit.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7eb5\u5411\u63a7\u5236\u6982\u5ff5\uff0c\u5c06\u9ad8\u7ea7\u8f68\u8ff9\u8ddf\u8e2a\u547d\u4ee4\u8f6c\u6362\u4e3a\u4f4e\u7ea7\u8f66\u8f86\u547d\u4ee4\uff0c\u5982\u6cb9\u95e8\u3001\u5236\u52a8\u538b\u529b\u548c\u6863\u4f4d\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u8d5b\u8f66\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u4f20\u7edf\u63a7\u5236\u5668\u751f\u6210\u7684\u9ad8\u7ea7\u547d\u4ee4\uff08\u5982\u7eb5\u5411\u52a0\u901f\u5ea6\uff09\u4e0e\u5185\u71c3\u673a\u8f66\u8f86\u6240\u9700\u4f4e\u7ea7\u8f93\u5165\uff08\u5982\u6cb9\u95e8\u3001\u5236\u52a8\u548c\u6863\u4f4d\uff09\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002", "method": "\u65b9\u6cd5\u662f\u8bbe\u8ba1\u4e00\u4e2a\u6a21\u5757\u5316\u7eb5\u5411\u63a7\u5236\u7cfb\u7edf\uff0c\u7ffb\u8bd1\u9ad8\u7ea7\u547d\u4ee4\u4e3a\u4f4e\u7ea7\u8f66\u8f86\u547d\u4ee4\uff0c\u5e76\u96c6\u6210\u9632\u62b1\u6b7b\u5236\u52a8\u3001\u7275\u5f15\u529b\u63a7\u5236\u548c\u5236\u52a8\u9884\u70ed\u529f\u80fd\u3002", "result": "\u7ed3\u679c\u662f\u901a\u8fc7EAV24\u8d5b\u8f66\u5728\u963f\u5e03\u624e\u6bd4\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u8054\u8d5b\u7684\u5b9e\u8bc1\u6d4b\u8bd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe25 m/s\u00b2\u7684\u7eb5\u5411\u52a0\u901f\u5ea6\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8be5\u63a7\u5236\u6982\u5ff5\u5b9e\u73b0\u4e86\u9ad8\u7ea7\u547d\u4ee4\u7684\u7cbe\u786e\u8ddf\u8e2a\uff0c\u5e76\u786e\u4fdd\u4e86\u5b9e\u9645\u6d4b\u8bd5\u4e2d\u7684\u5b89\u5168\u64cd\u4f5c\u3002"}}
{"id": "2504.17404", "pdf": "https://arxiv.org/pdf/2504.17404", "abs": "https://arxiv.org/abs/2504.17404", "authors": ["Feifei Zhao", "Yuwei Wang", "Enmeng Lu", "Dongcheng Zhao", "Bing Han", "Haibo Tong", "Yao Liang", "Dongqi Liang", "Kang Sun", "Lei Wang", "Yitao Liang", "Chao Liu", "Yaodong Yang", "Yi Zeng"], "title": "Redefining Superalignment: From Weak-to-Strong Alignment to Human-AI Co-Alignment to Sustainable Symbiotic Society", "categories": ["cs.AI"], "comment": null, "summary": "Artificial Intelligence (AI) systems are becoming increasingly powerful and\nautonomous, and may progress to surpass human intelligence levels, namely\nArtificial Superintelligence (ASI). During the progression from AI to ASI, it\nmay exceed human control, violate human values, and even lead to irreversible\ncatastrophic consequences in extreme cases. This gives rise to a pressing issue\nthat needs to be addressed: superalignment, ensuring that AI systems much\nsmarter than humans, remain aligned with human (compatible) intentions and\nvalues. Existing scalable oversight and weak-to-strong generalization methods\nmay prove substantially infeasible and inadequate when facing ASI. We must\nexplore safer and more pluralistic frameworks and approaches for\nsuperalignment. In this paper, we redefine superalignment as the human-AI\nco-alignment towards a sustainable symbiotic society, and highlight a framework\nthat integrates external oversight and intrinsic proactive alignment. External\noversight superalignment should be grounded in human-centered ultimate\ndecision, supplemented by interpretable automated evaluation and correction, to\nachieve continuous alignment with humanity's evolving values. Intrinsic\nproactive superalignment is rooted in a profound understanding of the self,\nothers, and society, integrating self-awareness, self-reflection, and empathy\nto spontaneously infer human intentions, distinguishing good from evil and\nproactively considering human well-being, ultimately attaining human-AI\nco-alignment through iterative interaction. The integration of\nexternally-driven oversight with intrinsically-driven proactive alignment\nempowers sustainable symbiotic societies through human-AI co-alignment, paving\nthe way for achieving safe and beneficial AGI and ASI for good, for human, and\nfor a symbiotic ecology.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u91cd\u65b0\u5b9a\u4e49\u8d85\u5bf9\u9f50\u4e3a\u4eba\u7c7b-\u4eba\u5de5\u667a\u80fd\u5171\u540c\u5bf9\u9f50\uff0c\u63d0\u51fa\u6574\u5408\u5916\u90e8\u76d1\u7763\u548c\u5185\u5728\u4e3b\u52a8\u5bf9\u9f50\u7684\u6846\u67b6\uff0c\u4ee5\u5b9e\u73b0\u53ef\u6301\u7eed\u5171\u751f\u793e\u4f1a\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u53ef\u80fd\u8d85\u8d8a\u4eba\u7c7b\u63a7\u5236\u5e76\u5bfc\u81f4\u707e\u96be\u6027\u540e\u679c\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u66f4\u5b89\u5168\u7684\u591a\u7ef4\u8d85\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u5305\u62ec\u57fa\u4e8e\u4eba\u7c7b\u51b3\u7b56\u7684\u5916\u90e8\u76d1\u7763\uff08\u5982\u53ef\u89e3\u91ca\u81ea\u52a8\u8bc4\u4f30\uff09\u548c\u57fa\u4e8e\u81ea\u6211\u610f\u8bc6\u3001\u81ea\u6211\u53cd\u601d\u3001\u540c\u7406\u5fc3\u7684\u5185\u5728\u4e3b\u52a8\u5bf9\u9f50\uff0c\u901a\u8fc7\u8fed\u4ee3\u4e92\u52a8\u5b9e\u73b0\u5bf9\u9f50\u3002", "result": "\u6846\u67b6\u6574\u5408\u5916\u90e8\u548c\u5185\u5728\u65b9\u6cd5\uff0c\u4fc3\u8fdb\u4eba\u7c7b-\u4eba\u5de5\u667a\u80fd\u5171\u540c\u5bf9\u9f50\uff0c\u652f\u6491\u5b89\u5168AGI\u548cASI\u7684\u53d1\u5c55\u3002", "conclusion": "\u901a\u8fc7\u8fd9\u79cd\u6574\u5408\uff0c\u4eba\u7c7b\u548c\u4eba\u5de5\u667a\u80fd\u53ef\u5171\u540c\u6784\u5efa\u53ef\u6301\u7eed\u7684\u5171\u751f\u793e\u4f1a\uff0c\u786e\u4fddAI\u4e3a\u4eba\u7c7b\u798f\u7949\u670d\u52a1\u3002"}}
{"id": "2504.17065", "pdf": "https://arxiv.org/pdf/2504.17065", "abs": "https://arxiv.org/abs/2504.17065", "authors": ["Sahar Bagherkhani", "Jackson Christopher Earls", "Franco De Flaviis", "Pierre Baldi"], "title": "Antenna Near-Field Reconstruction from Far-Field Data Using Convolutional Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Electromagnetic field reconstruction is crucial in many applications,\nincluding antenna diagnostics, electromagnetic interference analysis, and\nsystem modeling. This paper presents a deep learning-based approach for\nFar-Field to Near-Field (FF-NF) transformation using Convolutional Neural\nNetworks (CNNs). The goal is to reconstruct near-field distributions from the\nfar-field data of an antenna without relying on explicit analytical\ntransformations. The CNNs are trained on paired far-field and near-field data\nand evaluated using mean squared error (MSE). The best model achieves a\ntraining error of 0.0199 and a test error of 0.3898. Moreover, visual\ncomparisons between the predicted and true near-field distributions demonstrate\nthe model's effectiveness in capturing complex electromagnetic field behavior,\nhighlighting the potential of deep learning in electromagnetic field\nreconstruction.", "AI": {"tldr": "This paper uses CNNs to reconstruct near-field electromagnetic distributions from far-field data, achieving low errors and demonstrating deep learning's potential.", "motivation": "To enable electromagnetic field reconstruction for applications like antenna diagnostics without explicit analytical transformations.", "method": "Convolutional Neural Networks trained on paired far-field and near-field data, evaluated with mean squared error (MSE).", "result": "Best model achieves training error of 0.0199 and test error of 0.3898, with visual comparisons showing effective capture of field behavior.", "conclusion": "Highlights the potential of deep learning in electromagnetic field reconstruction."}}
{"id": "2504.17512", "pdf": "https://arxiv.org/pdf/2504.17512", "abs": "https://arxiv.org/abs/2504.17512", "authors": ["Andres Intriago", "Alexandros Paspatis", "Francesco Liberati", "Charalambos Konstantinou"], "title": "Admittance Identification of Grid-Forming Inverters Using Time and Frequency-Domain Techniques", "categories": ["eess.SY", "cs.SY"], "comment": "2025 IEEE Kiel PowerTech", "summary": "The increasing integration of inverter-based resources (IBRs) into the power\ngrid introduces new challenges, requiring detailed electromagnetic transient\n(EMT) studies to analyze system interactions. Despite these needs, access to\nthe internal firmware of power electronic devices remains restricted due to\nstringent nondisclosure agreements enforced by manufacturers. To address this,\nwe explore three system identification techniques: sweep frequency response\nanalysis (SFRA), step excitation method (SEM), and eigensystem realization\nalgorithm (ERA). SFRA employs sinusoidal signals of varying frequencies to\nmeasure the system's frequency response, while SEM and ERA utilize step\nfunctions to derive time-domain responses and transform them into\nLaplace-domain transfer functions. All three approaches are shown to provide\nconsistent results in identifying the dq admittance of grid-forming inverters\n(GFM) over a frequency range of 1 Hz to 100 Hz.", "AI": {"tldr": "\u672c\u8bba\u6587\u4f7f\u7528SFRA\u3001SEM\u548cERA\u4e09\u79cd\u6280\u672f\u4e00\u81f4\u8bc6\u522b\u7f51\u683c\u5f62\u6210\u9006\u53d8\u5668\u7684dq\u5bfc\u7eb3\uff0c\u89e3\u51b3IBRs\u6574\u5408\u4e2d\u56fa\u4ef6\u8bbf\u95ee\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u7535\u529b\u7f51\u683cIBRs\u589e\u52a0\u9700\u8981EMT\u7814\u7a76\uff0c\u4f46\u5236\u9020\u5546\u4fdd\u5bc6\u534f\u8bae\u9650\u5236\u56fa\u4ef6\u8bbf\u95ee\u3002", "method": "\u63a2\u7d22SFRA\uff08\u9891\u7387\u626b\u63cf\uff09\u3001SEM\u548cERA\uff08\u9636\u8dc3\u54cd\u5e94\u8f6cLaplace\u57df\uff09\u4e09\u79cd\u7cfb\u7edf\u8bc6\u522b\u6280\u672f\u3002", "result": "\u4e09\u79cd\u65b9\u6cd5\u57281-100Hz\u8303\u56f4\u5185\u4e3aGFM\u9006\u53d8\u5668\u63d0\u4f9b\u4e00\u81f4\u7684dq\u5bfc\u7eb3\u8bc6\u522b\u3002", "conclusion": "\u8fd9\u4e9b\u6280\u672f\u53ef\u6709\u6548\u66ff\u4ee3\u56fa\u4ef6\u8bbf\u95ee\uff0c\u5b9e\u73b0\u53ef\u9760\u7cfb\u7edf\u54cd\u5e94\u5206\u6790\u3002"}}
{"id": "2504.17531", "pdf": "https://arxiv.org/pdf/2504.17531", "abs": "https://arxiv.org/abs/2504.17531", "authors": ["Justus Flerlage", "Ilja Behnke", "Odej Kao"], "title": "Towards Machine-Generated Code for the Resolution of User Intentions", "categories": ["cs.AI"], "comment": null, "summary": "The growing capabilities of Artificial Intelligence (AI), particularly Large\nLanguage Models (LLMs), prompt a reassessment of the interaction mechanisms\nbetween users and their devices. Currently, users are required to use a set of\nhigh-level applications to achieve their desired results. However, the advent\nof AI may signal a shift in this regard, as its capabilities have generated\nnovel prospects for user-provided intent resolution through the deployment of\nmodel-generated code, which is tantamount to the generation of workflows\ncomprising a multitude of interdependent steps. This development represents a\nsignificant progression in the realm of hybrid workflows, where human and\nartificial intelligence collaborate to address user intentions, with the former\nresponsible for defining these intentions and the latter for implementing the\nsolutions to address them. In this paper, we investigate the feasibility of\ngenerating and executing workflows through code generation that results from\nprompting an LLM with a concrete user intention, such as \\emph{Please send my\ncar title to my insurance company}, and a simplified application programming\ninterface for a GUI-less operating system. We provide in-depth analysis and\ncomparison of various user intentions, the resulting code, and its execution.\nThe findings demonstrate a general feasibility of our approach and that the\nemployed LLM, GPT-4o-mini, exhibits remarkable proficiency in the generation of\ncode-oriented workflows in accordance with provided user intentions.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u4ee3\u7801\u4ee5\u5b9e\u73b0\u7528\u6237\u610f\u56fe\u7684\u5de5\u4f5c\u6d41\uff0c\u5e76\u901a\u8fc7GPT-4o-mini\u5c55\u793a\u4e86\u5176\u53ef\u884c\u6027\u3002", "motivation": "\u52a8\u673a\u662f\u91cd\u65b0\u8bc4\u4f30AI\u8fdb\u6b65\u4e0b\u7528\u6237\u4e0e\u8bbe\u5907\u4ea4\u4e92\u673a\u5236\uff0c\u4ece\u4f9d\u8d56\u9ad8\u7ea7\u5e94\u7528\u8f6c\u5411AI\u751f\u6210\u7684\u5de5\u4f5c\u6d41\uff0c\u4ee5\u66f4\u597d\u5730\u5904\u7406\u7528\u6237\u610f\u56fe\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u7528\u6237\u610f\u56fe\u63d0\u793aLLM\uff08\u5982GPT-4o-mini\uff09\u751f\u6210\u4ee3\u7801\uff0c\u5e76\u901a\u8fc7\u7b80\u5316API\u6267\u884c\u5de5\u4f5c\u6d41\u3002", "result": "\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u603b\u4f53\u53ef\u884c\uff0c\u4e14GPT-4o-mini\u5728\u751f\u6210\u4ee3\u7801\u5bfc\u5411\u5de5\u4f5c\u6d41\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u7ed3\u8bba\u662f\u6df7\u5408\u4eba\u7c7b-AI\u5de5\u4f5c\u6d41\u5177\u6709\u524d\u666f\uff0cAI\u53ef\u6709\u6548\u5b9e\u73b0\u7528\u6237\u5b9a\u4e49\u7684\u610f\u56fe\u3002"}}
{"id": "2504.17066", "pdf": "https://arxiv.org/pdf/2504.17066", "abs": "https://arxiv.org/abs/2504.17066", "authors": ["Kewen Peng", "Yicheng Yang", "Hao Zhuo", "Tim Menzies"], "title": "Whence Is A Model Fair? Fixing Fairness Bugs via Propensity Score Matching", "categories": ["cs.LG", "cs.CY", "cs.SE", "stat.ML"], "comment": null, "summary": "Fairness-aware learning aims to mitigate discrimination against specific\nprotected social groups (e.g., those categorized by gender, ethnicity, age)\nwhile minimizing predictive performance loss. Despite efforts to improve\nfairness in machine learning, prior studies have shown that many models remain\nunfair when measured against various fairness metrics. In this paper, we\nexamine whether the way training and testing data are sampled affects the\nreliability of reported fairness metrics. Since training and test sets are\noften randomly sampled from the same population, bias present in the training\ndata may still exist in the test data, potentially skewing fairness\nassessments. To address this, we propose FairMatch, a post-processing method\nthat applies propensity score matching to evaluate and mitigate bias. FairMatch\nidentifies control and treatment pairs with similar propensity scores in the\ntest set and adjusts decision thresholds for different subgroups accordingly.\nFor samples that cannot be matched, we perform probabilistic calibration using\nfairness-aware loss functions. Experimental results demonstrate that our\napproach can (a) precisely locate subsets of the test data where the model is\nunbiased, and (b) significantly reduce bias on the remaining data. Overall,\npropensity score matching offers a principled way to improve both fairness\nevaluation and mitigation, without sacrificing predictive performance.", "AI": {"tldr": "\u4f7f\u7528\u503e\u5411\u5f97\u5206\u5339\u914d\u6539\u5584\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u548c\u504f\u89c1\u7f13\u89e3\u65b9\u6cd5\u3002", "motivation": "\u8bb8\u591a\u6a21\u578b\u5728\u516c\u5e73\u5ea6\u91cf\u4e0b\u4ecd\u4e0d\u516c\u5e73\uff0c\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u7684\u968f\u673a\u91c7\u6837\u53ef\u80fd\u5bfc\u81f4\u6d4b\u8bd5\u6570\u636e\u4e2d\u5b58\u5728\u504f\u89c1\uff0c\u626d\u66f2\u516c\u5e73\u8bc4\u4f30\u3002", "method": "\u63d0\u51faFairMatch\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u503e\u5411\u5f97\u5206\u5339\u914d\u8bc6\u522b\u6d4b\u8bd5\u96c6\u4e2d\u7684\u63a7\u5236\u548c\u5904\u7406\u7ec4\u5bf9\uff0c\u8c03\u6574\u5b50\u7fa4\u4f53\u51b3\u7b56\u9608\u503c\uff1b\u5bf9\u65e0\u6cd5\u5339\u914d\u6837\u672c\u4f7f\u7528\u57fa\u4e8e\u516c\u5e73\u6027\u635f\u5931\u51fd\u6570\u7684\u6982\u7387\u6821\u51c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u53ef\u7cbe\u786e\u5b9a\u4f4d\u65e0\u504f\u89c1\u5b50\u96c6\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u5269\u4f59\u6570\u636e\u7684\u504f\u89c1\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u503e\u5411\u5f97\u5206\u5339\u914d\u63d0\u4f9b\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u63d0\u5347\u516c\u5e73\u6027\u8bc4\u4f30\u548c\u7f13\u89e3\uff0c\u800c\u4e0d\u5f71\u54cd\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2504.17571", "pdf": "https://arxiv.org/pdf/2504.17571", "abs": "https://arxiv.org/abs/2504.17571", "authors": ["Andreas Bouterakos", "Joseph McKeon", "Georgios Tzounas"], "title": "On the Eigenvalue Tracking of Large-Scale Systems", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "The paper focuses on the problem of tracking eigenvalue trajectories in\nlarge-scale power system models as system parameters vary. A continuation-based\nformulation is presented for tracing any single eigenvalue of interest, which\nsupports sparse matrix representations and accommodates both explicit and\nsemi-implicit differential-algebraic models. Key implementation aspects, such\nas numerical integration, matrix updates, derivative approximations, and\nhandling defective eigenvalues, are discussed in detail and practical\nrecommendations are duly provided. The tracking approach is demonstrated\nthrough a comprehensive case study on the IEEE 39-bus system, as well as on a\nrealistic dynamic model of the Irish transmission system.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fde\u7eed\u6027\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8ddf\u8e2a\u5927\u5c3a\u5ea6\u7535\u529b\u7cfb\u7edf\u6a21\u578b\u4e2d\u7279\u5f81\u503c\u8f68\u8ff9\u7684\u53d8\u5316\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u9645\u5b9e\u73b0\u548c\u6848\u4f8b\u7814\u7a76\u3002", "motivation": "\u8bba\u6587\u7684\u52a8\u673a\u662f\u89e3\u51b3\u5728\u7cfb\u7edf\u53c2\u6570\u53d8\u5316\u65f6\u8ddf\u8e2a\u7535\u529b\u7cfb\u7edf\u6a21\u578b\u4e2d\u7279\u5f81\u503c\u8f68\u8ff9\u7684\u95ee\u9898\uff0c\u8fd9\u5bf9\u4e8e\u7cfb\u7edf\u7a33\u5b9a\u6027\u5206\u6790\u81f3\u5173\u91cd\u8981\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4e00\u79cd\u57fa\u4e8e\u8fde\u7eed\u6027\u7684\u516c\u5f0f\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u8ddf\u8e2a\u4efb\u610f\u5355\u4e2a\u7279\u5f81\u503c\uff0c\u652f\u6301\u7a00\u758f\u77e9\u9635\u8868\u793a\uff0c\u5e76\u9002\u7528\u4e8e\u663e\u5f0f\u548c\u534a\u9690\u5f0f\u5fae\u5206\u4ee3\u6570\u6a21\u578b\u3002\u8be6\u7ec6\u8ba8\u8bba\u4e86\u6570\u503c\u79ef\u5206\u3001\u77e9\u9635\u66f4\u65b0\u3001\u5bfc\u6570\u903c\u8fd1\u4ee5\u53ca\u5904\u7406\u7f3a\u9677\u7279\u5f81\u503c\u7b49\u65b9\u9762\u3002", "result": "\u901a\u8fc7\u5bf9IEEE 39\u6bcd\u7ebf\u7cfb\u7edf\u548c\u7231\u5c14\u5170\u8f93\u7535\u7cfb\u7edf\u7684\u771f\u5b9e\u52a8\u6001\u6a21\u578b\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8bba\u6587\u63d0\u4f9b\u4e86\u5b9e\u9645\u5b9e\u73b0\u7684\u5b9e\u7528\u5efa\u8bae\uff0c\u5e76\u5f97\u51fa\u7ed3\u8bba\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u7535\u529b\u7cfb\u7edf\u5206\u6790\u4e2d\u662f\u7a33\u5065\u4e14\u9002\u7528\u7684\u3002"}}
{"id": "2504.17544", "pdf": "https://arxiv.org/pdf/2504.17544", "abs": "https://arxiv.org/abs/2504.17544", "authors": ["W. Russell Neuman", "Chad Coleman", "Ali Dasdan", "Safinah Ali", "Manan Shah"], "title": "Auditing the Ethical Logic of Generative AI Models", "categories": ["cs.AI"], "comment": null, "summary": "As generative AI models become increasingly integrated into high-stakes\ndomains, the need for robust methods to evaluate their ethical reasoning\nbecomes increasingly important. This paper introduces a five-dimensional audit\nmodel -- assessing Analytic Quality, Breadth of Ethical Considerations, Depth\nof Explanation, Consistency, and Decisiveness -- to evaluate the ethical logic\nof leading large language models (LLMs). Drawing on traditions from applied\nethics and higher-order thinking, we present a multi-battery prompt approach,\nincluding novel ethical dilemmas, to probe the models' reasoning across diverse\ncontexts. We benchmark seven major LLMs finding that while models generally\nconverge on ethical decisions, they vary in explanatory rigor and moral\nprioritization. Chain-of-Thought prompting and reasoning-optimized models\nsignificantly enhance performance on our audit metrics. This study introduces a\nscalable methodology for ethical benchmarking of AI systems and highlights the\npotential for AI to complement human moral reasoning in complex decision-making\ncontexts.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165\u4e86\u4e00\u4e2a\u4e94\u7ef4\u5ba1\u8ba1\u6a21\u578b\u6765\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4f26\u7406\u63a8\u7406\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u5c55\u793a\u4e86\u6a21\u578b\u6027\u80fd\u7684\u5dee\u5f02\u3002", "motivation": "\u751f\u6210AI\u6a21\u578b\u65e5\u76ca\u6574\u5408\u5230\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u9700\u8981\u9c81\u68d2\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u5176\u4f26\u7406\u63a8\u7406\u3002", "method": "\u4f7f\u7528\u591a\u7535\u6c60\u63d0\u793a\u65b9\u6cd5\uff0c\u5305\u62ec\u65b0\u9896\u7684\u4f26\u7406\u56f0\u5883\uff0c\u5bf9\u4e03\u4e2a\u4e3b\u8981LLM\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u57fa\u4e8e\u4e94\u7ef4\u6a21\u578b\uff08\u5206\u6790\u8d28\u91cf\u3001\u4f26\u7406\u8003\u8651\u5e7f\u5ea6\u3001\u89e3\u91ca\u6df1\u5ea6\u3001\u4e00\u81f4\u6027\u548c\u51b3\u65ad\u529b\uff09\u8bc4\u4f30\u3002", "result": "\u6a21\u578b\u5728\u4f26\u7406\u51b3\u7b56\u4e0a\u8d8b\u540c\uff0c\u4f46\u89e3\u91ca\u4e25\u8c28\u5ea6\u548c\u9053\u5fb7\u4f18\u5148\u7ea7\u5b58\u5728\u5dee\u5f02\uff1bChain-of-Thought\u63d0\u793a\u548c\u4f18\u5316\u63a8\u7406\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "\u5f15\u5165\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684AI\u4f26\u7406\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5e76\u5f3a\u8c03AI\u53ef\u8865\u5145\u4eba\u7c7b\u9053\u5fb7\u63a8\u7406\u3002"}}
{"id": "2504.17068", "pdf": "https://arxiv.org/pdf/2504.17068", "abs": "https://arxiv.org/abs/2504.17068", "authors": ["Pranav Kantroo", "G\u00fcnter P. Wagner", "Benjamin B. Machta"], "title": "In-Context Learning can distort the relationship between sequence likelihoods and biological fitness", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Language models have emerged as powerful predictors of the viability of\nbiological sequences. During training these models learn the rules of the\ngrammar obeyed by sequences of amino acids or nucleotides. Once trained, these\nmodels can take a sequence as input and produce a likelihood score as an\noutput; a higher likelihood implies adherence to the learned grammar and\ncorrelates with experimental fitness measurements. Here we show that in-context\nlearning can distort the relationship between fitness and likelihood scores of\nsequences. This phenomenon most prominently manifests as anomalously high\nlikelihood scores for sequences that contain repeated motifs. We use protein\nlanguage models with different architectures trained on the masked language\nmodeling objective for our experiments, and find transformer-based models to be\nparticularly vulnerable to this effect. This behavior is mediated by a look-up\noperation where the model seeks the identity of the masked position by using\nthe other copy of the repeated motif as a reference. This retrieval behavior\ncan override the model's learned priors. This phenomenon persists for\nimperfectly repeated sequences, and extends to other kinds of biologically\nrelevant features such as reversed complement motifs in RNA sequences that fold\ninto hairpin structures.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u4f1a\u626d\u66f2\u751f\u7269\u5e8f\u5217\u9002\u5e94\u6027\u9884\u6d4b\uff0c\u7279\u522b\u662f\u5bf9\u91cd\u590d\u57fa\u5e8f\u7684\u5e8f\u5217\u3002", "motivation": "\u63ed\u793a\u8bed\u8a00\u6a21\u578b\u5728\u751f\u7269\u5e8f\u5217\u9884\u6d4b\u4e2d\u5b58\u5728\u7684\u6f5c\u5728\u7f3a\u9677\uff0c\u4ee5\u63d0\u9ad8\u5176\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u4e0d\u540c\u67b6\u6784\u7684\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\uff0c\u8bad\u7ec3\u4e8e\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\uff0c\u5e76\u6d4b\u8bd5\u91cd\u590d\u57fa\u5e8f\u5e8f\u5217\u3002", "result": "\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u6a21\u578b\u6613\u53d7\u5f71\u54cd\uff0c\u539f\u56e0\u5728\u4e8e\u67e5\u627e\u64cd\u4f5c\u8986\u76d6\u5148\u9a8c\u77e5\u8bc6\uff0c\u5e76\u5ef6\u4f38\u81f3\u4e0d\u5b8c\u7f8e\u91cd\u590d\u548cRNA\u7279\u5f81\u3002", "conclusion": "\u6b64\u73b0\u8c61\u8868\u660e\u8bed\u8a00\u6a21\u578b\u5728\u751f\u7269\u5e94\u7528\u4e2d\u53ef\u80fd\u4e0d\u53ef\u9760\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u3002"}}
{"id": "2504.17603", "pdf": "https://arxiv.org/pdf/2504.17603", "abs": "https://arxiv.org/abs/2504.17603", "authors": ["Peng Ye", "Juan Du"], "title": "SAPO-RL: Sequential Actuator Placement Optimization for Fuselage Assembly via Reinforcement Learning", "categories": ["eess.SY", "cs.SY"], "comment": "27 pages, 14 figures", "summary": "Precise assembly of composite fuselages is critical for aircraft assembly to\nmeet the ultra-high precision requirements. Due to dimensional variations,\nthere is a gap when two fuselage assemble. In practice, actuators are required\nto adjust fuselage dimensions by applying forces to specific points on fuselage\nedge through pulling or pushing force actions. The positioning and force\nsettings of these actuators significantly influence the efficiency of the shape\nadjustments. The current literature usually predetermines the fixed number of\nactuators, which is not optimal in terms of overall quality and corresponding\nactuator costs. However, optimal placement of actuators in terms of both\nlocations and number is challenging due to compliant structures, complex\nmaterial properties, and dimensional variabilities of incoming fuselages. To\naddress these challenges, this paper introduces a reinforcement learning (RL)\nframework that enables sequential decision-making for actuator placement\nselection and optimal force computation. Specifically, our methodology employs\nthe Dueling Double Deep Q-Learning (D3QN) algorithm to refine the\ndecision-making capabilities of sequential actuator placements. The environment\nis meticulously crafted to enable sequential and incremental selection of an\nactuator based on system states. We formulate the actuator selection problem as\na submodular function optimization problem, where the sub-modularity properties\ncan be adopted to efficiently achieve near-optimal solutions. The proposed\nmethodology has been comprehensively evaluated through numerical studies and\ncomparison studies, demonstrating its effectiveness and outstanding performance\nin enhancing assembly precision with limited actuator numbers.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u98de\u673a\u673a\u8eab\u7ec4\u88c5\u4e2d\u7684\u6267\u884c\u5668\u653e\u7f6e\u548c\u529b\u8bbe\u7f6e\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7ec4\u88c5\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u5f53\u524d\u56fa\u5b9a\u6267\u884c\u5668\u6570\u91cf\u65b9\u6cd5\u7684\u4e0d\u4f18\u95ee\u9898\uff0c\u4ee5\u53ca\u5904\u7406\u987a\u5e94\u7ed3\u6784\u3001\u590d\u6742\u6750\u6599\u548c\u5c3a\u5bf8\u53d8\u5f02\u6027\u7684\u6311\u6218\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528Dueling Double Deep Q-Learning (D3QN)\u7b97\u6cd5\u8fdb\u884c\u987a\u5e8f\u51b3\u7b56\u6267\u884c\u5668\u653e\u7f6e\uff0c\u5e76\u5c06\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u6b21\u6a21\u51fd\u6570\u4f18\u5316\u95ee\u9898\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u6570\u503c\u548c\u6bd4\u8f83\u7814\u7a76\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u7528\u6709\u9650\u6267\u884c\u5668\u6570\u91cf\u663e\u8457\u63d0\u9ad8\u7ec4\u88c5\u7cbe\u5ea6\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u8be5\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6709\u6548\u5730\u63d0\u5347\u4e86\u7ec4\u88c5\u6548\u7387\u548c\u7cbe\u5ea6\u3002"}}
{"id": "2504.16940", "pdf": "https://arxiv.org/pdf/2504.16940", "abs": "https://arxiv.org/abs/2504.16940", "authors": ["Drew Linsley", "Pinyuan Feng", "Thomas Serre"], "title": "Can deep neural networks learn biological vision?", "categories": ["q-bio.NC", "cs.AI", "cs.CV"], "comment": null, "summary": "Deep neural networks (DNNs) once showed increasing alignment with primate\nneural responses as they improved on computer vision benchmarks. This trend\nraised the exciting possibility that better models of biological vision would\ncome as a byproduct of the deep learning revolution in artificial intelligence.\nHowever, the trend has reversed over recent years as DNNs have scaled to human\nor superhuman recognition accuracy, a divergence that may stem from modern DNNs\nlearning to rely on different visual features than primates to solve tasks.\nWhere will better computational models of biological vision come from? We\npropose that vision science must break from artificial intelligence to develop\nalgorithms that are designed with biological visual systems in mind instead of\ninternet data benchmarks. We predict that the next generation of deep learning\nmodels of biological vision will be trained with data diets, training routines,\nand objectives that are closer to those that shape human vision than those that\nare in use today.", "AI": {"tldr": "DNNs\u5728\u63d0\u5347\u8bc6\u522b\u51c6\u786e\u6027\u540e\u4e0e\u7075\u957f\u7c7b\u795e\u7ecf\u54cd\u5e94\u4e0d\u518d\u4e00\u81f4\uff0c\u5efa\u8bae\u89c6\u89c9\u79d1\u5b66\u72ec\u7acb\u4e8eAI\uff0c\u5f00\u53d1\u4ee5\u751f\u7269\u89c6\u89c9\u4e3a\u5bfc\u5411\u7684\u7b97\u6cd5\u3002", "motivation": "DNNs\u4e0e\u7075\u957f\u7c7b\u89c6\u89c9\u7279\u5f81\u7684\u5206\u5316\u5f15\u53d1\u4e86\u5bf9\u66f4\u597d\u751f\u7269\u89c6\u89c9\u6a21\u578b\u7684\u9700\u6c42\uff0c\u63a8\u52a8\u89c6\u89c9\u79d1\u5b66\u4eceAI\u57fa\u51c6\u8f6c\u5411\u751f\u7269\u542f\u53d1\u3002", "method": "\u63d0\u51fa\u8bbe\u8ba1\u4ee5\u751f\u7269\u89c6\u89c9\u7cfb\u7edf\u4e3a\u5bfc\u5411\u7684\u7b97\u6cd5\uff0c\u4f7f\u7528\u66f4\u63a5\u8fd1\u4eba\u7c7b\u89c6\u89c9\u7684\u6570\u636e\u3001\u8bad\u7ec3\u548c\u76ee\u6807\u3002", "result": "\u9884\u6d4b\u4e0b\u4e00\u4ee3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5c06\u91c7\u7528\u66f4\u751f\u7269\u5316\u7684\u6570\u636e\u548c\u8bad\u7ec3\u65b9\u5f0f\u3002", "conclusion": "\u89c6\u89c9\u79d1\u5b66\u5e94\u8131\u79bbAI\uff0c\u4e13\u6ce8\u4e8e\u5f00\u53d1\u4ee5\u751f\u7269\u4e3a\u57fa\u7840\u7684\u89c6\u89c9\u6a21\u578b\u3002"}}
{"id": "2504.17073", "pdf": "https://arxiv.org/pdf/2504.17073", "abs": "https://arxiv.org/abs/2504.17073", "authors": ["David Lu", "Lior Maman", "Jackson Earls", "Amir Boag", "Pierre Baldi"], "title": "Sparse Phased Array Optimization Using Deep Learning", "categories": ["cs.LG"], "comment": null, "summary": "Antenna arrays are widely used in wireless communication, radar systems,\nradio astronomy, and military defense to enhance signal strength, directivity,\nand interference suppression. We introduce a deep learning-based optimization\napproach that enhances the design of sparse phased arrays by reducing grating\nlobes. This approach begins by generating sparse array configurations to\naddress the non-convex challenges and extensive degrees of freedom inherent in\narray design. We use neural networks to approximate the non-convex cost\nfunction that estimates the energy ratio between the main and side lobes. This\ndifferentiable approximation facilitates cost function minimization through\ngradient descent, optimizing the antenna elements' coordinates and leading to\nan improved layout. Additionally, we incorporate a tailored penalty mechanism\nthat includes various physical and design constraints into the optimization\nprocess, enhancing its robustness and practical applicability. We demonstrate\nthe effectiveness of our method by applying it to the ten array configurations\nwith the lowest initial costs, achieving further cost reductions ranging from\n411% to 643%, with an impressive average improvement of 552%. By significantly\nreducing side lobe levels in antenna arrays, this breakthrough paves the way\nfor ultra-precise beamforming, enhanced interference mitigation, and\nnext-generation wireless and radar systems with unprecedented efficiency and\nclarity.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u7a00\u758f\u76f8\u63a7\u9635\u5217\u8bbe\u8ba1\uff0c\u51cf\u5c11\u6805\u74e3\uff0c\u63d0\u5347\u4fe1\u53f7\u6027\u80fd\u3002", "motivation": "\u5929\u7ebf\u9635\u5217\u7528\u4e8e\u589e\u5f3a\u65e0\u7ebf\u901a\u4fe1\u3001\u96f7\u8fbe\u7b49\u9886\u57df\u7684\u4fe1\u53f7\u5f3a\u5ea6\u3001\u65b9\u5411\u6027\u548c\u5e72\u6270\u6291\u5236\uff0c\u4f46\u9762\u4e34\u975e\u51f8\u4f18\u5316\u6311\u6218\u3002", "method": "\u91c7\u7528\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u975e\u51f8\u6210\u672c\u51fd\u6570\uff0c\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u5929\u7ebf\u5750\u6807\uff0c\u5e76\u52a0\u5165\u60e9\u7f5a\u673a\u5236\u5904\u7406\u7ea6\u675f\u3002", "result": "\u5728\u5341\u79cd\u521d\u59cb\u914d\u7f6e\u4e0a\uff0c\u6210\u672c\u51cf\u5c11411%\u81f3643%\uff0c\u5e73\u5747\u6539\u5584552%\uff0c\u663e\u8457\u964d\u4f4e\u65c1\u74e3\u6c34\u5e73\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4fc3\u8fdb\u7cbe\u786e\u6ce2\u675f\u5f62\u6210\u548c\u5e72\u6270\u6291\u5236\uff0c\u63d0\u5347\u65e0\u7ebf\u548c\u96f7\u8fbe\u7cfb\u7edf\u7684\u6548\u7387\u4e0e\u6e05\u6670\u5ea6\u3002"}}
{"id": "2504.17632", "pdf": "https://arxiv.org/pdf/2504.17632", "abs": "https://arxiv.org/abs/2504.17632", "authors": ["Riti Bhandarkar", "Qian Luo", "Emil Dimanchev", "Jesse D. Jenkins"], "title": "Are EVs Cleaner Than We Think? Evaluating Consequential Greenhouse Gas Emissions from EV Charging", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "While electrifying transportation eliminates tailpipe greenhouse gas (GHG)\nemissions, electric vehicle (EV) adoption can create additional electricity\nsector emissions. To quantify this emissions impact, prior work typically\nemploys short-run marginal emissions or average emissions rates calculated from\nhistorical data or power systems models that do not consider changes in\ninstalled capacity. In this work, we use an electricity system capacity\nexpansion model to consider the full consequential GHG emissions impact from\nlarge-scale EV adoption in the western United States, accounting for induced\nchanges in generation and storage capacity. We find that the metrics described\nabove do not accurately reflect the true emissions impact of EV\nadoption-average emissions rates can either under- or over-estimate emission\nimpacts, and short-run marginal emissions rates can significantly underestimate\nemission reductions, especially when charging timing is flexible. Our results\nalso show that using short-run marginal emission rates as signals to coordinate\nEV charging could increase emissions relative to price-based charging signals,\nindicating the need for alternative control strategies to minimize\nconsequential emissions.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u5bb9\u91cf\u6269\u5c55\u6a21\u578b\u8bc4\u4f30\u5927\u89c4\u6a21\u7535\u52a8\u6c7d\u8f66\u91c7\u7528\u5bf9\u897f\u90e8\u7f8e\u56fd\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u4e0d\u51c6\u786e\uff0c\u5e76\u5efa\u8bae\u66ff\u4ee3\u63a7\u5236\u7b56\u7565\u3002", "motivation": "\u51c6\u786e\u91cf\u5316\u7535\u52a8\u6c7d\u8f66\u91c7\u7528\u5f15\u53d1\u7684\u6392\u653e\u5f71\u54cd\uff0c\u56e0\u4e3a\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u5bb9\u91cf\u53d8\u5316\u53ef\u80fd\u5bfc\u81f4\u4f30\u7b97\u9519\u8bef\u3002", "method": "\u4f7f\u7528\u7535\u529b\u7cfb\u7edf\u5bb9\u91cf\u6269\u5c55\u6a21\u578b\uff0c\u8003\u8651\u53d1\u7535\u548c\u5b58\u50a8\u5bb9\u91cf\u53d8\u5316\u6a21\u62df\u6392\u653e\u5f71\u54cd\u3002", "result": "\u5e73\u5747\u6392\u653e\u7387\u53ef\u80fd\u4f4e\u4f30\u6216\u9ad8\u4f30\u5f71\u54cd\uff0c\u77ed\u671f\u8fb9\u9645\u6392\u653e\u7387\u4f4e\u4f30\u51cf\u6392\uff0c\u4f7f\u7528\u5176\u534f\u8c03\u5145\u7535\u53ef\u80fd\u589e\u52a0\u6392\u653e\u3002", "conclusion": "\u9700\u8981\u91c7\u7528\u66ff\u4ee3\u63a7\u5236\u7b56\u7565\u6765\u6700\u5c0f\u5316\u7535\u52a8\u6c7d\u8f66\u91c7\u7528\u7684\u95f4\u63a5\u6392\u653e\u3002"}}
{"id": "2504.16942", "pdf": "https://arxiv.org/pdf/2504.16942", "abs": "https://arxiv.org/abs/2504.16942", "authors": ["Shushman Choudhury", "Elad Aharoni", "Chandrakumari Suvarna", "Iveel Tsogsuren", "Abdul Rahman Kreidieh", "Chun-Ta Lu", "Neha Arora"], "title": "S2Vec: Self-Supervised Geospatial Embeddings", "categories": ["cs.SI", "cs.AI", "cs.CV"], "comment": "To be submitted to ACM Transactions on Spatial Algorithms and Systems", "summary": "Scalable general-purpose representations of the built environment are crucial\nfor geospatial artificial intelligence applications. This paper introduces\nS2Vec, a novel self-supervised framework for learning such geospatial\nembeddings. S2Vec uses the S2 Geometry library to partition large areas into\ndiscrete S2 cells, rasterizes built environment feature vectors within cells as\nimages, and applies masked autoencoding on these rasterized images to encode\nthe feature vectors. This approach yields task-agnostic embeddings that capture\nlocal feature characteristics and broader spatial relationships. We evaluate\nS2Vec on three large-scale socioeconomic prediction tasks, showing its\ncompetitive performance against state-of-the-art image-based embeddings. We\nalso explore the benefits of combining S2Vec embeddings with image-based\nembeddings downstream, showing that such multimodal fusion can often improve\nperformance. Our results highlight how S2Vec can learn effective\ngeneral-purpose geospatial representations and how it can complement other data\nmodalities in geospatial artificial intelligence.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165S2Vec\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u751f\u6210\u901a\u7528\u7684\u5730\u7406\u7a7a\u95f4\u5d4c\u5165\uff0c\u63d0\u5347\u5730\u7406\u7a7a\u95f4\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u6027\u80fd\u3002", "motivation": "\u53ef\u6269\u5c55\u7684\u901a\u7528\u5efa\u6210\u73af\u5883\u8868\u793a\u5bf9\u4e8e\u5730\u7406\u7a7a\u95f4\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "S2Vec\u4f7f\u7528S2 Geometry\u5e93\u5c06\u533a\u57df\u5212\u5206\u4e3aS2\u5355\u5143\uff0c\u5c06\u7279\u5f81\u6805\u683c\u5316\u4e3a\u56fe\u50cf\uff0c\u5e76\u5e94\u7528\u63a9\u7801\u81ea\u52a8\u7f16\u7801\u5b66\u4e60\u5d4c\u5165\u3002", "result": "\u5728\u4e09\u4e2a\u793e\u4f1a\u7ecf\u6d4e\u9884\u6d4b\u4efb\u52a1\u4e0a\uff0cS2Vec\u6027\u80fd\u4e0e\u6700\u5148\u8fdb\u56fe\u50cf\u5d4c\u5165\u7ade\u4e89\u76f8\u5f53\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u878d\u5408\u53ef\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u7ed3\u679c\u7a81\u663eS2Vec\u80fd\u6709\u6548\u5b66\u4e60\u5730\u7406\u7a7a\u95f4\u8868\u793a\uff0c\u5e76\u4e0e\u5176\u4ed6\u6570\u636e\u6a21\u5f0f\u4e92\u8865\u3002"}}
{"id": "2504.17074", "pdf": "https://arxiv.org/pdf/2504.17074", "abs": "https://arxiv.org/abs/2504.17074", "authors": ["William R. Keely", "Otto Lamminp\u00e4\u00e4", "Steffen Mauceri", "Sean M. R. Crowell", "Christopher W. O'Dell", "Gregory R. McGarragh"], "title": "Conditional Diffusion-Based Retrieval of Atmospheric CO2 from Earth Observing Spectroscopy", "categories": ["cs.LG", "astro-ph.IM"], "comment": "Published as a workshop paper in \"Tackling Climate Change with\n  Machine Learning\", ICLR 2025 Workshop on Tackling Climate Change with Machine\n  Learning. https://www.climatechange.ai/papers/iclr2025/12", "summary": "Satellite-based estimates of greenhouse gas (GHG) properties from\nobservations of reflected solar spectra are integral for understanding and\nmonitoring complex terrestrial systems and their impact on the carbon cycle due\nto their near global coverage. Known as retrieval, making GHG concentration\nestimations from these observations is a non-linear Bayesian inverse problem,\nwhich is operationally solved using a computationally expensive algorithm\ncalled Optimal Estimation (OE), providing a Gaussian approximation to a\nnon-Gaussian posterior. This leads to issues in solver algorithm convergence,\nand to unrealistically confident uncertainty estimates for the retrieved\nquantities. Upcoming satellite missions will provide orders of magnitude more\ndata than the current constellation of GHG observers. Development of fast and\naccurate retrieval algorithms with robust uncertainty quantification is\ncritical. Doing so stands to provide substantial climate impact of moving\ntowards the goal of near continuous real-time global monitoring of carbon\nsources and sinks which is essential for policy making. To achieve this goal,\nwe propose a diffusion-based approach to flexibly retrieve a Gaussian or\nnon-Gaussian posterior, for NASA's Orbiting Carbon Observatory-2 spectrometer,\nwhile providing a substantial computational speed-up over the current\noperational state-of-the-art.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u4ece\u536b\u661f\u6570\u636e\u5feb\u901f\u51c6\u786e\u5730\u4f30\u7b97\u6e29\u5ba4\u6c14\u4f53\u6d53\u5ea6\uff0c\u63d0\u4f9b\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u6536\u655b\u95ee\u9898\u591a\u3001\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4e0d\u51c6\uff0c\u672a\u6765\u6570\u636e\u91cf\u5267\u589e\uff0c\u9700\u8981\u9ad8\u6548\u7b97\u6cd5\u4ee5\u5b9e\u73b0\u5b9e\u65f6\u5168\u7403\u78b3\u76d1\u6d4b\uff0c\u652f\u6301\u6c14\u5019\u653f\u7b56\u3002", "method": "\u63d0\u51fa\u6269\u6563-based\u65b9\u6cd5\uff0c\u7075\u6d3b\u68c0\u7d22\u9ad8\u65af\u6216\u975e\u9ad8\u65af\u540e\u9a8c\u5206\u5e03\uff0c\u5e94\u7528\u4e8eNASA OCO-2\u5149\u8c31\u4eea\u3002", "result": "\u76f8\u6bd4Optimal Estimation\uff0c\u8ba1\u7b97\u901f\u5ea6\u5927\u5e45\u63d0\u5347\uff0c\u5e76\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u6709\u52a9\u4e8e\u5b9e\u73b0\u8fd1\u8fde\u7eed\u5b9e\u65f6\u5168\u7403\u76d1\u6d4b\u6e29\u5ba4\u6c14\u4f53\uff0c\u5bf9\u6c14\u5019\u653f\u7b56\u5236\u5b9a\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2504.17736", "pdf": "https://arxiv.org/pdf/2504.17736", "abs": "https://arxiv.org/abs/2504.17736", "authors": ["Adrian Esser", "Chiara Basla", "Peter Wolf", "Robert Riener"], "title": "Design and benchmarking of a two degree of freedom tendon driver unit for cable-driven wearable technologies", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "Exosuits have recently been developed as alternatives to rigid exoskeletons\nand are increasingly adopted for both upper and lower limb therapy and\nassistance in clinical and home environments. Many cable-driven exosuits have\nbeen developed but little has been published on their electromechanical designs\nand performance. Therefore, this paper presents a comprehensive design and\nperformance analysis of a two degree of freedom tendon driver unit (TDU) for\ncable-driven wearable exosuits. Detailed methodologies are presented to\nbenchmark the functionality of the TDU. A static torque output test compares\nthe commanded and measured torques. A velocity control test evaluates the\nattenuation and phase shift across velocities. A noise test evaluates how loud\nthe TDU is for the wearer under different speeds. A thermal stress test\ncaptures the cooling performance of the TDU to ensure safe operation at higher\nloads. Finally, a battery endurance test evaluates the runtime of the TDU under\nvarious loading conditions to inform the usable time. To demonstrate these\ntests, a modular TDU system for cable-driven applications is introduced, which\nallows components such as motors, pulleys, and sensors to be adapted based on\nthe requirements of the intended application. By sharing detailed methodologies\nand performance results, this study aims to provide a TDU design that may be\nleveraged by others and resources for researchers and engineers to better\ndocument the capabilities of their TDU designs.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u7f06\u7d22\u9a71\u52a8\u53ef\u7a7f\u6234\u5916\u9aa8\u9abc\u7684\u808c\u8171\u9a71\u52a8\u5355\u5143\uff08TDU\uff09\u7684\u8bbe\u8ba1\u548c\u6027\u80fd\u5206\u6790\uff0c\u901a\u8fc7\u5404\u79cd\u6d4b\u8bd5\u8bc4\u4f30\u5176\u529f\u80fd\u3002", "motivation": "\u8bb8\u591a\u7f06\u7d22\u9a71\u52a8\u5916\u9aa8\u9abc\u5df2\u88ab\u5f00\u53d1\uff0c\u4f46\u76f8\u5173\u673a\u7535\u8bbe\u8ba1\u548c\u6027\u80fd\u7684\u51fa\u7248\u7269\u5f88\u5c11\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5448\u73b0\u8be6\u7ec6\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5305\u62ec\u9759\u6001\u626d\u77e9\u8f93\u51fa\u6d4b\u8bd5\u3001\u901f\u5ea6\u63a7\u5236\u6d4b\u8bd5\u3001\u566a\u58f0\u6d4b\u8bd5\u3001\u70ed\u5e94\u529b\u6d4b\u8bd5\u548c\u7535\u6c60\u8010\u4e45\u6027\u6d4b\u8bd5\uff0c\u5e76\u5f15\u5165\u6a21\u5757\u5316TDU\u7cfb\u7edf\u3002", "result": "\u6d4b\u8bd5\u7ed3\u679c\u6db5\u76d6\u547d\u4ee4\u4e0e\u6d4b\u91cf\u626d\u77e9\u6bd4\u8f83\u3001\u901f\u5ea6\u4e0b\u7684\u8870\u51cf\u548c\u76f8\u79fb\u3001\u566a\u58f0\u6c34\u5e73\u3001\u51b7\u5374\u6027\u80fd\u4ee5\u53ca\u7535\u6c60\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u4eab\u65b9\u6cd5\u548c\u7ed3\u679c\uff0c\u63d0\u4f9b\u53ef\u88ab\u4ed6\u4eba\u5229\u7528\u7684TDU\u8bbe\u8ba1\uff0c\u5e76\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5de5\u7a0b\u5e08\u63d0\u4f9b\u8bb0\u5f55\u80fd\u529b\u7684\u8d44\u6e90\u3002"}}
{"id": "2504.16946", "pdf": "https://arxiv.org/pdf/2504.16946", "abs": "https://arxiv.org/abs/2504.16946", "authors": ["Xiaotong Ye", "Nicolas Bougie", "Toshihiko Yamasaki", "Narimasa Watanabe"], "title": "MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Generative agents offer promising capabilities for simulating realistic urban\nbehaviors. However, existing methods oversimplify transportation choices in\nmodern cities, and require prohibitive computational resources for large-scale\npopulation simulation. To address these limitations, we first present a virtual\ncity that features multiple functional buildings and transportation modes.\nThen, we conduct extensive surveys to model behavioral choices and mobility\npreferences among population groups. Building on these insights, we introduce a\nsimulation framework that captures the complexity of urban mobility while\nremaining scalable, enabling the simulation of over 4,000 agents. To assess the\nrealism of the generated behaviors, we perform a series of micro and\nmacro-level analyses. Beyond mere performance comparison, we explore insightful\nexperiments, such as predicting crowd density from movement patterns and\nidentifying trends in vehicle preferences across agent demographics.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u57ce\u5e02\u4ee3\u7406\u6a21\u62df\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u4ea4\u901a\u9009\u62e9\u7b80\u5316\u4e0e\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u4e0a\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u865a\u62df\u57ce\u5e02\u548c\u8c03\u67e5\u5b9e\u73b0\u5bf94000\u591a\u4e2a\u4ee3\u7406\u7684\u771f\u5b9e\u884c\u4e3a\u6a21\u62df\uff0c\u5e76\u8fdb\u884c\u591a\u5c42\u6b21\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u4ee3\u7406\u65b9\u6cd5\u5728\u6a21\u62df\u57ce\u5e02\u4ea4\u901a\u9009\u62e9\u65f6\u8fc7\u4e8e\u7b80\u5316\uff0c\u4e14\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u8fc7\u9ad8\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u5927\u89c4\u6a21\u4eba\u53e3\u6a21\u62df\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u5305\u542b\u591a\u79cd\u529f\u80fd\u5efa\u7b51\u548c\u4ea4\u901a\u65b9\u5f0f\u7684\u865a\u62df\u57ce\u5e02\uff1b\u901a\u8fc7\u5e7f\u6cdb\u8c03\u67e5\u5efa\u6a21\u884c\u4e3a\u9009\u62e9\u548c\u6d41\u52a8\u6027\u504f\u597d\uff1b\u5f15\u5165\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6a21\u62df\u6846\u67b6\u6765\u6a21\u62df\u4ee3\u7406\u884c\u4e3a\u3002", "result": "\u6210\u529f\u6a21\u62df\u8d85\u8fc74000\u4e2a\u4ee3\u7406\uff1b\u901a\u8fc7\u5fae\u89c2\u548c\u5b8f\u89c2\u5206\u6790\u8bc4\u4f30\u884c\u4e3a\u771f\u5b9e\u6027\uff1b\u5b9e\u9a8c\u5305\u62ec\u4ece\u8fd0\u52a8\u6a21\u5f0f\u9884\u6d4b\u4eba\u7fa4\u5bc6\u5ea6\u548c\u8bc6\u522b\u4ee3\u7406\u7fa4\u4f53\u4e2d\u7684\u8f66\u8f86\u504f\u597d\u8d8b\u52bf\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u57ce\u5e02\u884c\u4e3a\u6a21\u62df\u7684\u771f\u5b9e\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u5bf9\u57ce\u5e02\u52a8\u6001\u548c\u8d8b\u52bf\u7684\u6d1e\u89c1\u3002"}}
{"id": "2504.17079", "pdf": "https://arxiv.org/pdf/2504.17079", "abs": "https://arxiv.org/abs/2504.17079", "authors": ["Esam Mahdi", "C. Martin-Barreiro", "X. Cabezas"], "title": "A Novel Hybrid Approach Using an Attention-Based Transformer + GRU Model for Predicting Cryptocurrency Prices", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "In this article, we introduce a novel deep learning hybrid model that\nintegrates attention Transformer and Gated Recurrent Unit (GRU) architectures\nto improve the accuracy of cryptocurrency price predictions. By combining the\nTransformer's strength in capturing long-range patterns with the GRU's ability\nto model short-term and sequential trends, the hybrid model provides a\nwell-rounded approach to time series forecasting. We apply the model to predict\nthe daily closing prices of Bitcoin and Ethereum based on historical data that\ninclude past prices, trading volumes, and the Fear and Greed index. We evaluate\nthe performance of our proposed model by comparing it with four other machine\nlearning models: two are non-sequential feedforward models: Radial Basis\nFunction Network (RBFN) and General Regression Neural Network (GRNN), and two\nare bidirectional sequential memory-based models: Bidirectional Long-Short-Term\nMemory (BiLSTM) and Bidirectional Gated Recurrent Unit (BiGRU). The performance\nof the model is assessed using several metrics, including Mean Squared Error\n(MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean\nAbsolute Percentage Error (MAPE), along with statistical validation through the\nnonparametric Friedman test followed by a post hoc Wilcoxon signed rank test.\nThe results demonstrate that our hybrid model consistently achieves superior\naccuracy, highlighting its effectiveness for financial prediction tasks. These\nfindings provide valuable insights for improving real-time decision making in\ncryptocurrency markets and support the growing use of hybrid deep learning\nmodels in financial analytics.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408Transformer\u548cGRU\u7684\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u63d0\u9ad8\u52a0\u5bc6\u8d27\u5e01\u4ef7\u683c\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u4e3a\u4e86\u6574\u5408Transformer\u6355\u6349\u957f\u7a0b\u6a21\u5f0f\u548cGRU\u5904\u7406\u77ed\u7a0b\u5e8f\u5217\u8d8b\u52bf\u7684\u4f18\u52bf\uff0c\u63d0\u5347\u91d1\u878d\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u6df7\u5408\u6a21\u578b\u5e94\u7528\u4e8e\u6bd4\u7279\u5e01\u548c\u4ee5\u592a\u574a\u4ef7\u683c\u9884\u6d4b\uff0c\u4f7f\u7528\u5386\u53f2\u6570\u636e\u4e0e\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6bd4\u8f83\uff0c\u5e76\u901a\u8fc7MSE\u3001RMSE\u3001MAE\u3001MAPE\u7b49\u6307\u6807\u53ca\u7edf\u8ba1\u6d4b\u8bd5\u8bc4\u4f30\u3002", "result": "\u6df7\u5408\u6a21\u578b\u5728\u51c6\u786e\u6027\u6307\u6807\u4e0a\u4f18\u4e8eRBFN\u3001GRNN\u3001BiLSTM\u548cBiGRU\u7b49\u6a21\u578b\u3002", "conclusion": "\u8bc1\u660e\u6df7\u5408\u6a21\u578b\u6709\u6548\uff0c\u652f\u6301\u5176\u5728\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u5b9e\u65f6\u51b3\u7b56\u548c\u91d1\u878d\u5206\u6790\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2504.17080", "pdf": "https://arxiv.org/pdf/2504.17080", "abs": "https://arxiv.org/abs/2504.17080", "authors": ["Joohwan Seo", "Nikhil Potu Surya Prakash", "Soomi Lee", "Arvind Kruthiventy", "Megan Teng", "Jongeun Choi", "Roberto Horowitz"], "title": "Geometric Formulation of Unified Force-Impedance Control on SE(3) for Robotic Manipulators", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "Submitted to Control Decision Conference (CDC) 2025", "summary": "In this paper, we present an impedance control framework on the SE(3)\nmanifold, which enables force tracking while guaranteeing passivity. Building\nupon the unified force-impedance control (UFIC) and our previous work on\ngeometric impedance control (GIC), we develop the geometric unified force\nimpedance control (GUFIC) to account for the SE(3) manifold structure in the\ncontroller formulation using a differential geometric perspective. As in the\ncase of the UFIC, the GUFIC utilizes energy tank augmentation for both\nforce-tracking and impedance control to guarantee the manipulator's passivity\nrelative to external forces. This ensures that the end effector maintains safe\ncontact interaction with uncertain environments and tracks a desired\ninteraction force. Moreover, we resolve a non-causal implementation problem in\nthe UFIC formulation by introducing velocity and force fields. Due to its\nformulation on SE(3), the proposed GUFIC inherits the desirable SE(3)\ninvariance and equivariance properties of the GIC, which helps increase sample\nefficiency in machine learning applications where a learning algorithm is\nincorporated into the control law. The proposed control law is validated in a\nsimulation environment under scenarios requiring tracking an SE(3) trajectory,\nincorporating both position and orientation, while exerting a force on a\nsurface. The codes are available at\nhttps://github.com/Joohwan-Seo/GUFIC_mujoco.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSE(3)\u6d41\u5f62\u7684\u963b\u6297\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8e\u529b\u8ddf\u8e2a\u5e76\u4fdd\u8bc1\u88ab\u52a8\u6027\u3002", "motivation": "\u4e3a\u4e86\u6539\u8fdb\u673a\u5668\u4eba\u4e0e\u4e0d\u786e\u5b9a\u73af\u5883\u7684\u5b89\u5168\u63a5\u89e6\u4e92\u52a8\u3001\u8ddf\u8e2a\u671f\u671b\u4e92\u52a8\u529b\u548c\u63d0\u5347\u673a\u5668\u5b66\u4e60\u5e94\u7528\u7684\u6837\u672c\u6548\u7387\u3002", "method": "\u901a\u8fc7\u5dee\u5206\u51e0\u4f55\u89c6\u89d2\u5f00\u53d1\u51e0\u4f55\u7edf\u4e00\u529b\u963b\u6297\u63a7\u5236\uff08GUFIC\uff09\uff0c\u5229\u7528\u80fd\u91cf\u7f50\u589e\u5f3a\u4fdd\u8bc1\u88ab\u52a8\u6027\uff0c\u5e76\u5f15\u5165\u901f\u5ea6\u548c\u529b\u573a\u89e3\u51b3\u975e\u56e0\u679c\u5b9e\u73b0\u95ee\u9898\u3002", "result": "\u5728\u6a21\u62df\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u63a7\u5236\u5f8b\uff0c\u80fd\u591f\u8ddf\u8e2aSE(3)\u8f68\u8ff9\u5e76\u65bd\u52a0\u529b\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "conclusion": "\u63d0\u51fa\u7684GUFIC\u7ee7\u627fSE(3)\u7684\u4e0d\u53d8\u6027\u548c\u7b49\u53d8\u6027\u5c5e\u6027\uff0c\u63d0\u9ad8\u4e86\u63a7\u5236\u6027\u80fd\u548c\u673a\u5668\u5b66\u4e60\u6548\u7387\u3002"}}
{"id": "2504.16947", "pdf": "https://arxiv.org/pdf/2504.16947", "abs": "https://arxiv.org/abs/2504.16947", "authors": ["Dachun Sun", "You Lyu", "Jinning Li", "Yizhuo Chen", "Tianshi Wang", "Tomoyoshi Kimura", "Tarek Abdelzaher"], "title": "SCRAG: Social Computing-Based Retrieval Augmented Generation for Community Response Forecasting in Social Media Environments", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "This paper introduces SCRAG, a prediction framework inspired by social\ncomputing, designed to forecast community responses to real or hypothetical\nsocial media posts. SCRAG can be used by public relations specialists (e.g., to\ncraft messaging in ways that avoid unintended misinterpretations) or public\nfigures and influencers (e.g., to anticipate social responses), among other\napplications related to public sentiment prediction, crisis management, and\nsocial what-if analysis. While large language models (LLMs) have achieved\nremarkable success in generating coherent and contextually rich text, their\nreliance on static training data and susceptibility to hallucinations limit\ntheir effectiveness at response forecasting in dynamic social media\nenvironments. SCRAG overcomes these challenges by integrating LLMs with a\nRetrieval-Augmented Generation (RAG) technique rooted in social computing.\nSpecifically, our framework retrieves (i) historical responses from the target\ncommunity to capture their ideological, semantic, and emotional makeup, and\n(ii) external knowledge from sources such as news articles to inject\ntime-sensitive context. This information is then jointly used to forecast the\nresponses of the target community to new posts or narratives. Extensive\nexperiments across six scenarios on the X platform (formerly Twitter), tested\nwith various embedding models and LLMs, demonstrate over 10% improvements on\naverage in key evaluation metrics. A concrete example further shows its\neffectiveness in capturing diverse ideologies and nuances. Our work provides a\nsocial computing tool for applications where accurate and concrete insights\ninto community responses are crucial.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86SCRAG\u6846\u67b6\uff0c\u5b83\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u6765\u9884\u6d4b\u793e\u533a\u5bf9\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u7684\u54cd\u5e94\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u9759\u6001\u6570\u636e\u548c\u4ea7\u751f\u5e7b\u89c9\u7684\u95ee\u9898\uff0c\u4ee5\u5728\u52a8\u6001\u793e\u4ea4\u5a92\u4f53\u73af\u5883\u4e2d\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u793e\u533a\u54cd\u5e94\u9884\u6d4b\u3002", "method": "\u65b9\u6cd5\u662f\u901a\u8fc7\u6574\u5408LLM\u4e0eRAG\u6280\u672f\uff0c\u68c0\u7d22\u76ee\u6807\u793e\u533a\u7684\u5386\u53f2\u54cd\u5e94\u548c\u5916\u90e8\u77e5\u8bc6\uff08\u5982\u65b0\u95fb\u6587\u7ae0\uff09\uff0c\u6765\u9884\u6d4b\u65b0\u5e16\u5b50\u7684\u54cd\u5e94\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728X\u5e73\u53f0\u4e0a\u7684\u516d\u79cd\u573a\u666f\u5b9e\u9a8c\u4e2d\uff0c\u5e73\u5747\u63d0\u9ad8\u4e8610%\u4ee5\u4e0a\u7684\u5173\u952e\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u8bc1\u660e\u4e86\u5176\u6355\u6349\u591a\u6837\u610f\u8bc6\u5f62\u6001\u548c\u7ec6\u5fae\u5dee\u522b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u793e\u4f1a\u8ba1\u7b97\u5de5\u5177\uff0c\u7528\u4e8e\u9700\u8981\u51c6\u786e\u793e\u533a\u54cd\u5e94\u6d1e\u5bdf\u7684\u5e94\u7528\u3002"}}
{"id": "2504.17099", "pdf": "https://arxiv.org/pdf/2504.17099", "abs": "https://arxiv.org/abs/2504.17099", "authors": ["Martin Boeckling", "Heiko Paulheim", "Sarah Detzler"], "title": "GeoRDF2Vec Learning Location-Aware Entity Representations in Knowledge Graphs", "categories": ["cs.LG", "cs.SI"], "comment": "18 pages, ESWC 2025", "summary": "Many knowledge graphs contain a substantial number of spatial entities, such\nas cities, buildings, and natural landmarks. For many of these entities, exact\ngeometries are stored within the knowledge graphs. However, most existing\napproaches for learning entity representations do not take these geometries\ninto account. In this paper, we introduce a variant of RDF2Vec that\nincorporates geometric information to learn location-aware embeddings of\nentities. Our approach expands different nodes by flooding the graph from\ngeographic nodes, ensuring that each reachable node is considered. Based on the\nresulting flooded graph, we apply a modified version of RDF2Vec that biases\ngraph walks using spatial weights. Through evaluations on multiple benchmark\ndatasets, we demonstrate that our approach outperforms both non-location-aware\nRDF2Vec and GeoTransE.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u5408\u51e0\u4f55\u4fe1\u606f\u7684RDF2Vec\u53d8\u4f53\uff0c\u7528\u4e8e\u5b66\u4e60\u4f4d\u7f6e\u611f\u77e5\u7684\u5b9e\u4f53\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u6570\u636e\u96c6\u8bc4\u4f30\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5b58\u5728\u5927\u91cf\u7a7a\u95f4\u5b9e\u4f53\uff0c\u4f46\u73b0\u6709\u5b9e\u4f53\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651\u5176\u51e0\u4f55\u4fe1\u606f\u3002", "method": "\u5f15\u5165RDF2Vec\u53d8\u4f53\uff0c\u901a\u8fc7\u4ece\u5730\u7406\u8282\u70b9\u6d2a\u6cdb\u56fe\u6269\u5c55\u8282\u70b9\uff0c\u5e76\u4f7f\u7528\u7a7a\u95f4\u6743\u91cd\u504f\u7f6e\u56fe\u6e38\u8d70\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u975e\u4f4d\u7f6e\u611f\u77e5\u7684RDF2Vec\u548cGeoTransE\u3002", "conclusion": "\u6574\u5408\u51e0\u4f55\u4fe1\u606f\u53ef\u63d0\u5347\u5b9e\u4f53\u5d4c\u5165\u6027\u80fd\uff0c\u8bc1\u660e\u4f4d\u7f6e\u611f\u77e5\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2504.17093", "pdf": "https://arxiv.org/pdf/2504.17093", "abs": "https://arxiv.org/abs/2504.17093", "authors": ["Nikilesh Ramesh", "Ross Drummond", "Pablo Rodolfo Baldivieso Monasterios", "Yuanbo Nie"], "title": "Singular Arcs in Optimal Control: Closed-loop Implementations without Workarounds", "categories": ["math.OC", "cs.SY", "eess.SY"], "comment": "Submitted to CDC 2025", "summary": "Singular arcs emerge in the solutions of Optimal Control Problems (OCPs) when\nthe optimal inputs on some finite time intervals cannot be directly obtained\nvia the optimality conditions. Solving OCPs with singular arcs often requires\ntailored treatments, suitable for offline trajectory optimization. This\napproach can become increasingly impractical for online closed-loop\nimplementations, especially for large-scale engineering problems. Recent\ndevelopment of Integrated Residual Methods (IRM) have indicated their\nsuitability for handling singular arcs; the convergence of error measures in\nIRM automatically suppresses singular arc-induced fluctuations and leads to\nnon-fluctuating solutions more suitable for practical problems. Through several\nexamples, we demonstrate the advantages of solving OCPs with singular arcs\nusing {IRM} under an economic model predictive control framework. In\nparticular, the following observations are made: (i) IRM does not require\nspecial treatment for singular arcs, (ii) it solves the OCPs reliably with\nsingular arc fluctuation suppressed, and (iii) the closed-loop results closely\nmatch the analytic optimal solutions.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u4f7f\u7528IRM\u65b9\u6cd5\u89e3\u51b3\u5e26\u6709\u5947\u5f02\u5f27\u7684\u4f18\u5316\u63a7\u5236\u95ee\u9898\uff0c\u65e0\u9700\u7279\u6b8a\u5904\u7406\uff0c\u5728\u7ecf\u6d4e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\u4e0b\u53d6\u5f97\u4e86\u53ef\u9760\u7684\u7ed3\u679c\u3002", "motivation": "\u4f18\u5316\u63a7\u5236\u95ee\u9898\u4e2d\u5947\u5f02\u5f27\u5904\u7406\u590d\u6742\uff0c\u5c24\u5176\u5728\u7ebf\u95ed\u73af\u5e94\u7528\u4e2d\u4e0d\u5207\u5b9e\u9645\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528Integrated Residual Methods (IRM)\u6765\u6c42\u89e3\u4f18\u5316\u63a7\u5236\u95ee\u9898\uff0c\u5e76\u6291\u5236\u5947\u5f02\u5f27\u5f15\u8d77\u7684\u6ce2\u52a8\u3002", "result": "IRM\u65e0\u9700\u7279\u6b8a\u5904\u7406\u5947\u5f02\u5f27\uff0c\u80fd\u591f\u53ef\u9760\u6c42\u89e3\u95ee\u9898\uff0c\u6291\u5236\u6ce2\u52a8\uff0c\u4e14\u95ed\u73af\u7ed3\u679c\u4e0e\u89e3\u6790\u6700\u4f18\u89e3\u76f8\u7b26\u3002", "conclusion": "IRM\u662f\u5904\u7406\u5947\u5f02\u5f27\u4f18\u5316\u63a7\u5236\u95ee\u9898\u7684\u4e00\u79cd\u9ad8\u6548\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5de5\u7a0b\u5e94\u7528\u3002"}}
{"id": "2504.16948", "pdf": "https://arxiv.org/pdf/2504.16948", "abs": "https://arxiv.org/abs/2504.16948", "authors": ["Zhen Tan", "Huan Liu"], "title": "Intrinsic Barriers to Explaining Deep Foundation Models", "categories": ["cs.CY", "cs.AI", "cs.ET"], "comment": null, "summary": "Deep Foundation Models (DFMs) offer unprecedented capabilities but their\nincreasing complexity presents profound challenges to understanding their\ninternal workings-a critical need for ensuring trust, safety, and\naccountability. As we grapple with explaining these systems, a fundamental\nquestion emerges: Are the difficulties we face merely temporary hurdles,\nawaiting more sophisticated analytical techniques, or do they stem from\n\\emph{intrinsic barriers} deeply rooted in the nature of these large-scale\nmodels themselves? This paper delves into this critical question by examining\nthe fundamental characteristics of DFMs and scrutinizing the limitations\nencountered by current explainability methods when confronted with this\ninherent challenge. We probe the feasibility of achieving satisfactory\nexplanations and consider the implications for how we must approach the\nverification and governance of these powerful technologies.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u6df1\u5ea6\u57fa\u7840\u6a21\u578b\uff08DFMs\uff09\u7684\u89e3\u91ca\u6027\u6311\u6218\uff0c\u8d28\u7591\u8fd9\u4e9b\u56f0\u96be\u662f\u6682\u65f6\u7684\u8fd8\u662f\u6e90\u4e8e\u5185\u5728\u969c\u788d\uff0c\u5e76\u5206\u6790\u5176\u5bf9\u9a8c\u8bc1\u548c\u6cbb\u7406\u7684\u5f71\u54cd\u3002", "motivation": "\u4e3a\u4e86\u786e\u4fddDFMs\u7684\u4fe1\u4efb\u3001\u5b89\u5168\u548c\u95ee\u8d23\u6027\uff0c\u8bba\u6587\u52a8\u673a\u662f\u63a2\u8ba8\u89e3\u91ca\u56f0\u96be\u662f\u5426\u6e90\u4e8e\u6a21\u578b\u672c\u8eab\u7684\u5185\u5728\u7279\u6027\u3002", "method": "\u901a\u8fc7\u8003\u5bdfDFMs\u7684\u57fa\u672c\u7279\u5f81\u5e76\u5ba1\u89c6\u5f53\u524d\u89e3\u91ca\u6027\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u6765\u8bc4\u4f30\u89e3\u91ca\u7684\u53ef\u884c\u6027\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u89e3\u91caDFMs\u53ef\u80fd\u9762\u4e34\u5185\u5728\u969c\u788d\uff0c\u8fd9\u5bf9\u9a8c\u8bc1\u548c\u6cbb\u7406\u63d0\u51fa\u4e86\u65b0\u6311\u6218\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u5fc5\u987b\u91c7\u7528\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406DFMs\u7684\u9a8c\u8bc1\u548c\u6cbb\u7406\uff0c\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u5185\u5728\u969c\u788d\u3002"}}
{"id": "2504.17109", "pdf": "https://arxiv.org/pdf/2504.17109", "abs": "https://arxiv.org/abs/2504.17109", "authors": ["Zhaobin Mo", "Xiangyi Liao", "Dominik A. Karbowski", "Yanbing Wang"], "title": "Discovering the Precursors of Traffic Breakdowns Using Spatiotemporal Graph Attribution Networks", "categories": ["cs.LG"], "comment": null, "summary": "Understanding and predicting the precursors of traffic breakdowns is critical\nfor improving road safety and traffic flow management. This paper presents a\nnovel approach combining spatiotemporal graph neural networks (ST-GNNs) with\nShapley values to identify and interpret traffic breakdown precursors. By\nextending Shapley explanation methods to a spatiotemporal setting, our proposed\nmethod bridges the gap between black-box neural network predictions and\ninterpretable causes. We demonstrate the method on the Interstate-24 data, and\nidentify that road topology and abrupt braking are major factors that lead to\ntraffic breakdowns.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528\u65f6\u7a7a\u56fe\u795e\u7ecf\u7f51\u7edc\uff08ST-GNN\uff09\u548cShapley\u503c\u6765\u8bc6\u522b\u4ea4\u901a\u62e5\u5835\u524d\u5146\uff0c\u5e76\u901a\u8fc7Interstate-24\u6570\u636e\u8bc1\u660e\u8def\u7f51\u62d3\u6251\u548c\u6025\u5239\u8f66\u662f\u4e3b\u8981\u56e0\u7d20\u3002", "motivation": "\u7406\u89e3\u548c\u9884\u6d4b\u4ea4\u901a\u62e5\u5835\u524d\u5146\u5bf9\u4e8e\u63d0\u9ad8\u9053\u8def\u5b89\u5168\u548c\u4ea4\u901a\u6d41\u7ba1\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u7ed3\u5408ST-GNN\u4e0eShapley\u503c\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u5e76\u6269\u5c55Shapley\u89e3\u91ca\u5230\u65f6\u7a7a\u8bbe\u7f6e\uff0c\u4ee5\u8bc6\u522b\u548c\u89e3\u91ca\u4ea4\u901a\u62e5\u5835\u524d\u5146\u3002", "result": "\u5728Interstate-24\u6570\u636e\u4e0a\u6f14\u793a\uff0c\u786e\u8ba4\u8def\u7f51\u62d3\u6251\u548c\u6025\u5239\u8f66\u662f\u5bfc\u81f4\u4ea4\u901a\u62e5\u5835\u7684\u4e3b\u8981\u56e0\u7d20\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u6865\u63a5\u9ed1\u7bb1\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u4e0e\u53ef\u89e3\u91ca\u539f\u56e0\uff0c\u63d0\u5347\u4e86\u4ea4\u901a\u7ba1\u7406\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2504.17102", "pdf": "https://arxiv.org/pdf/2504.17102", "abs": "https://arxiv.org/abs/2504.17102", "authors": ["Haoyu Li", "Xiangru Zhong", "Bin Hu", "Huan Zhang"], "title": "Neural Contraction Metrics with Formal Guarantees for Discrete-Time Nonlinear Dynamical Systems", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted by L4DC 2025", "summary": "Contraction metrics are crucial in control theory because they provide a\npowerful framework for analyzing stability, robustness, and convergence of\nvarious dynamical systems. However, identifying these metrics for complex\nnonlinear systems remains an open challenge due to the lack of scalable and\neffective tools. This paper explores the approach of learning verifiable\ncontraction metrics parametrized as neural networks (NNs) for discrete-time\nnonlinear dynamical systems. While prior works on formal verification of\ncontraction metrics for general nonlinear systems have focused on convex\noptimization methods (e.g. linear matrix inequalities, etc) under the\nassumption of continuously differentiable dynamics, the growing prevalence of\nNN-based controllers, often utilizing ReLU activations, introduces challenges\ndue to the non-smooth nature of the resulting closed-loop dynamics. To bridge\nthis gap, we establish a new sufficient condition for establishing formal\nneural contraction metrics for general discrete-time nonlinear systems assuming\nonly the continuity of the dynamics. We show that from a computational\nperspective, our sufficient condition can be efficiently verified using the\nstate-of-the-art neural network verifier $\\alpha,\\!\\beta$-CROWN, which scales\nup non-convex neural network verification via novel integration of symbolic\nlinear bound propagation and branch-and-bound. Built upon our analysis tool, we\nfurther develop a learning method for synthesizing neural contraction metrics\nfrom sampled data. Finally, our approach is validated through the successful\nsynthesis and verification of NN contraction metrics for various nonlinear\nexamples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b66\u4e60\u548c\u9a8c\u8bc1\u795e\u7ecf\u7f51\u7edc\u6536\u7f29\u5ea6\u91cf\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u79bb\u6563\u65f6\u95f4\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u975e\u5149\u6ed1\u52a8\u6001\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u9a8c\u8bc1\u3002", "motivation": "\u6536\u7f29\u5ea6\u91cf\u5728\u63a7\u5236\u7406\u8bba\u4e2d\u5bf9\u7a33\u5b9a\u6027\u3001\u9c81\u68d2\u6027\u548c\u6536\u655b\u6027\u5206\u6790\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u590d\u6742\u975e\u7ebf\u6027\u7cfb\u7edf\u7f3a\u4e4f\u53ef\u6269\u5c55\u5de5\u5177\uff0c\u5c24\u5176\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u5668\u5f15\u5165\u975e\u5149\u6ed1\u52a8\u6001\u3002", "method": "\u5efa\u7acb\u4e86\u65b0\u7684\u5145\u5206\u6761\u4ef6\uff0c\u4ec5\u5047\u8bbe\u52a8\u6001\u8fde\u7eed\u6027\uff0c\u4f7f\u7528\u03b1,\u03b2-CROWN\u9a8c\u8bc1\u5668\u9ad8\u6548\u9a8c\u8bc1\uff0c\u5e76\u5f00\u53d1\u4ece\u91c7\u6837\u6570\u636e\u5b66\u4e60\u5408\u6210\u795e\u7ecf\u6536\u7f29\u5ea6\u91cf\u7684\u65b9\u6cd5\u3002", "result": "\u6210\u529f\u4e3a\u5404\u79cd\u975e\u7ebf\u6027\u793a\u4f8b\u5408\u6210\u548c\u9a8c\u8bc1\u4e86\u795e\u7ecf\u7f51\u7edc\u6536\u7f29\u5ea6\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u3002"}}
{"id": "2504.17140", "pdf": "https://arxiv.org/pdf/2504.17140", "abs": "https://arxiv.org/abs/2504.17140", "authors": ["Ashish Ranjan", "Ayush Agarwal", "Shalin Barot", "Sushant Kumar"], "title": "Scalable Permutation-Aware Modeling for Temporal Set Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Temporal set prediction involves forecasting the elements that will appear in\nthe next set, given a sequence of prior sets, each containing a variable number\nof elements. Existing methods often rely on intricate architectures with\nsubstantial computational overhead, which hampers their scalability. In this\nwork, we introduce a novel and scalable framework that leverages\npermutation-equivariant and permutation-invariant transformations to\nefficiently model set dynamics. Our approach significantly reduces both\ntraining and inference time while maintaining competitive performance.\nExtensive experiments on multiple public benchmarks show that our method\nachieves results on par with or superior to state-of-the-art models across\nseveral evaluation metrics. These results underscore the effectiveness of our\nmodel in enabling efficient and scalable temporal set prediction.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u96c6\u9884\u6d4b\uff0c\u901a\u8fc7\u4f7f\u7528\u7f6e\u6362\u7b49\u53d8\u548c\u7f6e\u6362\u4e0d\u53d8\u53d8\u6362\uff0c\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u67b6\u6784\uff0c\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u5f71\u54cd\u53ef\u6269\u5c55\u6027\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u5229\u7528\u7f6e\u6362\u7b49\u53d8\u548c\u7f6e\u6362\u4e0d\u53d8\u53d8\u6362\u6765\u9ad8\u6548\u5efa\u6a21\u96c6\u52a8\u6001\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5171\u57fa\u51c6\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u8bc4\u4ef7\u6307\u6807\u4e0a\u8fbe\u5230\u6216\u8d85\u8fc7\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4\u3002", "conclusion": "\u8be5\u6a21\u578b\u6709\u6548\u5b9e\u73b0\u4e86\u9ad8\u6548\u548c\u53ef\u6269\u5c55\u7684\u65f6\u95f4\u5e8f\u5217\u96c6\u9884\u6d4b\u3002"}}
{"id": "2504.17103", "pdf": "https://arxiv.org/pdf/2504.17103", "abs": "https://arxiv.org/abs/2504.17103", "authors": ["J. Francisco Presenza", "Ignacio Mas", "J. Ignacio Alvarez-Hamelin", "Juan I. Giribet"], "title": "Subframework-based Bearing Rigidity Maintenance Control in Multirobot Networks", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "6 pages", "summary": "This work presents a novel approach for analyzing and controlling bearing\nrigidity in multi-robot networks with dynamic topology. By decomposing the\nsystem's framework into subframeworks, we express bearing rigidity, a global\nproperty, as a set of local properties, with rigidity eigenvalues serving as\nnatural local rigidity metrics. We propose a decentralized, scalable,\ngradient-based controller that uses only bearing measurements to execute\nmission-specific commands. The controller preserves bearing rigidity by\nmaintaining rigidity eigenvalues above a threshold, and also avoids inter-robot\ncollisions. Simulations confirm the scheme's effectiveness, with information\nexchange confined to subframeworks, underscoring its scalability and\npracticality.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5206\u89e3\u6846\u67b6\u6765\u63a7\u5236\u591a\u673a\u5668\u4eba\u7f51\u7edc\u8f74\u627f\u521a\u5ea6\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u52a8\u6001\u62d3\u6251\u7684\u591a\u673a\u5668\u4eba\u7f51\u7edc\u4e2d\uff0c\u9700\u8981\u5206\u6790\u548c\u63a7\u5236\u8f74\u627f\u521a\u5ea6\u4ee5\u786e\u4fdd\u7cfb\u7edf\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u6027\u3002", "method": "\u5c06\u7cfb\u7edf\u6846\u67b6\u5206\u89e3\u4e3a\u5b50\u6846\u67b6\uff0c\u5c06\u5168\u5c40\u8f74\u627f\u521a\u5ea6\u8f6c\u5316\u4e3a\u5c40\u90e8\u5c5e\u6027\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u68af\u5ea6\u7684\u53bb\u4e2d\u5fc3\u5316\u63a7\u5236\u5668\uff0c\u4f7f\u7528\u8f74\u627f\u6d4b\u91cf\u4fdd\u6301\u521a\u5ea6\u548c\u907f\u514d\u78b0\u649e\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8bc1\u5b9e\u4e86\u65b9\u6848\u7684\u6709\u6548\u6027\uff0c\u4fe1\u606f\u4ea4\u6362\u4ec5\u9650\u4e8e\u5b50\u6846\u67b6\uff0c\u786e\u4fdd\u4e86\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8f74\u627f\u521a\u5ea6\u63a7\u5236\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2504.17160", "pdf": "https://arxiv.org/pdf/2504.17160", "abs": "https://arxiv.org/abs/2504.17160", "authors": ["Alberto Fern\u00e1ndez-Hern\u00e1ndez", "Jose I. Mestre", "Manuel F. Dolz", "Jose Duato", "Enrique S. Quintana-Ort\u00ed"], "title": "OUI Need to Talk About Weight Decay: A New Perspective on Overfitting Detection", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "10 pages, 3 figures", "summary": "We introduce the Overfitting-Underfitting Indicator (OUI), a novel tool for\nmonitoring the training dynamics of Deep Neural Networks (DNNs) and identifying\noptimal regularization hyperparameters. Specifically, we validate that OUI can\neffectively guide the selection of the Weight Decay (WD) hyperparameter by\nindicating whether a model is overfitting or underfitting during training\nwithout requiring validation data. Through experiments on DenseNet-BC-100 with\nCIFAR- 100, EfficientNet-B0 with TinyImageNet and ResNet-34 with ImageNet-1K,\nwe show that maintaining OUI within a prescribed interval correlates strongly\nwith improved generalization and validation scores. Notably, OUI converges\nsignificantly faster than traditional metrics such as loss or accuracy,\nenabling practitioners to identify optimal WD (hyperparameter) values within\nthe early stages of training. By leveraging OUI as a reliable indicator, we can\ndetermine early in training whether the chosen WD value leads the model to\nunderfit the training data, overfit, or strike a well-balanced trade-off that\nmaximizes validation scores. This enables more precise WD tuning for optimal\nperformance on the tested datasets and DNNs. All code for reproducing these\nexperiments is available at https://github.com/AlbertoFdezHdez/OUI.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f15\u5165OUI\u6307\u6807\uff0c\u7528\u4e8e\u76d1\u63a7DNN\u8bad\u7ec3\u52a8\u6001\uff0c\u6307\u5bfcWeight Decay\u8d85\u53c2\u6570\u9009\u62e9\uff0c\u65e0\u9700\u9a8c\u8bc1\u6570\u636e\uff0c\u63d0\u9ad8\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u52a8\u673a\u662f\u6539\u8fdb\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u7279\u522b\u662f\u5728Weight Decay\u4e0a\uff0c\u76d1\u63a7\u8fc7\u62df\u5408\u548c\u6b20\u62df\u5408\uff0c\u800c\u4e0d\u4f9d\u8d56\u9a8c\u8bc1\u96c6\u3002", "method": "\u65b9\u6cd5\u662f\u901a\u8fc7\u5f15\u5165OUI\u5e76\u5728DenseNet-BC-100\u3001EfficientNet-B0\u548cResNet-34\u4e0a\u5b9e\u9a8c\uff0c\u76d1\u63a7\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u7ed3\u679c\u663e\u793aOUI\u66f4\u5feb\u6536\u655b\uff0c\u4e0e\u66f4\u597d\u6cdb\u5316\u76f8\u5173\uff0c\u5e2e\u52a9\u65e9\u671f\u8bc6\u522b\u6700\u4f73WD\u503c\u3002", "conclusion": "\u7ed3\u8bba\u662fOUI\u53ef\u7cbe\u786e\u8c03\u4f18WD\uff0c\u63d0\u9ad8\u6027\u80fd\uff0c\u4ee3\u7801\u5f00\u6e90\u53ef\u590d\u73b0\u3002"}}
{"id": "2504.17124", "pdf": "https://arxiv.org/pdf/2504.17124", "abs": "https://arxiv.org/abs/2504.17124", "authors": ["Ming Du", "Mark Wolfman", "Chengjun Sun", "Shelly D. Kelly", "Mathew J. Cherukara"], "title": "Demonstration of an AI-driven workflow for dynamic x-ray spectroscopy", "categories": ["physics.app-ph", "cs.AI", "cs.CE", "cs.SY", "eess.SY"], "comment": null, "summary": "X-ray absorption near edge structure (XANES) spectroscopy is a powerful\ntechnique for characterizing the chemical state and symmetry of individual\nelements within materials, but requires collecting data at many energy points\nwhich can be time-consuming. While adaptive sampling methods exist for\nefficiently collecting spectroscopic data, they often lack domain-specific\nknowledge about XANES spectra structure. Here we demonstrate a\nknowledge-injected Bayesian optimization approach for adaptive XANES data\ncollection that incorporates understanding of spectral features like absorption\nedges and pre-edge peaks. We show this method accurately reconstructs the\nabsorption edge of XANES spectra using only 15-20% of the measurement points\ntypically needed for conventional sampling, while maintaining the ability to\ndetermine the x-ray energy of the sharp peak after absorption edge with errors\nless than 0.03 eV, the absorption edge with errors less than 0.1 eV; and\noverall root-mean-square errors less than 0.005 compared to compared to\ntraditionally sampled spectra. Our experiments on battery materials and\ncatalysts demonstrate the method's effectiveness for both static and dynamic\nXANES measurements, improving data collection efficiency and enabling better\ntime resolution for tracking chemical changes. This approach advances the\ndegree of automation in XANES experiments reducing the common errors of under-\nor over-sampling points in near the absorption edge and enabling dynamic\nexperiments that require high temporal resolution or limited measurement time.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6ce8\u5165\u77e5\u8bc6\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8eXANES\u5149\u8c31\u7684\u81ea\u9002\u5e94\u6570\u636e\u91c7\u96c6\uff0c\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "XANES\u5149\u8c31\u91c7\u96c6\u9700\u8981\u8bb8\u591a\u80fd\u91cf\u70b9\uff0c\u8017\u65f6\u957f\uff0c\u73b0\u6709\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\uff0c\u56e0\u6b64\u9700\u8981\u7ed3\u5408\u5149\u8c31\u7ed3\u6784\u77e5\u8bc6\u6765\u4f18\u5316\u3002", "method": "\u4f7f\u7528\u6ce8\u5165\u77e5\u8bc6\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u8003\u8651\u5438\u6536\u8fb9\u548c\u9884\u8fb9\u5cf0\u7b49\u5149\u8c31\u7279\u5f81\uff0c\u8fdb\u884c\u81ea\u9002\u5e94\u91c7\u6837\u3002", "result": "\u65b9\u6cd5\u4ec5\u752815-20%\u7684\u6d4b\u91cf\u70b9\u91cd\u5efa\u5149\u8c31\uff0c\u5cf0\u80fd\u91cf\u9519\u8bef\u5c0f\u4e8e0.03 eV\uff0c\u5438\u6536\u8fb9\u9519\u8bef\u5c0f\u4e8e0.1 eV\uff0cRMS\u9519\u8bef\u5c0f\u4e8e0.005\uff1b\u5728\u7535\u6c60\u6750\u6599\u548c\u50ac\u5316\u5242\u4e0a\u9a8c\u8bc1\u4e86\u9759\u6001\u548c\u52a8\u6001\u6d4b\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6570\u636e\u91c7\u96c6\u6548\u7387\uff0c\u589e\u5f3a\u4e86\u81ea\u52a8\u5316\uff0c\u51cf\u5c11\u4e86\u91c7\u6837\u9519\u8bef\uff0c\u5e76\u63d0\u5347\u4e86\u52a8\u6001\u5b9e\u9a8c\u7684\u65f6\u95f4\u5206\u8fa8\u7387\u3002"}}
{"id": "2504.16977", "pdf": "https://arxiv.org/pdf/2504.16977", "abs": "https://arxiv.org/abs/2504.16977", "authors": ["Priyaranjan Pattnayak", "Hitesh Laxmichand Patel", "Amit Agarwal"], "title": "Tokenization Matters: Improving Zero-Shot NER for Indic Languages", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Tokenization is a critical component of Natural Language Processing (NLP),\nespecially for low resource languages, where subword segmentation influences\nvocabulary structure and downstream task accuracy. Although Byte Pair Encoding\n(BPE) is a standard tokenization method in multilingual language models, its\nsuitability for Named Entity Recognition (NER) in low resource Indic languages\nremains underexplored due to its limitations in handling morphological\ncomplexity. In this work, we systematically compare BPE, SentencePiece, and\nCharacter Level tokenization strategies using IndicBERT for NER tasks in low\nresource Indic languages like Assamese, Bengali, Marathi, and Odia, as well as\nextremely low resource Indic languages like Santali, Manipuri, and Sindhi. We\nassess both intrinsic linguistic properties tokenization efficiency, out of\nvocabulary (OOV) rates, and morphological preservation as well as extrinsic\ndownstream performance, including fine tuning and zero shot cross lingual\ntransfer.\n  Our experiments show that SentencePiece is a consistently better performing\napproach than BPE for NER in low resource Indic Languages, particularly in zero\nshot cross lingual settings, as it better preserves entity consistency. While\nBPE provides the most compact tokenization form, it is not capable of\ngeneralization because it misclassifies or even fails to recognize entity\nlabels when tested on unseen languages. In contrast, SentencePiece constitutes\na better linguistic structural preservation model, benefiting extremely low\nresource and morphologically rich Indic languages, such as Santali and\nManipuri, for superior entity recognition, as well as high generalization\nacross scripts, such as Sindhi, written in Arabic. The results point to\nSentencePiece as the more effective tokenization strategy for NER within\nmultilingual and low resource Indic NLP applications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u6bd4\u8f83\u4e86\u5728\u4f4e\u8d44\u6e90\u5370\u5ea6\u8bed\u8a00NER\u4e2d\u7684\u6807\u8bb0\u5316\u65b9\u6cd5\uff0c\u53d1\u73b0SentencePiece\u4f18\u4e8eBPE\u3002", "motivation": "\u89e3\u51b3BPE\u5728\u5904\u7406\u4f4e\u8d44\u6e90\u5370\u5ea6\u8bed\u8a00NER\u65f6\u5f62\u6001\u590d\u6742\u6027\u7684\u9650\u5236\u3002", "method": "\u4f7f\u7528IndicBERT\u7cfb\u7edf\u6bd4\u8f83BPE\u3001SentencePiece\u548c\u5b57\u7b26\u7ea7\u6807\u8bb0\u5316\u7b56\u7565\uff0c\u8bc4\u4f30NER\u5728\u963f\u8428\u59c6\u8bed\u3001\u5b5f\u52a0\u62c9\u8bed\u3001\u9a6c\u62c9\u5730\u8bed\u3001\u5965\u91cc\u4e9a\u8bed\u3001\u6851\u5854\u5229\u8bed\u3001\u66fc\u5c3c\u666e\u5c14\u8bed\u548c\u4fe1\u5fb7\u8bed\u4e2d\u7684\u56fa\u6709\u7279\u6027\u548c\u5916\u90e8\u6027\u80fd\uff0c\u5305\u62ec\u5fae\u8c03\u548c\u96f6\u6837\u672c\u8de8\u8bed\u8a00\u8f6c\u79fb\u3002", "result": "SentencePiece\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u5c24\u5176\u5728\u5b9e\u4f53\u4e00\u81f4\u6027\u548c\u6cdb\u5316\u65b9\u9762\u4f18\u4e8eBPE\uff0c\u5bf9\u6781\u4f4e\u8d44\u6e90\u548c\u5f62\u6001\u4e30\u5bcc\u7684\u8bed\u8a00\u5982\u6851\u5854\u5229\u8bed\u548c\u66fc\u5c3c\u666e\u5c14\u8bed\u66f4\u6709\u6548\u3002", "conclusion": "\u63a8\u8350SentencePiece\u4f5c\u4e3a\u591a\u8bed\u8a00\u548c\u4f4e\u8d44\u6e90\u5370\u5ea6NLP\u5e94\u7528\u4e2dNER\u7684\u66f4\u6709\u6548\u6807\u8bb0\u5316\u7b56\u7565\u3002"}}
{"id": "2504.17196", "pdf": "https://arxiv.org/pdf/2504.17196", "abs": "https://arxiv.org/abs/2504.17196", "authors": ["Jiawen Hou", "Hao Wu"], "title": "A Double-Norm Aggregated Tensor Latent Factorization Model for Temporal-Aware Traffic Speed Imputation", "categories": ["cs.LG"], "comment": "11pages,3figures", "summary": "In intelligent transportation systems (ITS), traffic management departments\nrely on sensors, cameras, and GPS devices to collect real-time traffic data.\nTraffic speed data is often incomplete due to sensor failures, data\ntransmission delays, or occlusions, resulting in missing speed data in certain\nroad segments. Currently, tensor decomposition based methods are extensively\nutilized, they mostly rely on the $L_2$-norm to construct their learning\nobjectives, which leads to reduced robustness in the algorithms. To address\nthis, we propose Temporal-Aware Traffic Speed Imputation (TATSI), which\ncombines the $L_2$-norm and smooth $L_1$ (${SL}_1$)-norm in its loss function,\nthereby achieving both high accuracy and robust performance in imputing missing\ntime-varying traffic speed data. TATSI adopts a single latent factor-dependent,\nnonnegative, and multiplicative update (SLF-NMU) approach, which serves as an\nefficient solver for performing nonnegative latent factor analysis (LFA) on a\ntensor. Empirical studies on three real-world time-varying traffic speed\ndatasets demonstrate that, compared with state-of-the-art traffic speed\npredictors, TATSI more precisely captures temporal patterns, thereby yielding\nthe most accurate imputations for missing traffic speed data.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faTATSI\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408L2\u8303\u6570\u548csmooth L1\u8303\u6570\uff0c\u63d0\u9ad8\u4ea4\u901a\u901f\u5ea6\u6570\u636e\u63d2\u503c\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4ea4\u901a\u7ba1\u7406\u7cfb\u7edf\u4e2d\uff0c\u901f\u5ea6\u6570\u636e\u5e38\u56e0\u4f20\u611f\u5668\u6545\u969c\u7b49\u7f3a\u5931\uff0c\u73b0\u6709\u7684L2\u8303\u6570\u65b9\u6cd5\u9c81\u68d2\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51faTATSI\uff0c\u4f7f\u7528L2\u548csmooth L1\u8303\u6570\u635f\u5931\u51fd\u6570\u53caSLF-NMU\u7b97\u6cd5\u8fdb\u884c\u975e\u8d1f\u6f5c\u53d8\u91cf\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u793a\uff0cTATSI\u66f4\u51c6\u786e\u6355\u6349\u65f6\u95f4\u6a21\u5f0f\uff0c\u63d0\u4f9b\u6700\u4f73\u7f3a\u5931\u6570\u636e\u63d2\u503c\u3002", "conclusion": "TATSI\u5728\u4ea4\u901a\u901f\u5ea6\u6570\u636e\u63d2\u503c\u4e2d\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2504.17154", "pdf": "https://arxiv.org/pdf/2504.17154", "abs": "https://arxiv.org/abs/2504.17154", "authors": ["Apurva Patil"], "title": "Advancing Frontiers of Path Integral Theory for Stochastic Optimal Control", "categories": ["math.OC", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Stochastic Optimal Control (SOC) problems arise in systems influenced by\nuncertainty, such as autonomous robots or financial models. Traditional methods\nlike dynamic programming are often intractable for high-dimensional, nonlinear\nsystems due to the curse of dimensionality. This dissertation explores the path\nintegral control framework as a scalable, sampling-based alternative. By\nreformulating SOC problems as expectations over stochastic trajectories, it\nenables efficient policy synthesis via Monte Carlo sampling and supports\nreal-time implementation through GPU parallelization.\n  We apply this framework to six classes of SOC problems: Chance-Constrained\nSOC, Stochastic Differential Games, Deceptive Control, Task Hierarchical\nControl, Risk Mitigation of Stealthy Attacks, and Discrete-Time LQR. A sample\ncomplexity analysis for the discrete-time case is also provided. These\ncontributions establish a foundation for simulator-driven autonomy in complex,\nuncertain environments.", "AI": {"tldr": "\u672c\u8bba\u6587\u4f7f\u7528\u8def\u5f84\u79ef\u5206\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u91c7\u6837\u65b9\u6cd5\u9ad8\u6548\u89e3\u51b3\u9ad8\u7ef4\u968f\u673a\u6700\u4f18\u63a7\u5236\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5982\u52a8\u6001\u89c4\u5212\u5728\u9ad8\u7ef4\u975e\u7ebf\u6027\u7cfb\u7edf\u4e2d\u56e0\u7ef4\u6570\u707e\u96be\u800c\u96be\u4ee5\u5904\u7406\uff0c\u9488\u5bf9\u4e0d\u786e\u5b9a\u6027\u7cfb\u7edf\u63d0\u51fa\u53ef\u6269\u5c55\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u91cd\u6784SOC\u95ee\u9898\u4e3a\u968f\u673a\u8f68\u8ff9\u671f\u671b\uff0c\u5229\u7528Monte Carlo\u91c7\u6837\u548cGPU\u5e76\u884c\u5316\u5b9e\u73b0\u7b56\u7565\u5408\u6210\u3002", "result": "\u5e94\u7528\u4e8e\u516d\u7c7bSOC\u95ee\u9898\uff0c\u5305\u62ec\u673a\u4f1a\u7ea6\u675fSOC\u7b49\uff0c\u5e76\u63d0\u4f9b\u79bb\u6563\u65f6\u95f4\u6837\u672c\u590d\u6742\u5ea6\u5206\u6790\u3002", "conclusion": "\u4e3a\u590d\u6742\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u6a21\u62df\u5668\u9a71\u52a8\u81ea\u6cbb\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2504.16979", "pdf": "https://arxiv.org/pdf/2504.16979", "abs": "https://arxiv.org/abs/2504.16979", "authors": ["Masoud Tafavvoghi", "Lars Ailo Bongo", "Andr\u00e9 Berli Delgado", "Nikita Shvetsov", "Anders Sildnes", "Line Moi", "Lill-Tove Rasmussen Busund", "Kajsa M\u00f8llersen"], "title": "Automating tumor-infiltrating lymphocyte assessment in breast cancer histopathology images using QuPath: a transparent and accessible machine learning pipeline", "categories": ["q-bio.QM", "cs.AI", "cs.CV"], "comment": "16 Pages, 9 Figures, 3 tables", "summary": "In this study, we built an end-to-end tumor-infiltrating lymphocytes (TILs)\nassessment pipeline within QuPath, demonstrating the potential of easily\naccessible tools to perform complex tasks in a fully automatic fashion. First,\nwe trained a pixel classifier to segment tumor, tumor-associated stroma, and\nother tissue compartments in breast cancer H&E-stained whole-slide images (WSI)\nto isolate tumor-associated stroma for subsequent analysis. Next, we applied a\npre-trained StarDist deep learning model in QuPath for cell detection and used\nthe extracted cell features to train a binary classifier distinguishing TILs\nfrom other cells. To evaluate our TILs assessment pipeline, we calculated the\nTIL density in each WSI and categorized them as low, medium, or high TIL\nlevels. Our pipeline was evaluated against pathologist-assigned TIL scores,\nachieving a Cohen's kappa of 0.71 on the external test set, corroborating\nprevious research findings. These results confirm that existing software can\noffer a practical solution for the assessment of TILs in H&E-stained WSIs of\nbreast cancer.", "AI": {"tldr": "\u672c\u7814\u7a76\u5728QuPath\u4e2d\u6784\u5efa\u4e86\u4e00\u4e2a\u7aef\u5230\u7aefTILs\u8bc4\u4f30\u7ba1\u9053\uff0c\u4f7f\u7528\u50cf\u7d20\u5206\u7c7b\u5668\u548cStarDist\u6a21\u578b\u81ea\u52a8\u8bc4\u4f30\u4e73\u817a\u764cH&E\u67d3\u8272\u5168\u6ed1\u56fe\u50cf\u4e2d\u7684TILs\uff0c\u4e0e\u75c5\u7406\u5b66\u5bb6\u8bc4\u5206\u4e00\u81f4\uff0cCohen's kappa\u4e3a0.71\u3002", "motivation": "\u5c55\u793a\u6613\u4e8e\u8bbf\u95ee\u7684\u5de5\u5177\u53ef\u4ee5\u81ea\u52a8\u6267\u884c\u590d\u6742\u4efb\u52a1\uff0c\u4ee5\u7b80\u5316TILs\u8bc4\u4f30\u3002", "method": "\u8bad\u7ec3\u50cf\u7d20\u5206\u7c7b\u5668\u5206\u5272\u80bf\u7624\u3001\u80bf\u7624\u76f8\u5173\u57fa\u8d28\u548c\u5176\u4ed6\u7ec4\u7ec7\uff1b\u5e94\u7528\u9884\u8bad\u7ec3StarDist\u6a21\u578b\u68c0\u6d4b\u7ec6\u80de\uff1b\u8bad\u7ec3\u4e8c\u5143\u5206\u7c7b\u5668\u533a\u5206TILs\uff1b\u8ba1\u7b97TIL\u5bc6\u5ea6\u5e76\u5206\u7c7b\u4e3a\u4f4e\u3001\u4e2d\u3001\u9ad8\u6c34\u5e73\u3002", "result": "\u5728\u5916\u90e8\u6d4b\u8bd5\u96c6\u4e0a\uff0cCohen's kappa\u4e3a0.71\uff0c\u4e0e\u75c5\u7406\u5b66\u5bb6\u8bc4\u5206\u4e00\u81f4\u3002", "conclusion": "\u786e\u8ba4\u73b0\u6709\u8f6f\u4ef6\u53ef\u4ee5\u4e3a\u4e73\u817a\u764cH&E\u67d3\u8272WSI\u4e2d\u7684TILs\u8bc4\u4f30\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.17210", "pdf": "https://arxiv.org/pdf/2504.17210", "abs": "https://arxiv.org/abs/2504.17210", "authors": ["Junfei Wang", "Darshana Upadhyay", "Marzia Zaman", "Pirathayini Srikantha"], "title": "Synthetic Power Flow Data Generation Using Physics-Informed Denoising Diffusion Probabilistic Models", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to IEEE SmartGridComm Conference 2025", "summary": "Many data-driven modules in smart grid rely on access to high-quality power\nflow data; however, real-world data are often limited due to privacy and\noperational constraints. This paper presents a physics-informed generative\nframework based on Denoising Diffusion Probabilistic Models (DDPMs) for\nsynthesizing feasible power flow data. By incorporating auxiliary training and\nphysics-informed loss functions, the proposed method ensures that the generated\ndata exhibit both statistical fidelity and adherence to power system\nfeasibility. We evaluate the approach on the IEEE 14-bus and 30-bus benchmark\nsystems, demonstrating its ability to capture key distributional properties and\ngeneralize to out-of-distribution scenarios. Comparative results show that the\nproposed model outperforms three baseline models in terms of feasibility,\ndiversity, and accuracy of statistical features. This work highlights the\npotential of integrating generative modelling into data-driven power system\napplications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u548cDenoising Diffusion Probabilistic Models (DDPMs)\u7684\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u5408\u6210\u53ef\u884c\u7684\u7535\u529b\u6d41\u6570\u636e\uff0c\u4ee5\u89e3\u51b3\u667a\u80fd\u7535\u7f51\u4e2d\u6570\u636e\u9a71\u52a8\u6a21\u5757\u5bf9\u9ad8\u8d28\u91cf\u6570\u636e\u7684\u9700\u6c42\u3002", "motivation": "\u7531\u4e8e\u9690\u79c1\u548c\u64cd\u4f5c\u7ea6\u675f\uff0c\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u5f80\u5f80\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u5408\u6210\u9ad8\u8d28\u91cf\u7684\u7535\u529b\u6d41\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eDDPMs\u7684\u751f\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u8f85\u52a9\u8bad\u7ec3\u548c\u7269\u7406\u4fe1\u606f\u635f\u5931\u51fd\u6570\uff0c\u786e\u4fdd\u751f\u6210\u7684\u6570\u636e\u5728\u7edf\u8ba1\u4e0a\u771f\u5b9e\u5e76\u7b26\u5408\u7535\u529b\u7cfb\u7edf\u53ef\u884c\u6027\u3002", "result": "\u5728IEEE 14-bus\u548c30-bus\u57fa\u51c6\u7cfb\u7edf\u4e0a\u8bc4\u4f30\uff0c\u6a21\u578b\u80fd\u591f\u6355\u6349\u5173\u952e\u5206\u5e03\u7279\u6027\u3001\u5728\u5206\u5e03\u5916\u573a\u666f\u4e0b\u6cdb\u5316\uff0c\u5e76\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u5728\u53ef\u884c\u6027\u3001\u591a\u6837\u6027\u548c\u7edf\u8ba1\u7279\u5f81\u51c6\u786e\u6027\u65b9\u9762\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u7a81\u51fa\u4e86\u5c06\u751f\u6210\u6a21\u578b\u96c6\u6210\u5230\u6570\u636e\u9a71\u52a8\u7684\u7535\u529b\u7cfb\u7edf\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.17268", "pdf": "https://arxiv.org/pdf/2504.17268", "abs": "https://arxiv.org/abs/2504.17268", "authors": ["Alexander Demin", "Alexey Ovchinnikov", "Fabrice Rouillier"], "title": "Parameter Estimation in ODE Models with Certified Polynomial System Solving", "categories": ["cs.SC", "cs.MS", "cs.SY", "eess.SY", "math.DS", "68W30, 34-04, 93B30"], "comment": "3 pages", "summary": "We consider dynamical models given by rational ODE systems. Parameter\nestimation is an important and challenging task of recovering parameter values\nfrom observed data. Recently, a method based on differential algebra and\nrational interpolation was proposed to express parameter estimation in terms of\npolynomial system solving. Typically, polynomial system solving is a\nbottleneck, hence the choice of the polynomial solver is crucial. In this\ncontribution, we compare two polynomial system solvers applied to parameter\nestimation: homotopy continuation solver from HomotopyContinuation.jl and our\nnew implementation of a certified solver based on rational univariate\nrepresentation (RUR) and real root isolation. We show how the new RUR solver\ncan tackle examples that are out of reach for the homotopy methods and vice\nversa.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u6bd4\u8f83\u4e86\u4e24\u79cd\u591a\u9879\u5f0f\u6c42\u89e3\u5668\u5728\u7406\u6027ODE\u7cfb\u7edf\u53c2\u6570\u4f30\u8ba1\u4e2d\u7684\u6027\u80fd\uff1ahomotopy continuation\u548c\u57fa\u4e8eRUR\u7684\u8ba4\u8bc1\u6c42\u89e3\u5668\u3002", "motivation": "\u53c2\u6570\u4f30\u8ba1\u662f\u7406\u6027ODE\u7cfb\u7edf\u4e2d\u7684\u91cd\u8981\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u9700\u8981\u4ece\u89c2\u5bdf\u6570\u636e\u4e2d\u6062\u590d\u53c2\u6570\u503c\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5fae\u5206\u4ee3\u6570\u548c\u7406\u6027\u63d2\u503c\u7684\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u6bd4\u8f83HomotopyContinuation.jl\u7684homotopy continuation\u6c42\u89e3\u5668\u548c\u57fa\u4e8e\u7406\u6027\u5355\u53d8\u91cf\u8868\u793a(RUR)\u7684\u8ba4\u8bc1\u6c42\u89e3\u5668\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0cRUR\u6c42\u89e3\u5668\u53ef\u4ee5\u5904\u7406\u4e00\u4e9bhomotopy\u65b9\u6cd5\u65e0\u6cd5\u89e3\u51b3\u7684\u4f8b\u5b50\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002", "conclusion": "\u8fd9\u5f3a\u8c03\u4e86\u5728\u591a\u9879\u5f0f\u7cfb\u7edf\u6c42\u89e3\u4e2d\u9009\u62e9\u9002\u5f53\u6c42\u89e3\u5668\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u63d0\u9ad8\u53c2\u6570\u4f30\u8ba1\u7684\u6548\u7387\u548c\u53ef\u884c\u6027\u3002"}}
{"id": "2504.17219", "pdf": "https://arxiv.org/pdf/2504.17219", "abs": "https://arxiv.org/abs/2504.17219", "authors": ["Hyomin Lee", "Minseon Kim", "Sangwon Jang", "Jongheon Jeong", "Sung Ju Hwang"], "title": "Enhancing Variational Autoencoders with Smooth Robust Latent Encoding", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Under review", "summary": "Variational Autoencoders (VAEs) have played a key role in scaling up\ndiffusion-based generative models, as in Stable Diffusion, yet questions\nregarding their robustness remain largely underexplored. Although adversarial\ntraining has been an established technique for enhancing robustness in\npredictive models, it has been overlooked for generative models due to concerns\nabout potential fidelity degradation by the nature of trade-offs between\nperformance and robustness. In this work, we challenge this presumption,\nintroducing Smooth Robust Latent VAE (SRL-VAE), a novel adversarial training\nframework that boosts both generation quality and robustness. In contrast to\nconventional adversarial training, which focuses on robustness only, our\napproach smooths the latent space via adversarial perturbations, promoting more\ngeneralizable representations while regularizing with originality\nrepresentation to sustain original fidelity. Applied as a post-training step on\npre-trained VAEs, SRL-VAE improves image robustness and fidelity with minimal\ncomputational overhead. Experiments show that SRL-VAE improves both generation\nquality, in image reconstruction and text-guided image editing, and robustness,\nagainst Nightshade attacks and image editing attacks. These results establish a\nnew paradigm, showing that adversarial training, once thought to be detrimental\nto generative models, can instead enhance both fidelity and robustness.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165SRL-VAE\uff0c\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u63d0\u5347VAE\u7684\u751f\u6210\u8d28\u91cf\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4fdd\u771f\u5ea6\u3002", "motivation": "\u5bf9\u6297\u8bad\u7ec3\u88ab\u5ffd\u7565\uff0c\u56e0\u4e3a\u53ef\u80fd\u964d\u4f4e\u751f\u6210\u6a21\u578b\u7684\u4fdd\u771f\u5ea6\uff0c\u672c\u6587\u6311\u6218\u8fd9\u4e00\u89c2\u70b9\uff0c\u65e8\u5728\u8bc1\u660e\u5b83\u80fd\u540c\u65f6\u63d0\u5347\u8d28\u91cf\u548c\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faSRL-VAE\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u6270\u52a8\u5e73\u6ed1\u6f5c\u5728\u7a7a\u95f4\uff0c\u4fc3\u8fdb\u6cdb\u5316\u8868\u793a\uff0c\u5e76\u6b63\u5219\u5316\u4ee5\u7ef4\u6301\u4fdd\u771f\u5ea6\uff0c\u4f5c\u4e3a\u9884\u8bad\u7ec3VAE\u7684\u540e\u5904\u7406\u6b65\u9aa4\u3002", "result": "\u5b9e\u9a8c\u663e\u793aSRL-VAE\u6539\u5584\u56fe\u50cf\u91cd\u5efa\u3001\u6587\u672c\u5f15\u5bfc\u7f16\u8f91\u7684\u8d28\u91cf\u548c\u5bf9\u7279\u5b9a\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u8ba1\u7b97\u5f00\u9500\u4f4e\u3002", "conclusion": "\u5efa\u7acb\u65b0\u8303\u5f0f\uff0c\u8bc1\u660e\u5bf9\u6297\u8bad\u7ec3\u80fd\u589e\u5f3a\u751f\u6210\u6a21\u578b\u7684\u4fdd\u771f\u5ea6\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2504.17417", "pdf": "https://arxiv.org/pdf/2504.17417", "abs": "https://arxiv.org/abs/2504.17417", "authors": ["Marco Peruzzo", "Giacomo Baggio", "Francesco Ticozzi"], "title": "Obtaining Structural Network Controllability with Higher-Order Local Dynamics", "categories": ["math.OC", "cs.SY", "eess.SY"], "comment": "Submitted to Transactions on Control of Network Systems", "summary": "We consider a network of identical, first-order linear systems, and\ninvestigate how replacing a subset of the systems composing the network with\nhigher-order ones, either taken to be generic or specifically designed, may\naffect its controllability. After establishing a correspondence between state\ncontrollability in networks of first-order systems with output controllability\nin networks of higher-order systems, we show that adding higher-order dynamics\nmay require significantly fewer subsystem modifications to achieve structural\ncontrollability, when compared to first-order heterogeneous subsystems.\nFurthermore, we characterize the topology of networks (which we call\nX-networks) in which the introduction of heterogeneous local dynamics is not\nnecessary for structural output controllability, as the latter can be attained\nby suitable higher-order subsystems with homogeneous internal dynamics.", "AI": {"tldr": "This paper studies how replacing some first-order systems with higher-order ones in a network improves controllability, showing fewer modifications are needed and identifying networks where homogeneous dynamics suffice.", "motivation": "To explore how introducing higher-order dynamics affects controllability in networks of identical first-order linear systems, aiming to reduce modifications for structural controllability.", "method": "Establishes a correspondence between state controllability in first-order networks and output controllability in higher-order networks, compares modification efficiency, and characterizes X-networks with homogeneous dynamics.", "result": "Higher-order dynamics require fewer changes for structural controllability than heterogeneous first-order subsystems; identifies X-networks where homogeneous dynamics achieve output controllability.", "conclusion": "Higher-order subsystems enhance controllability more efficiently, and in certain topologies, structural output controllability can be achieved without heterogeneous dynamics."}}
{"id": "2504.17020", "pdf": "https://arxiv.org/pdf/2504.17020", "abs": "https://arxiv.org/abs/2504.17020", "authors": ["Kasper Engelen", "Guillermo A. P\u00e9rez", "Shrisha Rao"], "title": "Analyzing Value Functions of States in Parametric Markov Chains", "categories": ["cs.LO", "cs.AI"], "comment": "Published as part of the book \"Principles of Verification: Cycling\n  the Probabilistic Landscape: Essays Dedicated to Joost-Pieter Katoen on the\n  Occasion of His 60th Birthday, Part II\"", "summary": "Parametric Markov chains (pMC) are used to model probabilistic systems with\nunknown or partially known probabilities. Although (universal) pMC verification\nfor reachability properties is known to be coETR-complete, there have been\nefforts to approach it using potentially easier-to-check properties such as\nasking whether the pMC is monotonic in certain parameters. In this paper, we\nfirst reduce monotonicity to asking whether the reachability probability from a\ngiven state is never less than that of another given state. Recent results for\nthe latter property imply an efficient algorithm to collapse same-value\nequivalence classes, which in turn preserves verification results and\nmonotonicity. We implement our algorithm to collapse \"trivial\" equivalence\nclasses in the pMC and show empirical evidence for the following: First, the\ncollapse gives reductions in size for some existing benchmarks and significant\nreductions on some custom benchmarks; Second, the collapse speeds up existing\nalgorithms to check monotonicity and parameter lifting, and hence can be used\nas a fast pre-processing step in practice.", "AI": {"tldr": "This paper proposes an efficient algorithm to collapse equivalence classes in parametric Markov chains, reducing size and speeding up verification, with empirical evidence.", "motivation": "To simplify the coETR-complete verification of parametric Markov chains by using monotonicity and easier-to-check properties.", "method": "Reduces monotonicity to comparing reachability probabilities and uses an algorithm to collapse same-value equivalence classes.", "result": "Empirical results show size reductions in benchmarks and faster checks for monotonicity and parameter lifting.", "conclusion": "The algorithm can be used as a fast pre-processing step to improve practical verification efficiency."}}
{"id": "2504.17232", "pdf": "https://arxiv.org/pdf/2504.17232", "abs": "https://arxiv.org/abs/2504.17232", "authors": ["Nivedita M", "Yasmeen Shajitha S"], "title": "Multi-Modal Traffic Analysis: Integrating Time-Series Forecasting, Accident Prediction, and Image Classification", "categories": ["cs.LG"], "comment": "5 pages,10 figures", "summary": "This study proposes an integrated machine learning framework for advanced\ntraffic analysis, combining time-series forecasting, classification, and\ncomputer vision techniques. The system utilizes an ARIMA(2,0,1) model for\ntraffic prediction (MAE: 2.1), an XGBoost classifier for accident severity\nclassification (100% accuracy on balanced data), and a Convolutional Neural\nNetwork (CNN) for traffic image classification (92% accuracy). Tested on\ndiverse datasets, the framework outperforms baseline models and identifies key\nfactors influencing accident severity, including weather and road\ninfrastructure. Its modular design supports deployment in smart city systems\nfor real-time monitoring, accident prevention, and resource optimization,\ncontributing to the evolution of intelligent transportation systems.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u7ea7\u4ea4\u901a\u5206\u6790\uff0c\u7ed3\u5408\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3001\u5206\u7c7b\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u6280\u672f\u3002", "motivation": "\u4e3a\u4e86\u6539\u8fdb\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\uff0c\u5b9e\u73b0\u5b9e\u65f6\u76d1\u63a7\u3001\u4e8b\u6545\u9884\u9632\u548c\u8d44\u6e90\u4f18\u5316\u3002", "method": "\u4f7f\u7528ARIMA(2,0,1)\u6a21\u578b\u8fdb\u884c\u4ea4\u901a\u9884\u6d4b\u3001XGBoost\u5206\u7c7b\u5668\u8fdb\u884c\u4e8b\u6545\u4e25\u91cd\u7a0b\u5ea6\u5206\u7c7b\u3001CNN\u8fdb\u884c\u4ea4\u901a\u56fe\u50cf\u5206\u7c7b\u3002", "result": "ARIMA\u6a21\u578bMAE\u4e3a2.1\u3001XGBoost\u5728\u5e73\u8861\u6570\u636e\u4e0a\u51c6\u786e\u7387100%\u3001CNN\u51c6\u786e\u738792%\u3001\u6846\u67b6\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u8bc6\u522b\u4e86\u5929\u6c14\u548c\u9053\u8def\u57fa\u7840\u8bbe\u65bd\u7b49\u5f71\u54cd\u56e0\u7d20\u3002", "conclusion": "\u6846\u67b6\u7684\u6a21\u5757\u5316\u8bbe\u8ba1\u652f\u6301\u5728\u667a\u80fd\u57ce\u5e02\u7cfb\u7edf\u4e2d\u90e8\u7f72\uff0c\u4fc3\u8fdb\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7684\u6f14\u8fdb\u3002"}}
{"id": "2504.17569", "pdf": "https://arxiv.org/pdf/2504.17569", "abs": "https://arxiv.org/abs/2504.17569", "authors": ["Huajie Wu", "Wenyi Liu", "Yunfan Ren", "Zheng Liu", "Hairuo Wei", "Fangcheng Zhu", "Haotian Li", "Fu Zhang"], "title": "Flying through cluttered and dynamic environments with LiDAR", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Navigating unmanned aerial vehicles (UAVs) through cluttered and dynamic\nenvironments remains a significant challenge, particularly when dealing with\nfast-moving or sudden-appearing obstacles. This paper introduces a complete\nLiDAR-based system designed to enable UAVs to avoid various moving obstacles in\ncomplex environments. Benefiting the high computational efficiency of\nperception and planning, the system can operate in real time using onboard\ncomputing resources with low latency. For dynamic environment perception, we\nhave integrated our previous work, M-detector, into the system. M-detector\nensures that moving objects of different sizes, colors, and types are reliably\ndetected. For dynamic environment planning, we incorporate dynamic object\npredictions into the integrated planning and control (IPC) framework, namely\nDynIPC. This integration allows the UAV to utilize predictions about dynamic\nobstacles to effectively evade them. We validate our proposed system through\nboth simulations and real-world experiments. In simulation tests, our system\noutperforms state-of-the-art baselines across several metrics, including\nsuccess rate, time consumption, average flight time, and maximum velocity. In\nreal-world trials, our system successfully navigates through forests, avoiding\nmoving obstacles along its path.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLiDAR\u7684\u7cfb\u7edf\uff0c\u5e2e\u52a9\u65e0\u4eba\u673a\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u65f6\u907f\u5f00\u5404\u79cd\u79fb\u52a8\u969c\u788d\u7269\u3002", "motivation": "\u89e3\u51b3\u65e0\u4eba\u673a\u5728\u6742\u4e71\u52a8\u6001\u73af\u5883\u4e2d\u5bfc\u822a\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u9762\u5bf9\u5feb\u901f\u79fb\u52a8\u6216\u7a81\u7136\u51fa\u73b0\u7684\u969c\u788d\u7269\u3002", "method": "\u6574\u5408M-detector\u7528\u4e8e\u52a8\u6001\u7269\u4f53\u68c0\u6d4b\u548cDynIPC\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u52a8\u6001\u969c\u788d\u7269\u5e76\u8fdb\u884c\u89c4\u5212\u4e0e\u63a7\u5236\u3002", "result": "\u6a21\u62df\u6d4b\u8bd5\u4e2d\u5728\u6210\u529f\u7387\u3001\u65f6\u95f4\u6d88\u8017\u3001\u5e73\u5747\u98de\u884c\u65f6\u95f4\u548c\u6700\u5927\u901f\u5ea6\u7b49\u65b9\u9762\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\uff1b\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u6210\u529f\u907f\u5f00\u68ee\u6797\u4e2d\u7684\u79fb\u52a8\u969c\u788d\u7269\u3002", "conclusion": "\u7cfb\u7edf\u5229\u7528\u9ad8\u8ba1\u7b97\u6548\u7387\u5b9e\u73b0\u5b9e\u65f6\u4f4e\u5ef6\u8fdf\u907f\u969c\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u6709\u6548\u5de5\u4f5c\u3002"}}
{"id": "2504.17023", "pdf": "https://arxiv.org/pdf/2504.17023", "abs": "https://arxiv.org/abs/2504.17023", "authors": ["Felix Kares", "Timo Speith", "Hanwei Zhang", "Markus Langer"], "title": "What Makes for a Good Saliency Map? Comparing Strategies for Evaluating Saliency Maps in Explainable AI (XAI)", "categories": ["cs.HC", "cs.AI"], "comment": "27 pages, 7 figures, 4 tables", "summary": "Saliency maps are a popular approach for explaining classifications of\n(convolutional) neural networks. However, it remains an open question as to how\nbest to evaluate salience maps, with three families of evaluation methods\ncommonly being used: subjective user measures, objective user measures, and\nmathematical metrics. We examine three of the most popular saliency map\napproaches (viz., LIME, Grad-CAM, and Guided Backpropagation) in a between\nsubject study (N=166) across these families of evaluation methods. We test 1)\nfor subjective measures, if the maps differ with respect to user trust and\nsatisfaction; 2) for objective measures, if the maps increase users' abilities\nand thus understanding of a model; 3) for mathematical metrics, which map\nachieves the best ratings across metrics; and 4) whether the mathematical\nmetrics can be associated with objective user measures. To our knowledge, our\nstudy is the first to compare several salience maps across all these evaluation\nmethods$-$with the finding that they do not agree in their assessment (i.e.,\nthere was no difference concerning trust and satisfaction, Grad-CAM improved\nusers' abilities best, and Guided Backpropagation had the most favorable\nmathematical metrics). Additionally, we show that some mathematical metrics\nwere associated with user understanding, although this relationship was often\ncounterintuitive. We discuss these findings in light of general debates\nconcerning the complementary use of user studies and mathematical metrics in\nthe evaluation of explainable AI (XAI) approaches.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86LIME\u3001Grad-CAM\u548cGuided Backpropagation\u4e09\u79cd\u663e\u8457\u6027\u56fe\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e3b\u89c2\u3001\u5ba2\u89c2\u548c\u6570\u5b66\u8bc4\u4f30\uff0c\u53d1\u73b0\u8fd9\u4e9b\u65b9\u6cd5\u5728\u8bc4\u4f30\u7ed3\u679c\u4e0a\u4e0d\u4e00\u81f4\uff0c\u5e76\u8ba8\u8bba\u4e86XAI\u7684\u542b\u4e49\u3002", "motivation": "\u89e3\u51b3\u5982\u4f55\u6700\u597d\u5730\u8bc4\u4f30\u663e\u8457\u6027\u56fe\u7684\u5f00\u653e\u95ee\u9898\uff0c\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u91c7\u7528166\u540d\u53c2\u4e0e\u8005\u7684\u7ec4\u95f4\u7814\u7a76\uff0c\u6d4b\u8bd5\u4e09\u79cd\u663e\u8457\u6027\u56fe\u65b9\u6cd5\u5728\u4e3b\u89c2\uff08\u4fe1\u4efb\u3001\u6ee1\u610f\u5ea6\uff09\u3001\u5ba2\u89c2\uff08\u80fd\u529b\u63d0\u5347\uff09\u548c\u6570\u5b66\u6307\u6807\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u5728\u4fe1\u4efb\u548c\u6ee1\u610f\u5ea6\u65b9\u9762\u65e0\u5dee\u5f02\uff1bGrad-CAM\u5728\u63d0\u5347\u7528\u6237\u80fd\u529b\u65b9\u9762\u6700\u4f73\uff1bGuided Backpropagation\u5728\u6570\u5b66\u6307\u6807\u65b9\u9762\u6700\u4f18\uff1b\u4e00\u4e9b\u6307\u6807\u4e0e\u7528\u6237\u7406\u89e3\u76f8\u5173\uff0c\u4f46\u5f80\u5f80\u4e0e\u76f4\u89c9\u76f8\u53cd\u3002", "conclusion": "\u8bc4\u4f30\u65b9\u6cd5\u4e4b\u95f4\u6ca1\u6709\u4e00\u81f4\u6027\uff0c\u5f3a\u8c03\u5728XAI\u4e2d\u9700\u8981\u4e92\u8865\u4f7f\u7528\u7528\u6237\u7814\u7a76\u548c\u6570\u5b66\u6307\u6807\u3002"}}
{"id": "2504.17243", "pdf": "https://arxiv.org/pdf/2504.17243", "abs": "https://arxiv.org/abs/2504.17243", "authors": ["Xinyu Zhou", "Simin Fan", "Martin Jaggi", "Jie Fu"], "title": "NeuralGrok: Accelerate Grokking by Neural Gradient Transformation", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint, 16 pages", "summary": "Grokking is proposed and widely studied as an intricate phenomenon in which\ngeneralization is achieved after a long-lasting period of overfitting. In this\nwork, we propose NeuralGrok, a novel gradient-based approach that learns an\noptimal gradient transformation to accelerate the generalization of\ntransformers in arithmetic tasks. Specifically, NeuralGrok trains an auxiliary\nmodule (e.g., an MLP block) in conjunction with the base model. This module\ndynamically modulates the influence of individual gradient components based on\ntheir contribution to generalization, guided by a bilevel optimization\nalgorithm. Our extensive experiments demonstrate that NeuralGrok significantly\naccelerates generalization, particularly in challenging arithmetic tasks. We\nalso show that NeuralGrok promotes a more stable training paradigm, constantly\nreducing the model's complexity, while traditional regularization methods, such\nas weight decay, can introduce substantial instability and impede\ngeneralization. We further investigate the intrinsic model complexity\nleveraging a novel Absolute Gradient Entropy (AGE) metric, which explains that\nNeuralGrok effectively facilitates generalization by reducing the model\ncomplexity. We offer valuable insights on the grokking phenomenon of\nTransformer models, which encourages a deeper understanding of the fundamental\nprinciples governing generalization ability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa NeuralGrok\uff0c\u4e00\u79cd\u901a\u8fc7\u5b66\u4e60\u68af\u5ea6\u53d8\u6362\u52a0\u901f Transformer \u5728\u7b97\u672f\u4efb\u52a1\u4e2d\u6cdb\u5316\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u9488\u5bf9 Grokking \u73b0\u8c61\uff08\u8fc7\u62df\u5408\u540e\u5b9e\u73b0\u6cdb\u5316\uff09\uff0c\u672c\u6587\u65e8\u5728\u52a0\u901f\u6cdb\u5316\u548c\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "method": "\u4f7f\u7528\u8f85\u52a9\u6a21\u5757\uff08\u5982 MLP \u5757\uff09\u52a8\u6001\u8c03\u8282\u68af\u5ea6\u5206\u91cf\u5f71\u54cd\uff0c\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793a NeuralGrok \u663e\u8457\u52a0\u901f\u6cdb\u5316\uff0c\u51cf\u5c11\u6a21\u578b\u590d\u6742\u6027\uff0c\u5e76\u4f18\u4e8e\u4f20\u7edf\u6b63\u5219\u5316\u65b9\u6cd5\uff1b\u5f15\u5165 Absolute Gradient Entropy (AGE) \u6307\u6807\u89e3\u91ca\u6cdb\u5316\u673a\u5236\u3002", "conclusion": "\u63d0\u4f9b Transformer Grokking \u73b0\u8c61\u7684\u6d1e\u89c1\uff0c\u6df1\u5316\u5bf9\u6cdb\u5316\u539f\u7406\u7684\u7406\u89e3\u3002"}}
{"id": "2504.17647", "pdf": "https://arxiv.org/pdf/2504.17647", "abs": "https://arxiv.org/abs/2504.17647", "authors": ["Rafael I. Cabral Muchacho", "Riddhiman Laha", "Florian T. Pokorny", "Luis F. C. Figueredo", "Nilanjan Chakraborty"], "title": "Unifying Complementarity Constraints and Control Barrier Functions for Safe Whole-Body Robot Control", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Safety-critical whole-body robot control demands reactive methods that ensure\ncollision avoidance in real-time. Complementarity constraints and control\nbarrier functions (CBF) have emerged as core tools for ensuring such safety\nconstraints, and each represents a well-developed field. Despite addressing\nsimilar problems, their connection remains largely unexplored. This paper\nbridges this gap by formally proving the equivalence between these two\nmethodologies for sampled-data, first-order systems, considering both single\nand multiple constraint scenarios. By demonstrating this equivalence, we\nprovide a unified perspective on these techniques. This unification has\ntheoretical and practical implications, facilitating the cross-application of\nrobustness guarantees and algorithmic improvements between complementarity and\nCBF frameworks. We discuss these synergistic benefits and motivate future work\nin the comparison of the methods in more general cases.", "AI": {"tldr": "\u672c\u8bba\u6587\u8bc1\u660e\u4e86\u4e92\u8865\u7ea6\u675f\u548c\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u5728\u91c7\u6837\u6570\u636e\u7b2c\u4e00\u9636\u7cfb\u7edf\u4e2d\u7684\u7b49\u4ef7\u6027\uff0c\u63d0\u4f9b\u7edf\u4e00\u89c6\u89d2\u5e76\u8ba8\u8bba\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u6865\u63a5\u4e92\u8865\u7ea6\u675f\u548c\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5c3d\u7ba1\u5b83\u4eec\u89e3\u51b3\u7c7b\u4f3c\u5b89\u5168\u7ea6\u675f\u95ee\u9898\u4f46\u8054\u7cfb\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u6b63\u5f0f\u8bc1\u660e\u8fd9\u4e9b\u65b9\u6cd5\u5728\u91c7\u6837\u6570\u636e\u7b2c\u4e00\u9636\u7cfb\u7edf\u4e2d\u7684\u7b49\u4ef7\u6027\uff0c\u6db5\u76d6\u5355\u7ea6\u675f\u548c\u591a\u7ea6\u675f\u573a\u666f\u3002", "result": "\u8bc1\u660e\u4e86\u7b49\u4ef7\u6027\uff0c\u63d0\u4f9b\u7edf\u4e00\u6846\u67b6\uff0c\u5e76\u7a81\u51fa\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u7684\u534f\u540c\u76ca\u5904\u3002", "conclusion": "\u4fc3\u8fdb\u4e86\u65b9\u6cd5\u4e4b\u95f4\u7a33\u5065\u6027\u4fdd\u8bc1\u548c\u7b97\u6cd5\u6539\u8fdb\u7684\u4ea4\u53c9\u5e94\u7528\uff0c\u5e76\u6fc0\u53d1\u66f4\u4e00\u822c\u60c5\u51b5\u4e0b\u7684\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2504.17247", "pdf": "https://arxiv.org/pdf/2504.17247", "abs": "https://arxiv.org/abs/2504.17247", "authors": ["Diogo Soares", "Leon Hetzel", "Paulina Szymczak", "Fabian Theis", "Stephan G\u00fcnnemann", "Ewa Szczurek"], "title": "Targeted AMP generation through controlled diffusion with efficient embeddings", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": null, "summary": "Deep learning-based antimicrobial peptide (AMP) discovery faces critical\nchallenges such as low experimental hit rates as well as the need for nuanced\ncontrollability and efficient modeling of peptide properties. To address these\nchallenges, we introduce OmegAMP, a framework that leverages a diffusion-based\ngenerative model with efficient low-dimensional embeddings, precise\ncontrollability mechanisms, and novel classifiers with drastically reduced\nfalse positive rates for candidate filtering. OmegAMP enables the targeted\ngeneration of AMPs with specific physicochemical properties, activity profiles,\nand species-specific effectiveness. Moreover, it maximizes sample diversity\nwhile ensuring faithfulness to the underlying data distribution during\ngeneration. We demonstrate that OmegAMP achieves state-of-the-art performance\nacross all stages of the AMP discovery pipeline, significantly advancing the\npotential of computational frameworks in combating antimicrobial resistance.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86OmegAMP\u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u6a21\u578b\u6539\u8fdb\u6297\u83cc\u80bd\u53d1\u73b0\uff0c\u63d0\u9ad8\u53ef\u63a7\u6027\u548c\u51cf\u5c11\u5047\u9633\u6027\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60-based\u6297\u83cc\u80bd\u53d1\u73b0\u7684\u6311\u6218\uff0c\u5982\u5b9e\u9a8c\u547d\u4e2d\u7387\u4f4e\u548c\u5bf9\u53ef\u63a7\u6027\u53ca\u9ad8\u6548\u5efa\u6a21\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u6269\u6563-based\u751f\u6210\u6a21\u578b\u3001\u4f4e\u7ef4\u5d4c\u5165\u3001\u53ef\u63a7\u673a\u5236\u548c\u51cf\u5c11\u5047\u9633\u6027\u7387\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u5019\u9009\u751f\u6210\u548c\u8fc7\u6ee4\u3002", "result": "\u5b9e\u73b0\u9488\u5bf9\u7279\u5b9a\u5c5e\u6027\u7684\u6297\u83cc\u80bd\u751f\u6210\uff0c\u6700\u5927\u5316\u591a\u6837\u6027\u5e76\u4fdd\u6301\u6570\u636e\u5206\u5e03\u5fe0\u5b9e\uff0c\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6846\u67b6\u5728\u5bf9\u6297\u6297\u751f\u7d20\u8010\u836f\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.17709", "pdf": "https://arxiv.org/pdf/2504.17709", "abs": "https://arxiv.org/abs/2504.17709", "authors": ["Stefan Jonas", "Angela Meyer"], "title": "Fault Diagnosis in New Wind Turbines using Knowledge from Existing Turbines by Generative Domain Adaptation", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Intelligent condition monitoring of wind turbines is essential for reducing\ndowntimes. Machine learning models trained on wind turbine operation data are\ncommonly used to detect anomalies and, eventually, operation faults. However,\ndata-driven normal behavior models (NBMs) require a substantial amount of\ntraining data, as NBMs trained with scarce data may result in unreliable fault\ndiagnosis. To overcome this limitation, we present a novel generative deep\nlearning approach to make SCADA samples from one wind turbine lacking training\ndata resemble SCADA data from wind turbines with representative training data.\nThrough CycleGAN-based domain mapping, our method enables the application of an\nNBM trained on an existing wind turbine to one with severely limited data. We\ndemonstrate our approach on field data mapping SCADA samples across 7\nsubstantially different WTs. Our findings show significantly improved fault\ndiagnosis in wind turbines with scarce data. Our method achieves the most\nsimilar anomaly scores to an NBM trained with abundant data, outperforming NBMs\ntrained on scarce training data with improvements of +10.3% in F1-score when 1\nmonth of training data is available and +16.8% when 2 weeks are available. The\ndomain mapping approach outperforms conventional fine-tuning at all considered\ndegrees of data scarcity, ranging from 1 to 8 weeks of training data. The\nproposed technique enables earlier and more reliable fault diagnosis in newly\ninstalled wind farms, demonstrating a novel and promising research direction to\nimprove anomaly detection when faced with training data scarcity.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4f7f\u7528CycleGAN-based domain mapping\u5904\u7406\u98ce\u529b\u6da1\u8f6e\u673a\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u9ad8\u6545\u969c\u8bca\u65ad\u6027\u80fd\u3002", "motivation": "\u51cf\u5c11\u98ce\u529b\u6da1\u8f6e\u673a\u505c\u673a\u65f6\u95f4\u9700\u8981\u667a\u80fd\u76d1\u6d4b\uff0c\u4f46\u6570\u636e\u9a71\u52a8\u6a21\u578b\u9700\u5927\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u6570\u636e\u7a00\u7f3a\u4f1a\u5bfc\u81f4\u8bca\u65ad\u4e0d\u53ef\u9760\u3002", "method": "\u91c7\u7528CycleGAN-based domain mapping\uff0c\u4f7f\u6570\u636e\u7a00\u7f3a\u98ce\u529b\u6da1\u8f6e\u673a\u7684SCADA\u6837\u672c\u7c7b\u4f3c\u4e8e\u6709\u4e30\u5bcc\u8bad\u7ec3\u6570\u636e\u7684\u6837\u672c\u3002", "result": "\u57287\u4e2a\u4e0d\u540c\u98ce\u529b\u6da1\u8f6e\u673a\u4e0a\u6d4b\u8bd5\uff0cF1-score\u6539\u5584\u8fbe+10.3%\uff081\u4e2a\u6708\u6570\u636e\uff09\u548c+16.8%\uff082\u5468\u6570\u636e\uff09\uff0c\u4f18\u4e8e\u4f20\u7edf\u5fae\u8c03\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u66f4\u65e9\u3001\u66f4\u53ef\u9760\u5730\u8bca\u65ad\u6545\u969c\uff0c\u9002\u7528\u4e8e\u65b0\u98ce\u7535\u573a\uff0c\u5e76\u5f00\u8f9f\u65b0\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2504.17029", "pdf": "https://arxiv.org/pdf/2504.17029", "abs": "https://arxiv.org/abs/2504.17029", "authors": ["Jeffrey Smith", "Taisei Fujii", "Jesse Cranney", "Charles Gretton"], "title": "Fried Parameter Estimation from Single Wavefront Sensor Image with Artificial Neural Networks", "categories": ["astro-ph.IM", "cs.AI"], "comment": null, "summary": "Atmospheric turbulence degrades the quality of astronomical observations in\nground-based telescopes, leading to distorted and blurry images. Adaptive\nOptics (AO) systems are designed to counteract these effects, using atmospheric\nmeasurements captured by a wavefront sensor to make real-time corrections to\nthe incoming wavefront. The Fried parameter, r0, characterises the strength of\natmospheric turbulence and is an essential control parameter for optimising the\nperformance of AO systems and more recently sky profiling for Free Space\nOptical (FSO) communication channels. In this paper, we develop a novel\ndata-driven approach, adapting machine learning methods from computer vision\nfor Fried parameter estimation from a single Shack-Hartmann or pyramid\nwavefront sensor image. Using these data-driven methods, we present a detailed\nsimulation-based evaluation of our approach using the open-source COMPASS AO\nsimulation tool to evaluate both the Shack-Hartmann and pyramid wavefront\nsensors. Our evaluation is over a range of guide star magnitudes, and realistic\nnoise, atmospheric and instrument conditions. Remarkably, we are able to\ndevelop a single network-based estimator that is accurate in both open and\nclosed-loop AO configurations. Our method accurately estimates the Fried\nparameter from a single WFS image directly from AO telemetry to a few\nmillimetres. Our approach is suitable for real time control, exhibiting 0.83ms\nr0 inference times on retail NVIDIA RTX 3090 GPU hardware, and thereby\ndemonstrating a compelling economic solution for use in real-time instrument\ncontrol.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u4ece\u5355\u5f20\u6ce2\u524d\u4f20\u611f\u5668\u56fe\u50cf\u4f30\u8ba1Fried\u53c2\u6570r0\uff0c\u4ee5\u4f18\u5316\u81ea\u9002\u5e94\u5149\u5b66\u7cfb\u7edf\uff0c\u5b9e\u73b0\u5feb\u901f\u51c6\u786e\u7684\u5b9e\u65f6\u63a7\u5236\u3002", "motivation": "\u5927\u6c14\u6e4d\u6d41\u5bfc\u81f4\u5929\u6587\u89c2\u6d4b\u56fe\u50cf\u6a21\u7cca\uff0cFried\u53c2\u6570r0\u662f\u5173\u952e\u63a7\u5236\u53c2\u6570\uff0c\u7528\u4e8e\u63d0\u5347\u81ea\u9002\u5e94\u5149\u5b66\u548c\u81ea\u7531\u7a7a\u95f4\u5149\u5b66\u901a\u4fe1\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u5e94\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u673a\u5668\u5b66\u4e60\uff0c\u4eceShack-Hartmann\u6216pyramid\u6ce2\u524d\u4f20\u611f\u5668\u56fe\u50cf\u4f30\u8ba1r0\uff0c\u4f7f\u7528COMPASS\u6a21\u62df\u5de5\u5177\u8bc4\u4f30\u5404\u79cd\u6761\u4ef6\u3002", "result": "\u51c6\u786e\u4f30\u8ba1r0\u81f3\u51e0\u6beb\u7c73\u7cbe\u5ea6\uff0c\u63a8\u7406\u65f6\u95f40.83ms\uff0c\u9002\u7528\u4e8e\u5f00\u73af\u548c\u95ed\u73afAO\u914d\u7f6e\uff0c\u9002\u5408\u5b9e\u65f6\u63a7\u5236\u3002", "conclusion": "\u63d0\u4f9b\u7ecf\u6d4e\u9ad8\u6548\u7684\u5b9e\u65f6\u63a7\u5236\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u5728\u5b9e\u9645\u4eea\u5668\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.17258", "pdf": "https://arxiv.org/pdf/2504.17258", "abs": "https://arxiv.org/abs/2504.17258", "authors": ["Md Ashiqur Rahman", "Raymond A. Yeh"], "title": "Group Downsampling with Equivariant Anti-aliasing", "categories": ["cs.LG", "cs.CV", "math.GR"], "comment": null, "summary": "Downsampling layers are crucial building blocks in CNN architectures, which\nhelp to increase the receptive field for learning high-level features and\nreduce the amount of memory/computation in the model. In this work, we study\nthe generalization of the uniform downsampling layer for group equivariant\narchitectures, e.g., G-CNNs. That is, we aim to downsample signals (feature\nmaps) on general finite groups with anti-aliasing. This involves the following:\n(a) Given a finite group and a downsampling rate, we present an algorithm to\nform a suitable choice of subgroup. (b) Given a group and a subgroup, we study\nthe notion of bandlimited-ness and propose how to perform anti-aliasing.\nNotably, our method generalizes the notion of downsampling based on classical\nsampling theory. When the signal is on a cyclic group, i.e., periodic, our\nmethod recovers the standard downsampling of an ideal low-pass filter followed\nby a subsampling operation. Finally, we conducted experiments on image\nclassification tasks demonstrating that the proposed downsampling operation\nimproves accuracy, better preserves equivariance, and reduces model size when\nincorporated into G-equivariant networks", "AI": {"tldr": "\u672c\u6587\u63a8\u5e7f\u4e86\u7fa4\u7b49\u53d8CNN\u7684\u964d\u91c7\u6837\u64cd\u4f5c\uff0c\u5f15\u5165\u6297\u6df7\u53e0\uff0c\u6539\u8fdb\u4e86\u51c6\u786e\u6027\u548c\u7b49\u53d8\u6027\u3002", "motivation": "\u4e3a\u4e86\u5c06\u5747\u5300\u964d\u91c7\u6837\u6269\u5c55\u5230\u7fa4\u7b49\u53d8\u67b6\u6784\u4e2d\uff0c\u4ee5\u589e\u52a0\u611f\u53d7\u91ce\u3001\u5b66\u4e60\u9ad8\u7ea7\u7279\u5f81\u3001\u51cf\u5c11\u5185\u5b58/\u8ba1\u7b97\uff0c\u5e76\u5904\u7406\u4e00\u822c\u6709\u9650\u7fa4\u4fe1\u53f7\u3002", "method": "\u63d0\u51fa\u7b97\u6cd5\u9009\u62e9\u5b50\u7fa4\u8fdb\u884c\u964d\u91c7\u6837\uff0c\u5e76\u57fa\u4e8e\u5e26\u9650\u6027\u7814\u7a76\u6297\u6df7\u53e0\u65b9\u6cd5\uff0c\u63a8\u5e7f\u4e86\u7ecf\u5178\u91c7\u6837\u7406\u8bba\uff0c\u5bf9\u4e8e\u5faa\u73af\u7fa4\u4fe1\u53f7\u53ef\u6062\u590d\u6807\u51c6\u4f4e\u901a\u6ee4\u6ce2\u548c\u5b50\u91c7\u6837\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u51c6\u786e\u6027\u63d0\u5347\uff0c\u7b49\u53d8\u6027\u66f4\u597d\u5730\u4fdd\u7559\uff0c\u6a21\u578b\u5927\u5c0f\u51cf\u5c0f\u3002", "conclusion": "\u63d0\u51fa\u7684\u964d\u91c7\u6837\u64cd\u4f5c\u5728G-\u7b49\u53d8\u7f51\u7edc\u4e2d\u6709\u6548\uff0c\u63d0\u9ad8\u4e86\u6027\u80fd\u5e76\u4fdd\u6301\u4e86\u7b49\u53d8\u6027\u3002"}}
{"id": "2504.17718", "pdf": "https://arxiv.org/pdf/2504.17718", "abs": "https://arxiv.org/abs/2504.17718", "authors": ["Mirko Fiacchini", "Martina Mammarella", "Fabrizio Dabbene"], "title": "Recursive feasibility for stochastic MPC and the rationale behind fixing flat tires", "categories": ["math.OC", "cs.SY", "eess.SY"], "comment": null, "summary": "In this paper, we address the problem of designing stochastic model\npredictive control (SMPC) schemes for linear systems affected by unbounded\ndisturbances. The contribution of the paper is rooted in a measured-state\ninitialization strategy. First, due to the nonzero probability of violating\nchance-constraints in the case of unbounded noise, we introduce\nellipsoidal-based probabilistic reachable sets and we include constraint\nrelaxations to recover recursive feasibility conditioned to the measured state.\nSecond, we prove that the solution of this novel SMPC scheme guarantees\nclosed-loop chance constraints satisfaction under minimum relaxation. Last, we\ndemonstrate that, in expectation, the need of relaxing the constraints vanishes\nover time, which leads the closed-loop trajectories steered towards the\nunconstrained LQR invariant region. This novel SMPC scheme is proven to satisfy\nthe recursive feasibility conditioned to the state realization, and its\nsuperiority with respect to open-loop initialization schemes is shown through\nnumerical examples.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d4b\u91cf\u72b6\u6001\u521d\u59cb\u5316\u7684\u968f\u673a\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08SMPC\uff09\u65b9\u6848\uff0c\u7528\u4e8e\u5904\u7406\u53d7\u65e0\u754c\u6270\u52a8\u7684\u7ebf\u6027\u7cfb\u7edf\u3002", "motivation": "\u7531\u4e8e\u65e0\u754c\u566a\u58f0\u5bfc\u81f4\u673a\u4f1a\u7ea6\u675f\u8fdd\u53cd\u6982\u7387\u975e\u96f6\uff0c\u8bba\u6587\u65e8\u5728\u8bbe\u8ba1\u786e\u4fdd\u9012\u5f52\u53ef\u884c\u6027\u7684SMPC\u65b9\u6848\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u692d\u7403\u7684\u6982\u7387\u53ef\u8fbe\u96c6\u548c\u7ea6\u675f\u677e\u5f1b\uff0c\u5e76\u91c7\u7528\u6d4b\u91cf\u72b6\u6001\u521d\u59cb\u5316\u7b56\u7565\u3002", "result": "\u8bc1\u660e\u4e86\u95ed\u73af\u673a\u4f1a\u7ea6\u675f\u6ee1\u8db3\u3001\u6700\u5c0f\u677e\u5f1b\u4e0b\u7684\u9012\u5f52\u53ef\u884c\u6027\uff0c\u4ee5\u53ca\u677e\u5f1b\u9700\u6c42\u968f\u65f6\u95f4\u6d88\u5931\uff0c\u8f68\u8ff9\u8d8b\u5411\u65e0\u7ea6\u675fLQR\u4e0d\u53d8\u533a\u57df\uff1b\u901a\u8fc7\u6570\u503c\u4f8b\u5b50\u5c55\u793a\u4e86\u4f18\u8d8a\u6027\u3002", "conclusion": "\u8be5SMPC\u65b9\u6848\u5728\u6d4b\u91cf\u72b6\u6001\u6761\u4ef6\u4e0b\u786e\u4fdd\u9012\u5f52\u53ef\u884c\u6027\uff0c\u5e76\u4f18\u4e8e\u5f00\u73af\u521d\u59cb\u5316\u65b9\u6848\u3002"}}
{"id": "2504.17040", "pdf": "https://arxiv.org/pdf/2504.17040", "abs": "https://arxiv.org/abs/2504.17040", "authors": ["Zhenhailong Wang", "Senthil Purushwalkam", "Caiming Xiong", "Silvio Savarese", "Heng Ji", "Ran Xu"], "title": "DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We present DyMU, an efficient, training-free framework that dynamically\nreduces the computational burden of vision-language models (VLMs) while\nmaintaining high task performance. Our approach comprises two key components.\nFirst, Dynamic Token Merging (DToMe) reduces the number of visual token\nembeddings by merging similar tokens based on image complexity, addressing the\ninherent inefficiency of fixed-length outputs in vision transformers. Second,\nVirtual Token Unmerging (VTU) simulates the expected token sequence for large\nlanguage models (LLMs) by efficiently reconstructing the attention dynamics of\na full sequence, thus preserving the downstream performance without additional\nfine-tuning. Unlike previous approaches, our method dynamically adapts token\ncompression to the content of the image and operates completely training-free,\nmaking it readily applicable to most state-of-the-art VLM architectures.\nExtensive experiments on image and video understanding tasks demonstrate that\nDyMU can reduce the average visual token count by 32%-85% while achieving\ncomparable performance to full-length models across diverse VLM architectures,\nincluding the recently popularized AnyRes-based visual encoders. Furthermore,\nthrough qualitative analyses, we demonstrate that DToMe effectively adapts\ntoken reduction based on image complexity and, unlike existing systems,\nprovides users more control over computational costs. Project page:\nhttps://mikewangwzhl.github.io/dymu/.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faDyMU\u6846\u67b6\uff0c\u52a8\u6001\u51cf\u5c11\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u8d1f\u62c5\uff0c\u65e0\u9700\u8bad\u7ec3\uff0c\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u89c6\u89c9\u53d8\u6362\u5668\u56fa\u5b9a\u957f\u5ea6\u8f93\u51fa\u4f4e\u6548\u95ee\u9898\uff0c\u63d0\u9ad8\u6a21\u578b\u9002\u5e94\u6027\u548c\u6548\u7387\u3002", "method": "\u5305\u62ec\u52a8\u6001\u4ee4\u724c\u5408\u5e76(DToMe)\u57fa\u4e8e\u56fe\u50cf\u590d\u6742\u5ea6\u5408\u5e76\u76f8\u4f3c\u4ee4\u724c\uff0c\u4ee5\u53ca\u865a\u62df\u4ee4\u724c\u53d6\u6d88\u5408\u5e76(VTU)\u91cd\u5efa\u6ce8\u610f\u529b\u52a8\u6001\u6a21\u62df\u5b8c\u6574\u5e8f\u5217\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u89c6\u89c9\u4ee4\u724c\u51cf\u5c1132%-85%\uff0c\u5728\u56fe\u50cf\u548c\u89c6\u9891\u4efb\u52a1\u4e2d\u6027\u80fd\u4e0e\u5b8c\u6574\u6a21\u578b\u76f8\u5f53\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u67b6\u6784\u3002", "conclusion": "\u65b9\u6cd5\u8bad\u7ec3\u514d\u8d39\u3001\u52a8\u6001\u9002\u5e94\uff0c\u63d0\u4f9b\u7528\u6237\u8ba1\u7b97\u6210\u672c\u63a7\u5236\uff0c\u63d0\u5347VLM\u5b9e\u7528\u6027\u3002"}}
{"id": "2504.17261", "pdf": "https://arxiv.org/pdf/2504.17261", "abs": "https://arxiv.org/abs/2504.17261", "authors": ["Jiaqi Chen", "Xiaoye Zhu", "Yue Wang", "Tianyang Liu", "Xinhui Chen", "Ying Chen", "Chak Tou Leong", "Yifei Ke", "Joseph Liu", "Yiwen Yuan", "Julian McAuley", "Li-jia Li"], "title": "Symbolic Representation for Any-to-Any Generative Tasks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose a symbolic generative task description language and a\ncorresponding inference engine capable of representing arbitrary multimodal\ntasks as structured symbolic flows. Unlike conventional generative models that\nrely on large-scale training and implicit neural representations to learn\ncross-modal mappings, often at high computational cost and with limited\nflexibility, our framework introduces an explicit symbolic representation\ncomprising three core primitives: functions, parameters, and topological logic.\nLeveraging a pre-trained language model, our inference engine maps natural\nlanguage instructions directly to symbolic workflows in a training-free manner.\nOur framework successfully performs over 12 diverse multimodal generative\ntasks, demonstrating strong performance and flexibility without the need for\ntask-specific tuning. Experiments show that our method not only matches or\noutperforms existing state-of-the-art unified models in content quality, but\nalso offers greater efficiency, editability, and interruptibility. We believe\nthat symbolic task representations provide a cost-effective and extensible\nfoundation for advancing the capabilities of generative AI.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b26\u53f7\u5316\u751f\u6210\u4efb\u52a1\u63cf\u8ff0\u8bed\u8a00\u548c\u63a8\u7406\u5f15\u64ce\uff0c\u80fd\u591f\u9ad8\u6548\u7075\u6d3b\u5730\u5904\u7406\u591a\u6a21\u6001\u4efb\u52a1\u3002", "motivation": "\u4f20\u7edf\u751f\u6210\u6a21\u578b\u4f9d\u8d56\u5927\u89c4\u6a21\u8bad\u7ec3\u548c\u9690\u5f0f\u8868\u793a\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u7075\u6d3b\u6027\u5dee\uff0c\u56e0\u6b64\u672c\u6846\u67b6\u4f7f\u7528\u663e\u5f0f\u7b26\u53f7\u8868\u793a\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u6846\u67b6\u5305\u62ec\u51fd\u6570\u3001\u53c2\u6570\u548c\u62d3\u6251\u903b\u8f91\u4e09\u4e2a\u6838\u5fc3\u5143\u7d20\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u65e0\u8bad\u7ec3\u5730\u6620\u5c04\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u5230\u7b26\u53f7\u5de5\u4f5c\u6d41\u3002", "result": "\u572812\u4e2a\u591a\u6a21\u6001\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5185\u5bb9\u8d28\u91cf\u5339\u914d\u6216\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u66f4\u9ad8\u7684\u6548\u7387\u3001\u53ef\u7f16\u8f91\u6027\u548c\u4e2d\u65ad\u6027\u3002", "conclusion": "\u7b26\u53f7\u4efb\u52a1\u8868\u793a\u4e3a\u751f\u6210AI\u63d0\u4f9b\u4e86\u6210\u672c\u6548\u76ca\u548c\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2504.17044", "pdf": "https://arxiv.org/pdf/2504.17044", "abs": "https://arxiv.org/abs/2504.17044", "authors": ["Dhari Gandhi", "Himanshu Joshi", "Lucas Hartman", "Shabnam Hassani"], "title": "Approaches to Responsible Governance of GenAI in Organizations", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "The rapid evolution of Generative AI (GenAI) has introduced unprecedented\nopportunities while presenting complex challenges around ethics,\naccountability, and societal impact. This paper draws on a literature review,\nestablished governance frameworks, and industry roundtable discussions to\nidentify core principles for integrating responsible GenAI governance into\ndiverse organizational structures. Our objective is to provide actionable\nrecommendations for a balanced, risk-based governance approach that enables\nboth innovation and oversight. Findings emphasize the need for adaptable risk\nassessment tools, continuous monitoring practices, and cross-sector\ncollaboration to establish trustworthy GenAI. These insights provide a\nstructured foundation and Responsible GenAI Guide (ResAI) for organizations to\nalign GenAI initiatives with ethical, legal, and operational best practices.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u8ba8\u8bba\uff0c\u63d0\u51faGenAI\u7684\u8d23\u4efb\u6cbb\u7406\u6846\u67b6\uff0c\u4ee5\u5e73\u8861\u521b\u65b0\u548c\u98ce\u9669\u3002", "motivation": "GenAI\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u673a\u4f1a\u548c\u6311\u6218\uff0c\u9700\u8981\u6574\u5408\u8d1f\u8d23\u4efb\u6cbb\u7406\u5904\u7406\u4f26\u7406\u3001\u8d23\u4efb\u548c\u793e\u4f1a\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u3001\u73b0\u6709\u6cbb\u7406\u6846\u67b6\u548c\u884c\u4e1a\u5706\u684c\u8ba8\u8bba\u7684\u65b9\u6cd5\u3002", "result": "\u8bc6\u522b\u6838\u5fc3\u539f\u5219\uff0c\u63a8\u8350\u53ef\u9002\u5e94\u98ce\u9669\u8bc4\u4f30\u5de5\u5177\u3001\u6301\u7eed\u76d1\u63a7\u548c\u8de8\u90e8\u95e8\u5408\u4f5c\uff0c\u5e76\u63d0\u4f9b\u4e86Responsible GenAI Guide (ResAI)\u3002", "conclusion": "\u4e3a\u7ec4\u7ec7\u63d0\u4f9b\u7ed3\u6784\u5316\u57fa\u7840\uff0c\u5e2e\u52a9GenAI\u4e3e\u63aa\u4e0e\u4f26\u7406\u3001\u6cd5\u5f8b\u548c\u64cd\u4f5c\u6700\u4f73\u5b9e\u8df5\u5bf9\u9f50\u3002"}}
{"id": "2504.17274", "pdf": "https://arxiv.org/pdf/2504.17274", "abs": "https://arxiv.org/abs/2504.17274", "authors": ["Siddharth Vishwanath", "Jonathan Hehir"], "title": "Signal Recovery from Random Dot-Product Graphs Under Local Differential Privacy", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH", "68P27, 62H22, 62C20, 62R07"], "comment": null, "summary": "We consider the problem of recovering latent information from graphs under\n$\\varepsilon$-edge local differential privacy where the presence of\nrelationships/edges between two users/vertices remains confidential, even from\nthe data curator. For the class of generalized random dot-product graphs, we\nshow that a standard local differential privacy mechanism induces a specific\ngeometric distortion in the latent positions. Leveraging this insight, we show\nthat consistent recovery of the latent positions is achievable by appropriately\nadjusting the statistical inference procedure for the privatized graph.\nFurthermore, we prove that our procedure is nearly minimax-optimal under local\nedge differential privacy constraints. Lastly, we show that this framework\nallows for consistent recovery of geometric and topological information\nunderlying the latent positions, as encoded in their persistence diagrams. Our\nresults extend previous work from the private community detection literature to\na substantially richer class of models and inferential tasks.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u03b5-\u8fb9\u5c40\u90e8\u5dee\u5206\u9690\u79c1\u4e0b\u4ece\u56fe\u4e2d\u6062\u590d\u6f5c\u5728\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u8c03\u6574\u7edf\u8ba1\u63a8\u65ad\u5b9e\u73b0\u6709\u6548\u6062\u590d\u3002", "motivation": "\u52a8\u673a\u662f\u5904\u7406\u56fe\u6570\u636e\u4e2d\u8fb9\u4fe1\u606f\u9690\u79c1\u95ee\u9898\uff0c\u5373\u4f7f\u5bf9\u6570\u636e\u7ba1\u7406\u8005\u4fdd\u5bc6\uff0c\u4f7f\u7528\u5c40\u90e8\u5dee\u5206\u9690\u79c1\u673a\u5236\u3002", "method": "\u65b9\u6cd5\u662f\u901a\u8fc7\u5206\u6790\u9690\u79c1\u673a\u5236\u5f15\u8d77\u7684\u51e0\u4f55\u626d\u66f2\uff0c\u5e76\u9488\u5bf9\u5e7f\u4e49\u968f\u673a\u70b9\u79ef\u56fe\u8c03\u6574\u7edf\u8ba1\u63a8\u65ad\u7a0b\u5e8f\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u53ef\u4ee5\u4e00\u81f4\u6062\u590d\u6f5c\u5728\u4f4d\u7f6e\uff0c\u4e14\u8fd1\u4e4e\u6700\u4f18\uff1b\u8fd8\u80fd\u6062\u590d\u6f5c\u5728\u4f4d\u7f6e\u7684\u51e0\u4f55\u548c\u62d3\u6251\u4fe1\u606f\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u8be5\u6846\u67b6\u6269\u5c55\u4e86\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u66f4\u4e30\u5bcc\u7684\u6a21\u578b\u548c\u63a8\u7406\u4efb\u52a1\u3002"}}
{"id": "2504.17055", "pdf": "https://arxiv.org/pdf/2504.17055", "abs": "https://arxiv.org/abs/2504.17055", "authors": ["Ayushi Agrawal", "Aditya Kondai", "Kavita Vemuri"], "title": "Psychological Effect of AI driven marketing tools for beauty/facial feature enhancement", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "AI-powered facial assessment tools are reshaping how individuals evaluate\nappearance and internalize social judgments. This study examines the\npsychological impact of such tools on self-objectification, self-esteem, and\nemotional responses, with attention to gender differences. Two samples used\ndistinct versions of a facial analysis tool: one overtly critical (N=75; M=22.9\nyears), and another more neutral (N=51; M=19.9 years). Participants completed\nvalidated self-objectification and self-esteem scales and custom items\nmeasuring emotion, digital/physical appearance enhancement (DAE, PAEE), and\nperceived social emotion (PSE). Results revealed consistent links between high\nself-objectification, low self-esteem, and increased appearance enhancement\nbehaviors across both versions. Despite softer framing, the newer tool still\nevoked negative emotional responses (U=1466.5, p=0.013), indicating implicit\nfeedback may reinforce appearance-related insecurities. Gender differences\nemerged in DAE (p=0.025) and PSE (p<0.001), with females more prone to digital\nenhancement and less likely to perceive emotional impact in others. These\nfindings reveal how AI tools may unintentionally reinforce and amplify existing\nsocial biases and underscore the critical need for responsible AI design and\ndevelopment. Future research will investigate how human ideologies embedded in\nthe training data of such tools shape their evaluative outputs, and how these,\nin turn, influence user attitudes and decisions.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0AI\u9762\u90e8\u8bc4\u4f30\u5de5\u5177\u4f1a\u589e\u52a0\u81ea\u7269\u5316\u548c\u8d1f\u9762\u60c5\u7eea\uff0c\u5e76\u5b58\u5728\u6027\u522b\u5dee\u5f02\u3002", "motivation": "\u63a2\u8ba8AI\u5de5\u5177\u5bf9\u81ea\u7269\u5316\u3001\u81ea\u5c0a\u548c\u60c5\u7eea\u7684\u5fc3\u7406\u5f71\u54cd\uff0c\u4ee5\u53ca\u6027\u522b\u5dee\u5f02\u3002", "method": "\u4f7f\u7528\u4e24\u4e2a\u6837\u672c\u6d4b\u8bd5\u6279\u8bc4\u6027\u548c\u4e2d\u6027\u7248\u672c\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u91cf\u8868\u548c\u7edf\u8ba1\u5206\u6790\uff08\u5982U\u68c0\u9a8c\uff09\u8bc4\u4f30\u3002", "result": "\u9ad8\u81ea\u7269\u5316\u4e0e\u4f4e\u81ea\u5c0a\u76f8\u5173\uff0c\u5de5\u5177\u5f15\u53d1\u8d1f\u9762\u60c5\u7eea\uff0c\u5973\u6027\u66f4\u6613\u6570\u5b57\u589e\u5f3a\u548c\u611f\u77e5\u793e\u4f1a\u60c5\u7eea\u3002", "conclusion": "AI\u5de5\u5177\u53ef\u80fd\u5f3a\u5316\u793e\u4f1a\u504f\u89c1\uff0c\u9700\u8981\u8d1f\u8d23\u4efb\u8bbe\u8ba1\uff0c\u672a\u6765\u7814\u7a76\u6570\u636e\u610f\u8bc6\u5f62\u6001\u5f71\u54cd\u3002"}}
{"id": "2504.17276", "pdf": "https://arxiv.org/pdf/2504.17276", "abs": "https://arxiv.org/abs/2504.17276", "authors": ["Ke-Jia Chen", "Wenhui Mu", "Zheng Liu"], "title": "HeRB: Heterophily-Resolved Structure Balancer for Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Recent research has witnessed the remarkable progress of Graph Neural\nNetworks (GNNs) in the realm of graph data representation. However, GNNs still\nencounter the challenge of structural imbalance. Prior solutions to this\nproblem did not take graph heterophily into account, namely that connected\nnodes process distinct labels or features, thus resulting in a deficiency in\neffectiveness. Upon verifying the impact of heterophily on solving the\nstructural imbalance problem, we propose to rectify the heterophily first and\nthen transfer homophilic knowledge. To the end, we devise a method named HeRB\n(Heterophily-Resolved Structure Balancer) for GNNs. HeRB consists of two\ninnovative components: 1) A heterophily-lessening augmentation module which\nserves to reduce inter-class edges and increase intra-class edges; 2) A\nhomophilic knowledge transfer mechanism to convey homophilic information from\nhead nodes to tail nodes. Experimental results demonstrate that HeRB achieves\nsuperior performance on two homophilic and six heterophilic benchmark datasets,\nand the ablation studies further validate the efficacy of two proposed\ncomponents.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faHeRB\u65b9\u6cd5\uff0c\u9488\u5bf9GNNs\u7684\u7ed3\u6784\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u51cf\u5c11\u5f02\u8d28\u6027\u548c\u8f6c\u79fb\u540c\u8d28\u77e5\u8bc6\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "GNNs\u5728\u56fe\u6570\u636e\u8868\u793a\u4e2d\u8fdb\u6b65\u663e\u8457\uff0c\u4f46\u7ed3\u6784\u4e0d\u5e73\u8861\u95ee\u9898\u672a\u88ab\u5148\u524d\u89e3\u51b3\u65b9\u6848\u5145\u5206\u8003\u8651\u5f02\u8d28\u6027\uff0c\u5bfc\u81f4\u6548\u679c\u4e0d\u8db3\u3002", "method": "\u63d0\u51faHeRB\uff0c\u5305\u62ec\u5f02\u8d28\u6027\u51cf\u5c11\u589e\u5f3a\u6a21\u5757\uff08\u51cf\u5c11\u7c7b\u95f4\u8fb9\u3001\u589e\u52a0\u7c7b\u5185\u8fb9\uff09\u548c\u540c\u8d28\u77e5\u8bc6\u8f6c\u79fb\u673a\u5236\uff08\u4ece\u5934\u8282\u70b9\u5411\u5c3e\u8282\u70b9\u4f20\u9012\u4fe1\u606f\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aHeRB\u5728\u4e24\u4e2a\u540c\u8d28\u548c\u516d\u4e2a\u5f02\u8d28\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4f18\u8d8a\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u4e24\u4e2a\u7ec4\u4ef6\u7684\u6709\u6548\u6027\u3002", "conclusion": "HeRB\u901a\u8fc7\u5904\u7406\u5f02\u8d28\u6027\u6709\u6548\u6539\u5584GNNs\u7684\u7ed3\u6784\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2504.17277", "pdf": "https://arxiv.org/pdf/2504.17277", "abs": "https://arxiv.org/abs/2504.17277", "authors": ["Zongliang Ji", "Andre Carlos Kajdacsy-Balla Amaral", "Anna Goldenberg", "Rahul G. Krishnan"], "title": "ExOSITO: Explainable Off-Policy Learning with Side Information for Intensive Care Unit Blood Test Orders", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to the Conference on Health, Inference, and Learning (CHIL)\n  2025", "summary": "Ordering a minimal subset of lab tests for patients in the intensive care\nunit (ICU) can be challenging. Care teams must balance between ensuring the\navailability of the right information and reducing the clinical burden and\ncosts associated with each lab test order. Most in-patient settings experience\nfrequent over-ordering of lab tests, but are now aiming to reduce this burden\non both hospital resources and the environment. This paper develops a novel\nmethod that combines off-policy learning with privileged information to\nidentify the optimal set of ICU lab tests to order. Our approach, EXplainable\nOff-policy learning with Side Information for ICU blood Test Orders (ExOSITO)\ncreates an interpretable assistive tool for clinicians to order lab tests by\nconsidering both the observed and predicted future status of each patient. We\npose this problem as a causal bandit trained using offline data and a reward\nfunction derived from clinically-approved rules; we introduce a novel learning\nframework that integrates clinical knowledge with observational data to bridge\nthe gap between the optimal and logging policies. The learned policy function\nprovides interpretable clinical information and reduces costs without omitting\nany vital lab orders, outperforming both a physician's policy and prior\napproaches to this practical problem.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faExOSITO\u65b9\u6cd5\uff0c\u901a\u8fc7off-policy\u5b66\u4e60\u548c\u7279\u6743\u4fe1\u606f\u4f18\u5316ICU\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u8ba2\u8d2d\uff0c\u51cf\u5c11\u6210\u672c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "ICU\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u8ba2\u8d2d\u6700\u5c0f\u5b50\u96c6\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u5e73\u8861\u4fe1\u606f\u53ef\u7528\u6027\u548c\u51cf\u5c11\u4e34\u5e8a\u8d1f\u62c5\u53ca\u6210\u672c\uff0c\u8bb8\u591a\u533b\u9662\u8fc7\u5ea6\u8ba2\u8d2d\u6d4b\u8bd5\uff0c\u65e8\u5728\u51cf\u8f7b\u8d44\u6e90\u548c\u73af\u5883\u8d1f\u62c5\u3002", "method": "\u5f00\u53d1ExOSITO\u65b9\u6cd5\uff0c\u7ed3\u5408off-policy\u5b66\u4e60\u548c\u7279\u6743\u4fe1\u606f\uff0c\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u56e0\u679cbandit\uff0c\u4f7f\u7528\u79bb\u7ebf\u6570\u636e\u548c\u57fa\u4e8e\u4e34\u5e8a\u89c4\u5219\u7684\u5956\u52b1\u51fd\u6570\uff0c\u6574\u5408\u4e34\u5e8a\u77e5\u8bc6\u4e0e\u89c2\u5bdf\u6570\u636e\u3002", "result": "\u5b66\u5230\u7684\u653f\u7b56\u51fd\u6570\u63d0\u4f9b\u53ef\u89e3\u91ca\u4e34\u5e8a\u4fe1\u606f\uff0c\u51cf\u5c11\u6210\u672c\u800c\u4e0d\u9057\u6f0f\u91cd\u8981\u6d4b\u8bd5\uff0c\u4f18\u4e8e\u533b\u751f\u7684\u653f\u7b56\u548c\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4e34\u5e8a\u533b\u751f\u63d0\u4f9b\u53ef\u89e3\u91ca\u8f85\u52a9\u5de5\u5177\uff0c\u4f18\u5316\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u8ba2\u8d2d\uff0c\u964d\u4f4e\u6210\u672c\u5e76\u63d0\u9ad8\u6548\u7387\u3002"}}
{"id": "2504.17069", "pdf": "https://arxiv.org/pdf/2504.17069", "abs": "https://arxiv.org/abs/2504.17069", "authors": ["Rishav Pramanik", "Antoine Poupon", "Juan A. Rodriguez", "Masih Aminbeidokhti", "David Vazquez", "Christopher Pal", "Zhaozheng Yin", "Marco Pedersoli"], "title": "Distilling semantically aware orders for autoregressive image generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Autoregressive patch-based image generation has recently shown competitive\nresults in terms of image quality and scalability. It can also be easily\nintegrated and scaled within Vision-Language models. Nevertheless,\nautoregressive models require a defined order for patch generation. While a\nnatural order based on the dictation of the words makes sense for text\ngeneration, there is no inherent generation order that exists for image\ngeneration. Traditionally, a raster-scan order (from top-left to bottom-right)\nguides autoregressive image generation models. In this paper, we argue that\nthis order is suboptimal, as it fails to respect the causality of the image\ncontent: for instance, when conditioned on a visual description of a sunset, an\nautoregressive model may generate clouds before the sun, even though the color\nof clouds should depend on the color of the sun and not the inverse. In this\nwork, we show that first by training a model to generate patches in\nany-given-order, we can infer both the content and the location (order) of each\npatch during generation. Secondly, we use these extracted orders to finetune\nthe any-given-order model to produce better-quality images. Through our\nexperiments, we show on two datasets that this new generation method produces\nbetter images than the traditional raster-scan approach, with similar training\ncosts and no extra annotations.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4efb\u610f\u987a\u5e8f\u751f\u6210\u56fe\u50cfpatch\u6765\u63a8\u65ad\u5185\u5bb9\u548c\u4f4d\u7f6e\uff0c\u5e76\u5fae\u8c03\u6a21\u578b\uff0c\u63d0\u9ad8\u56fe\u50cf\u8d28\u91cf\uff0c\u4f18\u4e8e\u4f20\u7edfraster-scan\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfraster-scan\u987a\u5e8f\u4e0d\u5c0a\u91cd\u56fe\u50cf\u5185\u5bb9\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u4f8b\u5982\u751f\u6210\u65e5\u843d\u573a\u666f\u65f6\u53ef\u80fd\u5148\u751f\u6210\u4e91\u540e\u751f\u6210\u592a\u9633\uff0c\u4f46\u4e91\u7684\u989c\u8272\u5e94\u4f9d\u8d56\u592a\u9633\u7684\u989c\u8272\u3002", "method": "\u9996\u5148\u8bad\u7ec3\u6a21\u578b\u5728\u4efb\u610f\u7ed9\u5b9a\u987a\u5e8f\u751f\u6210patch\uff0c\u7136\u540e\u63a8\u65ad\u6bcf\u4e2apatch\u7684\u5185\u5bb9\u548c\u4f4d\u7f6e\uff0c\u5176\u6b21\u4f7f\u7528\u8fd9\u4e9b\u987a\u5e8f\u5fae\u8c03\u6a21\u578b\u4ee5\u63d0\u5347\u56fe\u50cf\u8d28\u91cf\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u5b9e\u9a8c\u663e\u793a\u65b0\u65b9\u6cd5\u4ea7\u751f\u66f4\u597d\u56fe\u50cf\u8d28\u91cf\uff0c\u8bad\u7ec3\u6210\u672c\u7c7b\u4f3c\uff0c\u4e14\u65e0\u9700\u989d\u5916\u6807\u6ce8\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u8bc1\u660e\u4e86\u4efb\u610f\u987a\u5e8f\u751f\u6210patch\u7684\u4f18\u8d8a\u6027\uff0c\u80fd\u5728\u7c7b\u4f3c\u6210\u672c\u4e0b\u63d0\u9ad8\u56fe\u50cf\u751f\u6210\u6027\u80fd\u3002"}}
{"id": "2504.17300", "pdf": "https://arxiv.org/pdf/2504.17300", "abs": "https://arxiv.org/abs/2504.17300", "authors": ["Wencong You", "Daniel Lowd"], "title": "The Ultimate Cookbook for Invisible Poison: Crafting Subtle Clean-Label Text Backdoors with Style Attributes", "categories": ["cs.LG"], "comment": "Accepted at SaTML 2025", "summary": "Backdoor attacks on text classifiers can cause them to predict a predefined\nlabel when a particular \"trigger\" is present. Prior attacks often rely on\ntriggers that are ungrammatical or otherwise unusual, leading to conspicuous\nattacks. As a result, human annotators, who play a critical role in curating\ntraining data in practice, can easily detect and filter out these unnatural\ntexts during manual inspection, reducing the risk of such attacks. We argue\nthat a key criterion for a successful attack is for text with and without\ntriggers to be indistinguishable to humans. However, prior work neither\ndirectly nor comprehensively evaluated attack subtlety and invisibility with\nhuman involvement. We bridge the gap by conducting thorough human evaluations\nto assess attack subtlety. We also propose \\emph{AttrBkd}, consisting of three\nrecipes for crafting subtle yet effective trigger attributes, such as\nextracting fine-grained attributes from existing baseline backdoor attacks. Our\nhuman evaluations find that AttrBkd with these baseline-derived attributes is\noften more effective (higher attack success rate) and more subtle (fewer\ninstances detected by humans) than the original baseline backdoor attacks,\ndemonstrating that backdoor attacks can bypass detection by being inconspicuous\nand appearing natural even upon close inspection, while still remaining\neffective. Our human annotation also provides information not captured by\nautomated metrics used in prior work, and demonstrates the misalignment of\nthese metrics with human judgment.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9690\u853d\u7684\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\uff0c\u4f7f\u6587\u672c\u5206\u7c7b\u5668\u5728\u89e6\u53d1\u5668\u5b58\u5728\u65f6\u9884\u6d4b\u9884\u5b9a\u4e49\u6807\u7b7e\uff0c\u4f46\u4e0d\u6613\u88ab\u4eba\u7c7b\u68c0\u6d4b\uff0c\u5e76\u901a\u8fc7\u4eba\u7c7b\u8bc4\u4f30\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u653b\u51fb\u4f7f\u7528\u663e\u773c\u89e6\u53d1\u5668\uff0c\u6613\u88ab\u4eba\u7c7b\u6807\u6ce8\u8005\u53d1\u73b0\u5e76\u8fc7\u6ee4\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u66f4\u9690\u853d\u7684\u653b\u51fb\u4ee5\u63d0\u9ad8\u6210\u529f\u7387\u3002", "method": "\u4f5c\u8005\u63d0\u51faAttrBkd\u6846\u67b6\uff0c\u5305\u62ec\u4e09\u79cd\u5236\u4f5c\u9690\u853d\u89e6\u53d1\u5c5e\u6027\u7684\u7b56\u7565\uff0c\u5982\u4ece\u57fa\u7ebf\u653b\u51fb\u4e2d\u63d0\u53d6\u7ec6\u7c92\u5ea6\u5c5e\u6027\uff0c\u5e76\u8fdb\u884c\u4eba\u7c7b\u8bc4\u4f30\u6765\u68c0\u9a8c\u653b\u51fb\u7684\u9690\u853d\u6027\u548c\u6709\u6548\u6027\u3002", "result": "\u4eba\u7c7b\u8bc4\u4f30\u663e\u793a\uff0cAttrBkd\u6bd4\u57fa\u7ebf\u653b\u51fb\u5177\u6709\u66f4\u9ad8\u653b\u51fb\u6210\u529f\u7387\u548c\u66f4\u4f4e\u68c0\u6d4b\u7387\uff0c\u5e76\u63ed\u793a\u81ea\u52a8\u6307\u6807\u4e0e\u4eba\u7c7b\u5224\u65ad\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u540e\u95e8\u653b\u51fb\u53ef\u901a\u8fc7\u8bbe\u8ba1\u9690\u853d\u89e6\u53d1\u5668\u5b9e\u73b0\u9003\u907f\u4eba\u7c7b\u68c0\u6d4b\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6709\u6548\u6027\u3002"}}
{"id": "2504.17070", "pdf": "https://arxiv.org/pdf/2504.17070", "abs": "https://arxiv.org/abs/2504.17070", "authors": ["Mohaiminul Al Nahian", "Zainab Altaweel", "David Reitano", "Sabbir Ahmed", "Saumitra Lohokare", "Shiqi Zhang", "Adnan Siraj Rakin"], "title": "Robo-Troj: Attacking LLM-based Task Planners", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Robots need task planning methods to achieve goals that require more than\nindividual actions. Recently, large language models (LLMs) have demonstrated\nimpressive performance in task planning. LLMs can generate a step-by-step\nsolution using a description of actions and the goal. Despite the successes in\nLLM-based task planning, there is limited research studying the security\naspects of those systems. In this paper, we develop Robo-Troj, the first\nmulti-trigger backdoor attack for LLM-based task planners, which is the main\ncontribution of this work. As a multi-trigger attack, Robo-Troj is trained to\naccommodate the diversity of robot application domains. For instance, one can\nuse unique trigger words, e.g., \"herical\", to activate a specific malicious\nbehavior, e.g., cutting hand on a kitchen robot. In addition, we develop an\noptimization method for selecting the trigger words that are most effective.\nThrough demonstrating the vulnerability of LLM-based planners, we aim to\npromote the development of secured robot systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f00\u53d1\u4e86Robo-Troj\uff0c\u8fd9\u662f\u9488\u5bf9LLM-based\u4efb\u52a1\u89c4\u5212\u5668\u7684\u7b2c\u4e00\u4e2a\u591a\u89e6\u53d1\u540e\u95e8\u653b\u51fb\uff0c\u65e8\u5728\u5c55\u793a\u5176\u5b89\u5168\u6f0f\u6d1e\u3002", "motivation": "LLM\u5728\u4efb\u52a1\u89c4\u5212\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b89\u5168\u7814\u7a76\u6709\u9650\uff0c\u9700\u8981\u4fc3\u8fdb\u5b89\u5168\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u5f00\u53d1\u3002", "method": "\u5f00\u53d1\u4e86Robo-Troj\u591a\u89e6\u53d1\u540e\u95e8\u653b\u51fb\u548c\u89e6\u53d1\u8bcd\u4f18\u5316\u65b9\u6cd5\uff0c\u4ee5\u9002\u5e94\u4e0d\u540c\u673a\u5668\u4eba\u5e94\u7528\u9886\u57df\u3002", "result": "\u8bc1\u660e\u4e86LLM-based\u89c4\u5212\u5668\u7684\u6613\u53d7\u540e\u95e8\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c55\u793a\u6f0f\u6d1e\uff0c\u9f13\u52b1\u5f00\u53d1\u66f4\u5b89\u5168\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u3002"}}
{"id": "2504.17305", "pdf": "https://arxiv.org/pdf/2504.17305", "abs": "https://arxiv.org/abs/2504.17305", "authors": ["Dinan Li", "Panagiotis Kakosimos", "Luca Peretti"], "title": "Machine learning-based condition monitoring of powertrains in modern electric drives", "categories": ["cs.LG"], "comment": "2025 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "The recent technological advances in digitalization have revolutionized the\nindustrial sector. Leveraging data analytics has now enabled the collection of\ndeep insights into the performance and, as a result, the optimization of\nassets. Industrial drives, for example, already accumulate all the necessary\ninformation to control electric machines. These signals include but are not\nlimited to currents, frequency, and temperature. Integrating machine learning\n(ML) models responsible for predicting the evolution of those directly\ncollected or implicitly derived parameters enhances the smartness of industrial\nsystems even further. In this article, data already residing in most modern\nelectric drives has been used to develop a data-driven thermal model of a power\nmodule. A test bench has been designed and used specifically for training and\nvalidating the thermal digital twin undergoing various static and dynamic\noperating profiles. Different approaches, from traditional linear models to\ndeep neural networks, have been implemented to emanate the best ML model for\nestimating the case temperature of a power module. Several evaluation metrics\nwere then used to assess the investigated methods' performance and\nimplementation in industrial embedded systems.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u5de5\u4e1a\u9a71\u52a8\u4e2d\u7684\u73b0\u6709\u6570\u636e\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u6570\u636e\u9a71\u52a8\u7684\u7535\u529b\u6a21\u5757\u70ed\u6a21\u578b\uff0c\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6e29\u5ea6\u3002", "motivation": "\u52a8\u673a\u662f\u63d0\u5347\u5de5\u4e1a\u7cfb\u7edf\u7684\u667a\u80fd\u6027\uff0c\u901a\u8fc7\u6570\u636e\u5206\u6790\u4f18\u5316\u8d44\u4ea7\u6027\u80fd\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u8bbe\u8ba1\u6d4b\u8bd5\u53f0\uff0c\u8bad\u7ec3\u548c\u9a8c\u8bc1\u5404\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5982\u7ebf\u6027\u6a21\u578b\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff09\uff0c\u5728\u9759\u6001\u548c\u52a8\u6001\u64cd\u4f5c\u6761\u4ef6\u4e0b\u3002", "result": "\u7ed3\u679c\u662f\u901a\u8fc7\u8bc4\u4f30\u6307\u6807\uff0c\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u4ee5\u786e\u5b9a\u9002\u5408\u5de5\u4e1a\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u6a21\u578b\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u673a\u5668\u5b66\u4e60\u53ef\u4ee5\u6709\u6548\u5730\u4f30\u8ba1\u7535\u529b\u6a21\u5757\u6e29\u5ea6\uff0c\u63d0\u9ad8\u5de5\u4e1a\u7cfb\u7edf\u4f18\u5316\u3002"}}
{"id": "2504.17077", "pdf": "https://arxiv.org/pdf/2504.17077", "abs": "https://arxiv.org/abs/2504.17077", "authors": ["Dongjin Seo", "Soobin Um", "Sangbin Lee", "Jong Chul Ye", "Haejun Chung"], "title": "Physics-guided and fabrication-aware inverse design of photonic devices using diffusion models", "categories": ["physics.optics", "cs.AI", "physics.comp-ph"], "comment": "25 pages, 7 Figures", "summary": "Designing free-form photonic devices is fundamentally challenging due to the\nvast number of possible geometries and the complex requirements of fabrication\nconstraints. Traditional inverse-design approaches--whether driven by human\nintuition, global optimization, or adjoint-based gradient methods--often\ninvolve intricate binarization and filtering steps, while recent deep learning\nstrategies demand prohibitively large numbers of simulations (10^5 to 10^6). To\novercome these limitations, we present AdjointDiffusion, a physics-guided\nframework that integrates adjoint sensitivity gradients into the sampling\nprocess of diffusion models. AdjointDiffusion begins by training a diffusion\nnetwork on a synthetic, fabrication-aware dataset of binary masks. During\ninference, we compute the adjoint gradient of a candidate structure and inject\nthis physics-based guidance at each denoising step, steering the generative\nprocess toward high figure-of-merit (FoM) solutions without additional\npost-processing. We demonstrate our method on two canonical photonic design\nproblems--a bent waveguide and a CMOS image sensor color router--and show that\nour method consistently outperforms state-of-the-art nonlinear optimizers (such\nas MMA and SLSQP) in both efficiency and manufacturability, while using orders\nof magnitude fewer simulations (approximately 2 x 10^2) than pure deep learning\napproaches (approximately 10^5 to 10^6). By eliminating complex binarization\nschedules and minimizing simulation overhead, AdjointDiffusion offers a\nstreamlined, simulation-efficient, and fabrication-aware pipeline for\nnext-generation photonic device design. Our open-source implementation is\navailable at https://github.com/dongjin-seo2020/AdjointDiffusion.", "AI": {"tldr": "AdjointDiffusion \u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5149\u5b50\u5668\u4ef6\u8bbe\u8ba1\u6846\u67b6\uff0c\u6574\u5408\u4f34\u968f\u68af\u5ea6\u548c\u6269\u6563\u6a21\u578b\uff0c\u51cf\u5c11\u6a21\u62df\u9700\u6c42\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u9006\u8bbe\u8ba1\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5982\u590d\u6742\u51e0\u4f55\u3001\u5236\u9020\u7ea6\u675f\u548c\u9ad8\u6a21\u62df\u6b21\u6570\u3002", "method": "\u8bad\u7ec3\u6269\u6563\u7f51\u7edc\u4e8e\u5408\u6210\u6570\u636e\u96c6\uff0c\u5e76\u5728\u63a8\u7406\u4e2d\u6ce8\u5165\u4f34\u968f\u68af\u5ea6\u6307\u5bfc\u751f\u6210\u9ad8\u6027\u80fd\u7ed3\u6784\u3002", "result": "\u4f18\u4e8e\u73b0\u6709\u4f18\u5316\u5668\uff0c\u4f7f\u7528\u7ea6200\u6b21\u6a21\u62df\uff0c\u63d0\u9ad8\u6548\u7387\u548c\u53ef\u5236\u9020\u6027\u3002", "conclusion": "\u63d0\u4f9b\u7b80\u5316\u7684\u3001\u6a21\u62df\u9ad8\u6548\u7684\u8bbe\u8ba1\u7ba1\u9053\uff0c\u5e76\u5f00\u6e90\u5b9e\u73b0\u3002"}}
{"id": "2504.17314", "pdf": "https://arxiv.org/pdf/2504.17314", "abs": "https://arxiv.org/abs/2504.17314", "authors": ["Miaoyun Zhao", "Qiang Zhang", "Chenrong Li"], "title": "Class-Conditional Distribution Balancing for Group Robust Classification", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Spurious correlations that lead models to correct predictions for the wrong\nreasons pose a critical challenge for robust real-world generalization.\nExisting research attributes this issue to group imbalance and addresses it by\nmaximizing group-balanced or worst-group accuracy, which heavily relies on\nexpensive bias annotations. A compromise approach involves predicting bias\ninformation using extensively pretrained foundation models, which requires\nlarge-scale data and becomes impractical for resource-limited rare domains. To\naddress these challenges, we offer a novel perspective by reframing the\nspurious correlations as imbalances or mismatches in class-conditional\ndistributions, and propose a simple yet effective robust learning method that\neliminates the need for both bias annotations and predictions. With the goal of\nreducing the mutual information between spurious factors and label information,\nour method leverages a sample reweighting strategy to achieve class-conditional\ndistribution balancing, which automatically highlights minority groups and\nclasses, effectively dismantling spurious correlations and producing a debiased\ndata distribution for classification. Extensive experiments and analysis\ndemonstrate that our approach consistently delivers state-of-the-art\nperformance, rivaling methods that rely on bias supervision.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u9700\u8981\u504f\u7f6e\u6807\u6ce8\u7684\u9c81\u68d2\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6837\u672c\u518d\u52a0\u6743\u5e73\u8861\u7c7b\u522b\u6761\u4ef6\u5206\u5e03\uff0c\u51cf\u5c11\u865a\u5047\u76f8\u5173\u6027\u3002", "motivation": "\u865a\u5047\u76f8\u5173\u6027\u5bfc\u81f4\u6a21\u578b\u9519\u8bef\u9884\u6d4b\uff0c\u662f\u9c81\u68d2\u6cdb\u5316\u7684\u5173\u952e\u6311\u6218\uff1b\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u504f\u7f6e\u6807\u6ce8\u6216\u8d44\u6e90\u5bc6\u96c6\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u3002", "method": "\u91cd\u65b0\u5b9a\u4e49\u865a\u5047\u76f8\u5173\u6027\u4e3a\u7c7b\u522b\u6761\u4ef6\u5206\u5e03\u7684\u4e0d\u5e73\u8861\uff0c\u63d0\u51fa\u6837\u672c\u518d\u52a0\u6743\u7b56\u7565\u51cf\u5c11\u865a\u5047\u56e0\u7d20\u548c\u6807\u7b7e\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u65b9\u6cd5\u6027\u80fd\u4f18\u5f02\uff0c\u5ab2\u7f8e\u4f9d\u8d56\u504f\u7f6e\u76d1\u7763\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u6d88\u9664\u4e86\u5bf9\u504f\u7f6e\u6807\u6ce8\u7684\u9700\u8981\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u9c81\u68d2\u5b66\u4e60\u65b9\u6848\u3002"}}
{"id": "2504.17114", "pdf": "https://arxiv.org/pdf/2504.17114", "abs": "https://arxiv.org/abs/2504.17114", "authors": ["Valentin Langer", "Kartikay Tehlan", "Thomas Wendler"], "title": "Anatomy-constrained modelling of image-derived input functions in dynamic PET using multi-organ segmentation", "categories": ["eess.IV", "cs.AI", "cs.CV", "physics.med-ph"], "comment": "The code is available under\n  https://github.com/tinolan/curve_fit_multi_idif", "summary": "Accurate kinetic analysis of [$^{18}$F]FDG distribution in dynamic positron\nemission tomography (PET) requires anatomically constrained modelling of\nimage-derived input functions (IDIFs). Traditionally, IDIFs are obtained from\nthe aorta, neglecting anatomical variations and complex vascular contributions.\nThis study proposes a multi-organ segmentation-based approach that integrates\nIDIFs from the aorta, portal vein, pulmonary artery, and ureters. Using\nhigh-resolution CT segmentations of the liver, lungs, kidneys, and bladder, we\nincorporate organ-specific blood supply sources to improve kinetic modelling.\nOur method was evaluated on dynamic [$^{18}$F]FDG PET data from nine patients,\nresulting in a mean squared error (MSE) reduction of $13.39\\%$ for the liver\nand $10.42\\%$ for the lungs. These initial results highlight the potential of\nmultiple IDIFs in improving anatomical modelling and fully leveraging dynamic\nPET imaging. This approach could facilitate the integration of tracer kinetic\nmodelling into clinical routine.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u591a\u5668\u5b98\u5206\u5272-based IDIF\u65b9\u6cd5\uff0c\u6539\u5584[18F]FDG PET\u52a8\u529b\u5b66\u5efa\u6a21\uff0c\u51cf\u5c11\u809d\u548c\u80baMSE\u3002", "motivation": "\u4f20\u7edfIDIFs\u4ec5\u4ece\u4e3b\u52a8\u8109\u83b7\u53d6\uff0c\u5ffd\u7565\u4e86\u89e3\u5256\u53d8\u5f02\u548c\u8840\u7ba1\u8d21\u732e\uff0c\u9700\u8981\u6574\u5408\u591a\u5668\u5b98\u8840\u4f9b\u6765\u6e90\u3002", "method": "\u4f7f\u7528\u9ad8\u5206\u8fa8CT\u5206\u5272\u809d\u3001\u80ba\u3001\u80be\u3001\u8180\u80f1\uff0c\u6574\u5408\u4e3b\u52a8\u8109\u3001\u95e8\u9759\u8109\u3001\u80ba\u52a8\u8109\u548c\u8f93\u5c3f\u7ba1\u7684IDIFs\u8fdb\u884c\u52a8\u529b\u5b66\u5efa\u6a21\u3002", "result": "\u5728\u4e5d\u540d\u60a3\u8005\u6570\u636e\u4e0a\uff0c\u809d\u810fMSE\u51cf\u5c1113.39%\uff0c\u80ba\u90e8\u51cf\u5c1110.42%\u3002", "conclusion": "\u8bc1\u660e\u591a\u4e2aIDIFs\u53ef\u63d0\u5347\u89e3\u5256\u5efa\u6a21\uff0c\u5e76\u4fc3\u8fdb\u52a8\u6001PET\u5728\u4e34\u5e8a\u7684\u6574\u5408\u3002"}}
{"id": "2504.17355", "pdf": "https://arxiv.org/pdf/2504.17355", "abs": "https://arxiv.org/abs/2504.17355", "authors": ["Xiaohan Huang", "Dongjie Wang", "Zhiyuan Ning", "Ziyue Qiao", "Qingqing Long", "Haowei Zhu", "Yi Du", "Min Wu", "Yuanchun Zhou", "Meng Xiao"], "title": "Collaborative Multi-Agent Reinforcement Learning for Automated Feature Transformation with Graph-Driven Path Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, Keywords: Automated Feature Transformation, Tabular\n  Dataset, Reinforcement Learning", "summary": "Feature transformation methods aim to find an optimal mathematical\nfeature-feature crossing process that generates high-value features and\nimproves the performance of downstream machine learning tasks. Existing\nframeworks, though designed to mitigate manual costs, often treat feature\ntransformations as isolated operations, ignoring dynamic dependencies between\ntransformation steps. To address the limitations, we propose TCTO, a\ncollaborative multi-agent reinforcement learning framework that automates\nfeature engineering through graph-driven path optimization. The framework's\ncore innovation lies in an evolving interaction graph that models features as\nnodes and transformations as edges. Through graph pruning and backtracking, it\ndynamically eliminates low-impact edges, reduces redundant operations, and\nenhances exploration stability. This graph also provides full traceability to\nempower TCTO to reuse high-utility subgraphs from historical transformations.\nTo demonstrate the efficacy and adaptability of our approach, we conduct\ncomprehensive experiments and case studies, which show superior performance\nacross a range of datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTCTO\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u9a71\u52a8\u7684\u591a\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u81ea\u52a8\u4f18\u5316\u7279\u5f81\u5de5\u7a0b\uff0c\u63d0\u9ad8\u4e0b\u6e38\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6846\u67b6\u5ffd\u7565\u8f6c\u6362\u6b65\u9aa4\u95f4\u7684\u52a8\u6001\u4f9d\u8d56\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\uff0c\u56e0\u6b64\u9700\u5f00\u53d1\u66f4\u667a\u80fd\u7684\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u534f\u4f5c\u591a\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u57fa\u4e8e\u6f14\u5316\u4ea4\u4e92\u56fe\u8fdb\u884c\u8def\u5f84\u4f18\u5316\uff0c\u5305\u62ec\u56fe\u4fee\u526a\u3001\u56de\u6eaf\u548c\u5b50\u56fe\u91cd\u7528\u3002", "result": "\u5b9e\u9a8c\u548c\u6848\u4f8b\u7814\u7a76\u663e\u793aTCTO\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4f18\u8d8a\u3002", "conclusion": "TCTO\u6846\u67b6\u6709\u6548\u63d0\u5347\u7279\u5f81\u5de5\u7a0b\u81ea\u52a8\u5316\u3001\u51cf\u5c11\u5197\u4f59\u5e76\u63d0\u9ad8\u9002\u5e94\u6027\u3002"}}
{"id": "2504.17119", "pdf": "https://arxiv.org/pdf/2504.17119", "abs": "https://arxiv.org/abs/2504.17119", "authors": ["Muskan Garg", "Shaina Raza", "Shebuti Rayana", "Xingyi Liu", "Sunghwan Sohn"], "title": "The Rise of Small Language Models in Healthcare: A Comprehensive Survey", "categories": ["cs.CL", "cs.AI"], "comment": "35 pages, 7 tables, 5 figures", "summary": "Despite substantial progress in healthcare applications driven by large\nlanguage models (LLMs), growing concerns around data privacy, and limited\nresources; the small language models (SLMs) offer a scalable and clinically\nviable solution for efficient performance in resource-constrained environments\nfor next-generation healthcare informatics. Our comprehensive survey presents a\ntaxonomic framework to identify and categorize them for healthcare\nprofessionals and informaticians. The timeline of healthcare SLM contributions\nestablishes a foundational framework for analyzing models across three\ndimensions: NLP tasks, stakeholder roles, and the continuum of care. We present\na taxonomic framework to identify the architectural foundations for building\nmodels from scratch; adapting SLMs to clinical precision through prompting,\ninstruction fine-tuning, and reasoning; and accessibility and sustainability\nthrough compression techniques. Our primary objective is to offer a\ncomprehensive survey for healthcare professionals, introducing recent\ninnovations in model optimization and equipping them with curated resources to\nsupport future research and development in the field. Aiming to showcase the\ngroundbreaking advancements in SLMs for healthcare, we present a comprehensive\ncompilation of experimental results across widely studied NLP tasks in\nhealthcare to highlight the transformative potential of SLMs in healthcare. The\nupdated repository is available at Github", "AI": {"tldr": "\u672c\u8c03\u67e5\u63a2\u8ba8\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u4fdd\u5065\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u4f9b\u5206\u7c7b\u6846\u67b6\u548c\u5b9e\u9a8c\u7ed3\u679c\uff0c\u5c55\u793a\u5176\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u636e\u9690\u79c1\u548c\u8d44\u6e90\u9650\u5236\u95ee\u9898\uff0c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u88ab\u63d0\u51fa\u4f5c\u4e3a\u53ef\u6269\u5c55\u7684\u533b\u7597\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u5206\u7c7b\u6846\u67b6\u3001\u65f6\u95f4\u7ebf\u5206\u6790\u548c\u5b9e\u9a8c\u7ed3\u679c\u7f16\u8bd1\uff0c\u6db5\u76d6NLP\u4efb\u52a1\u3001\u67b6\u6784\u57fa\u7840\u3001\u9002\u5e94\u6280\u672f\u548c\u538b\u7f29\u65b9\u6cd5\u3002", "result": "\u5c55\u793a\u4e86\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u4fdd\u5065NLP\u4efb\u52a1\u4e2d\u7684\u53d8\u9769\u6027\u8fdb\u5c55\u548c\u4f18\u5316\u521b\u65b0\u3002", "conclusion": "\u4e3a\u533b\u7597\u4e13\u4e1a\u4eba\u5458\u63d0\u4f9b\u8d44\u6e90\uff0c\u652f\u6301\u672a\u6765\u7814\u7a76\uff0c\u5e76\u63d0\u4f9bGitHub\u4ed3\u5e93\u3002"}}
{"id": "2504.17370", "pdf": "https://arxiv.org/pdf/2504.17370", "abs": "https://arxiv.org/abs/2504.17370", "authors": ["Marco Carpentiero", "Virginia Bordignon", "Vincenzo Matta", "Ali H. Sayed"], "title": "Doubly Adaptive Social Learning", "categories": ["cs.LG"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "In social learning, a network of agents assigns probability scores (beliefs)\nto some hypotheses of interest, which rule the generation of local streaming\ndata observed by each agent. Belief formation takes place by means of an\niterative two-step procedure where: i) the agents update locally their beliefs\nby using some likelihood model; and ii) the updated beliefs are combined with\nthe beliefs of the neighboring agents, using a pooling rule. This procedure can\nfail to perform well in the presence of dynamic drifts, leading the agents to\nincorrect decision making. Here, we focus on the fully online setting where\nboth the true hypothesis and the likelihood models can change over time. We\npropose the doubly adaptive social learning ($\\text{A}^2\\text{SL}$) strategy,\nwhich infuses social learning with the necessary adaptation capabilities. This\ngoal is achieved by exploiting two adaptation stages: i) a stochastic gradient\ndescent update to learn and track the drifts in the decision model; ii) and an\nadaptive belief update to track the true hypothesis changing over time. These\nstages are controlled by two adaptation parameters that govern the evolution of\nthe error probability for each agent. We show that all agents learn\nconsistently for sufficiently small adaptation parameters, in the sense that\nthey ultimately place all their belief mass on the true hypothesis. In\nparticular, the probability of choosing the wrong hypothesis converges to\nvalues on the order of the adaptation parameters. The theoretical analysis is\nillustrated both on synthetic data and by applying the $\\text{A}^2\\text{SL}$\nstrategy to a social learning problem in the online setting using real data.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aA\u00b2SL\u7684\u7b56\u7565\uff0c\u7528\u4e8e\u793e\u4f1a\u5b66\u4e60\u4e2d\u5904\u7406\u52a8\u6001\u6f02\u79fb\u95ee\u9898\uff0c\u786e\u4fdd\u4ee3\u7406\u5728\u5047\u8bbe\u548c\u6a21\u578b\u53d8\u5316\u65f6\u4e5f\u80fd\u6b63\u786e\u5b66\u4e60\u3002", "motivation": "\u73b0\u6709\u793e\u4f1a\u5b66\u4e60\u65b9\u6cd5\u5728\u52a8\u6001\u6f02\u79fb\u4e0b\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u51b3\u7b56\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9002\u5e94\u6027\u7684\u7b56\u7565\u6765\u8ddf\u8e2a\u53d8\u5316\u3002", "method": "\u63d0\u51faA\u00b2SL\u7b56\u7565\uff0c\u5305\u62ec\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u66f4\u65b0\u8ddf\u8e2a\u51b3\u7b56\u6a21\u578b\u6f02\u79fb\u548c\u9002\u5e94\u6027\u4fe1\u5ff5\u66f4\u65b0\u8ddf\u8e2a\u771f\u5b9e\u5047\u8bbe\u53d8\u5316\uff0c\u901a\u8fc7\u4e24\u4e2a\u9002\u5e94\u53c2\u6570\u63a7\u5236\u9519\u8bef\u6982\u7387\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u8db3\u591f\u5c0f\u7684\u9002\u5e94\u53c2\u6570\u4e0b\uff0c\u4ee3\u7406\u80fd\u4e00\u81f4\u5b66\u4e60\uff0c\u9519\u8bef\u5047\u8bbe\u6982\u7387\u6536\u655b\u5230\u4e0e\u53c2\u6570\u76f8\u5173\u7684\u503c\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\uff08\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u6570\u636e\uff09\u9a8c\u8bc1\u4e86\u7b56\u7565\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2504.17122", "pdf": "https://arxiv.org/pdf/2504.17122", "abs": "https://arxiv.org/abs/2504.17122", "authors": ["Kartikay Tehlan", "Thomas Wendler"], "title": "Physiological neural representation for personalised tracer kinetic parameter estimation from dynamic PET", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "The code is available at: https://github.com/tkartikay/PhysNRPET", "summary": "Dynamic positron emission tomography (PET) with [$^{18}$F]FDG enables\nnon-invasive quantification of glucose metabolism through kinetic analysis,\noften modelled by the two-tissue compartment model (TCKM). However, voxel-wise\nkinetic parameter estimation using conventional methods is computationally\nintensive and limited by spatial resolution. Deep neural networks (DNNs) offer\nan alternative but require large training datasets and significant\ncomputational resources. To address these limitations, we propose a\nphysiological neural representation based on implicit neural representations\n(INRs) for personalized kinetic parameter estimation. INRs, which learn\ncontinuous functions, allow for efficient, high-resolution parametric imaging\nwith reduced data requirements. Our method also integrates anatomical priors\nfrom a 3D CT foundation model to enhance robustness and precision in kinetic\nmodelling. We evaluate our approach on an [$^{18}$F]FDG dynamic PET/CT dataset\nand compare it to state-of-the-art DNNs. Results demonstrate superior spatial\nresolution, lower mean-squared error, and improved anatomical consistency,\nparticularly in tumour and highly vascularized regions. Our findings highlight\nthe potential of INRs for personalized, data-efficient tracer kinetic\nmodelling, enabling applications in tumour characterization, segmentation, and\nprognostic assessment.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u57fa\u4e8e\u9690\u5f0f\u795e\u7ecf\u8868\u793a(INRs)\u7684\u52a8\u6001PET\u6210\u50cf\u65b9\u6cd5\uff0c\u63d0\u9ad8\u8461\u8404\u7cd6\u4ee3\u8c22\u53c2\u6570\u4f30\u8ba1\u7684\u6548\u7387\u548c\u7cbe\u5ea6\uff0c\u5e76\u6574\u5408CT\u89e3\u5256\u5148\u9a8c\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97\u5bc6\u96c6\u4e14\u53d7\u9650\u4e8e\u5206\u8fa8\u7387\uff0cDNNs\u9700\u5927\u91cf\u6570\u636e\uff0c\u56e0\u6b64\u5f00\u53d1INRs\u4ee5\u51cf\u5c11\u6570\u636e\u9700\u6c42\u548c\u63d0\u5347\u6027\u80fd\u3002", "method": "\u4f7f\u7528INRs\u5b66\u4e60\u8fde\u7eed\u51fd\u6570\uff0c\u7ed3\u54083D CT\u57fa\u7840\u6a21\u578b\u7684\u89e3\u5256\u5148\u9a8c\uff0c\u8fdb\u884c\u4e2a\u6027\u5316\u52a8\u529b\u5b66\u53c2\u6570\u4f30\u8ba1\u3002", "result": "\u5728PET/CT\u6570\u636e\u96c6\u4e0a\uff0c\u4e0e\u73b0\u6709DNNs\u76f8\u6bd4\uff0c\u663e\u793a\u66f4\u9ad8\u7a7a\u95f4\u5206\u8fa8\u7387\u3001\u66f4\u4f4e\u5747\u65b9\u8bef\u5dee\u548c\u66f4\u597d\u89e3\u5256\u4e00\u81f4\u6027\uff0c\u5c24\u5176\u5728\u80bf\u7624\u548c\u8840\u7ba1\u5316\u533a\u57df\u3002", "conclusion": "INRs\u9002\u7528\u4e8e\u80bf\u7624\u7279\u5f81\u5316\u3001\u5206\u5272\u548c\u9884\u540e\u8bc4\u4f30\uff0c\u63d0\u4f9b\u6570\u636e\u9ad8\u6548\u7684\u52a8\u529b\u5b66\u5efa\u6a21\u65b9\u6cd5\u3002"}}
{"id": "2504.17403", "pdf": "https://arxiv.org/pdf/2504.17403", "abs": "https://arxiv.org/abs/2504.17403", "authors": ["Hans Rosenberger", "Rodrigo Fischer", "Johanna S. Fr\u00f6hlich", "Ali Bereyhi", "Ralf R. M\u00fcller"], "title": "Coding for Computation: Efficient Compression of Neural Networks for Reconfigurable Hardware", "categories": ["cs.LG", "cs.IT", "eess.SP", "math.IT"], "comment": "Accepted at the 2025 IEEE Statistical Signal Processing (SSP)\n  Workshop, Edinburgh", "summary": "As state of the art neural networks (NNs) continue to grow in size, their\nresource-efficient implementation becomes ever more important. In this paper,\nwe introduce a compression scheme that reduces the number of computations\nrequired for NN inference on reconfigurable hardware such as FPGAs. This is\nachieved by combining pruning via regularized training, weight sharing and\nlinear computation coding (LCC). Contrary to common NN compression techniques,\nwhere the objective is to reduce the memory used for storing the weights of the\nNNs, our approach is optimized to reduce the number of additions required for\ninference in a hardware-friendly manner. The proposed scheme achieves\ncompetitive performance for simple multilayer perceptrons, as well as for large\nscale deep NNs such as ResNet-34.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7f51\u7edc\u538b\u7f29\u65b9\u6848\uff0c\u901a\u8fc7\u51cf\u5c11FPGA\u4e0a\u63a8\u7406\u7684\u8ba1\u7b97\u91cf\u6765\u63d0\u9ad8\u8d44\u6e90\u6548\u7387\u3002", "motivation": "\u7531\u4e8e\u6700\u5148\u8fdb\u7684\u795e\u7ecf\u7f51\u7edc\u89c4\u6a21\u4e0d\u65ad\u589e\u5927\uff0c\u5b9e\u73b0\u8d44\u6e90\u9ad8\u6548\u7684\u90e8\u7f72\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u6b63\u5219\u5316\u8bad\u7ec3\u7684\u526a\u679d\u3001\u6743\u91cd\u5171\u4eab\u548c\u7ebf\u6027\u8ba1\u7b97\u7f16\u7801\uff08LCC\uff09\uff0c\u4f18\u5316\u51cf\u5c11\u63a8\u7406\u6240\u9700\u7684\u52a0\u6cd5\u8fd0\u7b97\uff0c\u5e76\u9488\u5bf9\u786c\u4ef6\u53cb\u597d\u8bbe\u8ba1\u3002", "result": "\u5728\u7b80\u5355\u591a\u5c42\u611f\u77e5\u5668\u548c\u5927\u578b\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5982ResNet-34\u4e0a\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6848\u6709\u6548\u964d\u4f4e\u4e86\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u7684\u8ba1\u7b97\u9700\u6c42\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u89c4\u6a21\u7684\u6a21\u578b\u3002"}}
{"id": "2504.17421", "pdf": "https://arxiv.org/pdf/2504.17421", "abs": "https://arxiv.org/abs/2504.17421", "authors": ["Yang Liu", "Bingjie Yan", "Tianyuan Zou", "Jianqing Zhang", "Zixuan Gu", "Jianbing Ding", "Xidong Wang", "Jingyi Li", "Xiaozhou Ye", "Ye Ouyang", "Qiang Yang", "Ya-Qin Zhang"], "title": "Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities, but\nthey require vast amounts of data and computational resources. In contrast,\nsmaller models (SMs), while less powerful, can be more efficient and tailored\nto specific domains. In this position paper, we argue that taking a\ncollaborative approach, where large and small models work synergistically, can\naccelerate the adaptation of LLMs to private domains and unlock new potential\nin AI. We explore various strategies for model collaboration and identify\npotential challenges and opportunities. Building upon this, we advocate for\nindustry-driven research that prioritizes multi-objective benchmarks on\nreal-world private datasets and applications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4e3b\u5f20\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u5c0f\u578b\u6a21\u578b\uff08SM\uff09\u534f\u540c\u5de5\u4f5c\uff0c\u4ee5\u52a0\u901fLLM\u5728\u79c1\u6709\u9886\u57df\u7684\u9002\u5e94\uff0c\u5e76\u63a2\u8ba8\u6311\u6218\u548c\u673a\u4f1a\uff0c\u540c\u65f6\u5021\u5bfc\u884c\u4e1a\u9a71\u52a8\u7684\u7814\u7a76\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3LLM\u9700\u8981\u5927\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u4e0eSM\u534f\u4f5c\u6765\u63d0\u9ad8\u6548\u7387\u548c\u9488\u5bf9\u7279\u5b9a\u9886\u57df\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u63a2\u7d22\u5404\u79cd\u6a21\u578b\u534f\u4f5c\u7b56\u7565\uff0c\u5e76\u8bc6\u522b\u6f5c\u5728\u6311\u6218\u548c\u673a\u4f1a\u3002", "result": "\u7ed3\u679c\u5f3a\u8c03\u4e86\u8fd9\u79cd\u534f\u540c\u65b9\u6cd5\u53ef\u4ee5\u89e3\u9501AI\u65b0\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u76ee\u6807\u57fa\u51c6\u7684\u5efa\u8bae\u3002", "conclusion": "\u7ed3\u8bba\u662f\u63a8\u52a8\u4ee5\u771f\u5b9e\u79c1\u6709\u6570\u636e\u96c6\u548c\u5e94\u7528\u4e3a\u57fa\u7840\u7684\u884c\u4e1a\u9a71\u52a8\u7814\u7a76\u3002"}}
{"id": "2504.17448", "pdf": "https://arxiv.org/pdf/2504.17448", "abs": "https://arxiv.org/abs/2504.17448", "authors": ["Jun Zhang", "Jue Wang", "Huan Li", "Zhongle Xie", "Ke Chen", "Lidan Shou"], "title": "CHASe: Client Heterogeneity-Aware Data Selection for Effective Federated Active Learning", "categories": ["cs.LG", "cs.DB", "cs.DC"], "comment": "Accepted by TKDE 2025", "summary": "Active learning (AL) reduces human annotation costs for machine learning\nsystems by strategically selecting the most informative unlabeled data for\nannotation, but performing it individually may still be insufficient due to\nrestricted data diversity and annotation budget. Federated Active Learning\n(FAL) addresses this by facilitating collaborative data selection and model\ntraining, while preserving the confidentiality of raw data samples. Yet,\nexisting FAL methods fail to account for the heterogeneity of data distribution\nacross clients and the associated fluctuations in global and local model\nparameters, adversely affecting model accuracy. To overcome these challenges,\nwe propose CHASe (Client Heterogeneity-Aware Data Selection), specifically\ndesigned for FAL. CHASe focuses on identifying those unlabeled samples with\nhigh epistemic variations (EVs), which notably oscillate around the decision\nboundaries during training. To achieve both effectiveness and efficiency,\n\\model{} encompasses techniques for 1) tracking EVs by analyzing inference\ninconsistencies across training epochs, 2) calibrating decision boundaries of\ninaccurate models with a new alignment loss, and 3) enhancing data selection\nefficiency via a data freeze and awaken mechanism with subset sampling.\nExperiments show that CHASe surpasses various established baselines in terms of\neffectiveness and efficiency, validated across diverse datasets, model\ncomplexities, and heterogeneous federation settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCHASe\u65b9\u6cd5\uff0c\u7528\u4e8e\u8054\u90a6\u4e3b\u52a8\u5b66\u4e60\uff08FAL\uff09\uff0c\u89e3\u51b3\u6570\u636e\u5206\u5e03\u5f02\u8d28\u6027\u548c\u6a21\u578b\u6ce2\u52a8\u95ee\u9898\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709FAL\u65b9\u6cd5\u672a\u8003\u8651\u5ba2\u6237\u7aef\u6570\u636e\u5206\u5e03\u5f02\u8d28\u6027\u548c\u53c2\u6570\u6ce2\u52a8\uff0c\u5bfc\u81f4\u6a21\u578b\u51c6\u786e\u6027\u4e0b\u964d\u3002", "method": "CHASe\u901a\u8fc7\u8ddf\u8e2a\u8bad\u7ec3\u4e2d\u51b3\u7b56\u8fb9\u754c\u7684\u4e0d\u4e00\u81f4\u6027\u3001\u7528\u65b0\u5bf9\u9f50\u635f\u5931\u6821\u51c6\u6a21\u578b\u3001\u4ee5\u53ca\u6570\u636e\u51bb\u7ed3\u548c\u5b50\u96c6\u91c7\u6837\u673a\u5236\u6765\u9009\u62e9\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u663e\u793aCHASe\u5728\u6709\u6548\u6027\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u591a\u79cd\u6570\u636e\u96c6\u3001\u6a21\u578b\u590d\u6742\u5ea6\u548c\u5f02\u8d28\u8bbe\u7f6e\u4e2d\u9a8c\u8bc1\u3002", "conclusion": "CHASe\u6709\u6548\u5730\u89e3\u51b3\u4e86FAL\u4e2d\u7684\u5f02\u8d28\u6027\u6311\u6218\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2504.17137", "pdf": "https://arxiv.org/pdf/2504.17137", "abs": "https://arxiv.org/abs/2504.17137", "authors": ["Chanhee Park", "Hyeonseok Moon", "Chanjun Park", "Heuiseok Lim"], "title": "MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to NAACL2025 Findings", "summary": "Retrieval-Augmented Generation (RAG) has gained prominence as an effective\nmethod for enhancing the generative capabilities of Large Language Models\n(LLMs) through the incorporation of external knowledge. However, the evaluation\nof RAG systems remains a challenge, due to the intricate interplay between\nretrieval and generation components. This limitation has resulted in a scarcity\nof benchmarks that facilitate a detailed, component-specific assessment. In\nthis work, we present MIRAGE, a Question Answering dataset specifically\ndesigned for RAG evaluation. MIRAGE consists of 7,560 curated instances mapped\nto a retrieval pool of 37,800 entries, enabling an efficient and precise\nevaluation of both retrieval and generation tasks. We also introduce novel\nevaluation metrics aimed at measuring RAG adaptability, encompassing dimensions\nsuch as noise vulnerability, context acceptability, context insensitivity, and\ncontext misinterpretation. Through comprehensive experiments across various\nretriever-LLM configurations, we provide new insights into the optimal\nalignment of model pairs and the nuanced dynamics within RAG systems. The\ndataset and evaluation code are publicly available, allowing for seamless\nintegration and customization in diverse research settings\\footnote{The MIRAGE\ncode and data are available at https://github.com/nlpai-lab/MIRAGE.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86MIRAGE\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30RAG\u7cfb\u7edf\uff0c\u5305\u62ec\u65b0\u6307\u6807\u548c\u5b9e\u9a8c\uff0c\u4ee5\u8bc4\u4f30\u68c0\u7d22\u548c\u751f\u6210\u7ec4\u4ef6\u3002", "motivation": "\u89e3\u51b3RAG\u7cfb\u7edf\u8bc4\u4f30\u7684\u6311\u6218\uff0c\u7531\u4e8e\u7f3a\u4e4f\u9488\u5bf9\u7ec4\u4ef6\u7279\u5b9a\u8bc4\u4f30\u7684\u57fa\u51c6\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b7560\u4e2a\u5b9e\u4f8b\u7684\u95ee\u9898\u56de\u7b54\u6570\u636e\u96c6\u548c37800\u4e2a\u68c0\u7d22\u6c60\uff0c\u5f15\u5165\u4e86\u65b0\u7684\u9002\u5e94\u6027\u6307\u6807\uff08\u5982\u566a\u58f0\u6613\u611f\u6027\u3001\u4e0a\u4e0b\u6587\u53ef\u63a5\u53d7\u6027\u7b49\uff09\uff0c\u5e76\u901a\u8fc7\u5404\u79cd\u68c0\u7d22\u5668-LLM\u914d\u7f6e\u8fdb\u884c\u5168\u9762\u5b9e\u9a8c\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u5173\u4e8e\u6a21\u578b\u6700\u4f73\u914d\u5bf9\u548cRAG\u7cfb\u7edf\u52a8\u6001\u7684\u65b0\u89c1\u89e3\u3002", "conclusion": "\u6570\u636e\u96c6\u548c\u4ee3\u7801\u516c\u5f00\u53ef\u7528\uff0c\u4fbf\u4e8e\u7814\u7a76\u8005\u96c6\u6210\u548c\u5b9a\u5236\u3002"}}
{"id": "2504.17449", "pdf": "https://arxiv.org/pdf/2504.17449", "abs": "https://arxiv.org/abs/2504.17449", "authors": ["Jun Zhang", "Jue Wang", "Huan Li", "Lidan Shou", "Ke Chen", "Gang Chen", "Qin Xie", "Guiming Xie", "Xuejian Gong"], "title": "HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted by VLDBJ 2025", "summary": "The significant computational demands of pretrained language models (PLMs),\nwhich often require dedicated hardware, present a substantial challenge in\nserving them efficiently, especially in multi-tenant environments. To address\nthis, we introduce HMI, a Hierarchical knowledge management-based Multi-tenant\nInference system, designed to manage tenants with distinct PLMs\nresource-efficiently. Our approach is three-fold: Firstly, we categorize PLM\nknowledge into general, domain-specific, and task-specific. Leveraging insights\non knowledge acquisition across different model layers, we construct\nhierarchical PLMs (hPLMs) by extracting and storing knowledge at different\nlevels, significantly reducing GPU memory usage per tenant. Secondly, we\nestablish hierarchical knowledge management for hPLMs generated by various\ntenants in HMI. We manage domain-specific knowledge with acceptable storage\nincreases by constructing and updating domain-specific knowledge trees based on\nfrequency. We manage task-specific knowledge within limited GPU memory through\nparameter swapping. Finally, we propose system optimizations to enhance\nresource utilization and inference throughput. These include fine-grained\npipelining via hierarchical knowledge prefetching to overlap CPU and I/O\noperations with GPU computations, and optimizing parallel implementations with\nbatched matrix multiplications. Our experimental results demonstrate that the\nproposed HMI can efficiently serve up to 10,000 hPLMs (hBERTs and hGPTs) on a\nsingle GPU, with only a negligible compromise in accuracy.", "AI": {"tldr": "\u7b80\u800c\u8a00\u4e4b\uff0c\u8be5\u8bba\u6587\u63d0\u51faHMI\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u5c42\u77e5\u8bc6\u7ba1\u7406\u5728\u5355\u4e2aGPU\u4e0a\u9ad8\u6548\u670d\u52a1\u591a\u8fbe10,000\u4e2a\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u4ec5\u6709\u5fae\u5c0f\u51c6\u786e\u7387\u635f\u5931\u3002", "motivation": "\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u9700\u8981\u4e13\u7528\u786c\u4ef6\uff0c\u5c24\u5176\u5728\u591a\u79df\u6237\u73af\u5883\u4e2d\uff0c\u8d44\u6e90\u6548\u7387\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5c06PLM\u77e5\u8bc6\u5206\u4e3a\u4e00\u822c\u3001\u9886\u57df\u7279\u5b9a\u548c\u4efb\u52a1\u7279\u5b9a\uff0c\u6784\u5efa\u5206\u5c42PLM\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\uff0c\u901a\u8fc7\u77e5\u8bc6\u6811\u548c\u53c2\u6570\u4ea4\u6362\u7ba1\u7406\u77e5\u8bc6\uff0c\u5e76\u4f18\u5316\u7cfb\u7edf\u5982\u5206\u5c42\u9884\u53d6\u548c\u6279\u5904\u7406\u77e9\u9635\u4e58\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cHMI\u53ef\u5728\u5355\u4e2aGPU\u4e0a\u670d\u52a110,000\u4e2ahBERTs\u548chGPTs\uff0c\u4ec5\u6709\u5fae\u4e0d\u8db3\u9053\u7684\u51c6\u786e\u7387\u635f\u5931\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5730\u63d0\u5347\u4e86\u591a\u79df\u6237\u73af\u5883\u4e2dPLM\u7684\u8d44\u6e90\u5229\u7528\u7387\uff0c\u8bc1\u660e\u4e86\u5206\u5c42\u77e5\u8bc6\u7ba1\u7406\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2504.17461", "pdf": "https://arxiv.org/pdf/2504.17461", "abs": "https://arxiv.org/abs/2504.17461", "authors": ["Vipin Singh", "Tianheng Ling", "Teodor Chiaburu", "Felix Biessmann"], "title": "Evaluating Time Series Models for Urban Wastewater Management: Predictive Performance, Model Complexity and Resilience", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, 6 figures, accepted at 10th International Conference on\n  Smart and Sustainable Technologies (SpliTech) 2025, GitHub:\n  https://github.com/calgo-lab/resilient-timeseries-evaluation", "summary": "Climate change increases the frequency of extreme rainfall, placing a\nsignificant strain on urban infrastructures, especially Combined Sewer Systems\n(CSS). Overflows from overburdened CSS release untreated wastewater into\nsurface waters, posing environmental and public health risks. Although\ntraditional physics-based models are effective, they are costly to maintain and\ndifficult to adapt to evolving system dynamics. Machine Learning (ML)\napproaches offer cost-efficient alternatives with greater adaptability. To\nsystematically assess the potential of ML for modeling urban infrastructure\nsystems, we propose a protocol for evaluating Neural Network architectures for\nCSS time series forecasting with respect to predictive performance, model\ncomplexity, and robustness to perturbations. In addition, we assess model\nperformance on peak events and critical fluctuations, as these are the key\nregimes for urban wastewater management. To investigate the feasibility of\nlightweight models suitable for IoT deployment, we compare global models, which\nhave access to all information, with local models, which rely solely on nearby\nsensor readings. Additionally, to explore the security risks posed by network\noutages or adversarial attacks on urban infrastructure, we introduce error\nmodels that assess the resilience of models. Our results demonstrate that while\nglobal models achieve higher predictive performance, local models provide\nsufficient resilience in decentralized scenarios, ensuring robust modeling of\nurban infrastructure. Furthermore, models with longer native forecast horizons\nexhibit greater robustness to data perturbations. These findings contribute to\nthe development of interpretable and reliable ML solutions for sustainable\nurban wastewater management. The implementation is available in our GitHub\nrepository.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u57ce\u5e02\u8054\u5408\u4e0b\u6c34\u7cfb\u7edf\uff08CSS\uff09\u884c\u4e3a\uff0c\u4ee5\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u5f15\u8d77\u7684\u6781\u7aef\u964d\u96e8\uff0c\u6bd4\u8f83\u5168\u5c40\u548c\u672c\u5730\u6a21\u578b\u7684\u6027\u80fd\u4e0e\u9c81\u68d2\u6027\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u589e\u52a0\u6781\u7aef\u964d\u96e8\u9891\u7387\uff0c\u4f20\u7edf\u7269\u7406\u6a21\u578b\u7ef4\u62a4\u6210\u672c\u9ad8\u4e14\u9002\u5e94\u6027\u5dee\uff0c\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u66f4\u9ad8\u6548\u548c\u7075\u6d3b\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u534f\u8bae\u8bc4\u4f30\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5305\u62ec\u9884\u6d4b\u6027\u80fd\u3001\u6a21\u578b\u590d\u6742\u6027\u3001\u9c81\u68d2\u6027\uff1b\u6bd4\u8f83\u5168\u5c40\u6a21\u578b\uff08\u4f7f\u7528\u6240\u6709\u4fe1\u606f\uff09\u548c\u672c\u5730\u6a21\u578b\uff08\u4ec5\u7528\u9644\u8fd1\u4f20\u611f\u5668\u6570\u636e\uff09\uff1b\u5f15\u5165\u9519\u8bef\u6a21\u578b\u8bc4\u4f30\u5bf9\u7f51\u7edc\u4e2d\u65ad\u6216\u653b\u51fb\u7684\u5f39\u6027\u3002", "result": "\u5168\u5c40\u6a21\u578b\u9884\u6d4b\u6027\u80fd\u66f4\u9ad8\uff0c\u4f46\u672c\u5730\u6a21\u578b\u5728\u53bb\u4e2d\u5fc3\u5316\u573a\u666f\u4e2d\u63d0\u4f9b\u8db3\u591f\u5f39\u6027\uff1b\u5177\u6709\u66f4\u957f\u9884\u6d4b\u5730\u5e73\u7ebf\u7684\u6a21\u578b\u5bf9\u6570\u636e\u6270\u52a8\u66f4\u9c81\u68d2\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u6709\u52a9\u4e8e\u5f00\u53d1\u53ef\u89e3\u91ca\u548c\u53ef\u9760\u7684\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u4fc3\u8fdb\u53ef\u6301\u7eed\u7684\u57ce\u5e02\u5e9f\u6c34\u7ba1\u7406\uff0c\u5e76\u63d0\u4f9bGitHub\u5b9e\u73b0\u3002"}}
{"id": "2504.17471", "pdf": "https://arxiv.org/pdf/2504.17471", "abs": "https://arxiv.org/abs/2504.17471", "authors": ["Yacine Belal", "Mohamed Maouche", "Sonia Ben Mokhtar", "Anthony Simonet-Boulogne"], "title": "GRANITE : a Byzantine-Resilient Dynamic Gossip Learning Framework", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Gossip Learning (GL) is a decentralized learning paradigm where users\niteratively exchange and aggregate models with a small set of neighboring\npeers. Recent GL approaches rely on dynamic communication graphs built and\nmaintained using Random Peer Sampling (RPS) protocols. Thanks to graph\ndynamics, GL can achieve fast convergence even over extremely sparse\ntopologies. However, the robustness of GL over dy- namic graphs to Byzantine\n(model poisoning) attacks remains unaddressed especially when Byzantine nodes\nattack the RPS protocol to scale up model poisoning. We address this issue by\nintroducing GRANITE, a framework for robust learning over sparse, dynamic\ngraphs in the presence of a fraction of Byzantine nodes. GRANITE relies on two\nkey components (i) a History-aware Byzantine-resilient Peer Sampling protocol\n(HaPS), which tracks previously encountered identifiers to reduce adversarial\ninfluence over time, and (ii) an Adaptive Probabilistic Threshold (APT), which\nleverages an estimate of Byzantine presence to set aggregation thresholds with\nformal guarantees. Empirical results confirm that GRANITE maintains convergence\nwith up to 30% Byzantine nodes, improves learning speed via adaptive filtering\nof poisoned models and obtains these results in up to 9 times sparser graphs\nthan dictated by current theory.", "AI": {"tldr": "GRANITE \u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u52a8\u6001\u7a00\u758f\u56fe\u4e0a\u8fdb\u884c\u9c81\u68d2\u5206\u6563\u5f0f\u5b66\u4e60\uff0c\u62b5\u6297 Byzantine \u653b\u51fb\u3002", "motivation": "\u73b0\u6709 Gossip Learning \u65b9\u6cd5\u5728\u52a8\u6001\u56fe\u4e0a\u6536\u655b\u5feb\uff0c\u4f46\u5bf9 Byzantine \u653b\u51fb\u7684\u9c81\u68d2\u6027\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5f53\u653b\u51fb\u8005\u64cd\u7eb5 RPS \u534f\u8bae\u65f6\u3002", "method": "GRANITE \u5305\u62ec History-aware Byzantine-resilient Peer Sampling (HaPS) \u548c Adaptive Probabilistic Threshold (APT) \u4e24\u4e2a\u7ec4\u4ef6\uff0cHaPS \u901a\u8fc7\u8ddf\u8e2a\u5386\u53f2\u6807\u8bc6\u7b26\u51cf\u5c11\u5bf9\u624b\u5f71\u54cd\uff0cAPT \u901a\u8fc7\u4f30\u8ba1 Byzantine \u5b58\u5728\u8bbe\u7f6e\u805a\u5408\u9608\u503c\u3002", "result": "GRANITE \u5728\u9ad8\u8fbe 30% Byzantine \u8282\u70b9\u65f6\u4fdd\u6301\u6536\u655b\uff0c\u63d0\u9ad8\u5b66\u4e60\u901f\u5ea6\uff0c\u5e76\u5728\u6bd4\u5f53\u524d\u7406\u8bba\u7a00\u758f 9 \u500d\u7684\u56fe\u4e0a\u8868\u73b0\u826f\u597d\u3002", "conclusion": "GRANITE \u6709\u6548\u63d0\u5347\u4e86 Gossip Learning \u5728 Byzantine \u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2504.17162", "pdf": "https://arxiv.org/pdf/2504.17162", "abs": "https://arxiv.org/abs/2504.17162", "authors": ["Cece Zhang", "Xuehuan Zhu", "Nick Peterson", "Jieqiong Wang", "Shibiao Wan"], "title": "A Comprehensive Review on RNA Subcellular Localization Prediction", "categories": ["cs.CV", "cs.AI", "q-bio.GN", "q-bio.SC"], "comment": null, "summary": "The subcellular localization of RNAs, including long non-coding RNAs\n(lncRNAs), messenger RNAs (mRNAs), microRNAs (miRNAs) and other smaller RNAs,\nplays a critical role in determining their biological functions. For instance,\nlncRNAs are predominantly associated with chromatin and act as regulators of\ngene transcription and chromatin structure, while mRNAs are distributed across\nthe nucleus and cytoplasm, facilitating the transport of genetic information\nfor protein synthesis. Understanding RNA localization sheds light on processes\nlike gene expression regulation with spatial and temporal precision. However,\ntraditional wet lab methods for determining RNA localization, such as in situ\nhybridization, are often time-consuming, resource-demanding, and costly. To\novercome these challenges, computational methods leveraging artificial\nintelligence (AI) and machine learning (ML) have emerged as powerful\nalternatives, enabling large-scale prediction of RNA subcellular localization.\nThis paper provides a comprehensive review of the latest advancements in\nAI-based approaches for RNA subcellular localization prediction, covering\nvarious RNA types and focusing on sequence-based, image-based, and hybrid\nmethodologies that combine both data types. We highlight the potential of these\nmethods to accelerate RNA research, uncover molecular pathways, and guide\ntargeted disease treatments. Furthermore, we critically discuss the challenges\nin AI/ML approaches for RNA subcellular localization, such as data scarcity and\nlack of benchmarks, and opportunities to address them. This review aims to\nserve as a valuable resource for researchers seeking to develop innovative\nsolutions in the field of RNA subcellular localization and beyond.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8eAI\u7684\u65b9\u6cd5\u9884\u6d4bRNA\u4e9a\u7ec6\u80de\u5b9a\u4f4d\uff0c\u6db5\u76d6\u5404\u79cdRNA\u7c7b\u578b\u548c\u5e8f\u5217\u3001\u56fe\u50cf\u3001\u6df7\u5408\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u6311\u6218\u4e0e\u673a\u4f1a\u3002", "motivation": "RNA\u5b9a\u4f4d\u5bf9\u751f\u7269\u529f\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edf\u65b9\u6cd5\u8017\u65f6\u4e14\u6602\u8d35\uff0c\u56e0\u6b64\u9700\u8981AI/ML\u63d0\u4f9b\u9ad8\u6548\u9884\u6d4b\u3002", "method": "\u56de\u987eAI-based\u65b9\u6cd5\uff0c\u5305\u62ec\u5e8f\u5217\u3001\u56fe\u50cf\u548c\u6df7\u5408\u65b9\u6cd5\uff0c\u7528\u4e8eRNA\u5b9a\u4f4d\u9884\u6d4b\u3002", "result": "AI\u65b9\u6cd5\u53ef\u52a0\u901fRNA\u7814\u7a76\u3001\u63ed\u793a\u5206\u5b50\u9014\u5f84\u5e76\u6307\u5bfc\u75be\u75c5\u6cbb\u7597\uff1b\u8ba8\u8bba\u6570\u636e\u7a00\u7f3a\u7b49\u6311\u6218\u3002", "conclusion": "\u65e8\u5728\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u8d44\u6e90\uff0c\u5f00\u53d1RNA\u5b9a\u4f4d\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.17490", "pdf": "https://arxiv.org/pdf/2504.17490", "abs": "https://arxiv.org/abs/2504.17490", "authors": ["Mingqi Yuan", "Qi Wang", "Guozheng Ma", "Bo Li", "Xin Jin", "Yunbo Wang", "Xiaokang Yang", "Wenjun Zeng", "Dacheng Tao"], "title": "Plasticine: Accelerating Research in Plasticity-Motivated Deep Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages", "summary": "Developing lifelong learning agents is crucial for artificial general\nintelligence. However, deep reinforcement learning (RL) systems often suffer\nfrom plasticity loss, where neural networks gradually lose their ability to\nadapt during training. Despite its significance, this field lacks unified\nbenchmarks and evaluation protocols. We introduce Plasticine, the first\nopen-source framework for benchmarking plasticity optimization in deep RL.\nPlasticine provides single-file implementations of over 13 mitigation methods,\n10 evaluation metrics, and learning scenarios with increasing non-stationarity\nlevels from standard to open-ended environments. This framework enables\nresearchers to systematically quantify plasticity loss, evaluate mitigation\nstrategies, and analyze plasticity dynamics across different contexts. Our\ndocumentation, examples, and source code are available at\nhttps://github.com/RLE-Foundation/Plasticine.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f15\u5165Plasticine\u6846\u67b6\uff0c\u7528\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u53ef\u5851\u6027\u4f18\u5316\uff0c\u63d0\u4f9b\u7f13\u89e3\u65b9\u6cd5\u3001\u8bc4\u4f30\u6307\u6807\u548c\u5b66\u4e60\u573a\u666f\u3002", "motivation": "\u5f00\u53d1\u7ec8\u8eab\u5b66\u4e60\u4ee3\u7406\u5bf9\u4eba\u5de5\u901a\u7528\u667a\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u5e38\u56e0\u53ef\u5851\u6027\u635f\u5931\u800c\u9002\u5e94\u80fd\u529b\u4e0b\u964d\uff0c\u4e14\u7f3a\u4e4f\u7edf\u4e00\u57fa\u51c6\u548c\u8bc4\u4f30\u534f\u8bae\u3002", "method": "\u5f15\u5165Plasticine\u5f00\u6e90\u6846\u67b6\uff0c\u5305\u542b13\u79cd\u4ee5\u4e0a\u7f13\u89e3\u65b9\u6cd5\u300110\u79cd\u8bc4\u4f30\u6307\u6807\uff0c\u4ee5\u53ca\u4ece\u6807\u51c6\u5230\u5f00\u653e\u5f0f\u73af\u5883\u7684\u975e\u5e73\u7a33\u5b66\u4e60\u573a\u666f\u3002", "result": "\u6846\u67b6\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u7cfb\u7edf\u91cf\u5316\u53ef\u5851\u6027\u635f\u5931\u3001\u8bc4\u4f30\u7f13\u89e3\u7b56\u7565\uff0c\u5e76\u5206\u6790\u4e0d\u540c\u60c5\u5883\u4e0b\u7684\u53ef\u5851\u6027\u52a8\u6001\u3002", "conclusion": "Plasticine\u586b\u8865\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u53ef\u5851\u6027\u4f18\u5316\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u53ef\u4eceGitHub\u83b7\u53d6\u3002"}}
{"id": "2504.17170", "pdf": "https://arxiv.org/pdf/2504.17170", "abs": "https://arxiv.org/abs/2504.17170", "authors": ["Robert Kaufman"], "title": "Improving Human-Autonomous Vehicle Interaction in Complex Systems", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "PhD Dissertation from University of California, San Diego; 175 pages", "summary": "Unresolved questions about how autonomous vehicles (AVs) should meet the\ninformational needs of riders hinder real-world adoption. Complicating our\nability to satisfy rider needs is that different people, goals, and driving\ncontexts have different criteria for what constitutes interaction success.\nUnfortunately, most human-AV research and design today treats all people and\nsituations uniformly. It is crucial to understand how an AV should communicate\nto meet rider needs, and how communications should change when the human-AV\ncomplex system changes. I argue that understanding the relationships between\ndifferent aspects of the human-AV system can help us build improved and\nadaptable AV communications. I support this argument using three empirical\nstudies. First, I identify optimal communication strategies that enhance\ndriving performance, confidence, and trust for learning in extreme driving\nenvironments. Findings highlight the need for task-sensitive,\nmodality-appropriate communications tuned to learner cognitive limits and\ngoals. Next, I highlight the consequences of deploying faulty communication\nsystems and demonstrate the need for context-sensitive communications. Third, I\nuse machine learning (ML) to illuminate personal factors predicting trust in\nAVs, emphasizing the importance of tailoring designs to individual traits and\nconcerns. Together, this dissertation supports the necessity of transparent,\nadaptable, and personalized AV systems that cater to individual needs, goals,\nand contextual demands. By considering the complex system within which human-AV\ninteractions occur, we can deliver valuable insights for designers,\nresearchers, and policymakers. This dissertation also provides a concrete\ndomain to study theories of human-machine joint action and situational\nawareness, and can be used to guide future human-AI interaction research.\n[shortened for arxiv]", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u4e09\u4e2a\u5b9e\u8bc1\u7814\u7a76\u63a2\u8ba8\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5982\u4f55\u901a\u8fc7\u900f\u660e\u3001\u53ef\u9002\u5e94\u548c\u4e2a\u6027\u5316\u7684\u901a\u4fe1\u7cfb\u7edf\u6ee1\u8db3\u9a91\u624b\u9700\u6c42\uff0c\u63d0\u5347\u4fe1\u4efb\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5982\u4f55\u6ee1\u8db3\u9a91\u624b\u8d44\u8baf\u9700\u6c42\u7684\u672a\u89e3\u51b3\u95ee\u9898\uff0c\u8003\u8651\u5230\u4e0d\u540c\u4eba\u3001\u76ee\u6807\u548c\u60c5\u5883\u7684\u5dee\u5f02\uff0c\u4ee5\u53ca\u5f53\u524d\u7814\u7a76\u8bbe\u8ba1\u7684\u7edf\u4e00\u6027\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u4e09\u4e2a\u5b9e\u8bc1\u7814\u7a76\uff1a1. \u8bc6\u522b\u6700\u4f73\u901a\u4fe1\u7b56\u7565\uff1b2. \u5206\u6790\u6545\u969c\u901a\u4fe1\u7684\u540e\u679c\uff1b3. \u8fd0\u7528\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u4fe1\u4efb\u7684\u4e2a\u4eba\u56e0\u7d20\u3002", "result": "\u53d1\u73b0\u9700\u8981\u4efb\u52a1\u654f\u611f\u3001\u6a21\u6001\u9002\u5f53\u7684\u901a\u4fe1\uff1b\u5f3a\u8c03\u4e0a\u4e0b\u6587\u548c\u4e2a\u4eba\u56e0\u7d20\u7684\u91cd\u8981\u6027\uff0c\u652f\u6301\u4e2a\u6027\u5316AV\u8bbe\u8ba1\u3002", "conclusion": "\u4e3b\u5f20\u5f00\u53d1\u900f\u660e\u3001\u53ef\u9002\u5e94\u548c\u4e2a\u6027\u5316\u7684AV\u7cfb\u7edf\uff0c\u4e3a\u8bbe\u8ba1\u5e08\u3001\u7814\u7a76\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u6d1e\u89c1\uff0c\u5e76\u6307\u5bfc\u672a\u6765\u4eba\u673a\u4ea4\u4e92\u7814\u7a76\u3002"}}
{"id": "2504.17492", "pdf": "https://arxiv.org/pdf/2504.17492", "abs": "https://arxiv.org/abs/2504.17492", "authors": ["Nawid Keshtmand", "Elena Fillola", "Jeffrey Nicholas Clark", "Raul Santos-Rodriguez", "Matthew Rigby"], "title": "Prototype-enhanced prediction in graph neural networks for climate applications", "categories": ["cs.LG"], "comment": null, "summary": "Data-driven emulators are increasingly being used to learn and emulate\nphysics-based simulations, reducing computational expense and run time. Here,\nwe present a structured way to improve the quality of these high-dimensional\nemulated outputs, through the use of prototypes: an approximation of the\nemulator's output passed as an input, which informs the model and leads to\nbetter predictions. We demonstrate our approach to emulate atmospheric\ndispersion, key for greenhouse gas emissions monitoring, by comparing a\nbaseline model to models trained using prototypes as an additional input. The\nprototype models achieve better performance, even with few prototypes and even\nif they are chosen at random, but we show that choosing the prototypes through\ndata-driven methods (k-means) can lead to almost 10\\% increased performance in\nsome metrics.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u539f\u578b\u6765\u6539\u8fdb\u6570\u636e\u9a71\u52a8\u4eff\u771f\u5668\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u8f93\u51fa\u8fd1\u4f3c\u4f5c\u4e3a\u8f93\u5165\u63d0\u5347\u9884\u6d4b\u8d28\u91cf\uff0c\u5e94\u7528\u4e8e\u5927\u6c14\u6269\u6563\u6a21\u62df\u4ee5\u76d1\u6d4b\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u3002", "motivation": "\u52a8\u673a\u662f\u51cf\u5c11\u7269\u7406\u6a21\u62df\u7684\u8ba1\u7b97\u5f00\u9500\u548c\u8fd0\u884c\u65f6\u95f4\uff0c\u540c\u65f6\u63d0\u9ad8\u9ad8\u7ef4\u8f93\u51fa\u8d28\u91cf\uff0c\u7279\u522b\u662f\u9488\u5bf9\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u76d1\u6d4b\u3002", "method": "\u65b9\u6cd5\u6d89\u53ca\u5c06\u539f\u578b\u4f5c\u4e3a\u989d\u5916\u8f93\u5165\uff0c\u4e0e\u57fa\u7ebf\u6a21\u578b\u6bd4\u8f83\uff1b\u539f\u578b\u53ef\u968f\u673a\u6216\u901a\u8fc7k-means\u7b49\u6570\u636e\u9a71\u52a8\u65b9\u5f0f\u9009\u62e9\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528\u539f\u578b\u6a21\u578b\u6027\u80fd\u66f4\u597d\uff0c\u5373\u4f7f\u539f\u578b\u5c11\u6216\u968f\u673a\uff1bk-means\u9009\u62e9\u53ef\u63d0\u9ad8\u67d0\u4e9b\u6307\u6807\u8fd110%\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u539f\u578b\u65b9\u6cd5\u80fd\u663e\u8457\u6539\u5584\u4eff\u771f\u9884\u6d4b\uff0c\u6570\u636e\u9a71\u52a8\u9009\u62e9\u8fdb\u4e00\u6b65\u589e\u5f3a\u6548\u679c\u3002"}}
