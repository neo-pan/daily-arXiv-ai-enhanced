{"id": "2504.15396", "pdf": "https://arxiv.org/pdf/2504.15396", "abs": "https://arxiv.org/abs/2504.15396", "authors": ["Igor Ladnik"], "title": "A Quadratic Control Framework for Dynamic Systems", "categories": ["eess.SY", "cs.SY"], "comment": "16 pages, 10 figures, 16 tables", "summary": "This article presents a unified approach to quadratic optimal control for\nboth linear and nonlinear discrete-time systems, with a focus on trajectory\ntracking. The control strategy is based on minimizing a quadratic cost function\nthat penalizes deviations of system states and control inputs from their\ndesired trajectories.\n  For linear systems, the classical Linear Quadratic Regulator (LQR) solution\nis derived using dynamic programming, resulting in recursive equations for\nfeedback and feedforward terms. For nonlinear dynamics, the Iterative Linear\nQuadratic Regulator (iLQR) method is employed, which iteratively linearizes the\nsystem and solves a sequence of LQR problems to converge to an optimal policy.\n  To implement this approach, a software service was developed and tested on\nseveral canonical models, including: Rayleigh oscillator, inverted pendulum on\na moving cart, two-link manipulator, and quadcopter. The results confirm that\niLQR enables efficient and accurate trajectory tracking in the presence of\nnonlinearities.\n  To further enhance performance, it can be seamlessly integrated with Model\nPredictive Control (MPC), enabling online adaptation and improved robustness to\nconstraints and system uncertainties."}
{"id": "2504.15423", "pdf": "https://arxiv.org/pdf/2504.15423", "abs": "https://arxiv.org/abs/2504.15423", "authors": ["Maitham F. AL-Sunni", "Hassan Almubarak", "John M. Dolan"], "title": "Safety Embedded Adaptive Control Using Barrier States", "categories": ["eess.SY", "cs.RO", "cs.SY"], "comment": "This work has been accepted for publication in the proceedings of the\n  2025 American Control Conference (ACC), Denver, CO, USA", "summary": "In this work, we explore the application of barrier states (BaS) in the realm\nof safe nonlinear adaptive control. Our proposed framework derives barrier\nstates for systems with parametric uncertainty, which are augmented into the\nuncertain dynamical model. We employ an adaptive nonlinear control strategy\nbased on a control Lyapunov functions approach to design a stabilizing\ncontroller for the augmented system. The developed theory shows that the\ncontroller ensures safe control actions for the original system while meeting\nspecified performance objectives. We validate the effectiveness of our approach\nthrough simulations on diverse systems, including a planar quadrotor subject to\nunknown drag forces and an adaptive cruise control system, for which we provide\ncomparisons with existing methodologies."}
{"id": "2504.15453", "pdf": "https://arxiv.org/pdf/2504.15453", "abs": "https://arxiv.org/abs/2504.15453", "authors": ["Hassan Almubarak", "Maitham F. AL-Sunni", "Justin T. Dubbin", "Nader Sadegh", "John M. Dolan", "Evangelos A. Theodorou"], "title": "Nearly Optimal Nonlinear Safe Control with BaS-SDRE", "categories": ["eess.SY", "cs.RO", "cs.SY"], "comment": null, "summary": "The State-Dependent Riccati Equation (SDRE) approach has emerged as a\nsystematic and effective means of designing nearly optimal nonlinear\ncontrollers. The Barrier States (BaS) embedding methodology was developed\nrecently for safe multi-objective controls in which the safety condition is\nmanifested as a state to be controlled along with other states of the system.\nThe overall system, termed the safety embedded system, is highly nonlinear even\nif the original system is linear. This paper develops a nonlinear nearly\noptimal safe feedback control technique by combining the two strategies\neffectively. First, the BaS is derived in an extended linearization formulation\nto be subsequently used to form an extended safety embedded system. A new\noptimal control problem is formed thereafter, which is used to construct a\nsafety embedded State-Dependent Riccati Equation, termed BaS-SDRE, whose\nsolution approximates the solution of the optimal control problem's associated\nHamilton-Jacobi-Bellman (HJB) equation. The BaS-SDRE is then solved online to\nsynthesize the nearly optimal safe control. The proposed technique's efficacy\nis demonstrated on an unstable, constrained linear system that shows how the\nsynthesized control reacts to nonlinearities near the unsafe region, a\nnonlinear flight control system with limited path angular velocity that exists\ndue to structural and dynamic concerns, and a planar quadrotor system that\nnavigates safely in a crowded environment."}
{"id": "2504.15540", "pdf": "https://arxiv.org/pdf/2504.15540", "abs": "https://arxiv.org/abs/2504.15540", "authors": ["Takayuki Ishizaki", "Takahiro Kawaguchi", "Yuichiro Yano", "Yuko Hanado"], "title": "Explicit Ensemble Mean Clock Synchronization for Optimal Atomic Time Scale Generation", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "This paper presents a novel theoretical framework for atomic time scale\ngeneration, called explicit ensemble mean synchronization, which unifies clock\nsynchronization and time scale generation within a control-theoretic paradigm.\nBy exploiting an observable canonical decomposition of a standard atomic clock\nensemble model, the system is decomposed into two complementary components: the\nobservable part, which represents the synchronization deviation, and the\nunobservable part, which captures the synchronization destination. Within this\nstructure, we mathematically prove that standard Kalman filtering, widely used\nin current time scale generation, can be interpreted as a special case of the\nproposed framework that optimizes long-term frequency stability in terms of the\nAllan variance. Furthermore, by applying appropriate state feedback control to\neach component based on the Kalman filtering, both clock synchronization and\noptimal time scale generation are achieved within a unified framework. This\nframework provides a principled basis for robust timekeeping systems that goes\nbeyond conventional approaches in both scope and performance."}
{"id": "2504.15304", "pdf": "https://arxiv.org/pdf/2504.15304", "abs": "https://arxiv.org/abs/2504.15304", "authors": ["Kangyu Wang"], "title": "Can Machine Learning Agents Deal with Hard Choices?", "categories": ["cs.AI"], "comment": "22 pages excluding bibliography, 27 pagas including bibliography, 3\n  figures", "summary": "Machine Learning ML agents have been increasingly used in decision-making\nacross a wide range of tasks and environments. These ML agents are typically\ndesigned to balance multiple objectives when making choices. Understanding how\ntheir decision-making processes align with or diverge from human reasoning is\nessential. Human agents often encounter hard choices, that is, situations where\noptions are incommensurable; neither option is preferred, yet the agent is not\nindifferent between them. In such cases, human agents can identify hard choices\nand resolve them through deliberation. In contrast, current ML agents, due to\nfundamental limitations in Multi-Objective Optimisation or MOO methods, cannot\nidentify hard choices, let alone resolve them. Neither Scalarised Optimisation\nnor Pareto Optimisation, the two principal MOO approaches, can capture\nincommensurability. This limitation generates three distinct alignment\nproblems: the alienness of ML decision-making behaviour from a human\nperspective; the unreliability of preference-based alignment strategies for\nhard choices; and the blockage of alignment strategies pursuing multiple\nobjectives. Evaluating two potential technical solutions, I recommend an\nensemble solution that appears most promising for enabling ML agents to\nidentify hard choices and mitigate alignment problems. However, no known\ntechnique allows ML agents to resolve hard choices through deliberation, as\nthey cannot autonomously change their goals. This underscores the\ndistinctiveness of human agency and urges ML researchers to reconceptualise\nmachine autonomy and develop frameworks and methods that can better address\nthis fundamental gap."}
{"id": "2504.15300", "pdf": "https://arxiv.org/pdf/2504.15300", "abs": "https://arxiv.org/abs/2504.15300", "authors": ["Chaoyue Niu", "Yucheng Ding", "Junhui Lu", "Zhengxiang Huang", "Hang Zeng", "Yutong Dai", "Xuezhen Tu", "Chengfei Lv", "Fan Wu", "Guihai Chen"], "title": "Collaborative Learning of On-Device Small Model and Cloud-Based Large Model: Advances and Future Directions", "categories": ["cs.LG", "cs.DC", "cs.MA"], "comment": null, "summary": "The conventional cloud-based large model learning framework is increasingly\nconstrained by latency, cost, personalization, and privacy concerns. In this\nsurvey, we explore an emerging paradigm: collaborative learning between\non-device small model and cloud-based large model, which promises low-latency,\ncost-efficient, and personalized intelligent services while preserving user\nprivacy. We provide a comprehensive review across hardware, system, algorithm,\nand application layers. At each layer, we summarize key problems and recent\nadvances from both academia and industry. In particular, we categorize\ncollaboration algorithms into data-based, feature-based, and parameter-based\nframeworks. We also review publicly available datasets and evaluation metrics\nwith user-level or device-level consideration tailored to collaborative\nlearning settings. We further highlight real-world deployments, ranging from\nrecommender systems and mobile livestreaming to personal intelligent\nassistants. We finally point out open research directions to guide future\ndevelopment in this rapidly evolving field."}
{"id": "2504.15578", "pdf": "https://arxiv.org/pdf/2504.15578", "abs": "https://arxiv.org/abs/2504.15578", "authors": ["Ian Mikesell", "Samuel Filgueira da Silva", "Mehmet Fatih Ozkan", "Faissal El Idrissi", "Prashanth Ramesh", "Marcello Canova"], "title": "Real-Time Optimal Design of Experiment for Parameter Identification of Li-Ion Cell Electrochemical Model", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "Accurately identifying the parameters of electrochemical models of li-ion\nbattery (LiB) cells is a critical task for enhancing the fidelity and\npredictive ability. Traditional parameter identification methods often require\nextensive data collection experiments and lack adaptability in dynamic\nenvironments. This paper describes a Reinforcement Learning (RL) based approach\nthat dynamically tailors the current profile applied to a LiB cell to optimize\nthe parameters identifiability of the electrochemical model. The proposed\nframework is implemented in real-time using a Hardware-in-the-Loop (HIL) setup,\nwhich serves as a reliable testbed for evaluating the RL-based design strategy.\nThe HIL validation confirms that the RL-based experimental design outperforms\nconventional test protocols used for parameter identification in terms of both\nreducing the modeling errors on a verification test and minimizing the duration\nof the experiment used for parameter identification."}
{"id": "2504.15313", "pdf": "https://arxiv.org/pdf/2504.15313", "abs": "https://arxiv.org/abs/2504.15313", "authors": ["Yajie Yu", "Yue Feng"], "title": "PolicyEvol-Agent: Evolving Policy via Environment Perception and Self-Awareness with Theory of Mind", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Multi-agents has exhibited significant intelligence in real-word simulations\nwith Large language models (LLMs) due to the capabilities of social cognition\nand knowledge retrieval. However, existing research on agents equipped with\neffective cognition chains including reasoning, planning, decision-making and\nreflecting remains limited, especially in the dynamically interactive\nscenarios. In addition, unlike human, prompt-based responses face challenges in\npsychological state perception and empirical calibration during uncertain\ngaming process, which can inevitably lead to cognition bias. In light of above,\nwe introduce PolicyEvol-Agent, a comprehensive LLM-empowered framework\ncharacterized by systematically acquiring intentions of others and adaptively\noptimizing irrational strategies for continual enhancement. Specifically,\nPolicyEvol-Agent first obtains reflective expertise patterns and then\nintegrates a range of cognitive operations with Theory of Mind alongside\ninternal and external perspectives. Simulation results, outperforming RL-based\nmodels and agent-based methods, demonstrate the superiority of PolicyEvol-Agent\nfor final gaming victory. Moreover, the policy evolution mechanism reveals the\neffectiveness of dynamic guideline adjustments in both automatic and human\nevaluation."}
{"id": "2504.15310", "pdf": "https://arxiv.org/pdf/2504.15310", "abs": "https://arxiv.org/abs/2504.15310", "authors": ["Syeda Tahreem Zahra", "Syed Kashif Imdad", "Sohail Khan", "Sohail Khalid", "Nauman Anwar Baig"], "title": "Power Transformer Health Index and Life Span Assessment: A Comprehensive Review of Conventional and Machine Learning based Approaches", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Power transformers play a critical role within the electrical power system,\nmaking their health assessment and the prediction of their remaining lifespan\nparamount for the purpose of ensuring efficient operation and facilitating\neffective maintenance planning. This paper undertakes a comprehensive\nexamination of existent literature, with a primary focus on both conventional\nand cutting-edge techniques employed within this domain. The merits and\ndemerits of recent methodologies and techniques are subjected to meticulous\nscrutiny and explication. Furthermore, this paper expounds upon intelligent\nfault diagnosis methodologies and delves into the most widely utilized\nintelligent algorithms for the assessment of transformer conditions. Diverse\nArtificial Intelligence (AI) approaches, including Artificial Neural Networks\n(ANN) and Convolutional Neural Network (CNN), Support Vector Machine (SVM),\nRandom Forest (RF), Genetic Algorithm (GA), and Particle Swarm Optimization\n(PSO), are elucidated offering pragmatic solutions for enhancing the\nperformance of transformer fault diagnosis. The amalgamation of multiple AI\nmethodologies and the exploration of timeseries analysis further contribute to\nthe augmentation of diagnostic precision and the early detection of faults in\ntransformers. By furnishing a comprehensive panorama of AI applications in the\nfield of transformer fault diagnosis, this study lays the groundwork for future\nresearch endeavors and the progression of this critical area of study."}
{"id": "2504.15611", "pdf": "https://arxiv.org/pdf/2504.15611", "abs": "https://arxiv.org/abs/2504.15611", "authors": ["Yaoze Liu", "Zhen Tian", "Qifan Zhou", "Zixuan Huang", "Hongyu Sun"], "title": "An ACO-MPC Framework for Energy-Efficient and Collision-Free Path Planning in Autonomous Maritime Navigation", "categories": ["eess.SY", "cs.RO", "cs.SY"], "comment": "This paper has been accepted by the 2025 8th International Conference\n  on Advanced Algorithms and Control Engineering (ICAACE 2025)", "summary": "Automated driving on ramps presents significant challenges due to the need to\nbalance both safety and efficiency during lane changes. This paper proposes an\nintegrated planner for automated vehicles (AVs) on ramps, utilizing an\nunsatisfactory level metric for efficiency and arrow-cluster-based sampling for\nsafety. The planner identifies optimal times for the AV to change lanes, taking\ninto account the vehicle's velocity as a key factor in efficiency.\nAdditionally, the integrated planner employs arrow-cluster-based sampling to\nevaluate collision risks and select an optimal lane-changing curve. Extensive\nsimulations were conducted in a ramp scenario to verify the planner's efficient\nand safe performance. The results demonstrate that the proposed planner can\neffectively select an appropriate lane-changing time point and a safe\nlane-changing curve for AVs, without incurring any collisions during the\nmaneuver."}
{"id": "2504.15360", "pdf": "https://arxiv.org/pdf/2504.15360", "abs": "https://arxiv.org/abs/2504.15360", "authors": ["Javier Fumanal-Idocin", "Javier Andreu-Perez"], "title": "Reliable Classification with Conformal Learning and Interval-Type 2 Fuzzy Sets", "categories": ["cs.AI"], "comment": null, "summary": "Classical machine learning classifiers tend to be overconfident can be\nunreliable outside of the laboratory benchmarks. Properly assessing the\nreliability of the output of the model per sample is instrumental for real-life\nscenarios where these systems are deployed. Because of this, different\ntechniques have been employed to properly quantify the quality of prediction\nfor a given model. These are most commonly Bayesian statistics and, more\nrecently, conformal learning. Given a calibration set, conformal learning can\nproduce outputs that are guaranteed to cover the target class with a desired\nsignificance level, and are more reliable than the standard confidence\nintervals used by Bayesian methods. In this work, we propose to use conformal\nlearning with fuzzy rule-based systems in classification and show some metrics\nof their performance. Then, we discuss how the use of type 2 fuzzy sets can\nimprove the quality of the output of the system compared to both fuzzy and\ncrisp rules. Finally, we also discuss how the fine-tuning of the system can be\nadapted to improve the quality of the conformal prediction."}
{"id": "2504.15312", "pdf": "https://arxiv.org/pdf/2504.15312", "abs": "https://arxiv.org/abs/2504.15312", "authors": ["Muhammad Mursil", "Hatem A. Rashwan", "Luis Santos-Calderon", "Pere Cavalle-Busquets", "Michelle M. Murphy", "Domenec Puig"], "title": "M-TabNet: A Multi-Encoder Transformer Model for Predicting Neonatal Birth Weight from Multimodal Data", "categories": ["cs.LG"], "comment": null, "summary": "Birth weight (BW) is a key indicator of neonatal health, with low birth\nweight (LBW) linked to increased mortality and morbidity. Early prediction of\nBW enables timely interventions; however, current methods like ultrasonography\nhave limitations, including reduced accuracy before 20 weeks and operator\ndependent variability. Existing models often neglect nutritional and genetic\ninfluences, focusing mainly on physiological and lifestyle factors. This study\npresents an attention-based transformer model with a multi-encoder architecture\nfor early (less than 12 weeks of gestation) BW prediction. Our model\neffectively integrates diverse maternal data such as physiological, lifestyle,\nnutritional, and genetic, addressing limitations seen in prior attention-based\nmodels such as TabNet. The model achieves a Mean Absolute Error (MAE) of 122\ngrams and an R-squared value of 0.94, demonstrating high predictive accuracy\nand interoperability with our in-house private dataset. Independent validation\nconfirms generalizability (MAE: 105 grams, R-squared: 0.95) with the IEEE\nchildren dataset. To enhance clinical utility, predicted BW is classified into\nlow and normal categories, achieving a sensitivity of 97.55% and a specificity\nof 94.48%, facilitating early risk stratification. Model interpretability is\nreinforced through feature importance and SHAP analyses, highlighting\nsignificant influences of maternal age, tobacco exposure, and vitamin B12\nstatus, with genetic factors playing a secondary role. Our results emphasize\nthe potential of advanced deep-learning models to improve early BW prediction,\noffering clinicians a robust, interpretable, and personalized tool for\nidentifying pregnancies at risk and optimizing neonatal outcomes."}
{"id": "2504.15704", "pdf": "https://arxiv.org/pdf/2504.15704", "abs": "https://arxiv.org/abs/2504.15704", "authors": ["Mazen Alamir"], "title": "On relaxing the N-Reachability Implicit Requirement in NMPC Design", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "This paper proposes a proof of stability for Model Predictive Control\nformulations involving a prediction horizon that might be too short to meet the\nreachability condition generally invoked as a sufficient condition for\nclosed-loop stability. This condition is replaced by a contraction condition on\nthe stage cost. But unlike the contraction based existing formulations where\nthe prediction horizon becomes a decision variable, the formulation proposed in\nthis paper remains standard in that it uses constant and short prediction\nhorizon. An illustrative example is provided to assess the relevance of the\nproposed formulation."}
{"id": "2504.15364", "pdf": "https://arxiv.org/pdf/2504.15364", "abs": "https://arxiv.org/abs/2504.15364", "authors": ["Junyoung Park", "Dalton Jones", "Matt Morse", "Raghavv Goel", "Mingu Lee", "Chris Lott"], "title": "KeDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments", "categories": ["cs.AI"], "comment": "8 pages, 14 figures", "summary": "In this work, we demonstrate that distinctive keys during LLM inference tend\nto have high attention scores. We explore this phenomenon and propose KeyDiff,\na training-free KV cache eviction method based on key similarity. This method\nfacilitates the deployment of LLM-based application requiring long input\nprompts in resource-constrained environments with limited memory and compute\nbudgets. Unlike other KV cache eviction methods, KeyDiff can process\narbitrarily long prompts within strict resource constraints and efficiently\ngenerate responses. We demonstrate that KeyDiff computes the optimal solution\nto a KV cache selection problem that maximizes key diversity, providing a\ntheoretical understanding of KeyDiff. Notably,KeyDiff does not rely on\nattention scores, allowing the use of optimized attention mechanisms like\nFlashAttention. We demonstrate the effectiveness of KeyDiff across diverse\ntasks and models, illustrating a performance gap of less than 0.04\\% with 8K\ncache budget ($\\sim$ 23\\% KV cache reduction) from the non-evicting baseline on\nthe LongBench benchmark for Llama 3.1-8B and Llama 3.2-3B."}
{"id": "2504.15315", "pdf": "https://arxiv.org/pdf/2504.15315", "abs": "https://arxiv.org/abs/2504.15315", "authors": ["Noa Cohen", "Rotem Dror", "Itzik Klein"], "title": "Diffusion-Driven Inertial Generated Data for Smartphone Location Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite the crucial role of inertial measurements in motion tracking and\nnavigation systems, the time-consuming and resource-intensive nature of\ncollecting extensive inertial data has hindered the development of robust\nmachine learning models in this field. In recent years, diffusion models have\nemerged as a revolutionary class of generative models, reshaping the landscape\nof artificial data generation. These models surpass generative adversarial\nnetworks and other state-of-the-art approaches to complex tasks. In this work,\nwe propose diffusion-driven specific force-generated data for smartphone\nlocation recognition. We provide a comprehensive evaluation methodology by\ncomparing synthetic and real recorded specific force data across multiple\nmetrics. Our results demonstrate that our diffusion-based generative model\nsuccessfully captures the distinctive characteristics of specific force signals\nacross different smartphone placement conditions. Thus, by creating diverse,\nrealistic synthetic data, we can reduce the burden of extensive data collection\nwhile providing high-quality training data for machine learning models."}
{"id": "2504.15768", "pdf": "https://arxiv.org/pdf/2504.15768", "abs": "https://arxiv.org/abs/2504.15768", "authors": ["Xiaoyu Liu", "Dimos V. Dimarogonas", "Changxin Liu", "Azita Dabiri", "Bart De Schutter"], "title": "Distributed model predictive control without terminal cost under inexact distributed optimization", "categories": ["eess.SY", "cs.SY"], "comment": "9 pages, 3 figures, submitted to Automatica", "summary": "This paper presents a novel distributed model predictive control (MPC)\nformulation without terminal cost and a corresponding distributed synthesis\napproach for distributed linear discrete-time systems with coupled constraints.\nThe proposed control scheme introduces an explicit stability condition as an\nadditional constraint based on relaxed dynamic programming. As a result,\ncontrary to other related approaches, system stability with the developed\ncontroller does not rely on designing a terminal cost. A distributed synthesis\napproach is then introduced to handle the stability constraint locally within\neach local agent. To solve the underlying optimization problem for distributed\nMPC, a violation-free distributed optimization approach is developed, using\nconstraint tightening to ensure feasibility throughout iterations. A numerical\nexample demonstrates that the proposed distributed MPC approach ensures\nclosed-loop stability for each feasible control sequence, with each agent\ncomputing its control input in parallel."}
{"id": "2504.15434", "pdf": "https://arxiv.org/pdf/2504.15434", "abs": "https://arxiv.org/abs/2504.15434", "authors": ["Sarath Shekkizhar", "Romain Cosentino"], "title": "AGI Is Coming... Right After AI Learns to Play Wordle", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "This paper investigates multimodal agents, in particular, OpenAI's\nComputer-User Agent (CUA), trained to control and complete tasks through a\nstandard computer interface, similar to humans. We evaluated the agent's\nperformance on the New York Times Wordle game to elicit model behaviors and\nidentify shortcomings. Our findings revealed a significant discrepancy in the\nmodel's ability to recognize colors correctly depending on the context. The\nmodel had a $5.36\\%$ success rate over several hundred runs across a week of\nWordle. Despite the immense enthusiasm surrounding AI agents and their\npotential to usher in Artificial General Intelligence (AGI), our findings\nreinforce the fact that even simple tasks present substantial challenges for\ntoday's frontier AI models. We conclude with a discussion of the potential\nunderlying causes, implications for future development, and research directions\nto improve these AI systems."}
{"id": "2504.15322", "pdf": "https://arxiv.org/pdf/2504.15322", "abs": "https://arxiv.org/abs/2504.15322", "authors": ["Xiao Zhou", "Yuze Sun", "Jie Wu", "Xiaomeng Huang"], "title": "How to systematically develop an effective AI-based bias correction model?", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": null, "summary": "This study introduces ReSA-ConvLSTM, an artificial intelligence (AI)\nframework for systematic bias correction in numerical weather prediction (NWP).\nWe propose three innovations by integrating dynamic climatological\nnormalization, ConvLSTM with temporal causality constraints, and residual\nself-attention mechanisms. The model establishes a physics-aware nonlinear\nmapping between ECMWF forecasts and ERA5 reanalysis data. Using 41 years\n(1981-2021) of global atmospheric data, the framework reduces systematic biases\nin 2-m air temperature (T2m), 10-m winds (U10/V10), and sea-level pressure\n(SLP), achieving up to 20% RMSE reduction over 1-7 day forecasts compared to\noperational ECMWF outputs. The lightweight architecture (10.6M parameters)\nenables efficient generalization to multiple variables and downstream\napplications, reducing retraining time by 85% for cross-variable correction\nwhile improving ocean model skill through bias-corrected boundary conditions.\nThe ablation experiments demonstrate that our innovations significantly improve\nthe model's correction performance, suggesting that incorporating variable\ncharacteristics into the model helps enhance forecasting skills."}
{"id": "2504.15793", "pdf": "https://arxiv.org/pdf/2504.15793", "abs": "https://arxiv.org/abs/2504.15793", "authors": ["Can Wan", "Biao Li", "Xuejun Hu", "Yunyi Li", "Ping Ju"], "title": "A Point-Hyperplane Geometry Method for Operational Security Region of Renewable Energy Generation in Power Systems", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "The rapid growth of renewable energy generation challenges the secure\noperation of power systems. It becomes crucial to quantify the critical\nsecurity boundaries and hosting capability of renewable generation at the\nsystem operation level. This paper proposes a novel point-hyperplane geometry\n(PHG) method to accurately obtain the geometric expression of the operational\nsecurity region of renewable energy generation for power systems. Firstly, the\ngeometric expression of the operational security region is defined as a\npolytope of boundary hyperplanes in the form of inequalities satisfying the\nsystem operation constraints. Then, an orthogonal basis generation method is\nproposed to solve a single boundary hyperplane of the polytope based on\nintersecting and orthogonal geometric principles. Next, a point-hyperplane\niteration algorithm is developed to progressively obtain the overall geometric\npolytope of the operational security region of renewable energy generation in\npower systems. Besides, the flexible performance trade-off can be achieved by\nmodifying the proposed maximum tolerated angle between adjacent hyperplanes.\nFinally, comprehensive case studies verify the effectiveness and superiority of\nthe PHG method."}
{"id": "2504.15457", "pdf": "https://arxiv.org/pdf/2504.15457", "abs": "https://arxiv.org/abs/2504.15457", "authors": ["Paresh Chaudhary", "Yancheng Liang", "Daphne Chen", "Simon S. Du", "Natasha Jaques"], "title": "Improving Human-AI Coordination through Adversarial Training and Generative Models", "categories": ["cs.AI"], "comment": null, "summary": "Being able to cooperate with new people is an important component of many\neconomically valuable AI tasks, from household robotics to autonomous driving.\nHowever, generalizing to novel humans requires training on data that captures\nthe diversity of human behaviors. Adversarial training is one avenue for\nsearching for such data and ensuring that agents are robust. However, it is\ndifficult to apply in the cooperative setting because adversarial policies\nintentionally learn to sabotage the task instead of simulating valid\ncooperation partners. To address this challenge, we propose a novel strategy\nfor overcoming self-sabotage that combines a pre-trained generative model to\nsimulate valid cooperative agent policies with adversarial training to maximize\nregret. We call our method GOAT: Generative Online Adversarial Training. In\nthis framework, the GOAT dynamically searches for and generates coordination\nstrategies where the learning policy -- the Cooperator agent -- underperforms.\nGOAT enables better generalization by exposing the Cooperator to various\nchallenging interaction scenarios. We maintain realistic coordination\nstrategies by updating only the generative model's embedding while keeping its\nparameters frozen, thus avoiding adversarial exploitation. We evaluate GOAT\nwith real human partners, and the results demonstrate state-of-the-art\nperformance on the Overcooked benchmark, highlighting its effectiveness in\ngeneralizing to diverse human behaviors."}
{"id": "2504.15323", "pdf": "https://arxiv.org/pdf/2504.15323", "abs": "https://arxiv.org/abs/2504.15323", "authors": ["Donggyun Kim", "Chanwoo Kim", "Seunghoon Hong"], "title": "HyperFlow: Gradient-Free Emulation of Few-Shot Fine-Tuning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "While test-time fine-tuning is beneficial in few-shot learning, the need for\nmultiple backpropagation steps can be prohibitively expensive in real-time or\nlow-resource scenarios. To address this limitation, we propose an approach that\nemulates gradient descent without computing gradients, enabling efficient\ntest-time adaptation. Specifically, we formulate gradient descent as an Euler\ndiscretization of an ordinary differential equation (ODE) and train an\nauxiliary network to predict the task-conditional drift using only the few-shot\nsupport set. The adaptation then reduces to a simple numerical integration\n(e.g., via the Euler method), which requires only a few forward passes of the\nauxiliary network -- no gradients or forward passes of the target model are\nneeded. In experiments on cross-domain few-shot classification using the\nMeta-Dataset and CDFSL benchmarks, our method significantly improves\nout-of-domain performance over the non-fine-tuned baseline while incurring only\n6\\% of the memory cost and 0.02\\% of the computation time of standard\nfine-tuning, thus establishing a practical middle ground between direct\ntransfer and fully fine-tuned approaches."}
{"id": "2504.15803", "pdf": "https://arxiv.org/pdf/2504.15803", "abs": "https://arxiv.org/abs/2504.15803", "authors": ["Kushal P. Singh", "Aditya K. Rao", "Twinkle Tripathy"], "title": "Finite time max-consensus for simultaneous target interception in switching graph topologies", "categories": ["eess.SY", "cs.SY"], "comment": "11 pages, 10 figures, Paper accepted for publication in IEEE\n  Transactions on Control of Network Systems", "summary": "In this paper, we propose a distributed guidance law for the simultaneous\ninterception of a stationary target. For a group of `n' heterogeneous pursuers,\nthe proposed guidance law establishes the necessary conditions on static graphs\nthat ensure simultaneous target interception, regardless of the initial\nconditions of the pursuers. Building on these results, we also establish the\nnecessary conditions for achieving simultaneous interception in switching graph\ntopologies as well. The major highlight of the work is that the target\ninterception occurs in finite time for both static and switching graph\ntopologies. We demonstrate all of these results through numerical simulations."}
{"id": "2504.15466", "pdf": "https://arxiv.org/pdf/2504.15466", "abs": "https://arxiv.org/abs/2504.15466", "authors": ["Jiayi Pan", "Xiuyu Li", "Long Lian", "Charlie Snell", "Yifei Zhou", "Adam Yala", "Trevor Darrell", "Kurt Keutzer", "Alane Suhr"], "title": "Learning Adaptive Parallel Reasoning with Language Models", "categories": ["cs.AI", "cs.CL"], "comment": "Code, model, and data are available at\n  https://github.com/Parallel-Reasoning/APR. The first three authors\n  contributed equally to this work", "summary": "Scaling inference-time computation has substantially improved the reasoning\ncapabilities of language models. However, existing methods have significant\nlimitations: serialized chain-of-thought approaches generate overly long\noutputs, leading to increased latency and exhausted context windows, while\nparallel methods such as self-consistency suffer from insufficient\ncoordination, resulting in redundant computations and limited performance\ngains. To address these shortcomings, we propose Adaptive Parallel Reasoning\n(APR), a novel reasoning framework that enables language models to orchestrate\nboth serialized and parallel computations end-to-end. APR generalizes existing\nreasoning methods by enabling adaptive multi-threaded inference using spawn()\nand join() operations. A key innovation is our end-to-end reinforcement\nlearning strategy, optimizing both parent and child inference threads to\nenhance task success rate without requiring predefined reasoning structures.\nExperiments on the Countdown reasoning task demonstrate significant benefits of\nAPR: (1) higher performance within the same context window (83.4% vs. 60.0% at\n4k context); (2) superior scalability with increased computation (80.1% vs.\n66.6% at 20k total tokens); (3) improved accuracy at equivalent latency (75.2%\nvs. 57.3% at approximately 5,000ms). APR represents a step towards enabling\nlanguage models to autonomously optimize their reasoning processes through\nadaptive allocation of computation."}
{"id": "2504.15325", "pdf": "https://arxiv.org/pdf/2504.15325", "abs": "https://arxiv.org/abs/2504.15325", "authors": ["Alberto Casagrande", "Francesco Fabris", "Rossano Girometti", "Roberto Pagliarini"], "title": "Significativity Indices for Agreement Values", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "27 pages, 6 figures", "summary": "Agreement measures, such as Cohen's kappa or intraclass correlation, gauge\nthe matching between two or more classifiers. They are used in a wide range of\ncontexts from medicine, where they evaluate the effectiveness of medical\ntreatments and clinical trials, to artificial intelligence, where they can\nquantify the approximation due to the reduction of a classifier. The\nconsistency of different classifiers to a golden standard can be compared\nsimply by using the order induced by their agreement measure with respect to\nthe golden standard itself. Nevertheless, labelling an approach as good or bad\nexclusively by using the value of an agreement measure requires a scale or a\nsignificativity index. Some quality scales have been proposed in the literature\nfor Cohen's kappa, but they are mainly naive, and their boundaries are\narbitrary. This work proposes a general approach to evaluate the\nsignificativity of any agreement value between two classifiers and introduces\ntwo significativity indices: one dealing with finite data sets, the other one\nhandling classification probability distributions. Moreover, this manuscript\nconsiders the computational issues of evaluating such indices and identifies\nsome efficient algorithms to evaluate them."}
{"id": "2504.15805", "pdf": "https://arxiv.org/pdf/2504.15805", "abs": "https://arxiv.org/abs/2504.15805", "authors": ["Hongyu Zhou", "Vasileios Tzoumas"], "title": "No-Regret Model Predictive Control with Online Learning of Koopman Operators", "categories": ["eess.SY", "cs.SY"], "comment": "ACC 2025", "summary": "We study a problem of simultaneous system identification and model predictive\ncontrol of nonlinear systems. Particularly, we provide an algorithm for systems\nwith unknown residual dynamics that can be expressed by Koopman operators. Such\nresidual dynamics can model external disturbances and modeling errors, such as\nwind and wave disturbances to aerial and marine vehicles, or inaccurate model\nparameters. The algorithm has finite-time near-optimality guarantees and\nasymptotically converges to the optimal non-causal controller. Specifically,\nthe algorithm enjoys sublinear \\textit{dynamic regret}, defined herein as the\nsuboptimality against an optimal clairvoyant controller that knows how the\nunknown dynamics will adapt to its states and actions. To this end, we assume\nthe algorithm is given Koopman observable functions such that the unknown\ndynamics can be approximated by a linear dynamical system. Then, it employs\nmodel predictive control based on the current learned model of the unknown\nresidual dynamics. This model is updated online using least squares in a\nself-supervised manner based on the data collected while controlling the\nsystem. We validate our algorithm in physics-based simulations of a cart-pole\nsystem aiming to maintain the pole upright despite inaccurate model parameters."}
{"id": "2504.15552", "pdf": "https://arxiv.org/pdf/2504.15552", "abs": "https://arxiv.org/abs/2504.15552", "authors": ["Gengxian Cao", "Fengyuan Li", "Hong Duan", "Ye Yang", "Bofeng Wang", "Donghe Li"], "title": "A Multi-Agent Framework for Automated Qinqiang Opera Script Generation Using Large Language Models", "categories": ["cs.AI"], "comment": "17 pages,7 figures,1 tables", "summary": "This paper introduces a novel multi-Agent framework that automates the end to\nend production of Qinqiang opera by integrating Large Language Models , visual\ngeneration, and Text to Speech synthesis. Three specialized agents collaborate\nin sequence: Agent1 uses an LLM to craft coherent, culturally grounded\nscripts;Agent2 employs visual generation models to render contextually accurate\nstage scenes; and Agent3 leverages TTS to produce synchronized, emotionally\nexpressive vocal performances. In a case study on Dou E Yuan, the system\nachieved expert ratings of 3.8 for script fidelity, 3.5 for visual coherence,\nand 3.8 for speech accuracy-culminating in an overall score of 3.6, a 0.3 point\nimprovement over a Single Agent baseline. Ablation experiments demonstrate that\nremoving Agent2 or Agent3 leads to drops of 0.4 and 0.5 points, respectively,\nunderscoring the value of modular collaboration. This work showcases how AI\ndriven pipelines can streamline and scale the preservation of traditional\nperforming arts, and points toward future enhancements in cross modal\nalignment, richer emotional nuance, and support for additional opera genres."}
{"id": "2504.15328", "pdf": "https://arxiv.org/pdf/2504.15328", "abs": "https://arxiv.org/abs/2504.15328", "authors": ["Usevalad Milasheuski", "Luca Barbieri", "Sanaz Kianoush", "Monica Nicoli", "Stefano Savazzi"], "title": "Bayesian Federated Learning for Continual Training", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Bayesian Federated Learning (BFL) enables uncertainty quantification and\nrobust adaptation in distributed learning. In contrast to the frequentist\napproach, it estimates the posterior distribution of a global model, offering\ninsights into model reliability. However, current BFL methods neglect continual\nlearning challenges in dynamic environments where data distributions shift over\ntime. We propose a continual BFL framework applied to human sensing with radar\ndata collected over several days. Using Stochastic Gradient Langevin Dynamics\n(SGLD), our approach sequentially updates the model, leveraging past posteriors\nto construct the prior for the new tasks. We assess the accuracy, the expected\ncalibration error (ECE) and the convergence speed of our approach against\nseveral baselines. Results highlight the effectiveness of continual Bayesian\nupdates in preserving knowledge and adapting to evolving data."}
{"id": "2504.15830", "pdf": "https://arxiv.org/pdf/2504.15830", "abs": "https://arxiv.org/abs/2504.15830", "authors": ["Adrian Wiltz", "Dimos V. Dimarogonas"], "title": "Predictive Synthesis of Control Barrier Functions and its Application to Time-Varying Constraints", "categories": ["eess.SY", "cs.SY", "math.OC"], "comment": "16 pages, 8 figures", "summary": "This paper presents a systematic method for synthesizing a Control Barrier\nFunction (CBF) that encodes predictive information into a CBF. Unlike other\nmethods, the synthesized CBF can account for changes and time-variations in the\nconstraints even when constructed for time-invariant constraints. This avoids\nrecomputing the CBF when the constraint specifications change. The method\nprovides an explicit characterization of the extended class K function {\\alpha}\nthat determines the dynamic properties of the CBF, and {\\alpha} can even be\nexplicitly chosen as a design parameter in the controller synthesis. The\nresulting CBF further accounts for input constraints, and its values can be\ndetermined at any point without having to compute the CBF over the entire\ndomain. The synthesis method is based on a finite horizon optimal control\nproblem inspired by Hamilton-Jacobi reachability analysis and does not rely on\na nominal control law. The synthesized CBF is time-invariant if the constraints\nare. The method poses mild assumptions on the controllability of the dynamic\nsystem and assumes the knowledge of at least a subset of some control invariant\nset. The paper provides a detailed analysis of the properties of the\nsynthesized CBF, including its application to time-varying constraints. A\nsimulation study applies the proposed approach to various dynamic systems in\nthe presence of time-varying constraints. The paper is accompanied by an online\navailable parallelized implementation of the proposed synthesis method."}
{"id": "2504.15610", "pdf": "https://arxiv.org/pdf/2504.15610", "abs": "https://arxiv.org/abs/2504.15610", "authors": ["Md Millat", "Md Motiur"], "title": "A LoRA-Based Approach to Fine-Tuning LLMs for Educational Guidance in Resource-Constrained Settings", "categories": ["cs.AI", "68T05 (Learning and adaptive systems), 68T07 (Artificial\n  intelligence and education)"], "comment": "18 pages, 6 figures (3 graphs + 3 flowchart/architecture diagrams),\n  submitted as a preprint for review consideration in AI for Education or\n  Machine Learning applications in low-resource settings. Includes detailed\n  experiments with LoRA and quantization methods for efficient LLM fine-tuning", "summary": "The current study describes a cost-effective method for adapting large\nlanguage models (LLMs) for academic advising with study-abroad contexts in mind\nand for application in low-resource methods for acculturation. With the\nMistral-7B-Instruct model applied with a Low-Rank Adaptation (LoRA) method and\na 4-bit quantization method, the model underwent training in two distinct\nstages related to this study's purpose to enhance domain specificity while\nmaintaining computational efficiency. In Phase 1, the model was conditioned\nwith a synthetic dataset via the Gemini Pro API, and in Phase 2, it was trained\nwith manually curated datasets from the StudyAbroadGPT project to achieve\nenhanced, contextualized responses. Technical innovations entailed\nmemory-efficient quantization, parameter-efficient adaptation, and continuous\ntraining analytics via Weights & Biases. After training, this study\ndemonstrated a reduction in training loss by 52.7%, 92% accuracy in\ndomain-specific recommendations, achieved 95% markdown-based formatting\nsupport, and a median run-rate of 100 samples per second on off-the-shelf GPU\nequipment. These findings support the effective application of\ninstruction-tuned LLMs within educational advisers, especially in low-resource\ninstitutional scenarios. Limitations included decreased generalizability and\nthe application of a synthetically generated dataset, but this framework is\nscalable for adding new multilingual-augmented and real-time academic advising\nprocesses. Future directions may include plans for the integration of\nretrieval-augmented generation, applying dynamic quantization routines, and\nconnecting to real-time academic databases to increase adaptability and\naccuracy."}
{"id": "2504.15366", "pdf": "https://arxiv.org/pdf/2504.15366", "abs": "https://arxiv.org/abs/2504.15366", "authors": ["Qifan Yan", "Andrew Liu", "Shiqi He", "Mathias Lécuyer", "Ivan Beschastnikh"], "title": "FedFetch: Faster Federated Learning with Adaptive Downstream Prefetching", "categories": ["cs.LG", "cs.DC"], "comment": "Accepted at INFOCOM 2025", "summary": "Federated learning (FL) is a machine learning paradigm that facilitates\nmassively distributed model training with end-user data on edge devices\ndirected by a central server. However, the large number of heterogeneous\nclients in FL deployments leads to a communication bottleneck between the\nserver and the clients. This bottleneck is made worse by straggling clients,\nany one of which will further slow down training. To tackle these challenges,\nresearchers have proposed techniques like client sampling and update\ncompression. These techniques work well in isolation but combine poorly in the\ndownstream, server-to-client direction. This is because unselected clients have\noutdated local model states and need to synchronize these states with the\nserver first.\n  We introduce FedFetch, a strategy to mitigate the download time overhead\ncaused by combining client sampling and compression techniques. FedFetch\nachieves this with an efficient prefetch schedule for clients to prefetch model\nstates multiple rounds before a stated training round. We empirically show that\nadding FedFetch to communication efficient FL techniques reduces end-to-end\ntraining time by 1.26$\\times$ and download time by 4.49$\\times$ across\ncompression techniques with heterogeneous client settings. Our implementation\nis available at https://github.com/DistributedML/FedFetch"}
{"id": "2504.15838", "pdf": "https://arxiv.org/pdf/2504.15838", "abs": "https://arxiv.org/abs/2504.15838", "authors": ["András Sasfi", "Ivan Markovsky", "Alberto Padoan", "Florian Dörfler"], "title": "Gaussian behaviors: representations and data-driven control", "categories": ["eess.SY", "cs.SY", "math.OC"], "comment": null, "summary": "We propose a modeling framework for stochastic systems based on Gaussian\nprocesses. Finite-length trajectories of the system are modeled as random\nvectors from a Gaussian distribution, which we call a Gaussian behavior. The\nproposed model naturally quantifies the uncertainty in the trajectories, yet it\nis simple enough to allow for tractable formulations. We relate the proposed\nmodel to existing descriptions of dynamical systems including deterministic and\nstochastic behaviors, and linear time-invariant (LTI) state-space models with\nGaussian process and measurement noise. Gaussian behaviors can be estimated\ndirectly from observed data as the empirical sample covariance under the\nassumption that the measured trajectories are from independent experiments. The\ndistribution of future outputs conditioned on inputs and past outputs provides\na predictive model that can be incorporated in predictive control frameworks.\nWe show that subspace predictive control (SPC) is a certainty-equivalence\ncontrol formulation with the estimated Gaussian behavior. Furthermore, the\nregularized data-enabled predictive control (DeePC) method is shown to be a\ndistributionally optimistic formulation that optimistically accounts for\nuncertainty in the Gaussian behavior. To mitigate the excessive optimism of\nDeePC, we propose a novel distributionally robust control formulation, and\nprovide a convex reformulation allowing for efficient implementation."}
{"id": "2504.15668", "pdf": "https://arxiv.org/pdf/2504.15668", "abs": "https://arxiv.org/abs/2504.15668", "authors": ["Mir Md Sajid Sarwar", "Rajarshi Ray"], "title": "Exploring Inevitable Waypoints for Unsolvability Explanation in Hybrid Planning Problems", "categories": ["cs.AI", "cs.FL", "I.2.0; F.4.3"], "comment": null, "summary": "Explaining unsolvability of planning problems is of significant research\ninterest in Explainable AI Planning. AI planning literature has reported\nseveral research efforts on generating explanations of solutions to planning\nproblems. However, explaining the unsolvability of planning problems remains a\nlargely open and understudied problem. A widely practiced approach to plan\ngeneration and automated problem solving, in general, is to decompose tasks\ninto sub-problems that help progressively converge towards the goal. In this\npaper, we propose to adopt the same philosophy of sub-problem identification as\na mechanism for analyzing and explaining unsolvability of planning problems in\nhybrid systems. In particular, for a given unsolvable planning problem, we\npropose to identify common waypoints, which are universal obstacles to plan\nexistence; in other words, they appear on every plan from the source to the\nplanning goal. This work envisions such waypoints as sub-problems of the\nplanning problem and the unreachability of any of these waypoints as an\nexplanation for the unsolvability of the original planning problem. We propose\na novel method of waypoint identification by casting the problem as an instance\nof the longest common subsequence problem, a widely popular problem in computer\nscience, typically considered as an illustrative example for the dynamic\nprogramming paradigm. Once the waypoints are identified, we perform symbolic\nreachability analysis on them to identify the earliest unreachable waypoint and\nreport it as the explanation of unsolvability. We present experimental results\non unsolvable planning problems in hybrid domains."}
{"id": "2504.15369", "pdf": "https://arxiv.org/pdf/2504.15369", "abs": "https://arxiv.org/abs/2504.15369", "authors": ["Calvin Luo", "Zilai Zeng", "Yilun Du", "Chen Sun"], "title": "Solving New Tasks by Adapting Internet Video Knowledge", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "ICLR 2025. Project Webpage:\n  https://diffusion-supervision.github.io/adapt2act/", "summary": "Video generative models demonstrate great promise in robotics by serving as\nvisual planners or as policy supervisors. When pretrained on internet-scale\ndata, such video models intimately understand alignment with natural language,\nand can thus facilitate generalization to novel downstream behavior through\ntext-conditioning. However, they may not be sensitive to the specificities of\nthe particular environment the agent inhabits. On the other hand, training\nvideo models on in-domain examples of robotic behavior naturally encodes\nenvironment-specific intricacies, but the scale of available demonstrations may\nnot be sufficient to support generalization to unseen tasks via natural\nlanguage specification. In this work, we investigate different adaptation\ntechniques that integrate in-domain information with large-scale pretrained\nvideo models, and explore the extent to which they enable novel\ntext-conditioned generalization for robotic tasks, while also considering their\nindependent data and resource considerations. We successfully demonstrate\nacross robotic environments that adapting powerful video models with small\nscales of example data can successfully facilitate generalization to novel\nbehaviors. In particular, we present a novel adaptation strategy, termed\nInverse Probabilistic Adaptation, that not only consistently achieves strong\ngeneralization performance across robotic tasks and settings, but also exhibits\nrobustness to the quality of adaptation data, successfully solving novel tasks\neven when only suboptimal in-domain demonstrations are available."}
{"id": "2504.15954", "pdf": "https://arxiv.org/pdf/2504.15954", "abs": "https://arxiv.org/abs/2504.15954", "authors": ["Tochukwu Elijah Ogri", "Muzaffar Qureshi", "Zachary I. Bell", "Matthew Longmire", "Rushikesh Kamalapurkar"], "title": "Monocular inspection of spacecraft under illumination constraints and avoidance regions", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "This paper presents an adaptive control approach to information-based\nguidance and control of a spacecraft carrying out on-orbit inspection by\nactively computing optimal policies for the spacecraft to achieve the best\npossible representation of objects within its orbital environment. Due to the\ncomplexity of navigating the space environment, it may be impossible to carry\nout on-orbit servicing to maintain space systems like satellites using a\nspacecraft equipped with controllers that cannot adapt to changing conditions.\nIn particular, the presence of constraints such as illumination, field-of-view\n(FOV), minimal fuel, the use of visual-inertial navigation for improved\nlocalization, and the need for real-time computation of control policies render\nthe spacecraft motion planning problem challenging. The control framework\ndeveloped in this paper addresses these challenges by formulating the\ninspection task as a constrained optimization problem where the goal is to\nmaximize information gained from the cameras, while navigating to the next best\nview, subject to illumination and FOV constraints. The developed architecture\nis analyzed using a Lyapunov-based stability analysis and the effectiveness of\nthe planning algorithm is verified in simulation."}
{"id": "2504.15699", "pdf": "https://arxiv.org/pdf/2504.15699", "abs": "https://arxiv.org/abs/2504.15699", "authors": ["Ning Wang", "Zihan Yan", "Weiyang Li", "Chuan Ma", "He Chen", "Tao Xiang"], "title": "Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation", "categories": ["cs.AI"], "comment": "9 pages", "summary": "Embodied agents exhibit immense potential across a multitude of domains,\nmaking the assurance of their behavioral safety a fundamental prerequisite for\ntheir widespread deployment. However, existing research predominantly\nconcentrates on the security of general large language models, lacking\nspecialized methodologies for establishing safety benchmarks and input\nmoderation tailored to embodied agents. To bridge this gap, this paper\nintroduces a novel input moderation framework, meticulously designed to\nsafeguard embodied agents. This framework encompasses the entire pipeline,\nincluding taxonomy definition, dataset curation, moderator architecture, model\ntraining, and rigorous evaluation. Notably, we introduce EAsafetyBench, a\nmeticulously crafted safety benchmark engineered to facilitate both the\ntraining and stringent assessment of moderators specifically designed for\nembodied agents. Furthermore, we propose Pinpoint, an innovative\nprompt-decoupled input moderation scheme that harnesses a masked attention\nmechanism to effectively isolate and mitigate the influence of functional\nprompts on moderation tasks. Extensive experiments conducted on diverse\nbenchmark datasets and models validate the feasibility and efficacy of the\nproposed approach. The results demonstrate that our methodologies achieve an\nimpressive average detection accuracy of 94.58%, surpassing the performance of\nexisting state-of-the-art techniques, alongside an exceptional moderation\nprocessing time of merely 0.002 seconds per instance."}
{"id": "2504.15399", "pdf": "https://arxiv.org/pdf/2504.15399", "abs": "https://arxiv.org/abs/2504.15399", "authors": ["Guy Zamir", "Aryan Dokania", "Bo Zhao", "Rose Yu"], "title": "Improving Learning to Optimize Using Parameter Symmetries", "categories": ["cs.LG"], "comment": "Accepted at the ICLR Workshop on Neural Network Weights as a New Data\n  Modality 2025", "summary": "We analyze a learning-to-optimize (L2O) algorithm that exploits parameter\nspace symmetry to enhance optimization efficiency. Prior work has shown that\njointly learning symmetry transformations and local updates improves\nmeta-optimizer performance. Supporting this, our theoretical analysis\ndemonstrates that even without identifying the optimal group element, the\nmethod locally resembles Newton's method. We further provide an example where\nthe algorithm provably learns the correct symmetry transformation during\ntraining. To empirically evaluate L2O with teleportation, we introduce a\nbenchmark, analyze its success and failure cases, and show that enhancements\nlike momentum further improve performance. Our results highlight the potential\nof leveraging neural network parameter space symmetry to advance\nmeta-optimization."}
{"id": "2504.16028", "pdf": "https://arxiv.org/pdf/2504.16028", "abs": "https://arxiv.org/abs/2504.16028", "authors": ["Tigran Bakaryan", "Christoph Aoun", "Ricardo de Lima Ribeiro", "Naira Hovakimyan", "Diogo Gomes"], "title": "Hessian Riemannian Flow For Multi-Population Wardrop Equilibrium", "categories": ["eess.SY", "cs.MA", "cs.SY", "math.OC"], "comment": null, "summary": "In this paper, we address the problem of optimizing flows on generalized\ngraphs that feature multiple entry points and multiple populations, each with\nvarying cost structures. We tackle this problem by considering the\nmulti-population Wardrop equilibrium, defined through variational inequalities.\nWe rigorously analyze the existence and uniqueness of the Wardrop equilibrium.\nFurthermore, we introduce an efficient numerical method to find the solution.\nIn particular, we reformulate the equilibrium problem as a distributed\noptimization problem over subgraphs and introduce a novel Hessian Riemannian\nflow method, a Riemannian-manifold-projected Hessian flow, to efficiently\ncompute a solution. Finally, we demonstrate the effectiveness of our approach\nthrough examples in urban traffic management, including routing for diverse\nvehicle types and strategies for minimizing emissions in congested\nenvironments."}
{"id": "2504.15716", "pdf": "https://arxiv.org/pdf/2504.15716", "abs": "https://arxiv.org/abs/2504.15716", "authors": ["Jie Zhu", "Qian Chen", "Huaixia Dou", "Junhui Li", "Lifan Guo", "Feng Chen", "Chi Zhang"], "title": "DianJin-R1: Evaluating and Enhancing Financial Reasoning in Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Effective reasoning remains a core challenge for large language models (LLMs)\nin the financial domain, where tasks often require domain-specific knowledge,\nprecise numerical calculations, and strict adherence to compliance rules. We\npropose DianJin-R1, a reasoning-enhanced framework designed to address these\nchallenges through reasoning-augmented supervision and reinforcement learning.\nCentral to our approach is DianJin-R1-Data, a high-quality dataset constructed\nfrom CFLUE, FinQA, and a proprietary compliance corpus (Chinese Compliance\nCheck, CCC), combining diverse financial reasoning scenarios with verified\nannotations. Our models, DianJin-R1-7B and DianJin-R1-32B, are fine-tuned from\nQwen2.5-7B-Instruct and Qwen2.5-32B-Instruct using a structured format that\ngenerates both reasoning steps and final answers. To further refine reasoning\nquality, we apply Group Relative Policy Optimization (GRPO), a reinforcement\nlearning method that incorporates dual reward signals: one encouraging\nstructured outputs and another rewarding answer correctness. We evaluate our\nmodels on five benchmarks: three financial datasets (CFLUE, FinQA, and CCC) and\ntwo general reasoning benchmarks (MATH-500 and GPQA-Diamond). Experimental\nresults show that DianJin-R1 models consistently outperform their non-reasoning\ncounterparts, especially on complex financial tasks. Moreover, on the\nreal-world CCC dataset, our single-call reasoning models match or even surpass\nthe performance of multi-agent systems that require significantly more\ncomputational cost. These findings demonstrate the effectiveness of DianJin-R1\nin enhancing financial reasoning through structured supervision and\nreward-aligned learning, offering a scalable and practical solution for\nreal-world applications."}
{"id": "2504.15439", "pdf": "https://arxiv.org/pdf/2504.15439", "abs": "https://arxiv.org/abs/2504.15439", "authors": ["Hao Zhuo", "Yicheng Yang", "Kewen Peng"], "title": "Combating Toxic Language: A Review of LLM-Based Strategies for Software Engineering", "categories": ["cs.LG", "cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) have become integral to software engineering\n(SE), where they are increasingly used in development workflows. However, their\nwidespread use raises concerns about the presence and propagation of toxic\nlanguage--harmful or offensive content that can foster exclusionary\nenvironments. This paper provides a comprehensive review of recent research on\ntoxicity detection and mitigation, focusing on both SE-specific and\ngeneral-purpose datasets. We examine annotation and preprocessing techniques,\nassess detection methodologies, and evaluate mitigation strategies,\nparticularly those leveraging LLMs. Additionally, we conduct an ablation study\ndemonstrating the effectiveness of LLM-based rewriting for reducing toxicity.\nBy synthesizing existing work and identifying open challenges, this review\nhighlights key areas for future research to ensure the responsible deployment\nof LLMs in SE and beyond."}
{"id": "2504.16048", "pdf": "https://arxiv.org/pdf/2504.16048", "abs": "https://arxiv.org/abs/2504.16048", "authors": ["Nicholas Julian Behr", "Mattia Bianchi", "Keith Moffat", "Saverio Bolognani", "Florian Dörfler"], "title": "PRIME: Fast Primal-Dual Feedback Optimization for Markets with Application to Optimal Power Flow", "categories": ["eess.SY", "cs.SY"], "comment": "Source code available at https://github.com/NicholasBehr/prime", "summary": "Online Feedback Optimization (OFO) controllers iteratively drive a plant to\nan optimal operating point that satisfies input and output constraints, relying\nsolely on the input-output sensitivity as model information. This paper\nintroduces PRIME (PRoximal Iterative MarkEts), a novel OFO approach based on\nproximal-point iterations. Unlike existing OFO solutions, PRIME admits a\nmarket-based implementation, where self-interested actors are incentivized to\nmake choices that result in a safe and efficient operation, without\ncommunicating private costs or constraints. Furthermore, PRIME can cope with\nnon-smooth objective functions, achieve fast convergence rates and rapid\nconstraint satisfaction, and reject measurement noise. We demonstrate PRIME on\nan AC optimal power flow problem, obtaining an efficient real-time nonlinear\nlocal marginal pricing scheme."}
{"id": "2504.15719", "pdf": "https://arxiv.org/pdf/2504.15719", "abs": "https://arxiv.org/abs/2504.15719", "authors": ["Anna Karnysheva", "Christian Drescher", "Dietrich Klakow"], "title": "Implementing Rational Choice Functions with LLMs and Measuring their Alignment with User Preferences", "categories": ["cs.AI"], "comment": null, "summary": "As large language models (LLMs) become integral to intelligent user\ninterfaces (IUIs), their role as decision-making agents raises critical\nconcerns about alignment. Although extensive research has addressed issues such\nas factuality, bias, and toxicity, comparatively little attention has been paid\nto measuring alignment to preferences, i.e., the relative desirability of\ndifferent alternatives, a concept used in decision making, economics, and\nsocial choice theory. However, a reliable decision-making agent makes choices\nthat align well with user preferences.\n  In this paper, we generalize existing methods that exploit LLMs for ranking\nalternative outcomes by addressing alignment with the broader and more flexible\nconcept of user preferences, which includes both strict preferences and\nindifference among alternatives. To this end, we put forward design principles\nfor using LLMs to implement rational choice functions, and provide the\nnecessary tools to measure preference satisfaction. We demonstrate the\napplicability of our approach through an empirical study in a practical\napplication of an IUI in the automotive domain."}
{"id": "2504.15458", "pdf": "https://arxiv.org/pdf/2504.15458", "abs": "https://arxiv.org/abs/2504.15458", "authors": ["Brandon Le", "Dustin Keller"], "title": "Compton Form Factor Extraction using Quantum Deep Neural Networks", "categories": ["cs.LG", "nucl-th", "quant-ph"], "comment": null, "summary": "Extraction tests of Compton Form Factors are performed using pseudodata based\non experimental data from Deeply Virtual Compton Scattering experiments\nconducted at Jefferson Lab. The standard Belitsky, Kirchner, and Muller\nformalism at twist-two is employed, along with a fitting procedure designed to\nreduce model dependency similar to traditional local fits. The extraction of\nthe Compton Form Factors is performed using both Classical Deep Neural Networks\n(CDNNs) and Quantum Deep Neural Networks (QDNNs). Comparative studies reveal\nthat QDNNs outperform CDNNs for this application, demonstrating improved\npredictive accuracy and precision even for limited model complexity. The\nresults demonstrate the potential of QDNNs for future studies in which quantum\nalgorithms can be fully optimized."}
{"id": "2504.15305", "pdf": "https://arxiv.org/pdf/2504.15305", "abs": "https://arxiv.org/abs/2504.15305", "authors": ["Abhishek Tyagi", "Charu Gaur"], "title": "SLAM-Based Navigation and Fault Resilience in a Surveillance Quadcopter with Embedded Vision Systems", "categories": ["cs.RO", "cs.CV", "cs.SY", "eess.SY", "68T40, 68U10, 70Q05", "I.2.9; I.4.8; I.2.10; C.3"], "comment": "18 pages, 21 figures, 4 tables. Onboard processing using Raspberry Pi\n  4 and Arduino Nano. Includes ORB-SLAM3-based navigation, LQR control, rotor\n  fault recovery, object detection, and PCA face recognition. Real-world and\n  simulation tests included. Designed for GPS-denied autonomous UAV\n  surveillance", "summary": "We present an autonomous aerial surveillance platform, Veg, designed as a\nfault-tolerant quadcopter system that integrates visual SLAM for\nGPS-independent navigation, advanced control architecture for dynamic\nstability, and embedded vision modules for real-time object and face\nrecognition. The platform features a cascaded control design with an LQR\ninner-loop and PD outer-loop trajectory control. It leverages ORB-SLAM3 for\n6-DoF localization and loop closure, and supports waypoint-based navigation\nthrough Dijkstra path planning over SLAM-derived maps. A real-time Failure\nDetection and Identification (FDI) system detects rotor faults and executes\nemergency landing through re-routing. The embedded vision system, based on a\nlightweight CNN and PCA, enables onboard object detection and face recognition\nwith high precision. The drone operates fully onboard using a Raspberry Pi 4\nand Arduino Nano, validated through simulations and real-world testing. This\nwork consolidates real-time localization, fault recovery, and embedded AI on a\nsingle platform suitable for constrained environments."}
{"id": "2504.15780", "pdf": "https://arxiv.org/pdf/2504.15780", "abs": "https://arxiv.org/abs/2504.15780", "authors": ["Daocheng Fu", "Zijun Chen", "Renqiu Xia", "Qi Liu", "Yuan Feng", "Hongbin Zhou", "Renrui Zhang", "Shiyang Feng", "Peng Gao", "Junchi Yan", "Botian Shi", "Bo Zhang", "Yu Qiao"], "title": "TrustGeoGen: Scalable and Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Mathematical geometric problem solving (GPS) often requires effective\nintegration of multimodal information and verifiable logical coherence. Despite\nthe fast development of large language models in general problem solving, it\nremains unresolved regarding with both methodology and benchmarks, especially\ngiven the fact that exiting synthetic GPS benchmarks are often not\nself-verified and contain noise and self-contradicted information due to the\nillusion of LLMs. In this paper, we propose a scalable data engine called\nTrustGeoGen for problem generation, with formal verification to provide a\nprincipled benchmark, which we believe lays the foundation for the further\ndevelopment of methods for GPS. The engine synthesizes geometric data through\nfour key innovations: 1) multimodal-aligned generation of diagrams, textual\ndescriptions, and stepwise solutions; 2) formal verification ensuring\nrule-compliant reasoning paths; 3) a bootstrapping mechanism enabling\ncomplexity escalation via recursive state generation and 4) our devised\nGeoExplore series algorithms simultaneously produce multi-solution variants and\nself-reflective backtracking traces. By formal logical verification,\nTrustGeoGen produces GeoTrust-200K dataset with guaranteed modality integrity,\nalong with GeoTrust-test testset. Experiments reveal the state-of-the-art\nmodels achieve only 49.17\\% accuracy on GeoTrust-test, demonstrating its\nevaluation stringency. Crucially, models trained on GeoTrust achieve OOD\ngeneralization on GeoQA, significantly reducing logical inconsistencies\nrelative to pseudo-label annotated by OpenAI-o1. Our code is available at\nhttps://github.com/Alpha-Innovator/TrustGeoGen"}
{"id": "2504.15477", "pdf": "https://arxiv.org/pdf/2504.15477", "abs": "https://arxiv.org/abs/2504.15477", "authors": ["Junda Wu", "Rohan Surana", "Zhouhang Xie", "Yiran Shen", "Yu Xia", "Tong Yu", "Ryan A. Rossi", "Prithviraj Ammanabrolu", "Julian McAuley"], "title": "In-context Ranking Preference Optimization", "categories": ["cs.LG"], "comment": "10 pages", "summary": "Recent developments in Direct Preference Optimization (DPO) allow large\nlanguage models (LLMs) to function as implicit ranking models by maximizing the\nmargin between preferred and non-preferred responses. In practice, user\nfeedback on such lists typically involves identifying a few relevant items in\ncontext rather than providing detailed pairwise comparisons for every possible\nitem pair. Moreover, many complex information retrieval tasks, such as\nconversational agents and summarization systems, critically depend on ranking\nthe highest-quality outputs at the top, emphasizing the need to support natural\nand flexible forms of user feedback. To address the challenge of limited and\nsparse pairwise feedback in the in-context setting, we propose an In-context\nRanking Preference Optimization (IRPO) framework that directly optimizes LLMs\nbased on ranking lists constructed during inference. To further capture\nflexible forms of feedback, IRPO extends the DPO objective by incorporating\nboth the relevance of items and their positions in the list. Modeling these\naspects jointly is non-trivial, as ranking metrics are inherently discrete and\nnon-differentiable, making direct optimization difficult. To overcome this,\nIRPO introduces a differentiable objective based on positional aggregation of\npairwise item preferences, enabling effective gradient-based optimization of\ndiscrete ranking metrics. We further provide theoretical insights showing that\nIRPO (i) automatically emphasizes items with greater disagreement between the\nmodel and the reference ranking, and (ii) links its gradient to an importance\nsampling estimator, yielding an unbiased estimator with reduced variance.\nEmpirical results show IRPO outperforms standard DPO approaches in ranking\nperformance, highlighting its effectiveness in aligning LLMs with direct\nin-context ranking preferences."}
{"id": "2504.15320", "pdf": "https://arxiv.org/pdf/2504.15320", "abs": "https://arxiv.org/abs/2504.15320", "authors": ["Qinghao Li", "Zhen Tian", "Xiaodan Wang", "Jinming Yang", "Zhihao Lin"], "title": "Efficient and Safe Planner for Automated Driving on Ramps Considering Unsatisfication", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "The 45th IEEE International Conference on Distributed Computing\n  Systems Workshop (ICDCSW) has accepted this paper\n  (https://icdcs2025.icdcs.org/accepted-papers/ In Conjunction Events/ Page 4/\n  Number 174)", "summary": "Automated driving on ramps presents significant challenges due to the need to\nbalance both safety and efficiency during lane changes. This paper proposes an\nintegrated planner for automated vehicles (AVs) on ramps, utilizing an\nunsatisfactory level metric for efficiency and arrow-cluster-based sampling for\nsafety. The planner identifies optimal times for the AV to change lanes, taking\ninto account the vehicle's velocity as a key factor in efficiency.\nAdditionally, the integrated planner employs arrow-cluster-based sampling to\nevaluate collision risks and select an optimal lane-changing curve. Extensive\nsimulations were conducted in a ramp scenario to verify the planner's efficient\nand safe performance. The results demonstrate that the proposed planner can\neffectively select an appropriate lane-changing time point and a safe\nlane-changing curve for AVs, without incurring any collisions during the\nmaneuver."}
{"id": "2504.15785", "pdf": "https://arxiv.org/pdf/2504.15785", "abs": "https://arxiv.org/abs/2504.15785", "authors": ["Siyu Zhou", "Tianyi Zhou", "Yijun Yang", "Guodong Long", "Deheng Ye", "Jing Jiang", "Chengqi Zhang"], "title": "WALL-E 2.0: World Alignment by NeuroSymbolic Learning improves World Model-based LLM Agents", "categories": ["cs.AI"], "comment": "Code is available at https://github.com/elated-sawyer/WALL-E", "summary": "Can we build accurate world models out of large language models (LLMs)? How\ncan world models benefit LLM agents? The gap between the prior knowledge of\nLLMs and the specified environment's dynamics usually bottlenecks LLMs'\nperformance as world models. To bridge the gap, we propose a training-free\n\"world alignment\" that learns an environment's symbolic knowledge complementary\nto LLMs. The symbolic knowledge covers action rules, knowledge graphs, and\nscene graphs, which are extracted by LLMs from exploration trajectories and\nencoded into executable codes to regulate LLM agents' policies. We further\npropose an RL-free, model-based agent \"WALL-E 2.0\" through the model-predictive\ncontrol (MPC) framework. Unlike classical MPC requiring costly optimization on\nthe fly, we adopt an LLM agent as an efficient look-ahead optimizer of future\nsteps' actions by interacting with the neurosymbolic world model. While the LLM\nagent's strong heuristics make it an efficient planner in MPC, the quality of\nits planned actions is also secured by the accurate predictions of the aligned\nworld model. They together considerably improve learning efficiency in a new\nenvironment. On open-world challenges in Mars (Minecraft like) and ALFWorld\n(embodied indoor environments), WALL-E 2.0 significantly outperforms existing\nmethods, e.g., surpassing baselines in Mars by 16.1%-51.6% of success rate and\nby at least 61.7% in score. In ALFWorld, it achieves a new record 98% success\nrate after only 4 iterations."}
{"id": "2504.15479", "pdf": "https://arxiv.org/pdf/2504.15479", "abs": "https://arxiv.org/abs/2504.15479", "authors": ["Jeremy Goldwasser", "Giles Hooker"], "title": "Unifying Image Counterfactuals and Feature Attributions with Latent-Space Adversarial Attacks", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Counterfactuals are a popular framework for interpreting machine learning\npredictions. These what if explanations are notoriously challenging to create\nfor computer vision models: standard gradient-based methods are prone to\nproduce adversarial examples, in which imperceptible modifications to image\npixels provoke large changes in predictions. We introduce a new,\neasy-to-implement framework for counterfactual images that can flexibly adapt\nto contemporary advances in generative modeling. Our method, Counterfactual\nAttacks, resembles an adversarial attack on the representation of the image\nalong a low-dimensional manifold. In addition, given an auxiliary dataset of\nimage descriptors, we show how to accompany counterfactuals with feature\nattribution that quantify the changes between the original and counterfactual\nimages. These importance scores can be aggregated into global counterfactual\nexplanations that highlight the overall features driving model predictions.\nWhile this unification is possible for any counterfactual method, it has\nparticular computational efficiency for ours. We demonstrate the efficacy of\nour approach with the MNIST and CelebA datasets."}
{"id": "2504.15412", "pdf": "https://arxiv.org/pdf/2504.15412", "abs": "https://arxiv.org/abs/2504.15412", "authors": ["Mohammed Adib Oumer", "Vishnu Murali", "Majid Zamani"], "title": "$k$-Inductive and Interpolation-Inspired Barrier Certificates for Stochastic Dynamical Systems", "categories": ["math.OC", "cs.SY", "eess.SY"], "comment": "This manuscript of 20 pages and 4 figures is a preprint under review\n  with a journal", "summary": "We introduce two notions of barrier certificates that use multiple functions\nto provide a lower bound on the probabilistic satisfaction of safety for\nstochastic dynamical systems. A barrier certificate for a stochastic dynamical\nsystem acts as a nonnegative supermartingale, and provides a lower bound on the\nprobability that the system is safe. The promise of such certificates is that\ntheir search can be effectively automated. Typically, one may use optimization\nor SMT solvers to find such barrier certificates of a given fixed template.\nWhen such approaches fail, a typical approach is to instead change the\ntemplate. We propose an alternative approach that we dub interpolation-inspired\nbarrier certificates. An interpolation-inspired barrier certificate consists of\na set of functions that jointly provide a lower bound on the probability of\nsatisfying safety. We show how one may find such certificates of a fixed\ntemplate, even when we fail to find standard barrier certificates of the same\ntemplate. However, we note that such certificates still need to ensure a\nsupermartingale guarantee for one function in the set. To address this\nchallenge, we consider the use of $k$-induction with these\ninterpolation-inspired certificates. The recent use of $k$-induction in barrier\ncertificates allows one to relax the supermartingale requirement at every time\nstep to a combination of a supermartingale requirement every $k$ steps and a\n$c$-martingale requirement for the intermediate steps. We provide a generic\nformulation of a barrier certificate that we dub $k$-inductive\ninterpolation-inspired barrier certificate. The formulation allows for several\ncombinations of interpolation and $k$-induction for barrier certificate. We\npresent two examples among the possible combinations. We finally present\nsum-of-squares programming to synthesize this set of functions and demonstrate\ntheir utility in case studies."}
{"id": "2504.15791", "pdf": "https://arxiv.org/pdf/2504.15791", "abs": "https://arxiv.org/abs/2504.15791", "authors": ["Raquel Fernandez-Peralta", "Javier Fumanal-Idocin", "Javier Andreu-Perez"], "title": "Crisp complexity of fuzzy classifiers", "categories": ["cs.AI"], "comment": null, "summary": "Rule-based systems are a very popular form of explainable AI, particularly in\nthe fuzzy community, where fuzzy rules are widely used for control and\nclassification problems. However, fuzzy rule-based classifiers struggle to\nreach bigger traction outside of fuzzy venues, because users sometimes do not\nknow about fuzzy and because fuzzy partitions are not so easy to interpret in\nsome situations. In this work, we propose a methodology to reduce fuzzy\nrule-based classifiers to crisp rule-based classifiers. We study different\npossible crisp descriptions and implement an algorithm to obtain them. Also, we\nanalyze the complexity of the resulting crisp classifiers. We believe that our\nresults can help both fuzzy and non-fuzzy practitioners understand better the\nway in which fuzzy rule bases partition the feature space and how easily one\nsystem can be translated to another and vice versa. Our complexity metric can\nalso help to choose between different fuzzy classifiers based on what the\nequivalent crisp partitions look like."}
{"id": "2504.15487", "pdf": "https://arxiv.org/pdf/2504.15487", "abs": "https://arxiv.org/abs/2504.15487", "authors": ["Moein Darman", "Pedram Hassanzadeh", "Laure Zanna", "Ashesh Chattopadhyay"], "title": "Fourier analysis of the physics of transfer learning for data-driven subgrid-scale models of ocean turbulence", "categories": ["cs.LG", "nlin.CD", "physics.ao-ph", "physics.geo-ph"], "comment": null, "summary": "Transfer learning (TL) is a powerful tool for enhancing the performance of\nneural networks (NNs) in applications such as weather and climate prediction\nand turbulence modeling. TL enables models to generalize to out-of-distribution\ndata with minimal training data from the new system. In this study, we employ a\n9-layer convolutional NN to predict the subgrid forcing in a two-layer ocean\nquasi-geostrophic system and examine which metrics best describe its\nperformance and generalizability to unseen dynamical regimes. Fourier analysis\nof the NN kernels reveals that they learn low-pass, Gabor, and high-pass\nfilters, regardless of whether the training data are isotropic or anisotropic.\nBy analyzing the activation spectra, we identify why NNs fail to generalize\nwithout TL and how TL can overcome these limitations: the learned weights and\nbiases from one dataset underestimate the out-of-distribution sample spectra as\nthey pass through the network, leading to an underestimation of output spectra.\nBy re-training only one layer with data from the target system, this\nunderestimation is corrected, enabling the NN to produce predictions that match\nthe target spectra. These findings are broadly applicable to data-driven\nparameterization of dynamical systems."}
{"id": "2504.15418", "pdf": "https://arxiv.org/pdf/2504.15418", "abs": "https://arxiv.org/abs/2504.15418", "authors": ["Victoria Marie Tuck", "Hardik Parwana", "Pei-Wei Chen", "Georgios Fainekos", "Bardh Hoxha", "Hideki Okamoto", "S. Shankar Sastry", "Sanjit A. Seshia"], "title": "MRTA-Sim: A Modular Simulator for Multi-Robot Allocation, Planning, and Control in Open-World Environments", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "8 pages, 9 figures, 3 tables", "summary": "This paper introduces MRTA-Sim, a Python/ROS2/Gazebo simulator for testing\napproaches to Multi-Robot Task Allocation (MRTA) problems on simulated robots\nin complex, indoor environments. Grid-based approaches to MRTA problems can be\ntoo restrictive for use in complex, dynamic environments such in warehouses,\ndepartment stores, hospitals, etc. However, approaches that operate in\nfree-space often operate at a layer of abstraction above the control and\nplanning layers of a robot and make an assumption on approximate travel time\nbetween points of interest in the system. These abstractions can neglect the\nimpact of the tight space and multi-agent interactions on the quality of the\nsolution. Therefore, MRTA solutions should be tested with the navigation stacks\nof the robots in mind, taking into account robot planning, conflict avoidance\nbetween robots, and human interaction and avoidance. This tool connects the\nallocation output of MRTA solvers to individual robot planning using the NAV2\nstack and local, centralized multi-robot deconfliction using Control Barrier\nFunction-Quadrtic Programs (CBF-QPs), creating a platform closer to real-world\noperation for more comprehensive testing of these approaches. The simulation\narchitecture is modular so that users can swap out methods at different levels\nof the stack. We show the use of our system with a Satisfiability Modulo\nTheories (SMT)-based approach to dynamic MRTA on a fleet of indoor delivery\nrobots."}
{"id": "2504.15829", "pdf": "https://arxiv.org/pdf/2504.15829", "abs": "https://arxiv.org/abs/2504.15829", "authors": ["Modhurita Mitra", "Martine G. de Vos", "Nicola Cortinovis", "Dawa Ometto"], "title": "Generative AI for Research Data Processing: Lessons Learnt From Three Use Cases", "categories": ["cs.AI", "68T50", "I.2.7"], "comment": "10 pages, 4 figures, 6 tables. Published in Proceedings of the 2024\n  IEEE 20th International Conference on e-Science (e-Science), Osaka, Japan", "summary": "There has been enormous interest in generative AI since ChatGPT was launched\nin 2022. However, there are concerns about the accuracy and consistency of the\noutputs of generative AI. We have carried out an exploratory study on the\napplication of this new technology in research data processing. We identified\ntasks for which rule-based or traditional machine learning approaches were\ndifficult to apply, and then performed these tasks using generative AI.\n  We demonstrate the feasibility of using the generative AI model Claude 3 Opus\nin three research projects involving complex data processing tasks:\n  1) Information extraction: We extract plant species names from historical\nseedlists (catalogues of seeds) published by botanical gardens.\n  2) Natural language understanding: We extract certain data points (name of\ndrug, name of health indication, relative effectiveness, cost-effectiveness,\netc.) from documents published by Health Technology Assessment organisations in\nthe EU.\n  3) Text classification: We assign industry codes to projects on the\ncrowdfunding website Kickstarter.\n  We share the lessons we learnt from these use cases: How to determine if\ngenerative AI is an appropriate tool for a given data processing task, and if\nso, how to maximise the accuracy and consistency of the results obtained."}
{"id": "2504.15491", "pdf": "https://arxiv.org/pdf/2504.15491", "abs": "https://arxiv.org/abs/2504.15491", "authors": ["Tengda Tang", "Jianhua Yao", "Yixian Wang", "Qiuwu Sha", "Hanrui Feng", "Zhen Xu"], "title": "Application of Deep Generative Models for Anomaly Detection in Complex Financial Transactions", "categories": ["cs.LG"], "comment": null, "summary": "This study proposes an algorithm for detecting suspicious behaviors in large\npayment flows based on deep generative models. By combining Generative\nAdversarial Networks (GAN) and Variational Autoencoders (VAE), the algorithm is\ndesigned to detect abnormal behaviors in financial transactions. First, the GAN\nis used to generate simulated data that approximates normal payment flows. The\ndiscriminator identifies anomalous patterns in transactions, enabling the\ndetection of potential fraud and money laundering behaviors. Second, a VAE is\nintroduced to model the latent distribution of payment flows, ensuring that the\ngenerated data more closely resembles real transaction features, thus improving\nthe model's detection accuracy. The method optimizes the generative\ncapabilities of both GAN and VAE, ensuring that the model can effectively\ncapture suspicious behaviors even in sparse data conditions. Experimental\nresults show that the proposed method significantly outperforms traditional\nmachine learning algorithms and other deep learning models across various\nevaluation metrics, especially in detecting rare fraudulent behaviors.\nFurthermore, this study provides a detailed comparison of performance in\nrecognizing different transaction patterns (such as normal, money laundering,\nand fraud) in large payment flows, validating the advantages of generative\nmodels in handling complex financial data."}
{"id": "2504.15472", "pdf": "https://arxiv.org/pdf/2504.15472", "abs": "https://arxiv.org/abs/2504.15472", "authors": ["Pingcheng Jian", "Xiao Wei", "Yanbaihui Liu", "Samuel A. Moore", "Michael M. Zavlanos", "Boyuan Chen"], "title": "LAPP: Large Language Model Feedback for Preference-Driven Reinforcement Learning", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "We introduce Large Language Model-Assisted Preference Prediction (LAPP), a\nnovel framework for robot learning that enables efficient, customizable, and\nexpressive behavior acquisition with minimum human effort. Unlike prior\napproaches that rely heavily on reward engineering, human demonstrations,\nmotion capture, or expensive pairwise preference labels, LAPP leverages large\nlanguage models (LLMs) to automatically generate preference labels from raw\nstate-action trajectories collected during reinforcement learning (RL). These\nlabels are used to train an online preference predictor, which in turn guides\nthe policy optimization process toward satisfying high-level behavioral\nspecifications provided by humans. Our key technical contribution is the\nintegration of LLMs into the RL feedback loop through trajectory-level\npreference prediction, enabling robots to acquire complex skills including\nsubtle control over gait patterns and rhythmic timing. We evaluate LAPP on a\ndiverse set of quadruped locomotion and dexterous manipulation tasks and show\nthat it achieves efficient learning, higher final performance, faster\nadaptation, and precise control of high-level behaviors. Notably, LAPP enables\nrobots to master highly dynamic and expressive tasks such as quadruped\nbackflips, which remain out of reach for standard LLM-generated or handcrafted\nrewards. Our results highlight LAPP as a promising direction for scalable\npreference-driven robot learning."}
{"id": "2504.15847", "pdf": "https://arxiv.org/pdf/2504.15847", "abs": "https://arxiv.org/abs/2504.15847", "authors": ["Xiang Liu", "Hau Chan", "Minming Li", "Xianlong Zeng", "Chenchen Fu", "Weiwei Wu"], "title": "CARE: Compatibility-Aware Incentive Mechanisms for Federated Learning with Budgeted Requesters", "categories": ["cs.AI"], "comment": null, "summary": "Federated learning (FL) is a promising approach that allows requesters (\\eg,\nservers) to obtain local training models from workers (e.g., clients). Since\nworkers are typically unwilling to provide training services/models freely and\nvoluntarily, many incentive mechanisms in FL are designed to incentivize\nparticipation by offering monetary rewards from requesters. However, existing\nstudies neglect two crucial aspects of real-world FL scenarios. First, workers\ncan possess inherent incompatibility characteristics (e.g., communication\nchannels and data sources), which can lead to degradation of FL efficiency\n(e.g., low communication efficiency and poor model generalization). Second, the\nrequesters are budgeted, which limits the amount of workers they can hire for\ntheir tasks. In this paper, we investigate the scenario in FL where multiple\nbudgeted requesters seek training services from incompatible workers with\nprivate training costs. We consider two settings: the cooperative budget\nsetting where requesters cooperate to pool their budgets to improve their\noverall utility and the non-cooperative budget setting where each requester\noptimizes their utility within their own budgets. To address efficiency\ndegradation caused by worker incompatibility, we develop novel\ncompatibility-aware incentive mechanisms, CARE-CO and CARE-NO, for both\nsettings to elicit true private costs and determine workers to hire for\nrequesters and their rewards while satisfying requester budget constraints. Our\nmechanisms guarantee individual rationality, truthfulness, budget feasibility,\nand approximation performance. We conduct extensive experiments using\nreal-world datasets to show that the proposed mechanisms significantly\noutperform existing baselines."}
{"id": "2504.15525", "pdf": "https://arxiv.org/pdf/2504.15525", "abs": "https://arxiv.org/abs/2504.15525", "authors": ["Chengjun Yu", "Yixin Ran", "Yangyi Xia", "Jia Wu", "Xiaojing Liu"], "title": "Federated Latent Factor Learning for Recovering Wireless Sensor Networks Signal with Privacy-Preserving", "categories": ["cs.LG"], "comment": "Accepted By ICAIS&ISAS 2025", "summary": "Wireless Sensor Networks (WSNs) are a cutting-edge domain in the field of\nintelligent sensing. Due to sensor failures and energy-saving strategies, the\ncollected data often have massive missing data, hindering subsequent analysis\nand decision-making. Although Latent Factor Learning (LFL) has been proven\neffective in recovering missing data, it fails to sufficiently consider data\nprivacy protection. To address this issue, this paper innovatively proposes a\nfederated latent factor learning (FLFL) based spatial signal recovery (SSR)\nmodel, named FLFL-SSR. Its main idea is two-fold: 1) it designs a sensor-level\nfederated learning framework, where each sensor uploads only gradient updates\ninstead of raw data to optimize the global model, and 2) it proposes a local\nspatial sharing strategy, allowing sensors within the same spatial region to\nshare their latent feature vectors, capturing spatial correlations and\nenhancing recovery accuracy. Experimental results on two real-world WSNs\ndatasets demonstrate that the proposed model outperforms existing federated\nmethods in terms of recovery performance."}
{"id": "2504.15483", "pdf": "https://arxiv.org/pdf/2504.15483", "abs": "https://arxiv.org/abs/2504.15483", "authors": ["Farnaz Fallahi", "Murat Yildirim", "Shijia Zhao", "Feng Qiu"], "title": "A Sensor-Driven Optimization Framework for Asset Management in Energy Systems: Implications for Full and Partial Digital Transformation in Hydro Fleets", "categories": ["math.OC", "cs.SY", "eess.SY"], "comment": "35 pages, 8 figures", "summary": "This paper proposes a novel prognostics-driven approach to optimize\noperations and maintenance (O&M) decisions in hydropower systems. Our approach\nharnesses the insights from sensor data to accurately predict the remaining\nlifetime distribution of critical generation assets in hydropower systems,\ni.e., thrust bearings, and use these predictions to optimally schedule O&M\nactions for a fleet of hydro generators. We consider complex interdependencies\nacross hydro generator failure risks, reservoir, production, and demand\nmanagement decisions. We propose a stochastic joint O&M scheduling model to\ntackle the unique challenges of hydropower O&M including the interdependency of\ngeneration capacities, the nonlinear nature of power production, operational\nrequirements, and uncertainties. We develop a two-level decomposition-based\nsolution algorithm to effectively handle large-scale cases. The algorithm\nincorporates a combination of Benders optimality cuts and integer cuts to solve\nthe problem in an efficient manner. We design an experimental framework to\nevaluate the proposed prognostics-driven O&M scheduling framework, using\nreal-world condition monitoring data from hydropower systems, historical market\nprices, and water inflow data. The developed framework can be partially\nimplemented for a phased-in approach. Our experiments demonstrate the\nsignificant benefits of the sensor-driven O&M framework in improving\nreliability, availability, effective usage of resources, and system\nprofitability, especially when gradually shifting from traditional time-based\nmaintenance policies to condition-based prognostics-driven maintenance\npolicies."}
{"id": "2504.15903", "pdf": "https://arxiv.org/pdf/2504.15903", "abs": "https://arxiv.org/abs/2504.15903", "authors": ["Nikhil Khandalkar", "Pavan Yadav", "Krishna Shinde", "Lokesh B. Ramegowda", "Rajarshi Das"], "title": "Impact of Noise on LLM-Models Performance in Abstraction and Reasoning Corpus (ARC) Tasks with Model Temperature Considerations", "categories": ["cs.AI"], "comment": "60 pages, 25 figures", "summary": "Recent advancements in Large Language Models (LLMs) have generated growing\ninterest in their structured reasoning capabilities, particularly in tasks\ninvolving abstraction and pattern recognition. The Abstraction and Reasoning\nCorpus (ARC) benchmark plays a crucial role in evaluating these capabilities by\ntesting how well AI models generalize to novel problems. While GPT-4o\ndemonstrates strong performance by solving all ARC tasks under zero-noise\nconditions, other models like DeepSeek R1 and LLaMA 3.2 fail to solve any,\nsuggesting limitations in their ability to reason beyond simple pattern\nmatching. To explore this gap, we systematically evaluate these models across\ndifferent noise levels and temperature settings. Our results reveal that the\nintroduction of noise consistently impairs model performance, regardless of\narchitecture. This decline highlights a shared vulnerability: current LLMs,\ndespite showing signs of abstract reasoning, remain highly sensitive to input\nperturbations. Such fragility raises concerns about their real-world\napplicability, where noise and uncertainty are common. By comparing how\ndifferent model architectures respond to these challenges, we offer insights\ninto the structural weaknesses of modern LLMs in reasoning tasks. This work\nunderscores the need for developing more robust and adaptable AI systems\ncapable of handling the ambiguity and variability inherent in real-world\nscenarios. Our findings aim to guide future research toward enhancing model\ngeneralization, robustness, and alignment with human-like cognitive\nflexibility."}
{"id": "2504.15539", "pdf": "https://arxiv.org/pdf/2504.15539", "abs": "https://arxiv.org/abs/2504.15539", "authors": ["Ryan J. Miller", "Alexander E. Dashuta", "Brayden Rudisill", "David Van Vranken", "Pierre Baldi"], "title": "Interpretable Deep Learning for Polar Mechanistic Reaction Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Accurately predicting chemical reactions is essential for driving innovation\nin synthetic chemistry, with broad applications in medicine, manufacturing, and\nagriculture. At the same time, reaction prediction is a complex problem which\ncan be both time-consuming and resource-intensive for chemists to solve. Deep\nlearning methods offer an appealing solution by enabling high-throughput\nreaction prediction. However, many existing models are trained on the US Patent\nOffice dataset and treat reactions as overall transformations: mapping\nreactants directly to products with limited interpretability or mechanistic\ninsight. To address this, we introduce PMechRP (Polar Mechanistic Reaction\nPredictor), a system that trains machine learning models on the PMechDB\ndataset, which represents reactions as polar elementary steps that capture\nelectron flow and mechanistic detail. To further expand model coverage and\nimprove generalization, we augment PMechDB with a diverse set of\ncombinatorially generated reactions. We train and compare a range of machine\nlearning models, including transformer-based, graph-based, and two-step siamese\narchitectures. Our best-performing approach was a hybrid model, which combines\na 5-ensemble of Chemformer models with a two-step Siamese framework to leverage\nthe accuracy of transformer architectures, while filtering away \"alchemical\"\nproducts using the two-step network predictions. For evaluation, we use a test\nsplit of the PMechDB dataset and additionally curate a human benchmark dataset\nconsisting of complete mechanistic pathways extracted from an organic chemistry\ntextbook. Our hybrid model achieves a top-10 accuracy of 94.9% on the PMechDB\ntest set and a target recovery rate of 84.9% on the pathway dataset."}
{"id": "2504.15600", "pdf": "https://arxiv.org/pdf/2504.15600", "abs": "https://arxiv.org/abs/2504.15600", "authors": ["Anlong Zhang", "Jianmin Ji"], "title": "Research on Navigation Methods Based on LLMs", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "In recent years, the field of indoor navigation has witnessed groundbreaking\nadvancements through the integration of Large Language Models (LLMs).\nTraditional navigation approaches relying on pre-built maps or reinforcement\nlearning exhibit limitations such as poor generalization and limited\nadaptability to dynamic environments. In contrast, LLMs offer a novel paradigm\nfor complex indoor navigation tasks by leveraging their exceptional semantic\ncomprehension, reasoning capabilities, and zero-shot generalization properties.\nWe propose an LLM-based navigation framework that leverages function calling\ncapabilities, positioning the LLM as the central controller. Our methodology\ninvolves modular decomposition of conventional navigation functions into\nreusable LLM tools with expandable configurations. This is complemented by a\nsystematically designed, transferable system prompt template and interaction\nworkflow that can be easily adapted across different implementations.\nExperimental validation in PyBullet simulation environments across diverse\nscenarios demonstrates the substantial potential and effectiveness of our\napproach, particularly in achieving context-aware navigation through dynamic\ntool composition."}
{"id": "2504.16042", "pdf": "https://arxiv.org/pdf/2504.16042", "abs": "https://arxiv.org/abs/2504.16042", "authors": ["Ismaïl Baaj"], "title": "Approximate matrices of systems of max-min fuzzy relational equations", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "In this article, we address the inconsistency of a system of max-min fuzzy\nrelational equations by minimally modifying the matrix governing the system in\norder to achieve consistency. Our method yields consistent systems that\napproximate the original inconsistent system in the following sense: the\nright-hand side vector of each consistent system is that of the inconsistent\nsystem, and the coefficients of the matrix governing each consistent system are\nobtained by modifying, exactly and minimally, the entries of the original\nmatrix that must be corrected to achieve consistency, while leaving all other\nentries unchanged.\n  To obtain a consistent system that closely approximates the considered\ninconsistent system, we study the distance (in terms of a norm among $L_1$,\n$L_2$ or $L_\\infty$) between the matrix of the inconsistent system and the set\nformed by the matrices of consistent systems that use the same right-hand side\nvector as the inconsistent system. We show that our method allows us to\ndirectly compute matrices of consistent systems that use the same right-hand\nside vector as the inconsistent system whose distance in terms of $L_\\infty$\nnorm to the matrix of the inconsistent system is minimal (the computational\ncosts are higher when using $L_1$ norm or $L_2$ norm). We also give an explicit\nanalytical formula for computing this minimal $L_\\infty$ distance. Finally, we\ntranslate our results for systems of min-max fuzzy relational equations and\npresent some potential applications."}
{"id": "2504.15562", "pdf": "https://arxiv.org/pdf/2504.15562", "abs": "https://arxiv.org/abs/2504.15562", "authors": ["Dip Roy"], "title": "Bayesian Autoencoder for Medical Anomaly Detection: Uncertainty-Aware Approach for Brain 2 MRI Analysis", "categories": ["cs.LG", "cs.CV"], "comment": "16 pages, 6 figures", "summary": "In medical imaging, anomaly detection is a vital element of healthcare\ndiagnostics, especially for neurological conditions which can be\nlife-threatening. Conventional deterministic methods often fall short when it\ncomes to capturing the inherent uncertainty of anomaly detection tasks. This\npaper introduces a Bayesian Variational Autoencoder (VAE) equipped with\nmulti-head attention mechanisms for detecting anomalies in brain magnetic\nresonance imaging (MRI). For the purpose of improving anomaly detection\nperformance, we incorporate both epistemic and aleatoric uncertainty estimation\nthrough Bayesian inference. The model was tested on the BraTS2020 dataset, and\nthe findings were a 0.83 ROC AUC and a 0.83 PR AUC. The data in our paper\nsuggests that modeling uncertainty is an essential component of anomaly\ndetection, enhancing both performance and interpretability and providing\nconfidence estimates, as well as anomaly predictions, for clinicians to\nleverage in making medical decisions."}
{"id": "2504.15623", "pdf": "https://arxiv.org/pdf/2504.15623", "abs": "https://arxiv.org/abs/2504.15623", "authors": ["Xiucheng Wang", "Qiming Zhang", "Nan Cheng", "Ruijin Sun", "Zan Li", "Shuguang Cui", "Xuemin Shen"], "title": "RadioDiff-$k^2$: Helmholtz Equation Informed Generative Diffusion Model for Multi-Path Aware Radio Map Construction", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "In this paper, we propose a novel physics-informed generative learning\napproach, termed RadioDiff-$\\bm{k^2}$, for accurate and efficient\nmultipath-aware radio map (RM) construction. As wireless communication evolves\ntowards environment-aware paradigms, driven by the increasing demand for\nintelligent and proactive optimization in sixth-generation (6G) networks,\naccurate construction of RMs becomes crucial yet highly challenging.\nConventional electromagnetic (EM)-based methods, such as full-wave solvers and\nray-tracing approaches, exhibit substantial computational overhead and limited\nadaptability to dynamic scenarios. Although, existing neural network (NN)\napproaches have efficient inferencing speed, they lack sufficient consideration\nof the underlying physics of EM wave propagation, limiting their effectiveness\nin accurately modeling critical EM singularities induced by complex multipath\nenvironments. To address these fundamental limitations, we propose a novel\nphysics-inspired RM construction method guided explicitly by the Helmholtz\nequation, which inherently governs EM wave propagation. Specifically, we\ntheoretically establish a direct correspondence between EM singularities, which\ncorrespond to the critical spatial features influencing wireless propagation,\nand regions defined by negative wave numbers in the Helmholtz equation. Based\non this insight, we design an innovative dual generative diffusion model (DM)\nframework comprising one DM dedicated to accurately inferring EM singularities\nand another DM responsible for reconstructing the complete RM using these\nsingularities along with environmental contextual information. Our\nphysics-informed approach uniquely combines the efficiency advantages of\ndata-driven methods with rigorous physics-based EM modeling, significantly\nenhancing RM accuracy, particularly in complex propagation environments\ndominated by multipath effects."}
{"id": "2504.15286", "pdf": "https://arxiv.org/pdf/2504.15286", "abs": "https://arxiv.org/abs/2504.15286", "authors": ["Daniele Gorla", "Shivam Kumar", "Pietro Nicolaus Roselli Lorenzini", "Alireza Alipourfaz"], "title": "CUBETESTERAI: Automated JUnit Test Generation using the LLaMA Model", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted to ICST 2025 Industry Track", "summary": "This paper presents an approach to automating JUnit test generation for Java\napplications using the Spring Boot framework, leveraging the LLaMA (Large\nLanguage Model Architecture) model to enhance the efficiency and accuracy of\nthe testing process. The resulting tool, called CUBETESTERAI, includes a\nuser-friendly web interface and the integration of a CI/CD pipeline using\nGitLab and Docker. These components streamline the automated test generation\nprocess, allowing developers to generate JUnit tests directly from their code\nsnippets with minimal manual intervention. The final implementation executes\nthe LLaMA models through RunPod, an online GPU service, which also enhances the\nprivacy of our tool. Using the advanced natural language processing\ncapabilities of the LLaMA model, CUBETESTERAI is able to generate test cases\nthat provide high code coverage and accurate validation of software\nfunctionalities in Java-based Spring Boot applications. Furthermore, it\nefficiently manages resource-intensive operations and refines the generated\ntests to address common issues like missing imports and handling of private\nmethods. By comparing CUBETESTERAI with some state-of-the-art tools, we show\nthat our proposal consistently demonstrates competitive and, in many cases,\nbetter performance in terms of code coverage in different real-life Java\nprograms."}
{"id": "2504.15582", "pdf": "https://arxiv.org/pdf/2504.15582", "abs": "https://arxiv.org/abs/2504.15582", "authors": ["Jason Hartline", "Yifan Wu", "Yunran Yang"], "title": "Smooth Calibration and Decision Making", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": "In FORC 2025", "summary": "Calibration requires predictor outputs to be consistent with their Bayesian\nposteriors. For machine learning predictors that do not distinguish between\nsmall perturbations, calibration errors are continuous in predictions, e.g.,\nsmooth calibration error (Foster and Hart, 2018), Distance to Calibration\n(Blasiok et al., 2023a). On the contrary, decision-makers who use predictions\nmake optimal decisions discontinuously in probabilistic space, experiencing\nloss from miscalibration discontinuously. Calibration errors for\ndecision-making are thus discontinuous, e.g., Expected Calibration Error\n(Foster and Vohra, 1997), and Calibration Decision Loss (Hu and Wu, 2024).\nThus, predictors with a low calibration error for machine learning may suffer a\nhigh calibration error for decision-making, i.e., they may not be trustworthy\nfor decision-makers optimizing assuming their predictions are correct. It is\nnatural to ask if post-processing a predictor with a low calibration error for\nmachine learning is without loss to achieve a low calibration error for\ndecision-making. In our paper, we show that post-processing an online predictor\nwith $\\epsilon$ distance to calibration achieves $O(\\sqrt{\\epsilon})$ ECE and\nCDL, which is asymptotically optimal. The post-processing algorithm adds noise\nto make predictions differentially private. The optimal bound from low distance\nto calibration predictors from post-processing is non-optimal compared with\nexisting online calibration algorithms that directly optimize for ECE and CDL."}
{"id": "2504.15753", "pdf": "https://arxiv.org/pdf/2504.15753", "abs": "https://arxiv.org/abs/2504.15753", "authors": ["Alexis M. H. Teter", "Wenqing Wang", "Sachin Shivakumar", "Abhishek Halder"], "title": "Markov Kernels, Distances and Optimal Control: A Parable of Linear Quadratic Non-Gaussian Distribution Steering", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY", "math.PR", "math.ST", "stat.TH"], "comment": null, "summary": "For a controllable linear time-varying (LTV) pair\n$(\\boldsymbol{A}_t,\\boldsymbol{B}_t)$ and $\\boldsymbol{Q}_{t}$ positive\nsemidefinite, we derive the Markov kernel for the It\\^{o} diffusion\n${\\mathrm{d}}\\boldsymbol{x}_{t}=\\boldsymbol{A}_{t}\\boldsymbol{x}_t {\\mathrm{d}}\nt + \\sqrt{2}\\boldsymbol{B}_{t}{\\mathrm{d}}\\boldsymbol{w}_{t}$ with an\naccompanying killing of probability mass at rate\n$\\frac{1}{2}\\boldsymbol{x}^{\\top}\\boldsymbol{Q}_{t}\\boldsymbol{x}$. This Markov\nkernel is the Green's function for an associated linear\nreaction-advection-diffusion partial differential equation. Our result\ngeneralizes the recently derived kernel for the special case\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t\\right)=\\left(\\boldsymbol{0},\\boldsymbol{I}\\right)$,\nand depends on the solution of an associated Riccati matrix ODE. A consequence\nof this result is that the linear quadratic non-Gaussian Schr\\\"{o}dinger bridge\nis exactly solvable. This means that the problem of steering a controlled LTV\ndiffusion from a given non-Gaussian distribution to another over a fixed\ndeadline while minimizing an expected quadratic cost can be solved using\ndynamic Sinkhorn recursions performed with the derived kernel. Our derivation\nfor the\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t,\\boldsymbol{Q}_t\\right)$-parametrized\nkernel pursues a new idea that relies on finding a state-time dependent\ndistance-like functional given by the solution of a deterministic optimal\ncontrol problem. This technique breaks away from existing methods, such as\ngeneralizing Hermite polynomials or Weyl calculus, which have seen limited\nsuccess in the reaction-diffusion context. Our technique uncovers a new\nconnection between Markov kernels, distances, and optimal control. This\nconnection is of interest beyond its immediate application in solving the\nlinear quadratic Schr\\\"{o}dinger bridge problem."}
{"id": "2504.15296", "pdf": "https://arxiv.org/pdf/2504.15296", "abs": "https://arxiv.org/abs/2504.15296", "authors": ["Yihong Jin", "Ze Yang"], "title": "Scalability Optimization in Cloud-Based AI Inference Services: Strategies for Real-Time Load Balancing and Automated Scaling", "categories": ["cs.DC", "cs.AI", "F.2.2; I.2.8"], "comment": "Accepted to BDICN 2025", "summary": "The rapid expansion of AI inference services in the cloud necessitates a\nrobust scalability solution to manage dynamic workloads and maintain high\nperformance. This study proposes a comprehensive scalability optimization\nframework for cloud AI inference services, focusing on real-time load balancing\nand autoscaling strategies. The proposed model is a hybrid approach that\ncombines reinforcement learning for adaptive load distribution and deep neural\nnetworks for accurate demand forecasting. This multi-layered approach enables\nthe system to anticipate workload fluctuations and proactively adjust\nresources, ensuring maximum resource utilisation and minimising latency.\nFurthermore, the incorporation of a decentralised decision-making process\nwithin the model serves to enhance fault tolerance and reduce response time in\nscaling operations. Experimental results demonstrate that the proposed model\nenhances load balancing efficiency by 35\\ and reduces response delay by 28\\,\nthereby exhibiting a substantial optimization effect in comparison with\nconventional scalability solutions."}
{"id": "2504.15587", "pdf": "https://arxiv.org/pdf/2504.15587", "abs": "https://arxiv.org/abs/2504.15587", "authors": ["Zimo Yan", "Jie Zhang", "Zheng Xie", "Chang Liu", "Yizhen Liu", "Yiping Song"], "title": "MetaMolGen: A Neural Graph Motif Generation Model for De Novo Molecular Design", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Molecular generation plays an important role in drug discovery and materials\nscience, especially in data-scarce scenarios where traditional generative\nmodels often struggle to achieve satisfactory conditional generalization. To\naddress this challenge, we propose MetaMolGen, a first-order\nmeta-learning-based molecular generator designed for few-shot and\nproperty-conditioned molecular generation. MetaMolGen standardizes the\ndistribution of graph motifs by mapping them to a normalized latent space, and\nemploys a lightweight autoregressive sequence model to generate SMILES\nsequences that faithfully reflect the underlying molecular structure. In\naddition, it supports conditional generation of molecules with target\nproperties through a learnable property projector integrated into the\ngenerative process.Experimental results demonstrate that MetaMolGen\nconsistently generates valid and diverse SMILES sequences under low-data\nregimes, outperforming conventional baselines. This highlights its advantage in\nfast adaptation and efficient conditional generation for practical molecular\ndesign."}
{"id": "2504.15758", "pdf": "https://arxiv.org/pdf/2504.15758", "abs": "https://arxiv.org/abs/2504.15758", "authors": ["Andrew Gracyk"], "title": "Observability conditions for neural state-space models with eigenvalues and their roots of unity", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.DS", "math.OC"], "comment": "First version", "summary": "We operate through the lens of ordinary differential equations and control\ntheory to study the concept of observability in the context of neural\nstate-space models and the Mamba architecture. We develop strategies to enforce\nobservability, which are tailored to a learning context, specifically where the\nhidden states are learnable at initial time, in conjunction to over its\ncontinuum, and high-dimensional. We also highlight our methods emphasize\neigenvalues, roots of unity, or both. Our methods effectuate computational\nefficiency when enforcing observability, sometimes at great scale. We formulate\nobservability conditions in machine learning based on classical control theory\nand discuss their computational complexity. Our nontrivial results are\nfivefold. We discuss observability through the use of permutations in neural\napplications with learnable matrices without high precision. We present two\nresults built upon the Fourier transform that effect observability with high\nprobability up to the randomness in the learning. These results are worked with\nthe interplay of representations in Fourier space and their eigenstructure,\nnonlinear mappings, and the observability matrix. We present a result for Mamba\nthat is similar to a Hautus-type condition, but instead employs an argument\nusing a Vandermonde matrix instead of eigenvectors. Our final result is a\nshared-parameter construction of the Mamba system, which is computationally\nefficient in high exponentiation. We develop a training algorithm with this\ncoupling, showing it satisfies a Robbins-Monro condition under certain\northogonality, while a more classical training procedure fails to satisfy a\ncontraction with high Lipschitz constant."}
{"id": "2504.15299", "pdf": "https://arxiv.org/pdf/2504.15299", "abs": "https://arxiv.org/abs/2504.15299", "authors": ["Haodong Wang", "Qihua Zhou", "Zicong Hong", "Song Guo"], "title": "D$^{2}$MoE: Dual Routing and Dynamic Scheduling for Efficient On-Device MoE-based LLM Serving", "categories": ["cs.DC", "cs.AI"], "comment": "Accepted by MobiCom 2025", "summary": "The mixture of experts (MoE) model is a sparse variant of large language\nmodels (LLMs), designed to hold a better balance between intelligent capability\nand computational overhead. Despite its benefits, MoE is still too expensive to\ndeploy on resource-constrained edge devices, especially with the demands of\non-device inference services. Recent research efforts often apply model\ncompression techniques, such as quantization, pruning and merging, to restrict\nMoE complexity. Unfortunately, due to their predefined static model\noptimization strategies, they cannot always achieve the desired\nquality-overhead trade-off when handling multiple requests, finally degrading\nthe on-device quality of service. These limitations motivate us to propose the\nD$^2$MoE, an algorithm-system co-design framework that matches diverse task\nrequirements by dynamically allocating the most proper bit-width to each\nexpert. Specifically, inspired by the nested structure of matryoshka dolls, we\npropose the matryoshka weight quantization (MWQ) to progressively compress\nexpert weights in a bit-nested manner and reduce the required runtime memory.\nOn top of it, we further optimize the I/O-computation pipeline and design a\nheuristic scheduling algorithm following our hottest-expert-bit-first (HEBF)\nprinciple, which maximizes the expert parallelism between I/O and computation\nqueue under constrained memory budgets, thus significantly reducing the idle\ntemporal bubbles waiting for the experts to load. Evaluations on real edge\ndevices show that D$^2$MoE improves the overall inference throughput by up to\n1.39$\\times$ and reduces the peak memory footprint by up to 53% over the latest\non-device inference frameworks, while still preserving comparable serving\naccuracy as its INT8 counterparts."}
{"id": "2504.15594", "pdf": "https://arxiv.org/pdf/2504.15594", "abs": "https://arxiv.org/abs/2504.15594", "authors": ["Tatsuhito Hasegawa", "Shunsuke Sakai"], "title": "Analytical Softmax Temperature Setting from Feature Dimensions for Model- and Domain-Robust Classification", "categories": ["cs.LG", "cs.CV"], "comment": "22 pages, 11 figures, under review", "summary": "In deep learning-based classification tasks, the softmax function's\ntemperature parameter $T$ critically influences the output distribution and\noverall performance. This study presents a novel theoretical insight that the\noptimal temperature $T^*$ is uniquely determined by the dimensionality of the\nfeature representations, thereby enabling training-free determination of $T^*$.\nDespite this theoretical grounding, empirical evidence reveals that $T^*$\nfluctuates under practical conditions owing to variations in models, datasets,\nand other confounding factors. To address these influences, we propose and\noptimize a set of temperature determination coefficients that specify how $T^*$\nshould be adjusted based on the theoretical relationship to feature\ndimensionality. Additionally, we insert a batch normalization layer immediately\nbefore the output layer, effectively stabilizing the feature space. Building on\nthese coefficients and a suite of large-scale experiments, we develop an\nempirical formula to estimate $T^*$ without additional training while also\nintroducing a corrective scheme to refine $T^*$ based on the number of classes\nand task complexity. Our findings confirm that the derived temperature not only\naligns with the proposed theoretical perspective but also generalizes\neffectively across diverse tasks, consistently enhancing classification\nperformance and offering a practical, training-free solution for determining\n$T^*$."}
{"id": "2504.15914", "pdf": "https://arxiv.org/pdf/2504.15914", "abs": "https://arxiv.org/abs/2504.15914", "authors": ["Magne Erlandsen", "Tomas Meijer", "Maurice Heemels", "Sebastiaan van den Eijnden"], "title": "Continuity Conditions for Piecewise Quadratic Functions on Simplicial Conic Partitions are Equivalent", "categories": ["math.OC", "cs.SY", "eess.SY"], "comment": "8 pages, 2 figures", "summary": "Analysis of continuous-time piecewise linear (PWL) systems based on piecewise\nquadratic (PWQ) Lyapunov functions typically requires continuity of these\nfunctions over a partition of the state space. Several conditions for\nguaranteeing continuity of PWQ functions over state space partitions can be\nfound in the literature. In this technical note, we show that these continuity\nconditions are equivalent over so-called simplicial conic partitions. A key\nelement in our proof is a technical lemma, which, in addition to being of\nindependent interest, plays a crucial role in demonstrating the equivalence of\nthese conditions. As a consequence, the choice of which condition to impose can\nbe based solely on practical considerations such as specific application or\nnumerical aspects, without introducing additional conservatism in the analysis."}
{"id": "2504.15301", "pdf": "https://arxiv.org/pdf/2504.15301", "abs": "https://arxiv.org/abs/2504.15301", "authors": ["Zoi Lygizou", "Dimitris Kalles"], "title": "A biologically Inspired Trust Model for Open Multi-Agent Systems that is Resilient to Rapid Performance Fluctuations", "categories": ["cs.MA", "cs.AI", "cs.DC"], "comment": null, "summary": "Trust management provides an alternative solution for securing open, dynamic,\nand distributed multi-agent systems, where conventional cryptographic methods\nprove to be impractical. However, existing trust models face challenges related\nto agent mobility, changing behaviors, and the cold start problem. To address\nthese issues we introduced a biologically inspired trust model in which\ntrustees assess their own capabilities and store trust data locally. This\ndesign improves mobility support, reduces communication overhead, resists\ndisinformation, and preserves privacy. Despite these advantages, prior\nevaluations revealed limitations of our model in adapting to provider\npopulation changes and continuous performance fluctuations. This study proposes\na novel algorithm, incorporating a self-classification mechanism for providers\nto detect performance drops potentially harmful for the service consumers.\nSimulation results demonstrate that the new algorithm outperforms its original\nversion and FIRE, a well-known trust and reputation model, particularly in\nhandling dynamic trustee behavior. While FIRE remains competitive under extreme\nenvironmental changes, the proposed algorithm demonstrates greater adaptability\nacross various conditions. In contrast to existing trust modeling research,\nthis study conducts a comprehensive evaluation of our model using widely\nrecognized trust model criteria, assessing its resilience against common\ntrust-related attacks while identifying strengths, weaknesses, and potential\ncountermeasures. Finally, several key directions for future research are\nproposed."}
{"id": "2504.15613", "pdf": "https://arxiv.org/pdf/2504.15613", "abs": "https://arxiv.org/abs/2504.15613", "authors": ["Minglian Han"], "title": "Learning Dynamic Graphs via Tensorized and Lightweight Graph Convolutional Networks", "categories": ["cs.LG"], "comment": null, "summary": "A dynamic graph (DG) is frequently encountered in numerous real-world\nscenarios. Consequently, A dynamic graph convolutional network (DGCN) has been\nsuccessfully applied to perform precise representation learning on a DG.\nHowever, conventional DGCNs typically consist of a static GCN coupled with a\nsequence neural network (SNN) to model spatial and temporal patterns\nseparately. This decoupled modeling mechanism inherently disrupts the intricate\nspatio-temporal dependencies. To address the issue, this study proposes a novel\nTensorized Lightweight Graph Convolutional Network (TLGCN) for accurate dynamic\ngraph learning. It mainly contains the following two key concepts: a) designing\na novel spatio-temporal information propagation method for joint propagation of\nspatio-temporal information based on the tensor M-product framework; b)\nproposing a tensorized lightweight graph convolutional network based on the\nabove method, which significantly reduces the memory occupation of the model by\nomitting complex feature transformation and nonlinear activation. Numerical\nexperiments on four real-world datasets demonstrate that the proposed TLGCN\noutperforms the state-of-the-art models in the weight estimation task on DGs."}
{"id": "2504.16037", "pdf": "https://arxiv.org/pdf/2504.16037", "abs": "https://arxiv.org/abs/2504.16037", "authors": ["Haolin Liu", "Shiliang Zhang", "Shangbin Jiao", "Xiaohui Zhang", "Xuehui Ma", "Yan Yan", "Wenchuan Cui", "Youmin Zhang"], "title": "Adaptive Fault-tolerant Control of Underwater Vehicles with Thruster Failures", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper presents a fault-tolerant control for the trajectory tracking of\nautonomous underwater vehicles (AUVs) against thruster failures. We formulate\nfaults in AUV thrusters as discrete switching events during a UAV mission, and\ndevelop a soft-switching approach in facilitating shift of control strategies\nacross fault scenarios. We mathematically define AUV thruster fault scenarios,\nand develop the fault-tolerant control that captures the fault scenario via\nBayesian approach. Particularly, when the AUV fault type switches from one to\nanother, the developed control captures the fault states and maintains the\ncontrol by a linear quadratic tracking controller. With the captured fault\nstates by Bayesian approach, we derive the control law by aggregating the\ncontrol outputs for individual fault scenarios weighted by their Bayesian\nposterior probability. The developed fault-tolerant control works in an\nadaptive way and guarantees soft-switching across fault scenarios, and requires\nno complicated fault detection dedicated to different type of faults. The\nentailed soft-switching ensures stable AUV trajectory tracking when fault type\nshifts, which otherwise leads to reduced control under hard-switching control\nstrategies. We conduct numerical simulations with diverse AUV thruster fault\nsettings. The results demonstrate that the proposed control can provide smooth\ntransition across thruster failures, and effectively sustain AUV trajectory\ntracking control in case of thruster failures and failure shifts."}
{"id": "2504.15303", "pdf": "https://arxiv.org/pdf/2504.15303", "abs": "https://arxiv.org/abs/2504.15303", "authors": ["Yi Xiong", "Jinqi Huang", "Wenjie Huang", "Xuebing Yu", "Entong Li", "Zhixiong Ning", "Jinhua Zhou", "Li Zeng", "Xin Chen"], "title": "High-Throughput LLM inference on Heterogeneous Clusters", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Nowadays, many companies possess various types of AI accelerators, forming\nheterogeneous clusters. Efficiently leveraging these clusters for\nhigh-throughput large language model (LLM) inference services can significantly\nreduce costs and expedite task processing. However, LLM inference on\nheterogeneous clusters presents two main challenges. Firstly, different\ndeployment configurations can result in vastly different performance. The\nnumber of possible configurations is large, and evaluating the effectiveness of\na specific setup is complex. Thus, finding an optimal configuration is not an\neasy task. Secondly, LLM inference instances within a heterogeneous cluster\npossess varying processing capacities, leading to different processing speeds\nfor handling inference requests. Evaluating these capacities and designing a\nrequest scheduling algorithm that fully maximizes the potential of each\ninstance is challenging. In this paper, we propose a high-throughput inference\nservice system on heterogeneous clusters. First, the deployment configuration\nis optimized by modeling the resource amount and expected throughput and using\nthe exhaustive search method. Second, a novel mechanism is proposed to schedule\nrequests among instances, which fully considers the different processing\ncapabilities of various instances. Extensive experiments show that the proposed\nscheduler improves throughput by 122.5% and 33.6% on two heterogeneous\nclusters, respectively."}
{"id": "2504.15615", "pdf": "https://arxiv.org/pdf/2504.15615", "abs": "https://arxiv.org/abs/2504.15615", "authors": ["Jingwu Tang", "Jiayun Wu", "Zhiwei Steven Wu", "Jiahao Zhang"], "title": "Dimension-Free Decision Calibration for Nonlinear Loss Functions", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "When model predictions inform downstream decision making, a natural question\nis under what conditions can the decision-makers simply respond to the\npredictions as if they were the true outcomes. Calibration suffices to\nguarantee that simple best-response to predictions is optimal. However,\ncalibration for high-dimensional prediction outcome spaces requires exponential\ncomputational and statistical complexity. The recent relaxation known as\ndecision calibration ensures the optimality of the simple best-response rule\nwhile requiring only polynomial sample complexity in the dimension of outcomes.\nHowever, known results on calibration and decision calibration crucially rely\non linear loss functions for establishing best-response optimality. A natural\napproach to handle nonlinear losses is to map outcomes $y$ into a feature space\n$\\phi(y)$ of dimension $m$, then approximate losses with linear functions of\n$\\phi(y)$. Unfortunately, even simple classes of nonlinear functions can demand\nexponentially large or infinite feature dimensions $m$. A key open problem is\nwhether it is possible to achieve decision calibration with sample complexity\nindependent of~$m$. We begin with a negative result: even verifying decision\ncalibration under standard deterministic best response inherently requires\nsample complexity polynomial in~$m$. Motivated by this lower bound, we\ninvestigate a smooth version of decision calibration in which decision-makers\nfollow a smooth best-response. This smooth relaxation enables dimension-free\ndecision calibration algorithms. We introduce algorithms that, given\n$\\mathrm{poly}(|A|,1/\\epsilon)$ samples and any initial predictor~$p$, can\nefficiently post-process it to satisfy decision calibration without worsening\naccuracy. Our algorithms apply broadly to function classes that can be\nwell-approximated by bounded-norm functions in (possibly infinite-dimensional)\nseparable RKHS."}
{"id": "2504.15310", "pdf": "https://arxiv.org/pdf/2504.15310", "abs": "https://arxiv.org/abs/2504.15310", "authors": ["Syeda Tahreem Zahra", "Syed Kashif Imdad", "Sohail Khan", "Sohail Khalid", "Nauman Anwar Baig"], "title": "Power Transformer Health Index and Life Span Assessment: A Comprehensive Review of Conventional and Machine Learning based Approaches", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Power transformers play a critical role within the electrical power system,\nmaking their health assessment and the prediction of their remaining lifespan\nparamount for the purpose of ensuring efficient operation and facilitating\neffective maintenance planning. This paper undertakes a comprehensive\nexamination of existent literature, with a primary focus on both conventional\nand cutting-edge techniques employed within this domain. The merits and\ndemerits of recent methodologies and techniques are subjected to meticulous\nscrutiny and explication. Furthermore, this paper expounds upon intelligent\nfault diagnosis methodologies and delves into the most widely utilized\nintelligent algorithms for the assessment of transformer conditions. Diverse\nArtificial Intelligence (AI) approaches, including Artificial Neural Networks\n(ANN) and Convolutional Neural Network (CNN), Support Vector Machine (SVM),\nRandom Forest (RF), Genetic Algorithm (GA), and Particle Swarm Optimization\n(PSO), are elucidated offering pragmatic solutions for enhancing the\nperformance of transformer fault diagnosis. The amalgamation of multiple AI\nmethodologies and the exploration of timeseries analysis further contribute to\nthe augmentation of diagnostic precision and the early detection of faults in\ntransformers. By furnishing a comprehensive panorama of AI applications in the\nfield of transformer fault diagnosis, this study lays the groundwork for future\nresearch endeavors and the progression of this critical area of study."}
{"id": "2504.15616", "pdf": "https://arxiv.org/pdf/2504.15616", "abs": "https://arxiv.org/abs/2504.15616", "authors": ["Kai Chen", "Xiaodong Zhao", "Yujie Huang", "Guoyu Fang", "Xiao Song", "Ruiping Wang", "Ziyuan Wang"], "title": "SocialMOIF: Multi-Order Intention Fusion for Pedestrian Trajectory Prediction", "categories": ["cs.LG", "cs.CV"], "comment": "11 pages,6 figures", "summary": "The analysis and prediction of agent trajectories are crucial for\ndecision-making processes in intelligent systems, with precise short-term\ntrajectory forecasting being highly significant across a range of applications.\nAgents and their social interactions have been quantified and modeled by\nresearchers from various perspectives; however, substantial limitations exist\nin the current work due to the inherent high uncertainty of agent intentions\nand the complex higher-order influences among neighboring groups. SocialMOIF is\nproposed to tackle these challenges, concentrating on the higher-order\nintention interactions among neighboring groups while reinforcing the primary\nrole of first-order intention interactions between neighbors and the target\nagent. This method develops a multi-order intention fusion model to achieve a\nmore comprehensive understanding of both direct and indirect intention\ninformation. Within SocialMOIF, a trajectory distribution approximator is\ndesigned to guide the trajectories toward values that align more closely with\nthe actual data, thereby enhancing model interpretability. Furthermore, a\nglobal trajectory optimizer is introduced to enable more accurate and efficient\nparallel predictions. By incorporating a novel loss function that accounts for\ndistance and direction during training, experimental results demonstrate that\nthe model outperforms previous state-of-the-art baselines across multiple\nmetrics in both dynamic and static datasets."}
{"id": "2504.15311", "pdf": "https://arxiv.org/pdf/2504.15311", "abs": "https://arxiv.org/abs/2504.15311", "authors": ["Fei Shang", "Haohua Du", "Dawei Yan", "Panlong Yang", "Xiang-Yang Li"], "title": "RINN: One Sample Radio Frequency Imaging based on Physics Informed Neural Network", "categories": ["eess.IV", "cs.AI"], "comment": null, "summary": "Due to its ability to work in non-line-of-sight and low-light environments,\nradio frequency (RF) imaging technology is expected to bring new possibilities\nfor embodied intelligence and multimodal sensing. However, widely used RF\ndevices (such as Wi-Fi) often struggle to provide high-precision\nelectromagnetic measurements and large-scale datasets, hindering the\napplication of RF imaging technology. In this paper, we combine the ideas of\nPINN to design the RINN network, using physical constraints instead of true\nvalue comparison constraints and adapting it with the characteristics of\nubiquitous RF signals, allowing the RINN network to achieve RF imaging using\nonly one sample without phase and with amplitude noise. Our numerical\nevaluation results show that compared with 5 classic algorithms based on phase\ndata for imaging results, RINN's imaging results based on phaseless data are\ngood, with indicators such as RRMSE (0.11) performing similarly well. RINN\nprovides new possibilities for the universal development of radio frequency\nimaging technology."}
{"id": "2504.15623", "pdf": "https://arxiv.org/pdf/2504.15623", "abs": "https://arxiv.org/abs/2504.15623", "authors": ["Xiucheng Wang", "Qiming Zhang", "Nan Cheng", "Ruijin Sun", "Zan Li", "Shuguang Cui", "Xuemin Shen"], "title": "RadioDiff-$k^2$: Helmholtz Equation Informed Generative Diffusion Model for Multi-Path Aware Radio Map Construction", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "In this paper, we propose a novel physics-informed generative learning\napproach, termed RadioDiff-$\\bm{k^2}$, for accurate and efficient\nmultipath-aware radio map (RM) construction. As wireless communication evolves\ntowards environment-aware paradigms, driven by the increasing demand for\nintelligent and proactive optimization in sixth-generation (6G) networks,\naccurate construction of RMs becomes crucial yet highly challenging.\nConventional electromagnetic (EM)-based methods, such as full-wave solvers and\nray-tracing approaches, exhibit substantial computational overhead and limited\nadaptability to dynamic scenarios. Although, existing neural network (NN)\napproaches have efficient inferencing speed, they lack sufficient consideration\nof the underlying physics of EM wave propagation, limiting their effectiveness\nin accurately modeling critical EM singularities induced by complex multipath\nenvironments. To address these fundamental limitations, we propose a novel\nphysics-inspired RM construction method guided explicitly by the Helmholtz\nequation, which inherently governs EM wave propagation. Specifically, we\ntheoretically establish a direct correspondence between EM singularities, which\ncorrespond to the critical spatial features influencing wireless propagation,\nand regions defined by negative wave numbers in the Helmholtz equation. Based\non this insight, we design an innovative dual generative diffusion model (DM)\nframework comprising one DM dedicated to accurately inferring EM singularities\nand another DM responsible for reconstructing the complete RM using these\nsingularities along with environmental contextual information. Our\nphysics-informed approach uniquely combines the efficiency advantages of\ndata-driven methods with rigorous physics-based EM modeling, significantly\nenhancing RM accuracy, particularly in complex propagation environments\ndominated by multipath effects."}
{"id": "2504.15315", "pdf": "https://arxiv.org/pdf/2504.15315", "abs": "https://arxiv.org/abs/2504.15315", "authors": ["Noa Cohen", "Rotem Dror", "Itzik Klein"], "title": "Diffusion-Driven Inertial Generated Data for Smartphone Location Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite the crucial role of inertial measurements in motion tracking and\nnavigation systems, the time-consuming and resource-intensive nature of\ncollecting extensive inertial data has hindered the development of robust\nmachine learning models in this field. In recent years, diffusion models have\nemerged as a revolutionary class of generative models, reshaping the landscape\nof artificial data generation. These models surpass generative adversarial\nnetworks and other state-of-the-art approaches to complex tasks. In this work,\nwe propose diffusion-driven specific force-generated data for smartphone\nlocation recognition. We provide a comprehensive evaluation methodology by\ncomparing synthetic and real recorded specific force data across multiple\nmetrics. Our results demonstrate that our diffusion-based generative model\nsuccessfully captures the distinctive characteristics of specific force signals\nacross different smartphone placement conditions. Thus, by creating diverse,\nrealistic synthetic data, we can reduce the burden of extensive data collection\nwhile providing high-quality training data for machine learning models."}
{"id": "2504.15634", "pdf": "https://arxiv.org/pdf/2504.15634", "abs": "https://arxiv.org/abs/2504.15634", "authors": ["Peizheng Liu", "Hitoshi Iba"], "title": "Enhancing Reinforcement learning in 3-Dimensional Hydrophobic-Polar Protein Folding Model with Attention-based layers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformer-based architectures have recently propelled advances in sequence\nmodeling across domains, but their application to the hydrophobic-hydrophilic\n(H-P) model for protein folding remains relatively unexplored. In this work, we\nadapt a Deep Q-Network (DQN) integrated with attention mechanisms\n(Transformers) to address the 3D H-P protein folding problem. Our system\nformulates folding decisions as a self-avoiding walk in a reinforced\nenvironment, and employs a specialized reward function based on favorable\nhydrophobic interactions. To improve performance, the method incorporates\nvalidity check including symmetry-breaking constraints, dueling and double\nQ-learning, and prioritized replay to focus learning on critical transitions.\nExperimental evaluations on standard benchmark sequences demonstrate that our\napproach achieves several known best solutions for shorter sequences, and\nobtains near-optimal results for longer chains. This study underscores the\npromise of attention-based reinforcement learning for protein folding, and\ncreated a prototype of Transformer-based Q-network structure for 3-dimensional\nlattice models."}
{"id": "2504.15317", "pdf": "https://arxiv.org/pdf/2504.15317", "abs": "https://arxiv.org/abs/2504.15317", "authors": ["Meher Boulaabi", "Takwa Ben Aïcha Gader", "Afef Kacem Echi", "Zied Bouraoui"], "title": "Enhancing DR Classification with Swin Transformer and Shifted Window Attention", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Diabetic retinopathy (DR) is a leading cause of blindness worldwide,\nunderscoring the importance of early detection for effective treatment.\nHowever, automated DR classification remains challenging due to variations in\nimage quality, class imbalance, and pixel-level similarities that hinder model\ntraining. To address these issues, we propose a robust preprocessing pipeline\nincorporating image cropping, Contrast-Limited Adaptive Histogram Equalization\n(CLAHE), and targeted data augmentation to improve model generalization and\nresilience. Our approach leverages the Swin Transformer, which utilizes\nhierarchical token processing and shifted window attention to efficiently\ncapture fine-grained features while maintaining linear computational\ncomplexity. We validate our method on the Aptos and IDRiD datasets for\nmulti-class DR classification, achieving accuracy rates of 89.65% and 97.40%,\nrespectively. These results demonstrate the effectiveness of our model,\nparticularly in detecting early-stage DR, highlighting its potential for\nimproving automated retinal screening in clinical settings."}
{"id": "2504.15664", "pdf": "https://arxiv.org/pdf/2504.15664", "abs": "https://arxiv.org/abs/2504.15664", "authors": ["Phuong Quynh Le", "Jörg Schlötterer", "Christin Seifert"], "title": "An XAI-based Analysis of Shortcut Learning in Neural Networks", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted at The World Conference on eXplainable Artificial\n  Intelligence 2025 (XAI-2025)", "summary": "Machine learning models tend to learn spurious features - features that\nstrongly correlate with target labels but are not causal. Existing approaches\nto mitigate models' dependence on spurious features work in some cases, but\nfail in others. In this paper, we systematically analyze how and where neural\nnetworks encode spurious correlations. We introduce the neuron spurious score,\nan XAI-based diagnostic measure to quantify a neuron's dependence on spurious\nfeatures. We analyze both convolutional neural networks (CNNs) and vision\ntransformers (ViTs) using architecture-specific methods. Our results show that\nspurious features are partially disentangled, but the degree of disentanglement\nvaries across model architectures. Furthermore, we find that the assumptions\nbehind existing mitigation methods are incomplete. Our results lay the\ngroundwork for the development of novel methods to mitigate spurious\ncorrelations and make AI models safer to use in practice."}
{"id": "2504.15322", "pdf": "https://arxiv.org/pdf/2504.15322", "abs": "https://arxiv.org/abs/2504.15322", "authors": ["Xiao Zhou", "Yuze Sun", "Jie Wu", "Xiaomeng Huang"], "title": "How to systematically develop an effective AI-based bias correction model?", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": null, "summary": "This study introduces ReSA-ConvLSTM, an artificial intelligence (AI)\nframework for systematic bias correction in numerical weather prediction (NWP).\nWe propose three innovations by integrating dynamic climatological\nnormalization, ConvLSTM with temporal causality constraints, and residual\nself-attention mechanisms. The model establishes a physics-aware nonlinear\nmapping between ECMWF forecasts and ERA5 reanalysis data. Using 41 years\n(1981-2021) of global atmospheric data, the framework reduces systematic biases\nin 2-m air temperature (T2m), 10-m winds (U10/V10), and sea-level pressure\n(SLP), achieving up to 20% RMSE reduction over 1-7 day forecasts compared to\noperational ECMWF outputs. The lightweight architecture (10.6M parameters)\nenables efficient generalization to multiple variables and downstream\napplications, reducing retraining time by 85% for cross-variable correction\nwhile improving ocean model skill through bias-corrected boundary conditions.\nThe ablation experiments demonstrate that our innovations significantly improve\nthe model's correction performance, suggesting that incorporating variable\ncharacteristics into the model helps enhance forecasting skills."}
{"id": "2504.15686", "pdf": "https://arxiv.org/pdf/2504.15686", "abs": "https://arxiv.org/abs/2504.15686", "authors": ["Phuong Quynh Le", "Christin Seifert", "Jörg Schlötterer"], "title": "Invariant Learning with Annotation-free Environments", "categories": ["cs.LG"], "comment": "Accepted at NeurIPS 2024 Workshop UniReps", "summary": "Invariant learning is a promising approach to improve domain generalization\ncompared to Empirical Risk Minimization (ERM). However, most invariant learning\nmethods rely on the assumption that training examples are pre-partitioned into\ndifferent known environments. We instead infer environments without the need\nfor additional annotations, motivated by observations of the properties within\nthe representation space of a trained ERM model. We show the preliminary\neffectiveness of our approach on the ColoredMNIST benchmark, achieving\nperformance comparable to methods requiring explicit environment labels and on\npar with an annotation-free method that poses strong restrictions on the ERM\nreference model."}
{"id": "2504.15323", "pdf": "https://arxiv.org/pdf/2504.15323", "abs": "https://arxiv.org/abs/2504.15323", "authors": ["Donggyun Kim", "Chanwoo Kim", "Seunghoon Hong"], "title": "HyperFlow: Gradient-Free Emulation of Few-Shot Fine-Tuning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "While test-time fine-tuning is beneficial in few-shot learning, the need for\nmultiple backpropagation steps can be prohibitively expensive in real-time or\nlow-resource scenarios. To address this limitation, we propose an approach that\nemulates gradient descent without computing gradients, enabling efficient\ntest-time adaptation. Specifically, we formulate gradient descent as an Euler\ndiscretization of an ordinary differential equation (ODE) and train an\nauxiliary network to predict the task-conditional drift using only the few-shot\nsupport set. The adaptation then reduces to a simple numerical integration\n(e.g., via the Euler method), which requires only a few forward passes of the\nauxiliary network -- no gradients or forward passes of the target model are\nneeded. In experiments on cross-domain few-shot classification using the\nMeta-Dataset and CDFSL benchmarks, our method significantly improves\nout-of-domain performance over the non-fine-tuned baseline while incurring only\n6\\% of the memory cost and 0.02\\% of the computation time of standard\nfine-tuning, thus establishing a practical middle ground between direct\ntransfer and fully fine-tuned approaches."}
{"id": "2504.15736", "pdf": "https://arxiv.org/pdf/2504.15736", "abs": "https://arxiv.org/abs/2504.15736", "authors": ["Jiawen Wu", "Bingguang Chen", "Yuyi Zhou", "Qi Meng", "Rongchan Zhu", "Zhi-Ming Ma"], "title": "Riemannian Neural Geodesic Interpolant", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Stochastic interpolants are efficient generative models that bridge two\narbitrary probability density functions in finite time, enabling flexible\ngeneration from the source to the target distribution or vice versa. These\nmodels are primarily developed in Euclidean space, and are therefore limited in\ntheir application to many distribution learning problems defined on Riemannian\nmanifolds in real-world scenarios. In this work, we introduce the Riemannian\nNeural Geodesic Interpolant (RNGI) model, which interpolates between two\nprobability densities on a Riemannian manifold along the stochastic geodesics,\nand then samples from one endpoint as the final state using the continuous flow\noriginating from the other endpoint. We prove that the temporal marginal\ndensity of RNGI solves a transport equation on the Riemannian manifold. After\ntraining the model's the neural velocity and score fields, we propose the\nEmbedding Stochastic Differential Equation (E-SDE) algorithm for stochastic\nsampling of RNGI. E-SDE significantly improves the sampling quality by reducing\nthe accumulated error caused by the excessive intrinsic discretization of\nRiemannian Brownian motion in the classical Geodesic Random Walk (GRW)\nalgorithm. We also provide theoretical bounds on the generative bias measured\nin terms of KL-divergence. Finally, we demonstrate the effectiveness of the\nproposed RNGI and E-SDE through experiments conducted on both collected and\nsynthetic distributions on S2 and SO(3)."}
{"id": "2504.15324", "pdf": "https://arxiv.org/pdf/2504.15324", "abs": "https://arxiv.org/abs/2504.15324", "authors": ["Vuong M. Ngo", "Edward Bolger", "Stan Goodwin", "John O'Sullivan", "Dinh Viet Cuong", "Mark Roantree"], "title": "A Graph Based Raman Spectral Processing Technique for Exosome Classification", "categories": ["q-bio.QM", "cs.AI", "cs.IT", "cs.LG", "math.IT"], "comment": "The 23rd International Conference on Artificial Intelligence in\n  Medicine (AIME 2025), LNAI, Springer, 11 pages", "summary": "Exosomes are small vesicles crucial for cell signaling and disease\nbiomarkers. Due to their complexity, an \"omics\" approach is preferable to\nindividual biomarkers. While Raman spectroscopy is effective for exosome\nanalysis, it requires high sample concentrations and has limited sensitivity to\nlipids and proteins. Surface-enhanced Raman spectroscopy helps overcome these\nchallenges. In this study, we leverage Neo4j graph databases to organize 3,045\nRaman spectra of exosomes, enhancing data generalization. To further refine\nspectral analysis, we introduce a novel spectral filtering process that\nintegrates the PageRank Filter with optimal Dimensionality Reduction. This\nmethod improves feature selection, resulting in superior classification\nperformance. Specifically, the Extra Trees model, using our spectral processing\napproach, achieves 0.76 and 0.857 accuracy in classifying hyperglycemic,\nhypoglycemic, and normal exosome samples based on Raman spectra and surface,\nrespectively, with group 10-fold cross-validation. Our results show that\ngraph-based spectral filtering combined with optimal dimensionality reduction\nsignificantly improves classification accuracy by reducing noise while\npreserving key biomarker signals. This novel framework enhances Raman-based\nexosome analysis, expanding its potential for biomedical applications, disease\ndiagnostics, and biomarker discovery."}
{"id": "2504.15758", "pdf": "https://arxiv.org/pdf/2504.15758", "abs": "https://arxiv.org/abs/2504.15758", "authors": ["Andrew Gracyk"], "title": "Observability conditions for neural state-space models with eigenvalues and their roots of unity", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.DS", "math.OC"], "comment": "First version", "summary": "We operate through the lens of ordinary differential equations and control\ntheory to study the concept of observability in the context of neural\nstate-space models and the Mamba architecture. We develop strategies to enforce\nobservability, which are tailored to a learning context, specifically where the\nhidden states are learnable at initial time, in conjunction to over its\ncontinuum, and high-dimensional. We also highlight our methods emphasize\neigenvalues, roots of unity, or both. Our methods effectuate computational\nefficiency when enforcing observability, sometimes at great scale. We formulate\nobservability conditions in machine learning based on classical control theory\nand discuss their computational complexity. Our nontrivial results are\nfivefold. We discuss observability through the use of permutations in neural\napplications with learnable matrices without high precision. We present two\nresults built upon the Fourier transform that effect observability with high\nprobability up to the randomness in the learning. These results are worked with\nthe interplay of representations in Fourier space and their eigenstructure,\nnonlinear mappings, and the observability matrix. We present a result for Mamba\nthat is similar to a Hautus-type condition, but instead employs an argument\nusing a Vandermonde matrix instead of eigenvectors. Our final result is a\nshared-parameter construction of the Mamba system, which is computationally\nefficient in high exponentiation. We develop a training algorithm with this\ncoupling, showing it satisfies a Robbins-Monro condition under certain\northogonality, while a more classical training procedure fails to satisfy a\ncontraction with high Lipschitz constant."}
{"id": "2504.15325", "pdf": "https://arxiv.org/pdf/2504.15325", "abs": "https://arxiv.org/abs/2504.15325", "authors": ["Alberto Casagrande", "Francesco Fabris", "Rossano Girometti", "Roberto Pagliarini"], "title": "Significativity Indices for Agreement Values", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "27 pages, 6 figures", "summary": "Agreement measures, such as Cohen's kappa or intraclass correlation, gauge\nthe matching between two or more classifiers. They are used in a wide range of\ncontexts from medicine, where they evaluate the effectiveness of medical\ntreatments and clinical trials, to artificial intelligence, where they can\nquantify the approximation due to the reduction of a classifier. The\nconsistency of different classifiers to a golden standard can be compared\nsimply by using the order induced by their agreement measure with respect to\nthe golden standard itself. Nevertheless, labelling an approach as good or bad\nexclusively by using the value of an agreement measure requires a scale or a\nsignificativity index. Some quality scales have been proposed in the literature\nfor Cohen's kappa, but they are mainly naive, and their boundaries are\narbitrary. This work proposes a general approach to evaluate the\nsignificativity of any agreement value between two classifiers and introduces\ntwo significativity indices: one dealing with finite data sets, the other one\nhandling classification probability distributions. Moreover, this manuscript\nconsiders the computational issues of evaluating such indices and identifies\nsome efficient algorithms to evaluate them."}
{"id": "2504.15771", "pdf": "https://arxiv.org/pdf/2504.15771", "abs": "https://arxiv.org/abs/2504.15771", "authors": ["Assaf Gerner", "Netta Madvil", "Nadav Barak", "Alex Zaikman", "Jonatan Liberman", "Liron Hamra", "Rotem Brazilay", "Shay Tsadok", "Yaron Friedman", "Neal Harow", "Noam Bresler", "Shir Chorev", "Philip Tannor"], "title": "Grounded in Context: Retrieval-Based Method for Hallucination Detection", "categories": ["cs.LG"], "comment": null, "summary": "Despite advancements in grounded content generation, production Large\nLanguage Models (LLMs) based applications still suffer from hallucinated\nanswers. We present \"Grounded in Context\" - Deepchecks' hallucination detection\nframework, designed for production-scale long-context data and tailored to\ndiverse use cases, including summarization, data extraction, and RAG. Inspired\nby RAG architecture, our method integrates retrieval and Natural Language\nInference (NLI) models to predict factual consistency between premises and\nhypotheses using an encoder-based model with only a 512-token context window.\nOur framework identifies unsupported claims with an F1 score of 0.83 in\nRAGTruth's response-level classification task, matching methods that trained on\nthe dataset, and outperforming all comparable frameworks using similar-sized\nmodels."}
{"id": "2504.15328", "pdf": "https://arxiv.org/pdf/2504.15328", "abs": "https://arxiv.org/abs/2504.15328", "authors": ["Usevalad Milasheuski", "Luca Barbieri", "Sanaz Kianoush", "Monica Nicoli", "Stefano Savazzi"], "title": "Bayesian Federated Learning for Continual Training", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Bayesian Federated Learning (BFL) enables uncertainty quantification and\nrobust adaptation in distributed learning. In contrast to the frequentist\napproach, it estimates the posterior distribution of a global model, offering\ninsights into model reliability. However, current BFL methods neglect continual\nlearning challenges in dynamic environments where data distributions shift over\ntime. We propose a continual BFL framework applied to human sensing with radar\ndata collected over several days. Using Stochastic Gradient Langevin Dynamics\n(SGLD), our approach sequentially updates the model, leveraging past posteriors\nto construct the prior for the new tasks. We assess the accuracy, the expected\ncalibration error (ECE) and the convergence speed of our approach against\nseveral baselines. Results highlight the effectiveness of continual Bayesian\nupdates in preserving knowledge and adapting to evolving data."}
{"id": "2504.15773", "pdf": "https://arxiv.org/pdf/2504.15773", "abs": "https://arxiv.org/abs/2504.15773", "authors": ["Cong Liu", "Sharvaree Vadgama", "David Ruhe", "Erik Bekkers", "Patrick Forrè"], "title": "Clifford Group Equivariant Diffusion Models for 3D Molecular Generation", "categories": ["cs.LG", "cs.AI"], "comment": "7 pages, 1 figure, 1 table", "summary": "This paper explores leveraging the Clifford algebra's expressive power for\n$\\E(n)$-equivariant diffusion models. We utilize the geometric products between\nClifford multivectors and the rich geometric information encoded in Clifford\nsubspaces in \\emph{Clifford Diffusion Models} (CDMs). We extend the diffusion\nprocess beyond just Clifford one-vectors to incorporate all higher-grade\nmultivector subspaces. The data is embedded in grade-$k$ subspaces, allowing us\nto apply latent diffusion across complete multivectors. This enables CDMs to\ncapture the joint distribution across different subspaces of the algebra,\nincorporating richer geometric information through higher-order features. We\nprovide empirical results for unconditional molecular generation on the QM9\ndataset, showing that CDMs provide a promising avenue for generative modeling."}
{"id": "2504.15330", "pdf": "https://arxiv.org/pdf/2504.15330", "abs": "https://arxiv.org/abs/2504.15330", "authors": ["Mohit Gupta", "Akiko Aizawa", "Rajiv Ratn Shah"], "title": "Med-CoDE: Medical Critique based Disagreement Evaluation Framework", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "8 pages, 4 figures, NAACL SRW 2025", "summary": "The emergence of large language models (LLMs) has significantly influenced\nnumerous fields, including healthcare, by enhancing the capabilities of\nautomated systems to process and generate human-like text. However, despite\ntheir advancements, the reliability and accuracy of LLMs in medical contexts\nremain critical concerns. Current evaluation methods often lack robustness and\nfail to provide a comprehensive assessment of LLM performance, leading to\npotential risks in clinical settings. In this work, we propose Med-CoDE, a\nspecifically designed evaluation framework for medical LLMs to address these\nchallenges. The framework leverages a critique-based approach to quantitatively\nmeasure the degree of disagreement between model-generated responses and\nestablished medical ground truths. This framework captures both accuracy and\nreliability in medical settings. The proposed evaluation framework aims to fill\nthe existing gap in LLM assessment by offering a systematic method to evaluate\nthe quality and trustworthiness of medical LLMs. Through extensive experiments\nand case studies, we illustrate the practicality of our framework in providing\na comprehensive and reliable evaluation of medical LLMs."}
{"id": "2504.15806", "pdf": "https://arxiv.org/pdf/2504.15806", "abs": "https://arxiv.org/abs/2504.15806", "authors": ["Kai Luo", "Juan Tang", "Mingchao Cai", "Xiaoqing Zeng", "Manqi Xie", "Ming Yan"], "title": "DAE-KAN: A Kolmogorov-Arnold Network Model for High-Index Differential-Algebraic Equations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to\nMulti-Layer Perceptrons (MLPs) due to their superior function-fitting abilities\nin data-driven modeling. In this paper, we propose a novel framework, DAE-KAN,\nfor solving high-index differential-algebraic equations (DAEs) by integrating\nKANs with Physics-Informed Neural Networks (PINNs). This framework not only\npreserves the ability of traditional PINNs to model complex systems governed by\nphysical laws but also enhances their performance by leveraging the\nfunction-fitting strengths of KANs. Numerical experiments demonstrate that for\nDAE systems ranging from index-1 to index-3, DAE-KAN reduces the absolute\nerrors of both differential and algebraic variables by 1 to 2 orders of\nmagnitude compared to traditional PINNs. To assess the effectiveness of this\napproach, we analyze the drift-off error and find that both PINNs and DAE-KAN\noutperform classical numerical methods in controlling this phenomenon. Our\nresults highlight the potential of neural network methods, particularly\nDAE-KAN, in solving high-index DAEs with substantial computational accuracy and\ngeneralization, offering a promising solution for challenging partial\ndifferential-algebraic equations."}
{"id": "2504.15369", "pdf": "https://arxiv.org/pdf/2504.15369", "abs": "https://arxiv.org/abs/2504.15369", "authors": ["Calvin Luo", "Zilai Zeng", "Yilun Du", "Chen Sun"], "title": "Solving New Tasks by Adapting Internet Video Knowledge", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "ICLR 2025. Project Webpage:\n  https://diffusion-supervision.github.io/adapt2act/", "summary": "Video generative models demonstrate great promise in robotics by serving as\nvisual planners or as policy supervisors. When pretrained on internet-scale\ndata, such video models intimately understand alignment with natural language,\nand can thus facilitate generalization to novel downstream behavior through\ntext-conditioning. However, they may not be sensitive to the specificities of\nthe particular environment the agent inhabits. On the other hand, training\nvideo models on in-domain examples of robotic behavior naturally encodes\nenvironment-specific intricacies, but the scale of available demonstrations may\nnot be sufficient to support generalization to unseen tasks via natural\nlanguage specification. In this work, we investigate different adaptation\ntechniques that integrate in-domain information with large-scale pretrained\nvideo models, and explore the extent to which they enable novel\ntext-conditioned generalization for robotic tasks, while also considering their\nindependent data and resource considerations. We successfully demonstrate\nacross robotic environments that adapting powerful video models with small\nscales of example data can successfully facilitate generalization to novel\nbehaviors. In particular, we present a novel adaptation strategy, termed\nInverse Probabilistic Adaptation, that not only consistently achieves strong\ngeneralization performance across robotic tasks and settings, but also exhibits\nrobustness to the quality of adaptation data, successfully solving novel tasks\neven when only suboptimal in-domain demonstrations are available."}
{"id": "2504.15812", "pdf": "https://arxiv.org/pdf/2504.15812", "abs": "https://arxiv.org/abs/2504.15812", "authors": ["Xuchuang Wang", "Qirun Zeng", "Jinhang Zuo", "Xutong Liu", "Mohammad Hajiesmaili", "John C. S. Lui", "Adam Wierman"], "title": "Fusing Reward and Dueling Feedback in Stochastic Bandits", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper investigates the fusion of absolute (reward) and relative\n(dueling) feedback in stochastic bandits, where both feedback types are\ngathered in each decision round. We derive a regret lower bound, demonstrating\nthat an efficient algorithm may incur only the smaller among the reward and\ndueling-based regret for each individual arm. We propose two fusion approaches:\n(1) a simple elimination fusion algorithm that leverages both feedback types to\nexplore all arms and unifies collected information by sharing a common\ncandidate arm set, and (2) a decomposition fusion algorithm that selects the\nmore effective feedback to explore the corresponding arms and randomly assigns\none feedback type for exploration and the other for exploitation in each round.\nThe elimination fusion experiences a suboptimal multiplicative term of the\nnumber of arms in regret due to the intrinsic suboptimality of dueling\nelimination. In contrast, the decomposition fusion achieves regret matching the\nlower bound up to a constant under a common assumption. Extensive experiments\nconfirm the efficacy of our algorithms and theoretical results."}
{"id": "2504.15376", "pdf": "https://arxiv.org/pdf/2504.15376", "abs": "https://arxiv.org/abs/2504.15376", "authors": ["Zhiqiu Lin", "Siyuan Cen", "Daniel Jiang", "Jay Karhade", "Hewei Wang", "Chancharik Mitra", "Tiffany Ling", "Yuhan Huang", "Sifan Liu", "Mingyu Chen", "Rushikesh Zawar", "Xue Bai", "Yilun Du", "Chuang Gan", "Deva Ramanan"], "title": "Towards Understanding Camera Motions in Any Video", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "comment": "Project site: https://linzhiqiu.github.io/papers/camerabench/", "summary": "We introduce CameraBench, a large-scale dataset and benchmark designed to\nassess and improve camera motion understanding. CameraBench consists of ~3,000\ndiverse internet videos, annotated by experts through a rigorous multi-stage\nquality control process. One of our contributions is a taxonomy of camera\nmotion primitives, designed in collaboration with cinematographers. We find,\nfor example, that some motions like \"follow\" (or tracking) require\nunderstanding scene content like moving subjects. We conduct a large-scale\nhuman study to quantify human annotation performance, revealing that domain\nexpertise and tutorial-based training can significantly enhance accuracy. For\nexample, a novice may confuse zoom-in (a change of intrinsics) with translating\nforward (a change of extrinsics), but can be trained to differentiate the two.\nUsing CameraBench, we evaluate Structure-from-Motion (SfM) and Video-Language\nModels (VLMs), finding that SfM models struggle to capture semantic primitives\nthat depend on scene content, while VLMs struggle to capture geometric\nprimitives that require precise estimation of trajectories. We then fine-tune a\ngenerative VLM on CameraBench to achieve the best of both worlds and showcase\nits applications, including motion-augmented captioning, video question\nanswering, and video-text retrieval. We hope our taxonomy, benchmark, and\ntutorials will drive future efforts towards the ultimate goal of understanding\ncamera motions in any video."}
{"id": "2504.15827", "pdf": "https://arxiv.org/pdf/2504.15827", "abs": "https://arxiv.org/abs/2504.15827", "authors": ["Xuyang Zhong", "Haochen Luo", "Chen Liu"], "title": "DualOptim: Enhancing Efficacy and Stability in Machine Unlearning with Dual Optimizers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Existing machine unlearning (MU) approaches exhibit significant sensitivity\nto hyperparameters, requiring meticulous tuning that limits practical\ndeployment. In this work, we first empirically demonstrate the instability and\nsuboptimal performance of existing popular MU methods when deployed in\ndifferent scenarios. To address this issue, we propose Dual Optimizer\n(DualOptim), which incorporates adaptive learning rate and decoupled momentum\nfactors. Empirical and theoretical evidence demonstrates that DualOptim\ncontributes to effective and stable unlearning. Through extensive experiments,\nwe show that DualOptim can significantly boost MU efficacy and stability across\ndiverse tasks, including image classification, image generation, and large\nlanguage models, making it a versatile approach to empower existing MU\nalgorithms."}
{"id": "2504.15417", "pdf": "https://arxiv.org/pdf/2504.15417", "abs": "https://arxiv.org/abs/2504.15417", "authors": ["Van-Giang Trinh", "Belaid Benhamou", "Sylvain Soliman", "François Fages"], "title": "On the Boolean Network Theory of Datalog$^\\neg$", "categories": ["cs.LO", "cs.AI"], "comment": "48 pages, 7 figures", "summary": "Datalog$^\\neg$ is a central formalism used in a variety of domains ranging\nfrom deductive databases and abstract argumentation frameworks to answer set\nprogramming. Its model theory is the finite counterpart of the logical\nsemantics developed for normal logic programs, mainly based on the notions of\nClark's completion and two-valued or three-valued canonical models including\nsupported, stable, regular and well-founded models. In this paper we establish\na formal link between Datalog$^\\neg$ and Boolean network theory, which was\ninitially introduced by Stuart Kaufman and Ren\\'e Thomas to reason about gene\nregulatory networks. We use previous results from Boolean network theory to\nprove that in the absence of odd cycles in a Datalog$^\\neg$ program, the\nregular models coincide with the stable models, which entails the existence of\nstable models, and in the absence of even cycles, we show the uniqueness of\nstable partial models, which entails the uniqueness of regular models. These\nresults on regular models have been claimed by You and Yuan in 1994 for normal\nlogic programs but we show problems in their definition of well-founded\nstratification and in their proofs that we can fix for negative normal logic\nprograms only. We also give upper bounds on the numbers of stable partial,\nregular, and stable models of a Datalog$^\\neg$ program using the cardinality of\na feedback vertex set in its atom dependency graph. Interestingly, our\nconnection to Boolean network theory also points us to the notion of trap\nspaces for Datalog$^\\neg$ programs. We relate the notions of supported or\nstable trap spaces to the other semantics of Datalog$^\\neg$, and show the\nequivalence between subset-minimal stable trap spaces and regular models."}
{"id": "2504.15846", "pdf": "https://arxiv.org/pdf/2504.15846", "abs": "https://arxiv.org/abs/2504.15846", "authors": ["Jonah Ekelund", "Savvas Raptis", "Vicki Toy-Edens", "Wenli Mo", "Drew L. Turner", "Ian J. Cohen", "Stefano Markidis"], "title": "Adaptive PCA-Based Outlier Detection for Multi-Feature Time Series in Space Missions", "categories": ["cs.LG", "physics.space-ph"], "comment": "Accepted to ICCS 2025", "summary": "Analyzing multi-featured time series data is critical for space missions\nmaking efficient event detection, potentially onboard, essential for automatic\nanalysis. However, limited onboard computational resources and data downlink\nconstraints necessitate robust methods for identifying regions of interest in\nreal time. This work presents an adaptive outlier detection algorithm based on\nthe reconstruction error of Principal Component Analysis (PCA) for feature\nreduction, designed explicitly for space mission applications. The algorithm\nadapts dynamically to evolving data distributions by using Incremental PCA,\nenabling deployment without a predefined model for all possible conditions. A\npre-scaling process normalizes each feature's magnitude while preserving\nrelative variance within feature types. We demonstrate the algorithm's\neffectiveness in detecting space plasma events, such as distinct space\nenvironments, dayside and nightside transients phenomena, and transition layers\nthrough NASA's MMS mission observations. Additionally, we apply the method to\nNASA's THEMIS data, successfully identifying a dayside transient using\nonboard-available measurements."}
{"id": "2504.15424", "pdf": "https://arxiv.org/pdf/2504.15424", "abs": "https://arxiv.org/abs/2504.15424", "authors": ["Nishath Rajiv Ranasinghe", "Shawn M. Jones", "Michal Kucer", "Ayan Biswas", "Daniel O'Malley", "Alexander Buschmann Most", "Selma Liliane Wanna", "Ajay Sreekumar"], "title": "LLM-Assisted Translation of Legacy FORTRAN Codes to C++: A Cross-Platform Study", "categories": ["cs.SE", "cs.AI", "I.2.2; I.2.7; D.2.3; D.2.4"], "comment": "12 pages, 7 figures, 2 tables", "summary": "Large Language Models (LLMs) are increasingly being leveraged for generating\nand translating scientific computer codes by both domain-experts and non-domain\nexperts. Fortran has served as one of the go to programming languages in legacy\nhigh-performance computing (HPC) for scientific discoveries. Despite growing\nadoption, LLM-based code translation of legacy code-bases has not been\nthoroughly assessed or quantified for its usability. Here, we studied the\napplicability of LLM-based translation of Fortran to C++ as a step towards\nbuilding an agentic-workflow using open-weight LLMs on two different\ncomputational platforms. We statistically quantified the compilation accuracy\nof the translated C++ codes, measured the similarity of the LLM translated code\nto the human translated C++ code, and statistically quantified the output\nsimilarity of the Fortran to C++ translation."}
{"id": "2504.15854", "pdf": "https://arxiv.org/pdf/2504.15854", "abs": "https://arxiv.org/abs/2504.15854", "authors": ["Georgios Mavroudeas", "Malik Magdon-Ismail", "Kristin P. Bennett", "Jason Kuruzovich"], "title": "Consistent Causal Inference of Group Effects in Non-Targeted Trials with Finitely Many Effect Levels", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "A treatment may be appropriate for some group (the ``sick\" group) on whom it\nhas a positive effect, but it can also have a detrimental effect on subjects\nfrom another group (the ``healthy\" group). In a non-targeted trial both sick\nand healthy subjects may be treated, producing heterogeneous effects within the\ntreated group. Inferring the correct treatment effect on the sick population is\nthen difficult, because the effects on the different groups get tangled. We\npropose an efficient nonparametric approach to estimating the group effects,\ncalled {\\bf PCM} (pre-cluster and merge). We prove its asymptotic consistency\nin a general setting and show, on synthetic data, more than a 10x improvement\nin accuracy over existing state-of-the-art. Our approach applies more generally\nto consistent estimation of functions with a finite range."}
{"id": "2504.15425", "pdf": "https://arxiv.org/pdf/2504.15425", "abs": "https://arxiv.org/abs/2504.15425", "authors": ["Songyuan Zhang", "Oswin So", "Mitchell Black", "Zachary Serlin", "Chuchu Fan"], "title": "Solving Multi-Agent Safe Optimal Control with Distributed Epigraph Form MARL", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA", "math.OC"], "comment": "28 pages, 16 figures; Accepted by Robotics: Science and Systems 2025", "summary": "Tasks for multi-robot systems often require the robots to collaborate and\ncomplete a team goal while maintaining safety. This problem is usually\nformalized as a constrained Markov decision process (CMDP), which targets\nminimizing a global cost and bringing the mean of constraint violation below a\nuser-defined threshold. Inspired by real-world robotic applications, we define\nsafety as zero constraint violation. While many safe multi-agent reinforcement\nlearning (MARL) algorithms have been proposed to solve CMDPs, these algorithms\nsuffer from unstable training in this setting. To tackle this, we use the\nepigraph form for constrained optimization to improve training stability and\nprove that the centralized epigraph form problem can be solved in a distributed\nfashion by each agent. This results in a novel centralized training distributed\nexecution MARL algorithm named Def-MARL. Simulation experiments on 8 different\ntasks across 2 different simulators show that Def-MARL achieves the best\noverall performance, satisfies safety constraints, and maintains stable\ntraining. Real-world hardware experiments on Crazyflie quadcopters demonstrate\nthe ability of Def-MARL to safely coordinate agents to complete complex\ncollaborative tasks compared to other methods."}
{"id": "2504.15897", "pdf": "https://arxiv.org/pdf/2504.15897", "abs": "https://arxiv.org/abs/2504.15897", "authors": ["Zherui Yang", "Zhengyang Xue", "Ligang Liu"], "title": "SUPRA: Subspace Parameterized Attention for Neural Operator on General Domains", "categories": ["cs.LG"], "comment": null, "summary": "Neural operators are efficient surrogate models for solving partial\ndifferential equations (PDEs), but their key components face challenges: (1) in\norder to improve accuracy, attention mechanisms suffer from computational\ninefficiency on large-scale meshes, and (2) spectral convolutions rely on the\nFast Fourier Transform (FFT) on regular grids and assume a flat geometry, which\ncauses accuracy degradation on irregular domains. To tackle these problems, we\nregard the matrix-vector operations in the standard attention mechanism on\nvectors in Euclidean space as bilinear forms and linear operators in vector\nspaces and generalize the attention mechanism to function spaces. This new\nattention mechanism is fully equivalent to the standard attention but\nimpossible to compute due to the infinite dimensionality of function spaces. To\naddress this, inspired by model reduction techniques, we propose a Subspace\nParameterized Attention (SUPRA) neural operator, which approximates the\nattention mechanism within a finite-dimensional subspace. To construct a\nsubspace on irregular domains for SUPRA, we propose using the Laplacian\neigenfunctions, which naturally adapt to domains' geometry and guarantee the\noptimal approximation for smooth functions. Experiments show that the SUPRA\nneural operator reduces error rates by up to 33% on various PDE datasets while\nmaintaining state-of-the-art computational efficiency."}
{"id": "2504.15431", "pdf": "https://arxiv.org/pdf/2504.15431", "abs": "https://arxiv.org/abs/2504.15431", "authors": ["Sungjun Han", "Juyoung Suk", "Suyeong An", "Hyungguk Kim", "Kyuseok Kim", "Wonsuk Yang", "Seungtaek Choi", "Jamin Shin"], "title": "Trillion 7B Technical Report", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Preview version", "summary": "We introduce Trillion-7B, the most token-efficient Korean-centric\nmultilingual LLM available. Our novel Cross-lingual Document Attention (XLDA)\nmechanism enables highly efficient and effective knowledge transfer from\nEnglish to target languages like Korean and Japanese. Combined with optimized\ndata mixtures, language-specific filtering, and tailored tokenizer\nconstruction, Trillion-7B achieves competitive performance while dedicating\nonly 10\\% of its 2T training tokens to multilingual data and requiring just\n59.4K H100 GPU hours (\\$148K) for full training. Comprehensive evaluations\nacross 27 benchmarks in four languages demonstrate Trillion-7B's robust\nmultilingual performance and exceptional cross-lingual consistency."}
{"id": "2504.15905", "pdf": "https://arxiv.org/pdf/2504.15905", "abs": "https://arxiv.org/abs/2504.15905", "authors": ["Wenjing Xiao", "Chenglong Shi", "Miaojiang Chen", "Zhiquan Liu", "Min Chen", "H. Herbert Song"], "title": "GraphEdge: Dynamic Graph Partition and Task Scheduling for GNNs Computing in Edge Network", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages,12 figures", "summary": "With the exponential growth of Internet of Things (IoT) devices, edge\ncomputing (EC) is gradually playing an important role in providing\ncost-effective services. However, existing approaches struggle to perform well\nin graph-structured scenarios where user data is correlated, such as traffic\nflow prediction and social relationship recommender systems. In particular,\ngraph neural network (GNN)-based approaches lead to expensive server\ncommunication cost. To address this problem, we propose GraphEdge, an efficient\nGNN-based EC architecture. It considers the EC system of GNN tasks, where there\nare associations between users and it needs to take into account the task data\nof its neighbors when processing the tasks of a user. Specifically, the\narchitecture first perceives the user topology and represents their data\nassociations as a graph layout at each time step. Then the graph layout is\noptimized by calling our proposed hierarchical traversal graph cut algorithm\n(HiCut), which cuts the graph layout into multiple weakly associated subgraphs\nbased on the aggregation characteristics of GNN, and the communication cost\nbetween different subgraphs during GNN inference is minimized. Finally, based\non the optimized graph layout, our proposed deep reinforcement learning (DRL)\nbased graph offloading algorithm (DRLGO) is executed to obtain the optimal\noffloading strategy for the tasks of users, the offloading strategy is\nsubgraph-based, it tries to offload user tasks in a subgraph to the same edge\nserver as possible while minimizing the task processing time and energy\nconsumption of the EC system. Experimental results show the good effectiveness\nand dynamic adaptation of our proposed architecture and it also performs well\neven in dynamic scenarios."}
{"id": "2504.15440", "pdf": "https://arxiv.org/pdf/2504.15440", "abs": "https://arxiv.org/abs/2504.15440", "authors": ["Andrey Fradkin"], "title": "Demand for LLMs: Descriptive Evidence on Substitution, Market Expansion, and Multihoming", "categories": ["cs.CY", "cs.AI", "econ.GN", "q-fin.EC", "K.4; I.2"], "comment": null, "summary": "This paper documents three stylized facts about the demand for Large Language\nModels (LLMs) using data from OpenRouter, a prominent LLM marketplace. First,\nnew models experience rapid initial adoption that stabilizes within weeks.\nSecond, model releases differ substantially in whether they primarily attract\nnew users or substitute demand from competing models. Third, multihoming, using\nmultiple models simultaneously, is common among apps. These findings suggest\nsignificant horizontal and vertical differentiation in the LLM market, implying\nopportunities for providers to maintain demand and pricing power despite rapid\ntechnological advances."}
{"id": "2504.15920", "pdf": "https://arxiv.org/pdf/2504.15920", "abs": "https://arxiv.org/abs/2504.15920", "authors": ["Xiang Li", "Haobing Liu", "Jianpeng Qi", "Yuan Cao", "Guoqing Chao", "Yanwei Yu"], "title": "ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order Neighboring Feature Fusion", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated strong performance across\nvarious graph-based tasks by effectively capturing relational information\nbetween nodes. These models rely on iterative message passing to propagate node\nfeatures, enabling nodes to aggregate information from their neighbors. Recent\nresearch has significantly improved the message-passing mechanism, enhancing\nGNN scalability on large-scale graphs. However, GNNs still face two main\nchallenges: over-smoothing, where excessive message passing results in\nindistinguishable node representations, especially in deep networks\nincorporating high-order neighbors; and scalability issues, as traditional\narchitectures suffer from high model complexity and increased inference time\ndue to redundant information aggregation. This paper proposes a novel framework\nfor large-scale graphs named ScaleGNN that simultaneously addresses both\nchallenges by adaptively fusing multi-level graph features. We first construct\nneighbor matrices for each order, learning their relative information through\ntrainable weights through an adaptive high-order feature fusion module. This\nallows the model to selectively emphasize informative high-order neighbors\nwhile reducing unnecessary computational costs. Additionally, we introduce a\nHigh-order redundant feature masking mechanism based on a Local Contribution\nScore (LCS), which enables the model to retain only the most relevant neighbors\nat each order, preventing redundant information propagation. Furthermore,\nlow-order enhanced feature aggregation adaptively integrates low-order and\nhigh-order features based on task relevance, ensuring effective capture of both\nlocal and global structural information without excessive complexity. Extensive\nexperiments on real-world datasets demonstrate that our approach consistently\noutperforms state-of-the-art GNN models in both accuracy and computational\nefficiency."}
{"id": "2504.15485", "pdf": "https://arxiv.org/pdf/2504.15485", "abs": "https://arxiv.org/abs/2504.15485", "authors": ["Atin Pothiraj", "Elias Stengel-Eskin", "Jaemin Cho", "Mohit Bansal"], "title": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Code and data: https://github.com/atinpothiraj/CAPTURe", "summary": "Recognizing and reasoning about occluded (partially or fully hidden) objects\nis vital to understanding visual scenes, as occlusions frequently occur in\nreal-world environments and act as obstacles for spatial comprehension. To test\nmodels' ability to reason about multiple occluded objects, we introduce a novel\ntask, Counting Amodally for Patterns Through Unseen REgions (CAPTURe), which\nrequires a model to count objects arranged in a pattern by inferring how the\npattern continues behind an occluder (an object which blocks parts of the\nscene). CAPTURe requires both recognizing visual patterns and reasoning, making\nit a useful testbed for evaluating vision-language models (VLMs) on whether\nthey understand occluded patterns and possess spatial understanding skills. By\nrequiring models to reason about occluded objects, CAPTURe also tests VLMs'\nability to form world models that would allow them to fill in missing\ninformation. CAPTURe consists of two parts: (1) CAPTURe-real, with manually\nfiltered images of real objects in patterns and (2) CAPTURe-synthetic, a\ncontrolled diagnostic with generated patterned images. We evaluate four strong\nVLMs (GPT-4o, Intern-VL2, Molmo, and Qwen2-VL) on CAPTURe, finding that models\nstruggle to count on both occluded and unoccluded patterns. Crucially, we find\nthat models perform worse with occlusion, suggesting that VLMs are also\ndeficient in inferring unseen spatial relationships: even the strongest VLMs\nlike GPT-4o fail to count with occlusion. In contrast, we find that humans\nachieve very little error on CAPTURe. We also find that providing auxiliary\ninformation of occluded object locations increases performance, underscoring\nthat the model error comes both from an inability to handle occlusion as well\nas difficulty counting in images."}
{"id": "2504.15924", "pdf": "https://arxiv.org/pdf/2504.15924", "abs": "https://arxiv.org/abs/2504.15924", "authors": ["Alycia Carey", "Xintao Wu"], "title": "Achieving Distributive Justice in Federated Learning via Uncertainty Quantification", "categories": ["cs.LG", "cs.AI", "stat.ML", "68T01", "I.2.0"], "comment": "21 pages, 1 figure, 7 tables", "summary": "Client-level fairness metrics for federated learning are used to ensure that\nall clients in a federation either: a) have similar final performance on their\nlocal data distributions (i.e., client parity), or b) obtain final performance\non their local data distributions relative to their contribution to the\nfederated learning process (i.e., contribution fairness). While a handful of\nworks that propose either client-parity or contribution-based fairness metrics\nground their definitions and decisions in social theories of equality -- such\nas distributive justice -- most works arbitrarily choose what notion of\nfairness to align with which makes it difficult for practitioners to choose\nwhich fairness metric aligns best with their fairness ethics. In this work, we\npropose UDJ-FL (Uncertainty-based Distributive Justice for Federated Learning),\na flexible federated learning framework that can achieve multiple distributive\njustice-based client-level fairness metrics. Namely, by utilizing techniques\ninspired by fair resource allocation, in conjunction with performing aleatoric\nuncertainty-based client weighing, our UDJ-FL framework is able to achieve\negalitarian, utilitarian, Rawls' difference principle, or desert-based\nclient-level fairness. We empirically show the ability of UDJ-FL to achieve all\nfour defined distributive justice-based client-level fairness metrics in\naddition to providing fairness equivalent to (or surpassing) other popular fair\nfederated learning works. Further, we provide justification for why aleatoric\nuncertainty weighing is necessary to the construction of our UDJ-FL framework\nas well as derive theoretical guarantees for the generalization bounds of\nUDJ-FL. Our code is publicly available at\nhttps://github.com/alycia-noel/UDJ-FL."}
{"id": "2504.15497", "pdf": "https://arxiv.org/pdf/2504.15497", "abs": "https://arxiv.org/abs/2504.15497", "authors": ["Noah Subedar", "Taeui Kim", "Saathwick Venkataramalingam"], "title": "Scalable APT Malware Classification via Parallel Feature Extraction and GPU-Accelerated Learning", "categories": ["cs.CR", "cs.AI", "I.2.0; I.2.6; K.6.5"], "comment": "26 pages, 54 figures, 14 tables", "summary": "This paper presents an underlying framework for both automating and\naccelerating malware classification, more specifically, mapping malicious\nexecutables to known Advanced Persistent Threat (APT) groups. The main feature\nof this analysis is the assembly-level instructions present in executables\nwhich are also known as opcodes. The collection of such opcodes on many\nmalicious samples is a lengthy process; hence, open-source reverse engineering\ntools are used in tandem with scripts that leverage parallel computing to\nanalyze multiple files at once. Traditional and deep learning models are\napplied to create models capable of classifying malware samples. One-gram and\ntwo-gram datasets are constructed and used to train models such as SVM, KNN,\nand Decision Tree; however, they struggle to provide adequate results without\nrelying on metadata to support n-gram sequences. The computational limitations\nof such models are overcome with convolutional neural networks (CNNs) and\nheavily accelerated using graphical compute unit (GPU) resources."}
{"id": "2504.15930", "pdf": "https://arxiv.org/pdf/2504.15930", "abs": "https://arxiv.org/abs/2504.15930", "authors": ["Yinmin Zhong", "Zili Zhang", "Xiaoniu Song", "Hanpeng Hu", "Chao Jin", "Bingyang Wu", "Nuo Chen", "Yukun Chen", "Yu Zhou", "Changyi Wan", "Hongyu Zhou", "Yimin Jiang", "Yibo Zhu", "Daxin Jiang"], "title": "StreamRL: Scalable, Heterogeneous, and Elastic RL for LLMs with Disaggregated Stream Generation", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Reinforcement learning (RL) has become the core post-training technique for\nlarge language models (LLMs). RL for LLMs involves two stages: generation and\ntraining. The LLM first generates samples online, which are then used to derive\nrewards for training. The conventional view holds that the colocated\narchitecture, where the two stages share resources via temporal multiplexing,\noutperforms the disaggregated architecture, in which dedicated resources are\nassigned to each stage. However, in real-world deployments, we observe that the\ncolocated architecture suffers from resource coupling, where the two stages are\nconstrained to use the same resources. This coupling compromises the\nscalability and cost-efficiency of colocated RL in large-scale training. In\ncontrast, the disaggregated architecture allows for flexible resource\nallocation, supports heterogeneous training setups, and facilitates\ncross-datacenter deployment.\n  StreamRL is designed with disaggregation from first principles and fully\nunlocks its potential by addressing two types of performance bottlenecks in\nexisting disaggregated RL frameworks: pipeline bubbles, caused by stage\ndependencies, and skewness bubbles, resulting from long-tail output length\ndistributions. To address pipeline bubbles, StreamRL breaks the traditional\nstage boundary in synchronous RL algorithms through stream generation and\nachieves full overlapping in asynchronous RL. To address skewness bubbles,\nStreamRL employs an output-length ranker model to identify long-tail samples\nand reduces generation time via skewness-aware dispatching and scheduling.\nExperiments show that StreamRL improves throughput by up to 2.66x compared to\nexisting state-of-the-art systems, and improves cost-effectiveness by up to\n1.33x in a heterogeneous, cross-datacenter setting."}
{"id": "2504.15499", "pdf": "https://arxiv.org/pdf/2504.15499", "abs": "https://arxiv.org/abs/2504.15499", "authors": ["James Mickens", "Sarah Radway", "Ravi Netravali"], "title": "Guillotine: Hypervisors for Isolating Malicious AIs", "categories": ["cs.CR", "cs.AI", "cs.OS"], "comment": "To be published in the ACM SIGOPS 2025 Workshop on Hot Topics in\n  Operating Systems", "summary": "As AI models become more embedded in critical sectors like finance,\nhealthcare, and the military, their inscrutable behavior poses ever-greater\nrisks to society. To mitigate this risk, we propose Guillotine, a hypervisor\narchitecture for sandboxing powerful AI models -- models that, by accident or\nmalice, can generate existential threats to humanity. Although Guillotine\nborrows some well-known virtualization techniques, Guillotine must also\nintroduce fundamentally new isolation mechanisms to handle the unique threat\nmodel posed by existential-risk AIs. For example, a rogue AI may try to\nintrospect upon hypervisor software or the underlying hardware substrate to\nenable later subversion of that control plane; thus, a Guillotine hypervisor\nrequires careful co-design of the hypervisor software and the CPUs, RAM, NIC,\nand storage devices that support the hypervisor software, to thwart side\nchannel leakage and more generally eliminate mechanisms for AI to exploit\nreflection-based vulnerabilities. Beyond such isolation at the software,\nnetwork, and microarchitectural layers, a Guillotine hypervisor must also\nprovide physical fail-safes more commonly associated with nuclear power plants,\navionic platforms, and other types of mission critical systems. Physical\nfail-safes, e.g., involving electromechanical disconnection of network cables,\nor the flooding of a datacenter which holds a rogue AI, provide defense in\ndepth if software, network, and microarchitectural isolation is compromised and\na rogue AI must be temporarily shut down or permanently destroyed."}
{"id": "2504.15956", "pdf": "https://arxiv.org/pdf/2504.15956", "abs": "https://arxiv.org/abs/2504.15956", "authors": ["Jerry Yao-Chieh Hu", "Hude Liu", "Hong-Yu Chen", "Weimin Wu", "Han Liu"], "title": "Universal Approximation with Softmax Attention", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We prove that with linear transformations, both (i) two-layer self-attention\nand (ii) one-layer self-attention followed by a softmax function are universal\napproximators for continuous sequence-to-sequence functions on compact domains.\nOur main technique is a new interpolation-based method for analyzing\nattention's internal mechanism. This leads to our key insight: self-attention\nis able to approximate a generalized version of ReLU to arbitrary precision,\nand hence subsumes many known universal approximators. Building on these, we\nshow that two-layer multi-head attention alone suffices as a\nsequence-to-sequence universal approximator. In contrast, prior works rely on\nfeed-forward networks to establish universal approximation in Transformers.\nFurthermore, we extend our techniques to show that, (softmax-)attention-only\nlayers are capable of approximating various statistical models in-context. We\nbelieve these techniques hold independent interest."}
{"id": "2504.15515", "pdf": "https://arxiv.org/pdf/2504.15515", "abs": "https://arxiv.org/abs/2504.15515", "authors": ["Wuchen Li"], "title": "Transport f divergences", "categories": ["math.ST", "cs.AI", "cs.IT", "math.IT", "stat.TH"], "comment": "Comments are welcome", "summary": "We define a class of divergences to measure differences between probability\ndensity functions in one-dimensional sample space. The construction is based on\nthe convex function with the Jacobi operator of mapping function that\npushforwards one density to the other. We call these information measures {\\em\ntransport $f$-divergences}. We present several properties of transport\n$f$-divergences, including invariances, convexities, variational formulations,\nand Taylor expansions in terms of mapping functions. Examples of transport\n$f$-divergences in generative models are provided."}
{"id": "2504.15995", "pdf": "https://arxiv.org/pdf/2504.15995", "abs": "https://arxiv.org/abs/2504.15995", "authors": ["Sindhuja Madabushi", "Ahmad Faraz Khan", "Haider Ali", "Jin-Hee Cho"], "title": "OPUS-VFL: Incentivizing Optimal Privacy-Utility Tradeoffs in Vertical Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Vertical Federated Learning (VFL) enables organizations with disjoint feature\nspaces but shared user bases to collaboratively train models without sharing\nraw data. However, existing VFL systems face critical limitations: they often\nlack effective incentive mechanisms, struggle to balance privacy-utility\ntradeoffs, and fail to accommodate clients with heterogeneous resource\ncapabilities. These challenges hinder meaningful participation, degrade model\nperformance, and limit practical deployment. To address these issues, we\npropose OPUS-VFL, an Optimal Privacy-Utility tradeoff Strategy for VFL.\nOPUS-VFL introduces a novel, privacy-aware incentive mechanism that rewards\nclients based on a principled combination of model contribution, privacy\npreservation, and resource investment. It employs a lightweight leave-one-out\n(LOO) strategy to quantify feature importance per client, and integrates an\nadaptive differential privacy mechanism that enables clients to dynamically\ncalibrate noise levels to optimize their individual utility. Our framework is\ndesigned to be scalable, budget-balanced, and robust to inference and poisoning\nattacks. Extensive experiments on benchmark datasets (MNIST, CIFAR-10, and\nCIFAR-100) demonstrate that OPUS-VFL significantly outperforms state-of-the-art\nVFL baselines in both efficiency and robustness. It reduces label inference\nattack success rates by up to 20%, increases feature inference reconstruction\nerror (MSE) by over 30%, and achieves up to 25% higher incentives for clients\nthat contribute meaningfully while respecting privacy and cost constraints.\nThese results highlight the practicality and innovation of OPUS-VFL as a\nsecure, fair, and performance-driven solution for real-world VFL."}
{"id": "2504.15524", "pdf": "https://arxiv.org/pdf/2504.15524", "abs": "https://arxiv.org/abs/2504.15524", "authors": ["Qiyao Wang", "Guhong Chen", "Hongbo Wang", "Huaren Liu", "Minghui Zhu", "Zhifei Qin", "Linwei Li", "Yilin Yue", "Shiqiang Wang", "Jiayan Li", "Yihang Wu", "Ziqiang Liu", "Longze Chen", "Run Luo", "Liyang Fan", "Jiaming Li", "Lei Zhang", "Kan Xu", "Hongfei Lin", "Hamid Alinejad-Rokny", "Shiwen Ni", "Yuan Lin", "Min Yang"], "title": "IPBench: Benchmarking the Knowledge of Large Language Models in Intellectual Property", "categories": ["cs.CL", "cs.AI"], "comment": "89 pages, 75 figures, 55 tables", "summary": "Intellectual Property (IP) is a unique domain that integrates technical and\nlegal knowledge, making it inherently complex and knowledge-intensive. As large\nlanguage models (LLMs) continue to advance, they show great potential for\nprocessing IP tasks, enabling more efficient analysis, understanding, and\ngeneration of IP-related content. However, existing datasets and benchmarks\neither focus narrowly on patents or cover limited aspects of the IP field,\nlacking alignment with real-world scenarios. To bridge this gap, we introduce\nthe first comprehensive IP task taxonomy and a large, diverse bilingual\nbenchmark, IPBench, covering 8 IP mechanisms and 20 tasks. This benchmark is\ndesigned to evaluate LLMs in real-world intellectual property applications,\nencompassing both understanding and generation. We benchmark 16 LLMs, ranging\nfrom general-purpose to domain-specific models, and find that even the\nbest-performing model achieves only 75.8% accuracy, revealing substantial room\nfor improvement. Notably, open-source IP and law-oriented models lag behind\nclosed-source general-purpose models. We publicly release all data and code of\nIPBench and will continue to update it with additional IP-related tasks to\nbetter reflect real-world challenges in the intellectual property domain."}
{"id": "2504.16020", "pdf": "https://arxiv.org/pdf/2504.16020", "abs": "https://arxiv.org/abs/2504.16020", "authors": ["Soham Sane"], "title": "AlphaGrad: Non-Linear Gradient Normalization Optimizer", "categories": ["cs.LG", "cs.AI", "cs.NE", "stat.ML"], "comment": null, "summary": "We introduce AlphaGrad, a memory-efficient, conditionally stateless optimizer\naddressing the memory overhead and hyperparameter complexity of adaptive\nmethods like Adam. AlphaGrad enforces scale invariance via tensor-wise L2\ngradient normalization followed by a smooth hyperbolic tangent transformation,\n$g' = \\tanh(\\alpha \\cdot \\tilde{g})$, controlled by a single steepness\nparameter $\\alpha$. Our contributions include: (1) the AlphaGrad algorithm\nformulation; (2) a formal non-convex convergence analysis guaranteeing\nstationarity; (3) extensive empirical evaluation on diverse RL benchmarks (DQN,\nTD3, PPO). Compared to Adam, AlphaGrad demonstrates a highly context-dependent\nperformance profile. While exhibiting instability in off-policy DQN, it\nprovides enhanced training stability with competitive results in TD3 (requiring\ncareful $\\alpha$ tuning) and achieves substantially superior performance in\non-policy PPO. These results underscore the critical importance of empirical\n$\\alpha$ selection, revealing strong interactions between the optimizer's\ndynamics and the underlying RL algorithm. AlphaGrad presents a compelling\nalternative optimizer for memory-constrained scenarios and shows significant\npromise for on-policy learning regimes where its stability and efficiency\nadvantages can be particularly impactful."}
{"id": "2504.15546", "pdf": "https://arxiv.org/pdf/2504.15546", "abs": "https://arxiv.org/abs/2504.15546", "authors": ["Jayachandu Bandlamudi", "Ritwik Chaudhuri", "Neelamadhav Gantayat", "Kushal Mukherjee", "Prerna Agarwal", "Renuka Sindhgatta", "Sameep Mehta"], "title": "A Framework for Testing and Adapting REST APIs as LLM Tools", "categories": ["cs.SE", "cs.AI", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) are enabling autonomous agents to perform\ncomplex workflows using external tools or functions, often provided via REST\nAPIs in enterprise systems. However, directly utilizing these APIs as tools\nposes challenges due to their complex input schemas, elaborate responses, and\noften ambiguous documentation. Current benchmarks for tool testing do not\nadequately address these complexities, leading to a critical gap in evaluating\nAPI readiness for agent-driven automation. In this work, we present a novel\ntesting framework aimed at evaluating and enhancing the readiness of REST APIs\nto function as tools for LLM-based agents. Our framework transforms apis as\ntools, generates comprehensive test cases for the APIs, translates tests cases\ninto natural language instructions suitable for agents, enriches tool\ndefinitions and evaluates the agent's ability t correctly invoke the API and\nprocess its inputs and responses. To provide actionable insights, we analyze\nthe outcomes of 750 test cases, presenting a detailed taxonomy of errors,\nincluding input misinterpretation, output handling inconsistencies, and schema\nmismatches. Additionally, we classify these test cases to streamline debugging\nand refinement of tool integrations. This work offers a foundational step\ntoward enabling enterprise APIs as tools, improving their usability in\nagent-based applications."}
{"id": "2504.16032", "pdf": "https://arxiv.org/pdf/2504.16032", "abs": "https://arxiv.org/abs/2504.16032", "authors": ["Yazan Otoum", "Arghavan Asad", "Amiya Nayak"], "title": "LLMs meet Federated Learning for Scalable and Secure IoT Management", "categories": ["cs.LG", "cs.AI", "cs.ET"], "comment": "This work has been submitted to the IEEE Global Communications\n  Conference (GLOBECOM) 2025 for possible publication", "summary": "The rapid expansion of IoT ecosystems introduces severe challenges in\nscalability, security, and real-time decision-making. Traditional centralized\narchitectures struggle with latency, privacy concerns, and excessive resource\nconsumption, making them unsuitable for modern large-scale IoT deployments.\nThis paper presents a novel Federated Learning-driven Large Language Model\n(FL-LLM) framework, designed to enhance IoT system intelligence while ensuring\ndata privacy and computational efficiency. The framework integrates Generative\nIoT (GIoT) models with a Gradient Sensing Federated Strategy (GSFS),\ndynamically optimizing model updates based on real-time network conditions. By\nleveraging a hybrid edge-cloud processing architecture, our approach balances\nintelligence, scalability, and security in distributed IoT environments.\nEvaluations on the IoT-23 dataset demonstrate that our framework improves model\naccuracy, reduces response latency, and enhances energy efficiency,\noutperforming traditional FL techniques (i.e., FedAvg, FedOpt). These findings\nhighlight the potential of integrating LLM-powered federated learning into\nlarge-scale IoT ecosystems, paving the way for more secure, scalable, and\nadaptive IoT management solutions."}
{"id": "2504.15549", "pdf": "https://arxiv.org/pdf/2504.15549", "abs": "https://arxiv.org/abs/2504.15549", "authors": ["Anjali Khurana", "Xiaotian Su", "April Yi Wang", "Parmit K Chilana"], "title": "Do It For Me vs. Do It With Me: Investigating User Perceptions of Different Paradigms of Automation in Copilots for Feature-Rich Software", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": "Accepted for publication in the CHI Conference on Human Factors in\n  Computing Systems (CHI 2025), April 26 - May 1, 2025, Yokohama, Japan", "summary": "Large Language Model (LLM)-based in-application assistants, or copilots, can\nautomate software tasks, but users often prefer learning by doing, raising\nquestions about the optimal level of automation for an effective user\nexperience. We investigated two automation paradigms by designing and\nimplementing a fully automated copilot (AutoCopilot) and a semi-automated\ncopilot (GuidedCopilot) that automates trivial steps while offering\nstep-by-step visual guidance. In a user study (N=20) across data analysis and\nvisual design tasks, GuidedCopilot outperformed AutoCopilot in user control,\nsoftware utility, and learnability, especially for exploratory and creative\ntasks, while AutoCopilot saved time for simpler visual tasks. A follow-up\ndesign exploration (N=10) enhanced GuidedCopilot with task-and state-aware\nfeatures, including in-context preview clips and adaptive instructions. Our\nfindings highlight the critical role of user control and tailored guidance in\ndesigning the next generation of copilots that enhance productivity, support\ndiverse skill levels, and foster deeper software engagement."}
{"id": "2504.16041", "pdf": "https://arxiv.org/pdf/2504.16041", "abs": "https://arxiv.org/abs/2504.16041", "authors": ["Amund Tveit", "Bjørn Remseth", "Arve Skogvold"], "title": "Muon Optimizer Accelerates Grokking", "categories": ["cs.LG", "cs.AI", "I.2"], "comment": "8 pages, 4 figures", "summary": "This paper investigates the impact of different optimizers on the grokking\nphenomenon, where models exhibit delayed generalization. We conducted\nexperiments across seven numerical tasks (primarily modular arithmetic) using a\nmodern Transformer architecture. The experimental configuration systematically\nvaried the optimizer (Muon vs. AdamW) and the softmax activation function\n(standard softmax, stablemax, and sparsemax) to assess their combined effect on\nlearning dynamics. Our empirical evaluation reveals that the Muon optimizer,\ncharacterized by its use of spectral norm constraints and second-order\ninformation, significantly accelerates the onset of grokking compared to the\nwidely used AdamW optimizer. Specifically, Muon reduced the mean grokking epoch\nfrom 153.09 to 102.89 across all configurations, a statistically significant\ndifference (t = 5.0175, p = 6.33e-08). This suggests that the optimizer choice\nplays a crucial role in facilitating the transition from memorization to\ngeneralization."}
{"id": "2504.15564", "pdf": "https://arxiv.org/pdf/2504.15564", "abs": "https://arxiv.org/abs/2504.15564", "authors": ["Musfiqur Rahman", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "A Large-scale Class-level Benchmark Dataset for Code Generation with LLMs", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "This paper was submitted to the 29th International Conference on\n  Evaluation and Assessment in Software Engineering (EASE 2025) AI models/data\n  track", "summary": "Recent advancements in large language models (LLMs) have demonstrated\npromising capabilities in code generation tasks. However, most existing\nbenchmarks focus on isolated functions and fail to capture the complexity of\nreal-world, class-level software structures. To address this gap, we introduce\na large-scale, Python class-level dataset curated from $13{,}174$ real-world\nopen-source projects. The dataset contains over 842,000 class skeletons, each\nincluding class and method signatures, along with associated docstrings when\navailable. We preserve structural and contextual dependencies critical to\nrealistic software development scenarios and enrich the dataset with static\ncode metrics to support downstream analysis. To evaluate the usefulness of this\ndataset, we use extracted class skeletons as prompts for GPT-4 to generate full\nclass implementations. Results show that the LLM-generated classes exhibit\nstrong lexical and structural similarity to human-written counterparts, with\naverage ROUGE@L, BLEU, and TSED scores of 0.80, 0.59, and 0.73, respectively.\nThese findings confirm that well-structured prompts derived from real-world\nclass skeletons significantly enhance LLM performance in class-level code\ngeneration. This dataset offers a valuable resource for benchmarking, training,\nand improving LLMs in realistic software engineering contexts."}
{"id": "2504.16054", "pdf": "https://arxiv.org/pdf/2504.16054", "abs": "https://arxiv.org/abs/2504.16054", "authors": ["Physical Intelligence", "Kevin Black", "Noah Brown", "James Darpinian", "Karan Dhabalia", "Danny Driess", "Adnan Esmail", "Michael Equi", "Chelsea Finn", "Niccolo Fusai", "Manuel Y. Galliker", "Dibya Ghosh", "Lachy Groom", "Karol Hausman", "Brian Ichter", "Szymon Jakubczak", "Tim Jones", "Liyiming Ke", "Devin LeBlanc", "Sergey Levine", "Adrian Li-Bell", "Mohith Mothukuri", "Suraj Nair", "Karl Pertsch", "Allen Z. Ren", "Lucy Xiaoyang Shi", "Laura Smith", "Jost Tobias Springenberg", "Kyle Stachowicz", "James Tanner", "Quan Vuong", "Homer Walke", "Anna Walling", "Haohuan Wang", "Lili Yu", "Ury Zhilinsky"], "title": "$π_{0.5}$: a Vision-Language-Action Model with Open-World Generalization", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "In order for robots to be useful, they must perform practically relevant\ntasks in the real world, outside of the lab. While vision-language-action (VLA)\nmodels have demonstrated impressive results for end-to-end robot control, it\nremains an open question how far such models can generalize in the wild. We\ndescribe $\\pi_{0.5}$, a new model based on $\\pi_{0}$ that uses co-training on\nheterogeneous tasks to enable broad generalization. $\\pi_{0.5}$\\ uses data from\nmultiple robots, high-level semantic prediction, web data, and other sources to\nenable broadly generalizable real-world robotic manipulation. Our system uses a\ncombination of co-training and hybrid multi-modal examples that combine image\nobservations, language commands, object detections, semantic subtask\nprediction, and low-level actions. Our experiments show that this kind of\nknowledge transfer is essential for effective generalization, and we\ndemonstrate for the first time that an end-to-end learning-enabled robotic\nsystem can perform long-horizon and dexterous manipulation skills, such as\ncleaning a kitchen or bedroom, in entirely new homes."}
{"id": "2504.15585", "pdf": "https://arxiv.org/pdf/2504.15585", "abs": "https://arxiv.org/abs/2504.15585", "authors": ["Kun Wang", "Guibin Zhang", "Zhenhong Zhou", "Jiahao Wu", "Miao Yu", "Shiqian Zhao", "Chenlong Yin", "Jinhu Fu", "Yibo Yan", "Hanjun Luo", "Liang Lin", "Zhihao Xu", "Haolang Lu", "Xinye Cao", "Xinyun Zhou", "Weifei Jin", "Fanci Meng", "Junyuan Mao", "Hao Wu", "Minghe Wang", "Fan Zhang", "Junfeng Fang", "Chengwei Liu", "Yifan Zhang", "Qiankun Li", "Chongye Guo", "Yalan Qin", "Yi Ding", "Donghai Hong", "Jiaming Ji", "Xinfeng Li", "Yifan Jiang", "Dongxia Wang", "Yihao Huang", "Yufei Guo", "Jen-tse Huang", "Yanwei Yue", "Wenke Huang", "Guancheng Wan", "Tianlin Li", "Lei Bai", "Jie Zhang", "Qing Guo", "Jingyi Wang", "Tianlong Chen", "Joey Tianyi Zhou", "Xiaojun Jia", "Weisong Sun", "Cong Wu", "Jing Chen", "Xuming Hu", "Yiming Li", "Xiao Wang", "Ningyu Zhang", "Luu Anh Tuan", "Guowen Xu", "Tianwei Zhang", "Xingjun Ma", "Xiang Wang", "Bo An", "Jun Sun", "Mohit Bansal", "Shirui Pan", "Yuval Elovici", "Bhavya Kailkhura", "Bo Li", "Yaodong Yang", "Hongwei Li", "Wenyuan Xu", "Yizhou Sun", "Wei Wang", "Qing Li", "Ke Tang", "Yu-Gang Jiang", "Felix Juefei-Xu", "Hui Xiong", "Xiaofeng Wang", "Shuicheng Yan", "Dacheng Tao", "Philip S. Yu", "Qingsong Wen", "Yang Liu"], "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "The remarkable success of Large Language Models (LLMs) has illuminated a\npromising pathway toward achieving Artificial General Intelligence for both\nacademic and industrial communities, owing to their unprecedented performance\nacross various applications. As LLMs continue to gain prominence in both\nresearch and commercial domains, their security and safety implications have\nbecome a growing concern, not only for researchers and corporations but also\nfor every nation. Currently, existing surveys on LLM safety primarily focus on\nspecific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning\nphase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs.\nTo address this gap, this paper introduces, for the first time, the concept of\n\"full-stack\" safety to systematically consider safety issues throughout the\nentire process of LLM training, deployment, and eventual commercialization.\nCompared to the off-the-shelf LLM safety surveys, our work demonstrates several\ndistinctive advantages: (I) Comprehensive Perspective. We define the complete\nLLM lifecycle as encompassing data preparation, pre-training, post-training,\ndeployment and final commercialization. To our knowledge, this represents the\nfirst safety survey to encompass the entire lifecycle of LLMs. (II) Extensive\nLiterature Support. Our research is grounded in an exhaustive review of over\n800+ papers, ensuring comprehensive coverage and systematic organization of\nsecurity issues within a more holistic understanding. (III) Unique Insights.\nThrough systematic literature analysis, we have developed reliable roadmaps and\nperspectives for each chapter. Our work identifies promising research\ndirections, including safety in data generation, alignment techniques, model\nediting, and LLM-based agent systems. These insights provide valuable guidance\nfor researchers pursuing future work in this field."}
{"id": "2504.16078", "pdf": "https://arxiv.org/pdf/2504.16078", "abs": "https://arxiv.org/abs/2504.16078", "authors": ["Thomas Schmied", "Jörg Bornschein", "Jordi Grau-Moya", "Markus Wulfmeier", "Razvan Pascanu"], "title": "LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The success of Large Language Models (LLMs) has sparked interest in various\nagentic applications. A key hypothesis is that LLMs, leveraging common sense\nand Chain-of-Thought (CoT) reasoning, can effectively explore and efficiently\nsolve complex domains. However, LLM agents have been found to suffer from\nsub-optimal exploration and the knowing-doing gap, the inability to effectively\nact on knowledge present in the model. In this work, we systematically study\nwhy LLMs perform sub-optimally in decision-making scenarios. In particular, we\nclosely examine three prevalent failure modes: greediness, frequency bias, and\nthe knowing-doing gap. We propose mitigation of these shortcomings by\nfine-tuning via Reinforcement Learning (RL) on self-generated CoT rationales.\nOur experiments across multi-armed bandits, contextual bandits, and\nTic-tac-toe, demonstrate that RL fine-tuning enhances the decision-making\nabilities of LLMs by increasing exploration and narrowing the knowing-doing\ngap. Finally, we study both classic exploration mechanisms, such as\n$\\epsilon$-greedy, and LLM-specific approaches, such as self-correction and\nself-consistency, to enable more effective fine-tuning of LLMs for\ndecision-making."}
{"id": "2504.15587", "pdf": "https://arxiv.org/pdf/2504.15587", "abs": "https://arxiv.org/abs/2504.15587", "authors": ["Zimo Yan", "Jie Zhang", "Zheng Xie", "Chang Liu", "Yizhen Liu", "Yiping Song"], "title": "MetaMolGen: A Neural Graph Motif Generation Model for De Novo Molecular Design", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Molecular generation plays an important role in drug discovery and materials\nscience, especially in data-scarce scenarios where traditional generative\nmodels often struggle to achieve satisfactory conditional generalization. To\naddress this challenge, we propose MetaMolGen, a first-order\nmeta-learning-based molecular generator designed for few-shot and\nproperty-conditioned molecular generation. MetaMolGen standardizes the\ndistribution of graph motifs by mapping them to a normalized latent space, and\nemploys a lightweight autoregressive sequence model to generate SMILES\nsequences that faithfully reflect the underlying molecular structure. In\naddition, it supports conditional generation of molecules with target\nproperties through a learnable property projector integrated into the\ngenerative process.Experimental results demonstrate that MetaMolGen\nconsistently generates valid and diverse SMILES sequences under low-data\nregimes, outperforming conventional baselines. This highlights its advantage in\nfast adaptation and efficient conditional generation for practical molecular\ndesign."}
{"id": "2504.15284", "pdf": "https://arxiv.org/pdf/2504.15284", "abs": "https://arxiv.org/abs/2504.15284", "authors": ["Weichen Li", "Albert Jan", "Baishakhi Ray", "Chengzhi Mao", "Junfeng Yang", "Kexin Pei"], "title": "EditLord: Learning Code Transformation Rules for Code Editing", "categories": ["cs.SE", "cs.CR", "cs.LG"], "comment": null, "summary": "Code editing is a foundational task in software development, where its\neffectiveness depends on whether it introduces desired code property changes\nwithout changing the original code's intended functionality. Existing\napproaches often formulate code editing as an implicit end-to-end task,\nomitting the fact that code-editing procedures inherently consist of discrete\nand explicit steps. Thus, they suffer from suboptimal performance and lack of\nrobustness and generalization. We introduce EditLord, a code editing framework\nthat makes the code transformation steps explicit. Our key insight is to employ\na language model (LM) as an inductive learner to extract code editing rules\nfrom the training code pairs as concise meta-rule sets. Such rule sets will be\nmanifested for each training sample to augment them for finetuning or assist in\nprompting- and iterative-based code editing. EditLordoutperforms the\nstate-of-the-art by an average of 22.7% in editing performance and 58.1% in\nrobustness while achieving 20.2% higher functional correctness across critical\nsoftware engineering and security applications, LM models, and editing modes."}
{"id": "2504.15604", "pdf": "https://arxiv.org/pdf/2504.15604", "abs": "https://arxiv.org/abs/2504.15604", "authors": ["Pavan Yadav", "Nikhil Khandalkar", "Krishna Shinde", "Lokesh B. Ramegowda", "Rajarshi Das"], "title": "Exploring Next Token Prediction in Theory of Mind (ToM) Tasks: Comparative Experiments with GPT-2 and LLaMA-2 AI Models", "categories": ["cs.CL", "cs.AI"], "comment": "75 pages, 60 figures", "summary": "Language models have made significant progress in generating coherent text\nand predicting next tokens based on input prompts. This study compares the\nnext-token prediction performance of two well-known models: OpenAI's GPT-2 and\nMeta's Llama-2-7b-chat-hf on Theory of Mind (ToM) tasks. To evaluate their\ncapabilities, we built a dataset from 10 short stories sourced from the Explore\nToM Dataset. We enhanced these stories by programmatically inserting additional\nsentences (infills) using GPT-4, creating variations that introduce different\nlevels of contextual complexity. This setup enables analysis of how increasing\ncontext affects model performance. We tested both models under four temperature\nsettings (0.01, 0.5, 1.0, 2.0) and evaluated their ability to predict the next\ntoken across three reasoning levels. Zero-order reasoning involves tracking the\nstate, either current (ground truth) or past (memory). First-order reasoning\nconcerns understanding another's mental state (e.g., \"Does Anne know the apple\nis salted?\"). Second-order reasoning adds recursion (e.g., \"Does Anne think\nthat Charles knows the apple is salted?\").\n  Our results show that adding more infill sentences slightly reduces\nprediction accuracy, as added context increases complexity and ambiguity.\nLlama-2 consistently outperforms GPT-2 in prediction accuracy, especially at\nlower temperatures, demonstrating greater confidence in selecting the most\nprobable token. As reasoning complexity rises, model responses diverge more.\nNotably, GPT-2 and Llama-2 display greater variability in predictions during\nfirst- and second-order reasoning tasks. These findings illustrate how model\narchitecture, temperature, and contextual complexity influence next-token\nprediction, contributing to a better understanding of the strengths and\nlimitations of current language models."}
{"id": "2504.15313", "pdf": "https://arxiv.org/pdf/2504.15313", "abs": "https://arxiv.org/abs/2504.15313", "authors": ["Yajie Yu", "Yue Feng"], "title": "PolicyEvol-Agent: Evolving Policy via Environment Perception and Self-Awareness with Theory of Mind", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Multi-agents has exhibited significant intelligence in real-word simulations\nwith Large language models (LLMs) due to the capabilities of social cognition\nand knowledge retrieval. However, existing research on agents equipped with\neffective cognition chains including reasoning, planning, decision-making and\nreflecting remains limited, especially in the dynamically interactive\nscenarios. In addition, unlike human, prompt-based responses face challenges in\npsychological state perception and empirical calibration during uncertain\ngaming process, which can inevitably lead to cognition bias. In light of above,\nwe introduce PolicyEvol-Agent, a comprehensive LLM-empowered framework\ncharacterized by systematically acquiring intentions of others and adaptively\noptimizing irrational strategies for continual enhancement. Specifically,\nPolicyEvol-Agent first obtains reflective expertise patterns and then\nintegrates a range of cognitive operations with Theory of Mind alongside\ninternal and external perspectives. Simulation results, outperforming RL-based\nmodels and agent-based methods, demonstrate the superiority of PolicyEvol-Agent\nfor final gaming victory. Moreover, the policy evolution mechanism reveals the\neffectiveness of dynamic guideline adjustments in both automatic and human\nevaluation."}
{"id": "2504.15634", "pdf": "https://arxiv.org/pdf/2504.15634", "abs": "https://arxiv.org/abs/2504.15634", "authors": ["Peizheng Liu", "Hitoshi Iba"], "title": "Enhancing Reinforcement learning in 3-Dimensional Hydrophobic-Polar Protein Folding Model with Attention-based layers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformer-based architectures have recently propelled advances in sequence\nmodeling across domains, but their application to the hydrophobic-hydrophilic\n(H-P) model for protein folding remains relatively unexplored. In this work, we\nadapt a Deep Q-Network (DQN) integrated with attention mechanisms\n(Transformers) to address the 3D H-P protein folding problem. Our system\nformulates folding decisions as a self-avoiding walk in a reinforced\nenvironment, and employs a specialized reward function based on favorable\nhydrophobic interactions. To improve performance, the method incorporates\nvalidity check including symmetry-breaking constraints, dueling and double\nQ-learning, and prioritized replay to focus learning on critical transitions.\nExperimental evaluations on standard benchmark sequences demonstrate that our\napproach achieves several known best solutions for shorter sequences, and\nobtains near-optimal results for longer chains. This study underscores the\npromise of attention-based reinforcement learning for protein folding, and\ncreated a prototype of Transformer-based Q-network structure for 3-dimensional\nlattice models."}
{"id": "2504.15324", "pdf": "https://arxiv.org/pdf/2504.15324", "abs": "https://arxiv.org/abs/2504.15324", "authors": ["Vuong M. Ngo", "Edward Bolger", "Stan Goodwin", "John O'Sullivan", "Dinh Viet Cuong", "Mark Roantree"], "title": "A Graph Based Raman Spectral Processing Technique for Exosome Classification", "categories": ["q-bio.QM", "cs.AI", "cs.IT", "cs.LG", "math.IT"], "comment": "The 23rd International Conference on Artificial Intelligence in\n  Medicine (AIME 2025), LNAI, Springer, 11 pages", "summary": "Exosomes are small vesicles crucial for cell signaling and disease\nbiomarkers. Due to their complexity, an \"omics\" approach is preferable to\nindividual biomarkers. While Raman spectroscopy is effective for exosome\nanalysis, it requires high sample concentrations and has limited sensitivity to\nlipids and proteins. Surface-enhanced Raman spectroscopy helps overcome these\nchallenges. In this study, we leverage Neo4j graph databases to organize 3,045\nRaman spectra of exosomes, enhancing data generalization. To further refine\nspectral analysis, we introduce a novel spectral filtering process that\nintegrates the PageRank Filter with optimal Dimensionality Reduction. This\nmethod improves feature selection, resulting in superior classification\nperformance. Specifically, the Extra Trees model, using our spectral processing\napproach, achieves 0.76 and 0.857 accuracy in classifying hyperglycemic,\nhypoglycemic, and normal exosome samples based on Raman spectra and surface,\nrespectively, with group 10-fold cross-validation. Our results show that\ngraph-based spectral filtering combined with optimal dimensionality reduction\nsignificantly improves classification accuracy by reducing noise while\npreserving key biomarker signals. This novel framework enhances Raman-based\nexosome analysis, expanding its potential for biomedical applications, disease\ndiagnostics, and biomarker discovery."}
{"id": "2504.15637", "pdf": "https://arxiv.org/pdf/2504.15637", "abs": "https://arxiv.org/abs/2504.15637", "authors": ["Farnaz Behrang", "Zhizhou Zhang", "Georgian-Vlad Saioc", "Peng Liu", "Milind Chabbi"], "title": "DR.FIX: Automatically Fixing Data Races at Industry Scale", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PL", "cs.SE"], "comment": "To appear in PLDI 2025", "summary": "Data races are a prevalent class of concurrency bugs in shared-memory\nparallel programs, posing significant challenges to software reliability and\nreproducibility. While there is an extensive body of research on detecting data\nraces and a wealth of practical detection tools across various programming\nlanguages, considerably less effort has been directed toward automatically\nfixing data races at an industrial scale. In large codebases, data races are\ncontinuously introduced and exhibit myriad patterns, making automated fixing\nparticularly challenging.\n  In this paper, we tackle the problem of automatically fixing data races at an\nindustrial scale. We present Dr.Fix, a tool that combines large language models\n(LLMs) with program analysis to generate fixes for data races in real-world\nsettings, effectively addressing a broad spectrum of racy patterns in complex\ncode contexts. Implemented for Go--the programming language widely used in\nmodern microservice architectures where concurrency is pervasive and data races\nare common--Dr.Fix seamlessly integrates into existing development workflows.\nWe detail the design of Dr.Fix and examine how individual design choices\ninfluence the quality of the fixes produced. Over the past 18 months, Dr.Fix\nhas been integrated into developer workflows at Uber demonstrating its\npractical utility. During this period, Dr.Fix produced patches for 224 (55%)\nfrom a corpus of 404 data races spanning various categories; 193 of these\npatches (86%) were accepted by more than a hundred developers via code reviews\nand integrated into the codebase."}
{"id": "2504.15327", "pdf": "https://arxiv.org/pdf/2504.15327", "abs": "https://arxiv.org/abs/2504.15327", "authors": ["Tianliang Yao", "Bo Lu", "Markus Kowarschik", "Yixuan Yuan", "Hubin Zhao", "Sebastien Ourselin", "Kaspar Althoefer", "Junbo Ge", "Peng Qi"], "title": "Advancing Embodied Intelligence in Robotic-Assisted Endovascular Procedures: A Systematic Review of AI Solutions", "categories": ["cs.RO", "cs.LG"], "comment": "24 pages, 7 figures, submitted to IEEE", "summary": "Endovascular procedures have revolutionized the treatment of vascular\ndiseases thanks to minimally invasive solutions that significantly reduce\npatient recovery time and enhance clinical outcomes. However, the precision and\ndexterity required during these procedures poses considerable challenges for\ninterventionists. Robotic systems have emerged offering transformative\nsolutions, addressing issues such as operator fatigue, radiation exposure, and\nthe inherent limitations of human precision. The integration of Embodied\nIntelligence (EI) into these systems signifies a paradigm shift, enabling\nrobots to navigate complex vascular networks and adapt to dynamic physiological\nconditions. Data-driven approaches, advanced computer vision, medical image\nanalysis, and machine learning techniques, are at the forefront of this\nevolution. These methods augment procedural intelligence by facilitating\nreal-time vessel segmentation, device tracking, and anatomical landmark\ndetection. Reinforcement learning and imitation learning further refine\nnavigation strategies and replicate experts' techniques. This review\nsystematically examines the integration of EI principles into robotic\ntechnologies, in relation to endovascular procedures. We discuss recent\nadvancements in intelligent perception and data-driven control, and their\npractical applications in robot-assisted endovascular procedures. By critically\nevaluating current limitations and emerging opportunities, this review\nestablishes a framework for future developments, emphasizing the potential for\ngreater autonomy and improved clinical outcomes. Emerging trends and specific\nareas of research, such as federated learning for medical data sharing,\nexplainable AI for clinical decision support, and advanced human-robot\ncollaboration paradigms, are also explored, offering insights into the future\ndirection of this rapidly evolving field."}
{"id": "2504.15640", "pdf": "https://arxiv.org/pdf/2504.15640", "abs": "https://arxiv.org/abs/2504.15640", "authors": ["Hongtao Wang", "Taiyan Zhang", "Renchi Yang", "Jianliang Xu"], "title": "Cost-Effective Text Clustering with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Text clustering aims to automatically partition a collection of text\ndocuments into distinct clusters based on linguistic features. In the\nliterature, this task is usually framed as metric clustering based on text\nembeddings from pre-trained encoders or a graph clustering problem upon\npairwise similarities from an oracle, e.g., a large ML model. Recently, large\nlanguage models (LLMs) bring significant advancement in this field by offering\ncontextualized text embeddings and highly accurate similarity scores, but\nmeanwhile, present grand challenges to cope with substantial computational\nand/or financial overhead caused by numerous API-based queries or inference\ncalls to the models.\n  In response, this paper proposes TECL, a cost-effective framework that taps\ninto the feedback from LLMs for accurate text clustering within a limited\nbudget of queries to LLMs. Under the hood, TECL adopts our EdgeLLM or\nTriangleLLM to construct must-link/cannot-link constraints for text pairs, and\nfurther leverages such constraints as supervision signals input to our weighted\nconstrained clustering approach to generate clusters. Particularly, EdgeLLM\n(resp. TriangleLLM) enables the identification of informative text pairs (resp.\ntriplets) for querying LLMs via well-thought-out greedy algorithms and accurate\nextraction of pairwise constraints through carefully-crafted prompting\ntechniques. Our experiments on multiple benchmark datasets exhibit that TECL\nconsistently and considerably outperforms existing solutions in unsupervised\ntext clustering under the same query cost for LLMs."}
{"id": "2504.15362", "pdf": "https://arxiv.org/pdf/2504.15362", "abs": "https://arxiv.org/abs/2504.15362", "authors": ["Yuan-Hong Liao", "Sven Elflein", "Liu He", "Laura Leal-Taixé", "Yejin Choi", "Sanja Fidler", "David Acuna"], "title": "LongPerceptualThoughts: Distilling System-2 Reasoning for System-1 Perception", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "24 pages, 10 figures, in submission. Project page:\n  https://andrewliao11.github.io/LongPerceptualThoughts", "summary": "Recent reasoning models through test-time scaling have demonstrated that long\nchain-of-thoughts can unlock substantial performance boosts in hard reasoning\ntasks such as math and code. However, the benefit of such long thoughts for\nsystem-2 reasoning is relatively less explored in other domains such as\nperceptual tasks where shallower, system-1 reasoning seems sufficient. In this\npaper, we introduce LongPerceptualThoughts, a new synthetic dataset with 30K\nlong-thought traces for perceptual tasks. The key challenges in synthesizing\nelaborate reasoning thoughts for perceptual tasks are that off-the-shelf models\nare not yet equipped with such thinking behavior and that it is not\nstraightforward to build a reliable process verifier for perceptual tasks.\nThus, we propose a novel three-stage data synthesis framework that first\nsynthesizes verifiable multiple-choice questions from dense image descriptions,\nthen extracts simple CoTs from VLMs for those verifiable problems, and finally\nexpands those simple thoughts to elaborate long thoughts via frontier reasoning\nmodels. In controlled experiments with a strong instruction-tuned 7B model, we\ndemonstrate notable improvements over existing visual reasoning data-generation\nmethods. Our model, trained on the generated dataset, achieves an average +3.4\npoints improvement over 5 vision-centric benchmarks, including +11.8 points on\nV$^*$ Bench. Notably, despite being tuned for vision tasks, it also improves\nperformance on the text reasoning benchmark, MMLU-Pro, by +2 points."}
{"id": "2504.15654", "pdf": "https://arxiv.org/pdf/2504.15654", "abs": "https://arxiv.org/abs/2504.15654", "authors": ["Md Abdul Baset Sarker", "Art Nguyen", "Sigmond Kukla", "Kevin Fite", "Masudul H. Imtiaz"], "title": "A Vision-Enabled Prosthetic Hand for Children with Upper Limb Disabilities", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "This paper introduces a novel AI vision-enabled pediatric prosthetic hand\ndesigned to assist children aged 10-12 with upper limb disabilities. The\nprosthesis features an anthropomorphic appearance, multi-articulating\nfunctionality, and a lightweight design that mimics a natural hand, making it\nboth accessible and affordable for low-income families. Using 3D printing\ntechnology and integrating advanced machine vision, sensing, and embedded\ncomputing, the prosthetic hand offers a low-cost, customizable solution that\naddresses the limitations of current myoelectric prostheses. A micro camera is\ninterfaced with a low-power FPGA for real-time object detection and assists\nwith precise grasping. The onboard DL-based object detection and grasp\nclassification models achieved accuracies of 96% and 100% respectively. In the\nforce prediction, the mean absolute error was found to be 0.018. The features\nof the proposed prosthetic hand can thus be summarized as: a) a wrist-mounted\nmicro camera for artificial sensing, enabling a wide range of hand-based tasks;\nb) real-time object detection and distance estimation for precise grasping; and\nc) ultra-low-power operation that delivers high performance within constrained\npower and resource limits."}
{"id": "2504.15370", "pdf": "https://arxiv.org/pdf/2504.15370", "abs": "https://arxiv.org/abs/2504.15370", "authors": ["Juno Nam", "Miguel Steiner", "Max Misterka", "Soojung Yang", "Avni Singhal", "Rafael Gómez-Bombarelli"], "title": "Transferable Learning of Reaction Pathways from Geometric Priors", "categories": ["physics.chem-ph", "cs.LG"], "comment": "14 pages, 6 figures; Supporting Information in ancillary files", "summary": "Identifying minimum-energy paths (MEPs) is crucial for understanding chemical\nreaction mechanisms but remains computationally demanding. We introduce MEPIN,\na scalable machine-learning method for efficiently predicting MEPs from\nreactant and product configurations, without relying on transition-state\ngeometries or pre-optimized reaction paths during training. The task is defined\nas predicting deviations from geometric interpolations along reaction\ncoordinates. We address this task with a continuous reaction path model based\non a symmetry-broken equivariant neural network that generates a flexible\nnumber of intermediate structures. The model is trained using an energy-based\nobjective, with efficiency enhanced by incorporating geometric priors from\ngeodesic interpolation as initial interpolations or pre-training objectives.\nOur approach generalizes across diverse chemical reactions and achieves\naccurate alignment with reference intrinsic reaction coordinates, as\ndemonstrated on various small molecule reactions and [3+2] cycloadditions. Our\nmethod enables the exploration of large chemical reaction spaces with\nefficient, data-driven predictions of reaction pathways."}
{"id": "2504.15659", "pdf": "https://arxiv.org/pdf/2504.15659", "abs": "https://arxiv.org/abs/2504.15659", "authors": ["Anjiang Wei", "Huanmi Tan", "Tarun Suresh", "Daniel Mendoza", "Thiago S. F. X. Teixeira", "Ke Wang", "Caroline Trippel", "Alex Aiken"], "title": "VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional Correctness Validation", "categories": ["cs.AR", "cs.AI", "cs.CL", "cs.LG", "cs.SE"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have sparked growing interest\nin applying them to Electronic Design Automation (EDA) tasks, particularly\nRegister Transfer Level (RTL) code generation. While several RTL datasets have\nbeen introduced, most focus on syntactic validity rather than functional\nvalidation with tests, leading to training examples that compile but may not\nimplement the intended behavior. We present VERICODER, a model for RTL code\ngeneration fine-tuned on a dataset validated for functional correctness. This\nfine-tuning dataset is constructed using a novel methodology that combines unit\ntest generation with feedback-directed refinement. Given a natural language\nspecification and an initial RTL design, we prompt a teacher model\n(GPT-4o-mini) to generate unit tests and iteratively revise the RTL design\nbased on its simulation results using the generated tests. If necessary, the\nteacher model also updates the tests to ensure they comply with the natural\nlanguage specification. As a result of this process, every example in our\ndataset is functionally validated, consisting of a natural language\ndescription, an RTL implementation, and passing tests. Fine-tuned on this\ndataset of over 125,000 examples, VERICODER achieves state-of-the-art metrics\nin functional correctness on VerilogEval and RTLLM, with relative gains of up\nto 71.7% and 27.4% respectively. An ablation study further shows that models\ntrained on our functionally validated dataset outperform those trained on\nfunctionally non-validated datasets, underscoring the importance of\nhigh-quality datasets in RTL code generation."}
{"id": "2504.15375", "pdf": "https://arxiv.org/pdf/2504.15375", "abs": "https://arxiv.org/abs/2504.15375", "authors": ["Bradley Boswell", "Seth Barrett", "Swarnamugi Rajaganapathy", "Gokila Dorai"], "title": "FLARE: Feature-based Lightweight Aggregation for Robust Evaluation of IoT Intrusion Detection", "categories": ["cs.CR", "cs.LG"], "comment": "23 pages, 19 tables, 2 algorithms, 2 figures, submitted to\n  SecureComm25", "summary": "The proliferation of Internet of Things (IoT) devices has expanded the attack\nsurface, necessitating efficient intrusion detection systems (IDSs) for network\nprotection. This paper presents FLARE, a feature-based lightweight aggregation\nfor robust evaluation of IoT intrusion detection to address the challenges of\nsecuring IoT environments through feature aggregation techniques. FLARE\nutilizes a multilayered processing approach, incorporating session, flow, and\ntime-based sliding-window data aggregation to analyze network behavior and\ncapture vital features from IoT network traffic data. We perform extensive\nevaluations on IoT data generated from our laboratory experimental setup to\nassess the effectiveness of the proposed aggregation technique. To classify\nattacks in IoT IDS, we employ four supervised learning models and two deep\nlearning models. We validate the performance of these models in terms of\naccuracy, precision, recall, and F1-score. Our results reveal that\nincorporating the FLARE aggregation technique as a foundational step in feature\nengineering, helps lay a structured representation, and enhances the\nperformance of complex end-to-end models, making it a crucial step in IoT IDS\npipeline. Our findings highlight the potential of FLARE as a valuable technique\nto improve performance and reduce computational costs of end-to-end IDS\nimplementations, thereby fostering more robust IoT intrusion detection systems."}
{"id": "2504.15663", "pdf": "https://arxiv.org/pdf/2504.15663", "abs": "https://arxiv.org/abs/2504.15663", "authors": ["Ju Yeon Kang", "Ji Won Yoon", "Semin Kim", "Min Hyun Han", "Nam Soo Kim"], "title": "FADEL: Uncertainty-aware Fake Audio Detection with Evidential Deep Learning", "categories": ["eess.AS", "cs.AI"], "comment": "Accepted at ICASSP 2025", "summary": "Recently, fake audio detection has gained significant attention, as\nadvancements in speech synthesis and voice conversion have increased the\nvulnerability of automatic speaker verification (ASV) systems to spoofing\nattacks. A key challenge in this task is generalizing models to detect unseen,\nout-of-distribution (OOD) attacks. Although existing approaches have shown\npromising results, they inherently suffer from overconfidence issues due to the\nusage of softmax for classification, which can produce unreliable predictions\nwhen encountering unpredictable spoofing attempts. To deal with this\nlimitation, we propose a novel framework called fake audio detection with\nevidential learning (FADEL). By modeling class probabilities with a Dirichlet\ndistribution, FADEL incorporates model uncertainty into its predictions,\nthereby leading to more robust performance in OOD scenarios. Experimental\nresults on the ASVspoof2019 Logical Access (LA) and ASVspoof2021 LA datasets\nindicate that the proposed method significantly improves the performance of\nbaseline models. Furthermore, we demonstrate the validity of uncertainty\nestimation by analyzing a strong correlation between average uncertainty and\nequal error rate (EER) across different spoofing algorithms."}
{"id": "2504.15376", "pdf": "https://arxiv.org/pdf/2504.15376", "abs": "https://arxiv.org/abs/2504.15376", "authors": ["Zhiqiu Lin", "Siyuan Cen", "Daniel Jiang", "Jay Karhade", "Hewei Wang", "Chancharik Mitra", "Tiffany Ling", "Yuhan Huang", "Sifan Liu", "Mingyu Chen", "Rushikesh Zawar", "Xue Bai", "Yilun Du", "Chuang Gan", "Deva Ramanan"], "title": "Towards Understanding Camera Motions in Any Video", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "comment": "Project site: https://linzhiqiu.github.io/papers/camerabench/", "summary": "We introduce CameraBench, a large-scale dataset and benchmark designed to\nassess and improve camera motion understanding. CameraBench consists of ~3,000\ndiverse internet videos, annotated by experts through a rigorous multi-stage\nquality control process. One of our contributions is a taxonomy of camera\nmotion primitives, designed in collaboration with cinematographers. We find,\nfor example, that some motions like \"follow\" (or tracking) require\nunderstanding scene content like moving subjects. We conduct a large-scale\nhuman study to quantify human annotation performance, revealing that domain\nexpertise and tutorial-based training can significantly enhance accuracy. For\nexample, a novice may confuse zoom-in (a change of intrinsics) with translating\nforward (a change of extrinsics), but can be trained to differentiate the two.\nUsing CameraBench, we evaluate Structure-from-Motion (SfM) and Video-Language\nModels (VLMs), finding that SfM models struggle to capture semantic primitives\nthat depend on scene content, while VLMs struggle to capture geometric\nprimitives that require precise estimation of trajectories. We then fine-tune a\ngenerative VLM on CameraBench to achieve the best of both worlds and showcase\nits applications, including motion-augmented captioning, video question\nanswering, and video-text retrieval. We hope our taxonomy, benchmark, and\ntutorials will drive future efforts towards the ultimate goal of understanding\ncamera motions in any video."}
{"id": "2504.15707", "pdf": "https://arxiv.org/pdf/2504.15707", "abs": "https://arxiv.org/abs/2504.15707", "authors": ["Yannic Neuhaus", "Matthias Hein"], "title": "RePOPE: Impact of Annotation Errors on the POPE Benchmark", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Since data annotation is costly, benchmark datasets often incorporate labels\nfrom established image datasets. In this work, we assess the impact of label\nerrors in MSCOCO on the frequently used object hallucination benchmark POPE. We\nre-annotate the benchmark images and identify an imbalance in annotation errors\nacross different subsets. Evaluating multiple models on the revised labels,\nwhich we denote as RePOPE, we observe notable shifts in model rankings,\nhighlighting the impact of label quality. Code and data are available at\nhttps://github.com/YanNeu/RePOPE ."}
{"id": "2504.15386", "pdf": "https://arxiv.org/pdf/2504.15386", "abs": "https://arxiv.org/abs/2504.15386", "authors": ["Rebecca Knowlton", "Layla Parast"], "title": "Assessing Surrogate Heterogeneity in Real World Data Using Meta-Learners", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "Surrogate markers are most commonly studied within the context of randomized\nclinical trials. However, the need for alternative outcomes extends beyond\nthese settings and may be more pronounced in real-world public health and\nsocial science research, where randomized trials are often impractical.\nResearch on identifying surrogates in real-world non-randomized data is scarce,\nas available statistical approaches for evaluating surrogate markers tend to\nrely on the assumption that treatment is randomized. While the few methods that\nallow for non-randomized treatment/exposure appropriately handle confounding\nindividual characteristics, they do not offer a way to examine surrogate\nheterogeneity with respect to patient characteristics. In this paper, we\npropose a framework to assess surrogate heterogeneity in real-world, i.e.,\nnon-randomized, data and implement this framework using various meta-learners.\nOur approach allows us to quantify heterogeneity in surrogate strength with\nrespect to patient characteristics while accommodating confounders through the\nuse of flexible, off-the-shelf machine learning methods. In addition, we use\nour framework to identify individuals for whom the surrogate is a valid\nreplacement of the primary outcome. We examine the performance of our methods\nvia a simulation study and application to examine heterogeneity in the\nsurrogacy of hemoglobin A1c as a surrogate for fasting plasma glucose."}
{"id": "2504.15724", "pdf": "https://arxiv.org/pdf/2504.15724", "abs": "https://arxiv.org/abs/2504.15724", "authors": ["Yiannis Papageorgiou", "Yannis Thomas", "Alexios Filippakopoulos", "Ramin Khalili", "Iordanis Koutsopoulos"], "title": "Collaborative Split Federated Learning with Parallel Training and Aggregation", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Federated learning (FL) operates based on model exchanges between the server\nand the clients, and it suffers from significant client-side computation and\ncommunication burden. Split federated learning (SFL) arises a promising\nsolution by splitting the model into two parts, that are trained sequentially:\nthe clients train the first part of the model (client-side model) and transmit\nit to the server that trains the second (server-side model). Existing SFL\nschemes though still exhibit long training delays and significant communication\noverhead, especially when clients of different computing capability\nparticipate. Thus, we propose Collaborative-Split Federated Learning~(C-SFL), a\nnovel scheme that splits the model into three parts, namely the model parts\ntrained at the computationally weak clients, the ones trained at the\ncomputationally strong clients, and the ones at the server. Unlike existing\nworks, C-SFL enables parallel training and aggregation of model's parts at the\nclients and at the server, resulting in reduced training delays and\ncommmunication overhead while improving the model's accuracy. Experiments\nverify the multiple gains of C-SFL against the existing schemes."}
{"id": "2504.15388", "pdf": "https://arxiv.org/pdf/2504.15388", "abs": "https://arxiv.org/abs/2504.15388", "authors": ["Tianyi Ma", "Tengyao Wang", "Richard J. Samworth"], "title": "Deep learning with missing data", "categories": ["stat.ME", "cs.LG", "math.ST", "stat.ML", "stat.TH", "62C20, 62D10, 62G08"], "comment": "49 pages, 9 figures", "summary": "In the context of multivariate nonparametric regression with missing\ncovariates, we propose Pattern Embedded Neural Networks (PENNs), which can be\napplied in conjunction with any existing imputation technique. In addition to a\nneural network trained on the imputed data, PENNs pass the vectors of\nobservation indicators through a second neural network to provide a compact\nrepresentation. The outputs are then combined in a third neural network to\nproduce final predictions. Our main theoretical result exploits an assumption\nthat the observation patterns can be partitioned into cells on which the Bayes\nregression function behaves similarly, and belongs to a compositional H\\\"older\nclass. It provides a finite-sample excess risk bound that holds for an\narbitrary missingness mechanism, and in combination with a complementary\nminimax lower bound, demonstrates that our PENN estimator attains in typical\ncases the minimax rate of convergence as if the cells of the partition were\nknown in advance, up to a poly-logarithmic factor in the sample size. Numerical\nexperiments on simulated, semi-synthetic and real data confirm that the PENN\nestimator consistently improves, often dramatically, on standard neural\nnetworks without pattern embedding. Code to reproduce our experiments, as well\nas a tutorial on how to apply our method, is publicly available."}
{"id": "2504.15743", "pdf": "https://arxiv.org/pdf/2504.15743", "abs": "https://arxiv.org/abs/2504.15743", "authors": ["Seung Gyu Jeong", "Sung Woo Nam", "Seong Kwan Jung", "Seong-Eun Kim"], "title": "iMedic: Towards Smartphone-based Self-Auscultation Tool for AI-Powered Pediatric Respiratory Assessment", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "Respiratory auscultation is crucial for early detection of pediatric\npneumonia, a condition that can quickly worsen without timely intervention. In\nareas with limited physician access, effective auscultation is challenging. We\npresent a smartphone-based system that leverages built-in microphones and\nadvanced deep learning algorithms to detect abnormal respiratory sounds\nindicative of pneumonia risk. Our end-to-end deep learning framework employs\ndomain generalization to integrate a large electronic stethoscope dataset with\na smaller smartphone-derived dataset, enabling robust feature learning for\naccurate respiratory assessments without expensive equipment. The accompanying\nmobile application guides caregivers in collecting high-quality lung sound\nsamples and provides immediate feedback on potential pneumonia risks. User\nstudies show strong classification performance and high acceptance,\ndemonstrating the system's ability to facilitate proactive interventions and\nreduce preventable childhood pneumonia deaths. By seamlessly integrating into\nubiquitous smartphones, this approach offers a promising avenue for more\nequitable and comprehensive remote pediatric care."}
{"id": "2504.15414", "pdf": "https://arxiv.org/pdf/2504.15414", "abs": "https://arxiv.org/abs/2504.15414", "authors": ["Dylan Khor", "Bowen Weng"], "title": "Post-Convergence Sim-to-Real Policy Transfer: A Principled Alternative to Cherry-Picking", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Learning-based approaches, particularly reinforcement learning (RL), have\nbecome widely used for developing control policies for autonomous agents, such\nas locomotion policies for legged robots. RL training typically maximizes a\npredefined reward (or minimizes a corresponding cost/loss) by iteratively\noptimizing policies within a simulator. Starting from a randomly initialized\npolicy, the empirical expected reward follows a trajectory with an overall\nincreasing trend. While some policies become temporarily stuck in local optima,\na well-defined training process generally converges to a reward level with\nnoisy oscillations. However, selecting a policy for real-world deployment is\nrarely an analytical decision (i.e., simply choosing the one with the highest\nreward) and is instead often performed through trial and error. To improve\nsim-to-real transfer, most research focuses on the pre-convergence stage,\nemploying techniques such as domain randomization, multi-fidelity training,\nadversarial training, and architectural innovations. However, these methods do\nnot eliminate the inevitable convergence trajectory and noisy oscillations of\nrewards, leading to heuristic policy selection or cherry-picking. This paper\naddresses the post-convergence sim-to-real transfer problem by introducing a\nworst-case performance transference optimization approach, formulated as a\nconvex quadratic-constrained linear programming problem. Extensive experiments\ndemonstrate its effectiveness in transferring RL-based locomotion policies from\nsimulation to real-world laboratory tests."}
{"id": "2504.15766", "pdf": "https://arxiv.org/pdf/2504.15766", "abs": "https://arxiv.org/abs/2504.15766", "authors": ["Tobias Demmler", "Lennart Hartung", "Andreas Tamke", "Thao Dang", "Alexander Hegai", "Karsten Haug", "Lars Mikelsons"], "title": "Dynamic Intent Queries for Motion Transformer-based Trajectory Prediction", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "In autonomous driving, accurately predicting the movements of other traffic\nparticipants is crucial, as it significantly influences a vehicle's planning\nprocesses. Modern trajectory prediction models strive to interpret complex\npatterns and dependencies from agent and map data. The Motion Transformer (MTR)\narchitecture and subsequent work define the most accurate methods in common\nbenchmarks such as the Waymo Open Motion Benchmark. The MTR model employs\npre-generated static intention points as initial goal points for trajectory\nprediction. However, the static nature of these points frequently leads to\nmisalignment with map data in specific traffic scenarios, resulting in\nunfeasible or unrealistic goal points. Our research addresses this limitation\nby integrating scene-specific dynamic intention points into the MTR model. This\nadaptation of the MTR model was trained and evaluated on the Waymo Open Motion\nDataset. Our findings demonstrate that incorporating dynamic intention points\nhas a significant positive impact on trajectory prediction accuracy, especially\nfor predictions over long time horizons. Furthermore, we analyze the impact on\nground truth trajectories which are not compliant with the map data or are\nillegal maneuvers."}
{"id": "2504.15425", "pdf": "https://arxiv.org/pdf/2504.15425", "abs": "https://arxiv.org/abs/2504.15425", "authors": ["Songyuan Zhang", "Oswin So", "Mitchell Black", "Zachary Serlin", "Chuchu Fan"], "title": "Solving Multi-Agent Safe Optimal Control with Distributed Epigraph Form MARL", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA", "math.OC"], "comment": "28 pages, 16 figures; Accepted by Robotics: Science and Systems 2025", "summary": "Tasks for multi-robot systems often require the robots to collaborate and\ncomplete a team goal while maintaining safety. This problem is usually\nformalized as a constrained Markov decision process (CMDP), which targets\nminimizing a global cost and bringing the mean of constraint violation below a\nuser-defined threshold. Inspired by real-world robotic applications, we define\nsafety as zero constraint violation. While many safe multi-agent reinforcement\nlearning (MARL) algorithms have been proposed to solve CMDPs, these algorithms\nsuffer from unstable training in this setting. To tackle this, we use the\nepigraph form for constrained optimization to improve training stability and\nprove that the centralized epigraph form problem can be solved in a distributed\nfashion by each agent. This results in a novel centralized training distributed\nexecution MARL algorithm named Def-MARL. Simulation experiments on 8 different\ntasks across 2 different simulators show that Def-MARL achieves the best\noverall performance, satisfies safety constraints, and maintains stable\ntraining. Real-world hardware experiments on Crazyflie quadcopters demonstrate\nthe ability of Def-MARL to safely coordinate agents to complete complex\ncollaborative tasks compared to other methods."}
{"id": "2504.15773", "pdf": "https://arxiv.org/pdf/2504.15773", "abs": "https://arxiv.org/abs/2504.15773", "authors": ["Cong Liu", "Sharvaree Vadgama", "David Ruhe", "Erik Bekkers", "Patrick Forrè"], "title": "Clifford Group Equivariant Diffusion Models for 3D Molecular Generation", "categories": ["cs.LG", "cs.AI"], "comment": "7 pages, 1 figure, 1 table", "summary": "This paper explores leveraging the Clifford algebra's expressive power for\n$\\E(n)$-equivariant diffusion models. We utilize the geometric products between\nClifford multivectors and the rich geometric information encoded in Clifford\nsubspaces in \\emph{Clifford Diffusion Models} (CDMs). We extend the diffusion\nprocess beyond just Clifford one-vectors to incorporate all higher-grade\nmultivector subspaces. The data is embedded in grade-$k$ subspaces, allowing us\nto apply latent diffusion across complete multivectors. This enables CDMs to\ncapture the joint distribution across different subspaces of the algebra,\nincorporating richer geometric information through higher-order features. We\nprovide empirical results for unconditional molecular generation on the QM9\ndataset, showing that CDMs provide a promising avenue for generative modeling."}
{"id": "2504.15431", "pdf": "https://arxiv.org/pdf/2504.15431", "abs": "https://arxiv.org/abs/2504.15431", "authors": ["Sungjun Han", "Juyoung Suk", "Suyeong An", "Hyungguk Kim", "Kyuseok Kim", "Wonsuk Yang", "Seungtaek Choi", "Jamin Shin"], "title": "Trillion 7B Technical Report", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Preview version", "summary": "We introduce Trillion-7B, the most token-efficient Korean-centric\nmultilingual LLM available. Our novel Cross-lingual Document Attention (XLDA)\nmechanism enables highly efficient and effective knowledge transfer from\nEnglish to target languages like Korean and Japanese. Combined with optimized\ndata mixtures, language-specific filtering, and tailored tokenizer\nconstruction, Trillion-7B achieves competitive performance while dedicating\nonly 10\\% of its 2T training tokens to multilingual data and requiring just\n59.4K H100 GPU hours (\\$148K) for full training. Comprehensive evaluations\nacross 27 benchmarks in four languages demonstrate Trillion-7B's robust\nmultilingual performance and exceptional cross-lingual consistency."}
{"id": "2504.15779", "pdf": "https://arxiv.org/pdf/2504.15779", "abs": "https://arxiv.org/abs/2504.15779", "authors": ["Aaron J. Gutknecht", "Fernando E. Rosas", "David A. Ehrlich", "Abdullah Makkeh", "Pedro A. M. Mediano", "Michael Wibral"], "title": "Shannon invariants: A scalable approach to information decomposition", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT", "nlin.AO", "physics.data-an"], "comment": "16 pages, 4 Figures", "summary": "Distributed systems, such as biological and artificial neural networks,\nprocess information via complex interactions engaging multiple subsystems,\nresulting in high-order patterns with distinct properties across scales.\nInvestigating how these systems process information remains challenging due to\ndifficulties in defining appropriate multivariate metrics and ensuring their\nscalability to large systems. To address these challenges, we introduce a novel\nframework based on what we call \"Shannon invariants\" -- quantities that capture\nessential properties of high-order information processing in a way that depends\nonly on the definition of entropy and can be efficiently calculated for large\nsystems. Our theoretical results demonstrate how Shannon invariants can be used\nto resolve long-standing ambiguities regarding the interpretation of widely\nused multivariate information-theoretic measures. Moreover, our practical\nresults reveal distinctive information-processing signatures of various deep\nlearning architectures across layers, which lead to new insights into how these\nsystems process information and how this evolves during training. Overall, our\nframework resolves fundamental limitations in analyzing high-order phenomena\nand offers broad opportunities for theoretical developments and empirical\nanalyses."}
{"id": "2504.15465", "pdf": "https://arxiv.org/pdf/2504.15465", "abs": "https://arxiv.org/abs/2504.15465", "authors": ["Patrick H. Coppock", "Brian Zhang", "Eliot H. Solomon", "Vasilis Kypriotis", "Leon Yang", "Bikash Sharma", "Dan Schatzberg", "Todd C. Mowry", "Dimitrios Skarlatos"], "title": "LithOS: An Operating System for Efficient Machine Learning on GPUs", "categories": ["cs.OS", "cs.LG"], "comment": null, "summary": "The surging demand for GPUs in datacenters for machine learning (ML) has made\nefficient GPU utilization crucial. However, meeting the diverse needs of ML\nmodels while optimizing resource usage is challenging. To enable transparent,\nfine-grained GPU management that maximizes utilization and energy efficiency\nwhile maintaining strong isolation, an operating system (OS) approach is\nneeded. This paper introduces LithOS, a first step toward a GPU OS. LithOS\nincludes the following new abstractions and mechanisms for efficient GPU\nresource management: (i) a novel TPC Scheduler that supports spatial scheduling\nat the granularity of individual TPCs, unlocking efficient TPC stealing between\nworkloads; (ii) transparent kernel atomization to reduce head-of-line blocking\nand enable dynamic resource reallocation mid-execution; (iii) a lightweight\nhardware right-sizing mechanism that determines the minimal TPC resources\nneeded per atom; and (iv) a transparent power management mechanism that reduces\npower consumption based on in-flight work behavior. We implement LithOS in Rust\nand evaluate its performance across extensive ML environments, comparing it to\nstate-of-the-art solutions from NVIDIA and prior research. For inference\nstacking, LithOS reduces tail latencies by 13x compared to MPS; compared to the\nbest SotA, it reduces tail latencies by 3x while improving aggregate throughput\nby 1.6x. In hybrid inference-training stacking, LithOS reduces tail latencies\nby 4.7x compared to MPS; compared to the best SotA, it reduces tail latencies\n1.18x while improving aggregate throughput by 1.35x. Finally, for a modest\nperformance hit under 4%, LithOS's right-sizing provides a quarter of GPU\ncapacity savings on average, while for a 7% hit, its power management yields a\nquarter of a GPU's energy savings. Overall, LithOS increases GPU efficiency,\nestablishing a foundation for future OS research on GPUs."}
{"id": "2504.15784", "pdf": "https://arxiv.org/pdf/2504.15784", "abs": "https://arxiv.org/abs/2504.15784", "authors": ["Ruizhe Li", "Chiwei Zhu", "Benfeng Xu", "Xiaorui Wang", "Zhendong Mao"], "title": "Automated Creativity Evaluation for Large Language Models: A Reference-Based Approach", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Creative writing is a key capability of Large Language Models (LLMs), with\npotential applications in literature, storytelling, and various creative\ndomains. However, evaluating the creativity of machine-generated texts remains\na significant challenge, as existing methods either rely on costly manual\nannotations or fail to align closely with human assessments. In this paper, we\npropose an effective automated evaluation method based on the Torrance Test of\nCreative Writing (TTCW), which evaluates creativity as product. Our method\nemploys a reference-based Likert-style approach, scoring generated creative\ntexts relative to high-quality reference texts across various tests.\nExperimental results demonstrate that our method significantly improves the\nalignment between LLM evaluations and human assessments, achieving a pairwise\naccuracy of 0.75 (+15\\%)."}
{"id": "2504.15472", "pdf": "https://arxiv.org/pdf/2504.15472", "abs": "https://arxiv.org/abs/2504.15472", "authors": ["Pingcheng Jian", "Xiao Wei", "Yanbaihui Liu", "Samuel A. Moore", "Michael M. Zavlanos", "Boyuan Chen"], "title": "LAPP: Large Language Model Feedback for Preference-Driven Reinforcement Learning", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "We introduce Large Language Model-Assisted Preference Prediction (LAPP), a\nnovel framework for robot learning that enables efficient, customizable, and\nexpressive behavior acquisition with minimum human effort. Unlike prior\napproaches that rely heavily on reward engineering, human demonstrations,\nmotion capture, or expensive pairwise preference labels, LAPP leverages large\nlanguage models (LLMs) to automatically generate preference labels from raw\nstate-action trajectories collected during reinforcement learning (RL). These\nlabels are used to train an online preference predictor, which in turn guides\nthe policy optimization process toward satisfying high-level behavioral\nspecifications provided by humans. Our key technical contribution is the\nintegration of LLMs into the RL feedback loop through trajectory-level\npreference prediction, enabling robots to acquire complex skills including\nsubtle control over gait patterns and rhythmic timing. We evaluate LAPP on a\ndiverse set of quadruped locomotion and dexterous manipulation tasks and show\nthat it achieves efficient learning, higher final performance, faster\nadaptation, and precise control of high-level behaviors. Notably, LAPP enables\nrobots to master highly dynamic and expressive tasks such as quadruped\nbackflips, which remain out of reach for standard LLM-generated or handcrafted\nrewards. Our results highlight LAPP as a promising direction for scalable\npreference-driven robot learning."}
{"id": "2504.15801", "pdf": "https://arxiv.org/pdf/2504.15801", "abs": "https://arxiv.org/abs/2504.15801", "authors": ["Valeria Lerman", "Yaniv Dover"], "title": "A closer look at how large language models trust humans: patterns and biases", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "As large language models (LLMs) and LLM-based agents increasingly interact\nwith humans in decision-making contexts, understanding the trust dynamics\nbetween humans and AI agents becomes a central concern. While considerable\nliterature studies how humans trust AI agents, it is much less understood how\nLLM-based agents develop effective trust in humans. LLM-based agents likely\nrely on some sort of implicit effective trust in trust-related contexts (e.g.,\nevaluating individual loan applications) to assist and affect decision making.\nUsing established behavioral theories, we develop an approach that studies\nwhether LLMs trust depends on the three major trustworthiness dimensions:\ncompetence, benevolence and integrity of the human subject. We also study how\ndemographic variables affect effective trust. Across 43,200 simulated\nexperiments, for five popular language models, across five different scenarios\nwe find that LLM trust development shows an overall similarity to human trust\ndevelopment. We find that in most, but not all cases, LLM trust is strongly\npredicted by trustworthiness, and in some cases also biased by age, religion\nand gender, especially in financial scenarios. This is particularly true for\nscenarios common in the literature and for newer models. While the overall\npatterns align with human-like mechanisms of effective trust formation,\ndifferent models exhibit variation in how they estimate trust; in some cases,\ntrustworthiness and demographic factors are weak predictors of effective trust.\nThese findings call for a better understanding of AI-to-human trust dynamics\nand monitoring of biases and trust development patterns to prevent unintended\nand potentially harmful outcomes in trust-sensitive applications of AI."}
{"id": "2504.15473", "pdf": "https://arxiv.org/pdf/2504.15473", "abs": "https://arxiv.org/abs/2504.15473", "authors": ["Berk Tinaz", "Zalan Fabian", "Mahdi Soltanolkotabi"], "title": "Emergence and Evolution of Interpretable Concepts in Diffusion Models", "categories": ["cs.CV", "cs.LG", "eess.IV", "I.2.6; I.2.10"], "comment": "32 pages, 32 figures, preliminary version", "summary": "Diffusion models have become the go-to method for text-to-image generation,\nproducing high-quality images from noise through a process called reverse\ndiffusion. Understanding the dynamics of the reverse diffusion process is\ncrucial in steering the generation and achieving high sample quality. However,\nthe inner workings of diffusion models is still largely a mystery due to their\nblack-box nature and complex, multi-step generation process. Mechanistic\nInterpretability (MI) techniques, such as Sparse Autoencoders (SAEs), aim at\nuncovering the operating principles of models through granular analysis of\ntheir internal representations. These MI techniques have been successful in\nunderstanding and steering the behavior of large language models at scale.\nHowever, the great potential of SAEs has not yet been applied toward gaining\ninsight into the intricate generative process of diffusion models. In this\nwork, we leverage the SAE framework to probe the inner workings of a popular\ntext-to-image diffusion model, and uncover a variety of human-interpretable\nconcepts in its activations. Interestingly, we find that even before the first\nreverse diffusion step is completed, the final composition of the scene can be\npredicted surprisingly well by looking at the spatial distribution of activated\nconcepts. Moreover, going beyond correlational analysis, we show that the\ndiscovered concepts have a causal effect on the model output and can be\nleveraged to steer the generative process. We design intervention techniques\naimed at manipulating image composition and style, and demonstrate that (1) in\nearly stages of diffusion image composition can be effectively controlled, (2)\nin the middle stages of diffusion image composition is finalized, however\nstylistic interventions are effective, and (3) in the final stages of diffusion\nonly minor textural details are subject to change."}
{"id": "2504.15804", "pdf": "https://arxiv.org/pdf/2504.15804", "abs": "https://arxiv.org/abs/2504.15804", "authors": ["Ning Wang", "Bingkun Yao", "Jie Zhou", "Yuchen Hu", "Xi Wang", "Nan Guan", "Zhe Jiang"], "title": "Insights from Verification: Training a Verilog Generation LLM with Reinforcement Learning with Testbench Feedback", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown strong performance in Verilog\ngeneration from natural language description. However, ensuring the functional\ncorrectness of the generated code remains a significant challenge. This paper\nintroduces a method that integrates verification insights from testbench into\nthe training of Verilog generation LLMs, aligning the training with the\nfundamental goal of hardware design: functional correctness. The main obstacle\nin using LLMs for Verilog code generation is the lack of sufficient functional\nverification data, particularly testbenches paired with design specifications\nand code. To address this problem, we introduce an automatic testbench\ngeneration pipeline that decomposes the process and uses feedback from the\nVerilog compiler simulator (VCS) to reduce hallucination and ensure\ncorrectness. We then use the testbench to evaluate the generated codes and\ncollect them for further training, where verification insights are introduced.\nOur method applies reinforcement learning (RL), specifically direct preference\noptimization (DPO), to align Verilog code generation with functional\ncorrectness by training preference pairs based on testbench outcomes. In\nevaluations on VerilogEval-Machine, VerilogEval-Human, RTLLM v1.1, RTLLM v2,\nand VerilogEval v2, our approach consistently outperforms state-of-the-art\nbaselines in generating functionally correct Verilog code. We open source all\ntraining code, data, and models at\nhttps://anonymous.4open.science/r/VeriPrefer-E88B."}
{"id": "2504.15512", "pdf": "https://arxiv.org/pdf/2504.15512", "abs": "https://arxiv.org/abs/2504.15512", "authors": ["Siyuan Liang", "Jiayang Liu", "Jiecheng Zhai", "Tianmeng Fang", "Rongcheng Tu", "Aishan Liu", "Xiaochun Cao", "Dacheng Tao"], "title": "T2VShield: Model-Agnostic Jailbreak Defense for Text-to-Video Models", "categories": ["cs.CR", "cs.LG"], "comment": "25 pages, 5 figures", "summary": "The rapid development of generative artificial intelligence has made text to\nvideo models essential for building future multimodal world simulators.\nHowever, these models remain vulnerable to jailbreak attacks, where specially\ncrafted prompts bypass safety mechanisms and lead to the generation of harmful\nor unsafe content. Such vulnerabilities undermine the reliability and security\nof simulation based applications. In this paper, we propose T2VShield, a\ncomprehensive and model agnostic defense framework designed to protect text to\nvideo models from jailbreak threats. Our method systematically analyzes the\ninput, model, and output stages to identify the limitations of existing\ndefenses, including semantic ambiguities in prompts, difficulties in detecting\nmalicious content in dynamic video outputs, and inflexible model centric\nmitigation strategies. T2VShield introduces a prompt rewriting mechanism based\non reasoning and multimodal retrieval to sanitize malicious inputs, along with\na multi scope detection module that captures local and global inconsistencies\nacross time and modalities. The framework does not require access to internal\nmodel parameters and works with both open and closed source systems. Extensive\nexperiments on five platforms show that T2VShield can reduce jailbreak success\nrates by up to 35 percent compared to strong baselines. We further develop a\nhuman centered audiovisual evaluation protocol to assess perceptual safety,\nemphasizing the importance of visual level defense in enhancing the\ntrustworthiness of next generation multimodal simulators."}
{"id": "2504.15806", "pdf": "https://arxiv.org/pdf/2504.15806", "abs": "https://arxiv.org/abs/2504.15806", "authors": ["Kai Luo", "Juan Tang", "Mingchao Cai", "Xiaoqing Zeng", "Manqi Xie", "Ming Yan"], "title": "DAE-KAN: A Kolmogorov-Arnold Network Model for High-Index Differential-Algebraic Equations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to\nMulti-Layer Perceptrons (MLPs) due to their superior function-fitting abilities\nin data-driven modeling. In this paper, we propose a novel framework, DAE-KAN,\nfor solving high-index differential-algebraic equations (DAEs) by integrating\nKANs with Physics-Informed Neural Networks (PINNs). This framework not only\npreserves the ability of traditional PINNs to model complex systems governed by\nphysical laws but also enhances their performance by leveraging the\nfunction-fitting strengths of KANs. Numerical experiments demonstrate that for\nDAE systems ranging from index-1 to index-3, DAE-KAN reduces the absolute\nerrors of both differential and algebraic variables by 1 to 2 orders of\nmagnitude compared to traditional PINNs. To assess the effectiveness of this\napproach, we analyze the drift-off error and find that both PINNs and DAE-KAN\noutperform classical numerical methods in controlling this phenomenon. Our\nresults highlight the potential of neural network methods, particularly\nDAE-KAN, in solving high-index DAEs with substantial computational accuracy and\ngeneralization, offering a promising solution for challenging partial\ndifferential-algebraic equations."}
{"id": "2504.15517", "pdf": "https://arxiv.org/pdf/2504.15517", "abs": "https://arxiv.org/abs/2504.15517", "authors": ["Mingchen Song", "Xiang Deng", "Guoqiang Zhong", "Qi Lv", "Jia Wan", "Yinchuan Li", "Jianye Hao", "Weili Guan"], "title": "Few-Shot Vision-Language Action-Incremental Policy Learning", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Recently, Transformer-based robotic manipulation methods utilize multi-view\nspatial representations and language instructions to learn robot motion\ntrajectories by leveraging numerous robot demonstrations. However, the\ncollection of robot data is extremely challenging, and existing methods lack\nthe capability for continuous learning on new tasks with only a few\ndemonstrations. In this paper, we formulate these challenges as the Few-Shot\nAction-Incremental Learning (FSAIL) task, and accordingly design a Task-prOmpt\ngraPh evolutIon poliCy (TOPIC) to address these issues. Specifically, to\naddress the data scarcity issue in robotic imitation learning, TOPIC learns\nTask-Specific Prompts (TSP) through the deep interaction of multi-modal\ninformation within few-shot demonstrations, thereby effectively extracting the\ntask-specific discriminative information. On the other hand, to enhance the\ncapability for continual learning on new tasks and mitigate the issue of\ncatastrophic forgetting, TOPIC adopts a Continuous Evolution Strategy (CES).\nCES leverages the intrinsic relationships between tasks to construct a task\nrelation graph, which effectively facilitates the adaptation of new tasks by\nreusing skills learned from previous tasks. TOPIC pioneers few-shot continual\nlearning in the robotic manipulation task, and extensive experimental results\ndemonstrate that TOPIC outperforms state-of-the-art baselines by over 26$\\%$ in\nsuccess rate, significantly enhancing the continual learning capabilities of\nexisting Transformer-based policies."}
{"id": "2504.15812", "pdf": "https://arxiv.org/pdf/2504.15812", "abs": "https://arxiv.org/abs/2504.15812", "authors": ["Xuchuang Wang", "Qirun Zeng", "Jinhang Zuo", "Xutong Liu", "Mohammad Hajiesmaili", "John C. S. Lui", "Adam Wierman"], "title": "Fusing Reward and Dueling Feedback in Stochastic Bandits", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper investigates the fusion of absolute (reward) and relative\n(dueling) feedback in stochastic bandits, where both feedback types are\ngathered in each decision round. We derive a regret lower bound, demonstrating\nthat an efficient algorithm may incur only the smaller among the reward and\ndueling-based regret for each individual arm. We propose two fusion approaches:\n(1) a simple elimination fusion algorithm that leverages both feedback types to\nexplore all arms and unifies collected information by sharing a common\ncandidate arm set, and (2) a decomposition fusion algorithm that selects the\nmore effective feedback to explore the corresponding arms and randomly assigns\none feedback type for exploration and the other for exploitation in each round.\nThe elimination fusion experiences a suboptimal multiplicative term of the\nnumber of arms in regret due to the intrinsic suboptimality of dueling\nelimination. In contrast, the decomposition fusion achieves regret matching the\nlower bound up to a constant under a common assumption. Extensive experiments\nconfirm the efficacy of our algorithms and theoretical results."}
{"id": "2504.15541", "pdf": "https://arxiv.org/pdf/2504.15541", "abs": "https://arxiv.org/abs/2504.15541", "authors": ["Qichao Liu", "Heye Huang", "Shiyue Zhao", "Lei Shi", "Soyoung Ahn", "Xiaopeng Li"], "title": "RiskNet: Interaction-Aware Risk Forecasting for Autonomous Driving in Long-Tail Scenarios", "categories": ["cs.RO", "cs.LG"], "comment": "24 pages, 14 figures", "summary": "Ensuring the safety of autonomous vehicles (AVs) in long-tail scenarios\nremains a critical challenge, particularly under high uncertainty and complex\nmulti-agent interactions. To address this, we propose RiskNet, an\ninteraction-aware risk forecasting framework, which integrates deterministic\nrisk modeling with probabilistic behavior prediction for comprehensive risk\nassessment. At its core, RiskNet employs a field-theoretic model that captures\ninteractions among ego vehicle, surrounding agents, and infrastructure via\ninteraction fields and force. This model supports multidimensional risk\nevaluation across diverse scenarios (highways, intersections, and roundabouts),\nand shows robustness under high-risk and long-tail settings. To capture the\nbehavioral uncertainty, we incorporate a graph neural network (GNN)-based\ntrajectory prediction module, which learns multi-modal future motion\ndistributions. Coupled with the deterministic risk field, it enables dynamic,\nprobabilistic risk inference across time, enabling proactive safety assessment\nunder uncertainty. Evaluations on the highD, inD, and rounD datasets, spanning\nlane changes, turns, and complex merges, demonstrate that our method\nsignificantly outperforms traditional approaches (e.g., TTC, THW, RSS, NC\nField) in terms of accuracy, responsiveness, and directional sensitivity, while\nmaintaining strong generalization across scenarios. This framework supports\nreal-time, scenario-adaptive risk forecasting and demonstrates strong\ngeneralization across uncertain driving environments. It offers a unified\nfoundation for safety-critical decision-making in long-tail scenarios."}
{"id": "2504.15823", "pdf": "https://arxiv.org/pdf/2504.15823", "abs": "https://arxiv.org/abs/2504.15823", "authors": ["Songyan Xie", "Jinghang Wen", "Encheng Su", "Qiucheng Yu"], "title": "Human-Imperceptible Physical Adversarial Attack for NIR Face Recognition Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Near-infrared (NIR) face recognition systems, which can operate effectively\nin low-light conditions or in the presence of makeup, exhibit vulnerabilities\nwhen subjected to physical adversarial attacks. To further demonstrate the\npotential risks in real-world applications, we design a novel, stealthy, and\npractical adversarial patch to attack NIR face recognition systems in a\nblack-box setting. We achieved this by utilizing human-imperceptible\ninfrared-absorbing ink to generate multiple patches with digitally optimized\nshapes and positions for infrared images. To address the optimization mismatch\nbetween digital and real-world NIR imaging, we develop a light reflection model\nfor human skin to minimize pixel-level discrepancies by simulating NIR light\nreflection.\n  Compared to state-of-the-art (SOTA) physical attacks on NIR face recognition\nsystems, the experimental results show that our method improves the attack\nsuccess rate in both digital and physical domains, particularly maintaining\neffectiveness across various face postures. Notably, the proposed approach\noutperforms SOTA methods, achieving an average attack success rate of 82.46% in\nthe physical domain across different models, compared to 64.18% for existing\nmethods. The artifact is available at\nhttps://anonymous.4open.science/r/Human-imperceptible-adversarial-patch-0703/."}
{"id": "2504.15549", "pdf": "https://arxiv.org/pdf/2504.15549", "abs": "https://arxiv.org/abs/2504.15549", "authors": ["Anjali Khurana", "Xiaotian Su", "April Yi Wang", "Parmit K Chilana"], "title": "Do It For Me vs. Do It With Me: Investigating User Perceptions of Different Paradigms of Automation in Copilots for Feature-Rich Software", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": "Accepted for publication in the CHI Conference on Human Factors in\n  Computing Systems (CHI 2025), April 26 - May 1, 2025, Yokohama, Japan", "summary": "Large Language Model (LLM)-based in-application assistants, or copilots, can\nautomate software tasks, but users often prefer learning by doing, raising\nquestions about the optimal level of automation for an effective user\nexperience. We investigated two automation paradigms by designing and\nimplementing a fully automated copilot (AutoCopilot) and a semi-automated\ncopilot (GuidedCopilot) that automates trivial steps while offering\nstep-by-step visual guidance. In a user study (N=20) across data analysis and\nvisual design tasks, GuidedCopilot outperformed AutoCopilot in user control,\nsoftware utility, and learnability, especially for exploratory and creative\ntasks, while AutoCopilot saved time for simpler visual tasks. A follow-up\ndesign exploration (N=10) enhanced GuidedCopilot with task-and state-aware\nfeatures, including in-context preview clips and adaptive instructions. Our\nfindings highlight the critical role of user control and tailored guidance in\ndesigning the next generation of copilots that enhance productivity, support\ndiverse skill levels, and foster deeper software engagement."}
{"id": "2504.15827", "pdf": "https://arxiv.org/pdf/2504.15827", "abs": "https://arxiv.org/abs/2504.15827", "authors": ["Xuyang Zhong", "Haochen Luo", "Chen Liu"], "title": "DualOptim: Enhancing Efficacy and Stability in Machine Unlearning with Dual Optimizers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Existing machine unlearning (MU) approaches exhibit significant sensitivity\nto hyperparameters, requiring meticulous tuning that limits practical\ndeployment. In this work, we first empirically demonstrate the instability and\nsuboptimal performance of existing popular MU methods when deployed in\ndifferent scenarios. To address this issue, we propose Dual Optimizer\n(DualOptim), which incorporates adaptive learning rate and decoupled momentum\nfactors. Empirical and theoretical evidence demonstrates that DualOptim\ncontributes to effective and stable unlearning. Through extensive experiments,\nwe show that DualOptim can significantly boost MU efficacy and stability across\ndiverse tasks, including image classification, image generation, and large\nlanguage models, making it a versatile approach to empower existing MU\nalgorithms."}
{"id": "2504.15561", "pdf": "https://arxiv.org/pdf/2504.15561", "abs": "https://arxiv.org/abs/2504.15561", "authors": ["Jingkai Xu", "Xiangli Nie"], "title": "SPECI: Skill Prompts based Hierarchical Continual Imitation Learning for Robot Manipulation", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Real-world robot manipulation in dynamic unstructured environments requires\nlifelong adaptability to evolving objects, scenes and tasks. Traditional\nimitation learning relies on static training paradigms, which are ill-suited\nfor lifelong adaptation. Although Continual Imitation Learnin (CIL) enables\nincremental task adaptation while preserving learned knowledge, current CIL\nmethods primarily overlook the intrinsic skill characteristics of robot\nmanipulation or depend on manually defined and rigid skills, leading to\nsuboptimal cross-task knowledge transfer. To address these issues, we propose\nSkill Prompts-based HiErarchical Continual Imitation Learning (SPECI), a novel\nend-to-end hierarchical CIL policy architecture for robot manipulation. The\nSPECI framework consists of a multimodal perception and fusion module for\nheterogeneous sensory information encoding, a high-level skill inference module\nfor dynamic skill extraction and selection, and a low-level action execution\nmodule for precise action generation. To enable efficient knowledge transfer on\nboth skill and task levels, SPECI performs continual implicit skill acquisition\nand reuse via an expandable skill codebook and an attention-driven skill\nselection mechanism. Furthermore, we introduce mode approximation to augment\nthe last two modules with task-specific and task-sharing parameters, thereby\nenhancing task-level knowledge transfer. Extensive experiments on diverse\nmanipulation task suites demonstrate that SPECI consistently outperforms\nstate-of-the-art CIL methods across all evaluated metrics, revealing\nexceptional bidirectional knowledge transfer and superior overall performance."}
{"id": "2504.15865", "pdf": "https://arxiv.org/pdf/2504.15865", "abs": "https://arxiv.org/abs/2504.15865", "authors": ["Lotfi Abdelkrim Mecharbat", "Ibrahim Elmakky", "Martin Takac", "Mohammed Yaqub"], "title": "MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep learning (DL) has achieved remarkable progress in the field of medical\nimaging. However, adapting DL models to medical tasks remains a significant\nchallenge, primarily due to two key factors: (1) architecture selection, as\ndifferent tasks necessitate specialized model designs, and (2) weight\ninitialization, which directly impacts the convergence speed and final\nperformance of the models. Although transfer learning from ImageNet is a widely\nadopted strategy, its effectiveness is constrained by the substantial\ndifferences between natural and medical images. To address these challenges, we\nintroduce Medical Neural Network Search (MedNNS), the first Neural Network\nSearch framework for medical imaging applications. MedNNS jointly optimizes\narchitecture selection and weight initialization by constructing a meta-space\nthat encodes datasets and models based on how well they perform together. We\nbuild this space using a Supernetwork-based approach, expanding the model zoo\nsize by 51x times over previous state-of-the-art (SOTA) methods. Moreover, we\nintroduce rank loss and Fr\\'echet Inception Distance (FID) loss into the\nconstruction of the space to capture inter-model and inter-dataset\nrelationships, thereby achieving more accurate alignment in the meta-space.\nExperimental results across multiple datasets demonstrate that MedNNS\nsignificantly outperforms both ImageNet pre-trained DL models and SOTA Neural\nArchitecture Search (NAS) methods, achieving an average accuracy improvement of\n1.7% across datasets while converging substantially faster. The code and the\nprocessed meta-space is available at https://github.com/BioMedIA-MBZUAI/MedNNS."}
{"id": "2504.15564", "pdf": "https://arxiv.org/pdf/2504.15564", "abs": "https://arxiv.org/abs/2504.15564", "authors": ["Musfiqur Rahman", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "A Large-scale Class-level Benchmark Dataset for Code Generation with LLMs", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "This paper was submitted to the 29th International Conference on\n  Evaluation and Assessment in Software Engineering (EASE 2025) AI models/data\n  track", "summary": "Recent advancements in large language models (LLMs) have demonstrated\npromising capabilities in code generation tasks. However, most existing\nbenchmarks focus on isolated functions and fail to capture the complexity of\nreal-world, class-level software structures. To address this gap, we introduce\na large-scale, Python class-level dataset curated from $13{,}174$ real-world\nopen-source projects. The dataset contains over 842,000 class skeletons, each\nincluding class and method signatures, along with associated docstrings when\navailable. We preserve structural and contextual dependencies critical to\nrealistic software development scenarios and enrich the dataset with static\ncode metrics to support downstream analysis. To evaluate the usefulness of this\ndataset, we use extracted class skeletons as prompts for GPT-4 to generate full\nclass implementations. Results show that the LLM-generated classes exhibit\nstrong lexical and structural similarity to human-written counterparts, with\naverage ROUGE@L, BLEU, and TSED scores of 0.80, 0.59, and 0.73, respectively.\nThese findings confirm that well-structured prompts derived from real-world\nclass skeletons significantly enhance LLM performance in class-level code\ngeneration. This dataset offers a valuable resource for benchmarking, training,\nand improving LLMs in realistic software engineering contexts."}
{"id": "2504.15876", "pdf": "https://arxiv.org/pdf/2504.15876", "abs": "https://arxiv.org/abs/2504.15876", "authors": ["Qizhen Wu Lei Chen", "Kexin Liu", "Jinhu Lü"], "title": "Bidirectional Task-Motion Planning Based on Hierarchical Reinforcement Learning for Strategic Confrontation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "In swarm robotics, confrontation scenarios, including strategic\nconfrontations, require efficient decision-making that integrates discrete\ncommands and continuous actions. Traditional task and motion planning methods\nseparate decision-making into two layers, but their unidirectional structure\nfails to capture the interdependence between these layers, limiting\nadaptability in dynamic environments. Here, we propose a novel bidirectional\napproach based on hierarchical reinforcement learning, enabling dynamic\ninteraction between the layers. This method effectively maps commands to task\nallocation and actions to path planning, while leveraging cross-training\ntechniques to enhance learning across the hierarchical framework. Furthermore,\nwe introduce a trajectory prediction model that bridges abstract task\nrepresentations with actionable planning goals. In our experiments, it achieves\nover 80\\% in confrontation win rate and under 0.01 seconds in decision time,\noutperforming existing approaches. Demonstrations through large-scale tests and\nreal-world robot experiments further emphasize the generalization capabilities\nand practical applicability of our method."}
{"id": "2504.15577", "pdf": "https://arxiv.org/pdf/2504.15577", "abs": "https://arxiv.org/abs/2504.15577", "authors": ["Qingyuan He", "Chang Liu", "Juecen Zhan", "Weiqiang Huang", "Ran Hao"], "title": "State-Aware IoT Scheduling Using Deep Q-Networks and Edge-Based Coordination", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "This paper addresses the challenge of energy efficiency management faced by\nintelligent IoT devices in complex application environments. A novel\noptimization method is proposed, combining Deep Q-Network (DQN) with an edge\ncollaboration mechanism. The method builds a state-action-reward interaction\nmodel and introduces edge nodes as intermediaries for state aggregation and\npolicy scheduling. This enables dynamic resource coordination and task\nallocation among multiple devices. During the modeling process, device status,\ntask load, and network resources are jointly incorporated into the state space.\nThe DQN is used to approximate and learn the optimal scheduling strategy. To\nenhance the model's ability to perceive inter-device relationships, a\ncollaborative graph structure is introduced to model the multi-device\nenvironment and assist in decision optimization. Experiments are conducted\nusing real-world IoT data collected from the FastBee platform. Several\ncomparative and validation tests are performed, including energy efficiency\ncomparisons across different scheduling strategies, robustness analysis under\nvarying task loads, and evaluation of state dimension impacts on policy\nconvergence speed. The results show that the proposed method outperforms\nexisting baseline approaches in terms of average energy consumption, processing\nlatency, and resource utilization. This confirms its effectiveness and\npracticality in intelligent IoT scenarios."}
{"id": "2504.15883", "pdf": "https://arxiv.org/pdf/2504.15883", "abs": "https://arxiv.org/abs/2504.15883", "authors": ["Farida Mohsen", "Samir Belhaouari", "Zubair Shah"], "title": "Integrating Non-Linear Radon Transformation for Diabetic Retinopathy Grading", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diabetic retinopathy is a serious ocular complication that poses a\nsignificant threat to patients' vision and overall health. Early detection and\naccurate grading are essential to prevent vision loss. Current automatic\ngrading methods rely heavily on deep learning applied to retinal fundus images,\nbut the complex, irregular patterns of lesions in these images, which vary in\nshape and distribution, make it difficult to capture subtle changes. This study\nintroduces RadFuse, a multi-representation deep learning framework that\nintegrates non-linear RadEx-transformed sinogram images with traditional fundus\nimages to enhance diabetic retinopathy detection and grading. Our RadEx\ntransformation, an optimized non-linear extension of the Radon transform,\ngenerates sinogram representations to capture complex retinal lesion patterns.\nBy leveraging both spatial and transformed domain information, RadFuse enriches\nthe feature set available to deep learning models, improving the\ndifferentiation of severity levels. We conducted extensive experiments on two\nbenchmark datasets, APTOS-2019 and DDR, using three convolutional neural\nnetworks (CNNs): ResNeXt-50, MobileNetV2, and VGG19. RadFuse showed significant\nimprovements over fundus-image-only models across all three CNN architectures\nand outperformed state-of-the-art methods on both datasets. For severity\ngrading across five stages, RadFuse achieved a quadratic weighted kappa of\n93.24%, an accuracy of 87.07%, and an F1-score of 87.17%. In binary\nclassification between healthy and diabetic retinopathy cases, the method\nreached an accuracy of 99.09%, precision of 98.58%, and recall of 99.6%,\nsurpassing previously established models. These results demonstrate RadFuse's\ncapacity to capture complex non-linear features, advancing diabetic retinopathy\nclassification and promoting the integration of advanced mathematical\ntransforms in medical image analysis."}
{"id": "2504.15578", "pdf": "https://arxiv.org/pdf/2504.15578", "abs": "https://arxiv.org/abs/2504.15578", "authors": ["Ian Mikesell", "Samuel Filgueira da Silva", "Mehmet Fatih Ozkan", "Faissal El Idrissi", "Prashanth Ramesh", "Marcello Canova"], "title": "Real-Time Optimal Design of Experiment for Parameter Identification of Li-Ion Cell Electrochemical Model", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "Accurately identifying the parameters of electrochemical models of li-ion\nbattery (LiB) cells is a critical task for enhancing the fidelity and\npredictive ability. Traditional parameter identification methods often require\nextensive data collection experiments and lack adaptability in dynamic\nenvironments. This paper describes a Reinforcement Learning (RL) based approach\nthat dynamically tailors the current profile applied to a LiB cell to optimize\nthe parameters identifiability of the electrochemical model. The proposed\nframework is implemented in real-time using a Hardware-in-the-Loop (HIL) setup,\nwhich serves as a reliable testbed for evaluating the RL-based design strategy.\nThe HIL validation confirms that the RL-based experimental design outperforms\nconventional test protocols used for parameter identification in terms of both\nreducing the modeling errors on a verification test and minimizing the duration\nof the experiment used for parameter identification."}
{"id": "2504.15894", "pdf": "https://arxiv.org/pdf/2504.15894", "abs": "https://arxiv.org/abs/2504.15894", "authors": ["Chengbo Zheng", "Tim Miller", "Alina Bialkowski", "H Peter Soyer", "Monika Janda"], "title": "Supporting Data-Frame Dynamics in AI-assisted Decision Making", "categories": ["cs.HC", "cs.AI"], "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING", "summary": "High stakes decision-making often requires a continuous interplay between\nevolving evidence and shifting hypotheses, a dynamic that is not well supported\nby current AI decision support systems. In this paper, we introduce a\nmixed-initiative framework for AI assisted decision making that is grounded in\nthe data-frame theory of sensemaking and the evaluative AI paradigm. Our\napproach enables both humans and AI to collaboratively construct, validate, and\nadapt hypotheses. We demonstrate our framework with an AI-assisted skin cancer\ndiagnosis prototype that leverages a concept bottleneck model to facilitate\ninterpretable interactions and dynamic updates to diagnostic hypotheses."}
{"id": "2504.15580", "pdf": "https://arxiv.org/pdf/2504.15580", "abs": "https://arxiv.org/abs/2504.15580", "authors": ["Chengyuan Deng", "Jie Gao", "Jalaj Upadhyay", "Chen Wang", "Samson Zhou"], "title": "On the Price of Differential Privacy for Hierarchical Clustering", "categories": ["cs.DS", "cs.CR", "cs.LG"], "comment": "ICLR 2025", "summary": "Hierarchical clustering is a fundamental unsupervised machine learning task\nwith the aim of organizing data into a hierarchy of clusters. Many applications\nof hierarchical clustering involve sensitive user information, therefore\nmotivating recent studies on differentially private hierarchical clustering\nunder the rigorous framework of Dasgupta's objective. However, it has been\nshown that any privacy-preserving algorithm under edge-level differential\nprivacy necessarily suffers a large error. To capture practical applications of\nthis problem, we focus on the weight privacy model, where each edge of the\ninput graph is at least unit weight. We present a novel algorithm in the weight\nprivacy model that shows significantly better approximation than known\nimpossibility results in the edge-level DP setting. In particular, our\nalgorithm achieves $O(\\log^{1.5}n/\\varepsilon)$ multiplicative error for\n$\\varepsilon$-DP and runs in polynomial time, where $n$ is the size of the\ninput graph, and the cost is never worse than the optimal additive error in\nexisting work. We complement our algorithm by showing if the unit-weight\nconstraint does not apply, the lower bound for weight-level DP hierarchical\nclustering is essentially the same as the edge-level DP, i.e.\n$\\Omega(n^2/\\varepsilon)$ additive error. As a result, we also obtain a new\nlower bound of $\\tilde{\\Omega}(1/\\varepsilon)$ additive error for balanced\nsparsest cuts in the weight-level DP model, which may be of independent\ninterest. Finally, we evaluate our algorithm on synthetic and real-world\ndatasets. Our experimental results show that our algorithm performs well in\nterms of extra cost and has good scalability to large graphs."}
{"id": "2504.15895", "pdf": "https://arxiv.org/pdf/2504.15895", "abs": "https://arxiv.org/abs/2504.15895", "authors": ["Chenxu Yang", "Qingyi Si", "Yongjie Duan", "Zheliang Zhu", "Chenyu Zhu", "Zheng Lin", "Li Cao", "Weiping Wang"], "title": "Dynamic Early Exit in Reasoning Models", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages, 11 figures", "summary": "Recent advances in large reasoning language models (LRLMs) rely on test-time\nscaling, which extends long chain-of-thought (CoT) generation to solve complex\ntasks. However, overthinking in long CoT not only slows down the efficiency of\nproblem solving, but also risks accuracy loss due to the extremely detailed or\nredundant reasoning steps. We propose a simple yet effective method that allows\nLLMs to self-truncate CoT sequences by early exit during generation. Instead of\nrelying on fixed heuristics, the proposed method monitors model behavior at\npotential reasoning transition points (e.g.,\"Wait\" tokens) and dynamically\nterminates the next reasoning chain's generation when the model exhibits high\nconfidence in a trial answer. Our method requires no additional training and\ncan be seamlessly integrated into existing o1-like reasoning LLMs. Experiments\non multiple reasoning benchmarks MATH-500, AMC 2023, GPQA Diamond and AIME 2024\nshow that the proposed method is consistently effective on deepseek-series\nreasoning LLMs, reducing the length of CoT sequences by an average of 31% to\n43% while improving accuracy by 1.7% to 5.7%."}
{"id": "2504.15585", "pdf": "https://arxiv.org/pdf/2504.15585", "abs": "https://arxiv.org/abs/2504.15585", "authors": ["Kun Wang", "Guibin Zhang", "Zhenhong Zhou", "Jiahao Wu", "Miao Yu", "Shiqian Zhao", "Chenlong Yin", "Jinhu Fu", "Yibo Yan", "Hanjun Luo", "Liang Lin", "Zhihao Xu", "Haolang Lu", "Xinye Cao", "Xinyun Zhou", "Weifei Jin", "Fanci Meng", "Junyuan Mao", "Hao Wu", "Minghe Wang", "Fan Zhang", "Junfeng Fang", "Chengwei Liu", "Yifan Zhang", "Qiankun Li", "Chongye Guo", "Yalan Qin", "Yi Ding", "Donghai Hong", "Jiaming Ji", "Xinfeng Li", "Yifan Jiang", "Dongxia Wang", "Yihao Huang", "Yufei Guo", "Jen-tse Huang", "Yanwei Yue", "Wenke Huang", "Guancheng Wan", "Tianlin Li", "Lei Bai", "Jie Zhang", "Qing Guo", "Jingyi Wang", "Tianlong Chen", "Joey Tianyi Zhou", "Xiaojun Jia", "Weisong Sun", "Cong Wu", "Jing Chen", "Xuming Hu", "Yiming Li", "Xiao Wang", "Ningyu Zhang", "Luu Anh Tuan", "Guowen Xu", "Tianwei Zhang", "Xingjun Ma", "Xiang Wang", "Bo An", "Jun Sun", "Mohit Bansal", "Shirui Pan", "Yuval Elovici", "Bhavya Kailkhura", "Bo Li", "Yaodong Yang", "Hongwei Li", "Wenyuan Xu", "Yizhou Sun", "Wei Wang", "Qing Li", "Ke Tang", "Yu-Gang Jiang", "Felix Juefei-Xu", "Hui Xiong", "Xiaofeng Wang", "Shuicheng Yan", "Dacheng Tao", "Philip S. Yu", "Qingsong Wen", "Yang Liu"], "title": "A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "The remarkable success of Large Language Models (LLMs) has illuminated a\npromising pathway toward achieving Artificial General Intelligence for both\nacademic and industrial communities, owing to their unprecedented performance\nacross various applications. As LLMs continue to gain prominence in both\nresearch and commercial domains, their security and safety implications have\nbecome a growing concern, not only for researchers and corporations but also\nfor every nation. Currently, existing surveys on LLM safety primarily focus on\nspecific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning\nphase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs.\nTo address this gap, this paper introduces, for the first time, the concept of\n\"full-stack\" safety to systematically consider safety issues throughout the\nentire process of LLM training, deployment, and eventual commercialization.\nCompared to the off-the-shelf LLM safety surveys, our work demonstrates several\ndistinctive advantages: (I) Comprehensive Perspective. We define the complete\nLLM lifecycle as encompassing data preparation, pre-training, post-training,\ndeployment and final commercialization. To our knowledge, this represents the\nfirst safety survey to encompass the entire lifecycle of LLMs. (II) Extensive\nLiterature Support. Our research is grounded in an exhaustive review of over\n800+ papers, ensuring comprehensive coverage and systematic organization of\nsecurity issues within a more holistic understanding. (III) Unique Insights.\nThrough systematic literature analysis, we have developed reliable roadmaps and\nperspectives for each chapter. Our work identifies promising research\ndirections, including safety in data generation, alignment techniques, model\nediting, and LLM-based agent systems. These insights provide valuable guidance\nfor researchers pursuing future work in this field."}
{"id": "2504.15905", "pdf": "https://arxiv.org/pdf/2504.15905", "abs": "https://arxiv.org/abs/2504.15905", "authors": ["Wenjing Xiao", "Chenglong Shi", "Miaojiang Chen", "Zhiquan Liu", "Min Chen", "H. Herbert Song"], "title": "GraphEdge: Dynamic Graph Partition and Task Scheduling for GNNs Computing in Edge Network", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages,12 figures", "summary": "With the exponential growth of Internet of Things (IoT) devices, edge\ncomputing (EC) is gradually playing an important role in providing\ncost-effective services. However, existing approaches struggle to perform well\nin graph-structured scenarios where user data is correlated, such as traffic\nflow prediction and social relationship recommender systems. In particular,\ngraph neural network (GNN)-based approaches lead to expensive server\ncommunication cost. To address this problem, we propose GraphEdge, an efficient\nGNN-based EC architecture. It considers the EC system of GNN tasks, where there\nare associations between users and it needs to take into account the task data\nof its neighbors when processing the tasks of a user. Specifically, the\narchitecture first perceives the user topology and represents their data\nassociations as a graph layout at each time step. Then the graph layout is\noptimized by calling our proposed hierarchical traversal graph cut algorithm\n(HiCut), which cuts the graph layout into multiple weakly associated subgraphs\nbased on the aggregation characteristics of GNN, and the communication cost\nbetween different subgraphs during GNN inference is minimized. Finally, based\non the optimized graph layout, our proposed deep reinforcement learning (DRL)\nbased graph offloading algorithm (DRLGO) is executed to obtain the optimal\noffloading strategy for the tasks of users, the offloading strategy is\nsubgraph-based, it tries to offload user tasks in a subgraph to the same edge\nserver as possible while minimizing the task processing time and energy\nconsumption of the EC system. Experimental results show the good effectiveness\nand dynamic adaptation of our proposed architecture and it also performs well\neven in dynamic scenarios."}
{"id": "2504.15599", "pdf": "https://arxiv.org/pdf/2504.15599", "abs": "https://arxiv.org/abs/2504.15599", "authors": ["Shichen Li", "Chenhui Shao"], "title": "Multi-Modal Fusion of In-Situ Video Data and Process Parameters for Online Forecasting of Cookie Drying Readiness", "categories": ["cs.CV", "cs.LG"], "comment": "17 pages, 12 figures", "summary": "Food drying is essential for food production, extending shelf life, and\nreducing transportation costs. Accurate real-time forecasting of drying\nreadiness is crucial for minimizing energy consumption, improving productivity,\nand ensuring product quality. However, this remains challenging due to the\ndynamic nature of drying, limited data availability, and the lack of effective\npredictive analytical methods. To address this gap, we propose an end-to-end\nmulti-modal data fusion framework that integrates in-situ video data with\nprocess parameters for real-time food drying readiness forecasting. Our\napproach leverages a new encoder-decoder architecture with modality-specific\nencoders and a transformer-based decoder to effectively extract features while\npreserving the unique structure of each modality. We apply our approach to\nsugar cookie drying, where time-to-ready is predicted at each timestamp.\nExperimental results demonstrate that our model achieves an average prediction\nerror of only 15 seconds, outperforming state-of-the-art data fusion methods by\n65.69% and a video-only model by 11.30%. Additionally, our model balances\nprediction accuracy, model size, and computational efficiency, making it\nwell-suited for heterogenous industrial datasets. The proposed model is\nextensible to various other industrial modality fusion tasks for online\ndecision-making."}
{"id": "2504.15912", "pdf": "https://arxiv.org/pdf/2504.15912", "abs": "https://arxiv.org/abs/2504.15912", "authors": ["Riley Pierson", "Armin Moin"], "title": "Automated Bug Report Prioritization in Large Open-Source Projects", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large open-source projects receive a large number of issues (known as bugs),\nincluding software defect (i.e., bug) reports and new feature requests from\ntheir user and developer communities at a fast rate. The often limited project\nresources do not allow them to deal with all issues. Instead, they have to\nprioritize them according to the project's priorities and the issues'\nseverities. In this paper, we propose a novel approach to automated bug\nprioritization based on the natural language text of the bug reports that are\nstored in the open bug repositories of the issue-tracking systems. We conduct\ntopic modeling using a variant of LDA called TopicMiner-MTM and text\nclassification with the BERT large language model to achieve a higher\nperformance level compared to the state-of-the-art. Experimental results using\nan existing reference dataset containing 85,156 bug reports of the Eclipse\nPlatform project indicate that we outperform existing approaches in terms of\nAccuracy, Precision, Recall, and F1-measure of the bug report priority\nprediction."}
{"id": "2504.15632", "pdf": "https://arxiv.org/pdf/2504.15632", "abs": "https://arxiv.org/abs/2504.15632", "authors": ["Seyed Shayan Daneshvar", "Da Tan", "Shaowei Wang", "Carson Leung"], "title": "A Study On Mixup-inspired Augmentation Methods For Software Vulnerability Detection", "categories": ["cs.SE", "cs.CR", "cs.LG"], "comment": "Accepted at EASE 2025, Istanbul, Turkey", "summary": "Various Deep Learning (DL) methods have recently been utilized to detect\nsoftware vulnerabilities. Real-world software vulnerability datasets are rare\nand hard to acquire as there's no simple metric for classifying vulnerability.\nSuch datasets are heavily imbalanced, and none of the current datasets are\nconsidered huge for DL models. To tackle these problems a recent work has tried\nto augment the dataset using the source code and generate realistic\nsingle-statement vulnerabilities which is not quite practical and requires\nmanual checking of the generated vulnerabilities. In this regard, we aim to\nexplore the augmentation of vulnerabilities at the representation level to help\ncurrent models learn better which has never been done before to the best of our\nknowledge. We implement and evaluate the 5 augmentation techniques that augment\nthe embedding of the data and recently have been used for code search which is\na completely different software engineering task. We also introduced a\nconditioned version of those augmentation methods, which ensures the\naugmentation does not change the vulnerable section of the vector\nrepresentation. We show that such augmentation methods can be helpful and\nincrease the f1-score by up to 9.67%, yet they cannot beat Random Oversampling\nwhen balancing datasets which increases the f1-score by 10.82%!"}
{"id": "2504.15918", "pdf": "https://arxiv.org/pdf/2504.15918", "abs": "https://arxiv.org/abs/2504.15918", "authors": ["Chang Zong", "Bin Li", "Shoujun Zhou", "Jian Wan", "Lei Zhang"], "title": "Ask2Loc: Learning to Locate Instructional Visual Answers by Asking Questions", "categories": ["cs.CV", "cs.AI", "cs.HC", "68T45, 68T20"], "comment": "16 pages, 8 figures", "summary": "Locating specific segments within an instructional video is an efficient way\nto acquire guiding knowledge. Generally, the task of obtaining video segments\nfor both verbal explanations and visual demonstrations is known as visual\nanswer localization (VAL). However, users often need multiple interactions to\nobtain answers that align with their expectations when using the system. During\nthese interactions, humans deepen their understanding of the video content by\nasking themselves questions, thereby accurately identifying the location.\nTherefore, we propose a new task, named In-VAL, to simulate the multiple\ninteractions between humans and videos in the procedure of obtaining visual\nanswers. The In-VAL task requires interactively addressing several semantic gap\nissues, including 1) the ambiguity of user intent in the input questions, 2)\nthe incompleteness of language in video subtitles, and 3) the fragmentation of\ncontent in video segments. To address these issues, we propose Ask2Loc, a\nframework for resolving In-VAL by asking questions. It includes three key\nmodules: 1) a chatting module to refine initial questions and uncover clear\nintentions, 2) a rewriting module to generate fluent language and create\ncomplete descriptions, and 3) a searching module to broaden local context and\nprovide integrated content. We conduct extensive experiments on three\nreconstructed In-VAL datasets. Compared to traditional end-to-end and two-stage\nmethods, our proposed Ask2Loc can improve performance by up to 14.91 (mIoU) on\nthe In-VAL task. Our code and datasets can be accessed at\nhttps://github.com/changzong/Ask2Loc."}
{"id": "2504.15637", "pdf": "https://arxiv.org/pdf/2504.15637", "abs": "https://arxiv.org/abs/2504.15637", "authors": ["Farnaz Behrang", "Zhizhou Zhang", "Georgian-Vlad Saioc", "Peng Liu", "Milind Chabbi"], "title": "DR.FIX: Automatically Fixing Data Races at Industry Scale", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PL", "cs.SE"], "comment": "To appear in PLDI 2025", "summary": "Data races are a prevalent class of concurrency bugs in shared-memory\nparallel programs, posing significant challenges to software reliability and\nreproducibility. While there is an extensive body of research on detecting data\nraces and a wealth of practical detection tools across various programming\nlanguages, considerably less effort has been directed toward automatically\nfixing data races at an industrial scale. In large codebases, data races are\ncontinuously introduced and exhibit myriad patterns, making automated fixing\nparticularly challenging.\n  In this paper, we tackle the problem of automatically fixing data races at an\nindustrial scale. We present Dr.Fix, a tool that combines large language models\n(LLMs) with program analysis to generate fixes for data races in real-world\nsettings, effectively addressing a broad spectrum of racy patterns in complex\ncode contexts. Implemented for Go--the programming language widely used in\nmodern microservice architectures where concurrency is pervasive and data races\nare common--Dr.Fix seamlessly integrates into existing development workflows.\nWe detail the design of Dr.Fix and examine how individual design choices\ninfluence the quality of the fixes produced. Over the past 18 months, Dr.Fix\nhas been integrated into developer workflows at Uber demonstrating its\npractical utility. During this period, Dr.Fix produced patches for 224 (55%)\nfrom a corpus of 404 data races spanning various categories; 193 of these\npatches (86%) were accepted by more than a hundred developers via code reviews\nand integrated into the codebase."}
{"id": "2504.15924", "pdf": "https://arxiv.org/pdf/2504.15924", "abs": "https://arxiv.org/abs/2504.15924", "authors": ["Alycia Carey", "Xintao Wu"], "title": "Achieving Distributive Justice in Federated Learning via Uncertainty Quantification", "categories": ["cs.LG", "cs.AI", "stat.ML", "68T01", "I.2.0"], "comment": "21 pages, 1 figure, 7 tables", "summary": "Client-level fairness metrics for federated learning are used to ensure that\nall clients in a federation either: a) have similar final performance on their\nlocal data distributions (i.e., client parity), or b) obtain final performance\non their local data distributions relative to their contribution to the\nfederated learning process (i.e., contribution fairness). While a handful of\nworks that propose either client-parity or contribution-based fairness metrics\nground their definitions and decisions in social theories of equality -- such\nas distributive justice -- most works arbitrarily choose what notion of\nfairness to align with which makes it difficult for practitioners to choose\nwhich fairness metric aligns best with their fairness ethics. In this work, we\npropose UDJ-FL (Uncertainty-based Distributive Justice for Federated Learning),\na flexible federated learning framework that can achieve multiple distributive\njustice-based client-level fairness metrics. Namely, by utilizing techniques\ninspired by fair resource allocation, in conjunction with performing aleatoric\nuncertainty-based client weighing, our UDJ-FL framework is able to achieve\negalitarian, utilitarian, Rawls' difference principle, or desert-based\nclient-level fairness. We empirically show the ability of UDJ-FL to achieve all\nfour defined distributive justice-based client-level fairness metrics in\naddition to providing fairness equivalent to (or surpassing) other popular fair\nfederated learning works. Further, we provide justification for why aleatoric\nuncertainty weighing is necessary to the construction of our UDJ-FL framework\nas well as derive theoretical guarantees for the generalization bounds of\nUDJ-FL. Our code is publicly available at\nhttps://github.com/alycia-noel/UDJ-FL."}
{"id": "2504.15654", "pdf": "https://arxiv.org/pdf/2504.15654", "abs": "https://arxiv.org/abs/2504.15654", "authors": ["Md Abdul Baset Sarker", "Art Nguyen", "Sigmond Kukla", "Kevin Fite", "Masudul H. Imtiaz"], "title": "A Vision-Enabled Prosthetic Hand for Children with Upper Limb Disabilities", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "This paper introduces a novel AI vision-enabled pediatric prosthetic hand\ndesigned to assist children aged 10-12 with upper limb disabilities. The\nprosthesis features an anthropomorphic appearance, multi-articulating\nfunctionality, and a lightweight design that mimics a natural hand, making it\nboth accessible and affordable for low-income families. Using 3D printing\ntechnology and integrating advanced machine vision, sensing, and embedded\ncomputing, the prosthetic hand offers a low-cost, customizable solution that\naddresses the limitations of current myoelectric prostheses. A micro camera is\ninterfaced with a low-power FPGA for real-time object detection and assists\nwith precise grasping. The onboard DL-based object detection and grasp\nclassification models achieved accuracies of 96% and 100% respectively. In the\nforce prediction, the mean absolute error was found to be 0.018. The features\nof the proposed prosthetic hand can thus be summarized as: a) a wrist-mounted\nmicro camera for artificial sensing, enabling a wide range of hand-based tasks;\nb) real-time object detection and distance estimation for precise grasping; and\nc) ultra-low-power operation that delivers high performance within constrained\npower and resource limits."}
{"id": "2504.15927", "pdf": "https://arxiv.org/pdf/2504.15927", "abs": "https://arxiv.org/abs/2504.15927", "authors": ["Ling Cheng", "Jiashu Pu", "Ruicheng Liang", "Qian Shao", "Hezhe Qiao", "Feida Zhu"], "title": "New Recipe for Semi-supervised Community Detection: Clique Annealing under Crystallization Kinetics", "categories": ["cs.SI", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2203.05898 by other authors", "summary": "Semi-supervised community detection methods are widely used for identifying\nspecific communities due to the label scarcity. Existing semi-supervised\ncommunity detection methods typically involve two learning stages learning in\nboth initial identification and subsequent adjustment, which often starts from\nan unreasonable community core candidate. Moreover, these methods encounter\nscalability issues because they depend on reinforcement learning and generative\nadversarial networks, leading to higher computational costs and restricting the\nselection of candidates. To address these limitations, we draw a parallel\nbetween crystallization kinetics and community detection to integrate the\nspontaneity of the annealing process into community detection. Specifically, we\nliken community detection to identifying a crystal subgrain (core) that expands\ninto a complete grain (community) through a process similar to annealing. Based\non this finding, we propose CLique ANNealing (CLANN), which applies kinetics\nconcepts to community detection by integrating these principles into the\noptimization process to strengthen the consistency of the community core.\nSubsequently, a learning-free Transitive Annealer was employed to refine the\nfirst-stage candidates by merging neighboring cliques and repositioning the\ncommunity core, enabling a spontaneous growth process that enhances\nscalability. Extensive experiments on \\textbf{43} different network settings\ndemonstrate that CLANN outperforms state-of-the-art methods across multiple\nreal-world datasets, showcasing its exceptional efficacy and efficiency in\ncommunity detection."}
{"id": "2504.15657", "pdf": "https://arxiv.org/pdf/2504.15657", "abs": "https://arxiv.org/abs/2504.15657", "authors": ["Yibo Liu", "Paul Kry", "Kenny Erleben", "Noam Aigerman", "Sune Darkner", "Teseo Schneider"], "title": "Neural Kinematic Bases for Fluids", "categories": ["cs.GR", "cs.LG", "physics.flu-dyn"], "comment": null, "summary": "We propose mesh-free fluid simulations that exploit a kinematic neural basis\nfor velocity fields represented by an MLP. We design a set of losses that\nensures that these neural bases satisfy fundamental physical properties such as\northogonality, divergence-free, boundary alignment, and smoothness. Our neural\nbases can then be used to fit an input sketch of a flow, which will inherit the\nsame fundamental properties from the bases. We then can animate such flow in\nreal-time using standard time integrators. Our neural bases can accommodate\ndifferent domains and naturally extend to three dimensions."}
{"id": "2504.15928", "pdf": "https://arxiv.org/pdf/2504.15928", "abs": "https://arxiv.org/abs/2504.15928", "authors": ["Meng Wang", "Tian Lin", "Qingshan Hou", "Aidi Lin", "Jingcheng Wang", "Qingsheng Peng", "Truong X. Nguyen", "Danqi Fang", "Ke Zou", "Ting Xu", "Cancan Xue", "Ten Cheer Quek", "Qinkai Yu", "Minxin Liu", "Hui Zhou", "Zixuan Xiao", "Guiqin He", "Huiyu Liang", "Tingkun Shi", "Man Chen", "Linna Liu", "Yuanyuan Peng", "Lianyu Wang", "Qiuming Hu", "Junhong Chen", "Zhenhua Zhang", "Cheng Chen", "Yitian Zhao", "Dianbo Liu", "Jianhua Wu", "Xinjian Chen", "Changqing Zhang", "Triet Thanh Nguyen", "Yanda Meng", "Yalin Zheng", "Yih Chung Tham", "Carol Y. Cheung", "Huazhu Fu", "Haoyu Chen", "Ching-Yu Cheng"], "title": "A Clinician-Friendly Platform for Ophthalmic Image Analysis Without Technical Barriers", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Artificial intelligence (AI) shows remarkable potential in medical imaging\ndiagnostics, but current models typically require retraining when deployed\nacross different clinical centers, limiting their widespread adoption. We\nintroduce GlobeReady, a clinician-friendly AI platform that enables ocular\ndisease diagnosis without retraining/fine-tuning or technical expertise.\nGlobeReady achieves high accuracy across imaging modalities: 93.9-98.5% for an\n11-category fundus photo dataset and 87.2-92.7% for a 15-category OCT dataset.\nThrough training-free local feature augmentation, it addresses domain shifts\nacross centers and populations, reaching an average accuracy of 88.9% across\nfive centers in China, 86.3% in Vietnam, and 90.2% in the UK. The built-in\nconfidence-quantifiable diagnostic approach further boosted accuracy to\n94.9-99.4% (fundus) and 88.2-96.2% (OCT), while identifying out-of-distribution\ncases at 86.3% (49 CFP categories) and 90.6% (13 OCT categories). Clinicians\nfrom multiple countries rated GlobeReady highly (average 4.6 out of 5) for its\nusability and clinical relevance. These results demonstrate GlobeReady's\nrobust, scalable diagnostic capability and potential to support ophthalmic care\nwithout technical barriers."}
{"id": "2504.15659", "pdf": "https://arxiv.org/pdf/2504.15659", "abs": "https://arxiv.org/abs/2504.15659", "authors": ["Anjiang Wei", "Huanmi Tan", "Tarun Suresh", "Daniel Mendoza", "Thiago S. F. X. Teixeira", "Ke Wang", "Caroline Trippel", "Alex Aiken"], "title": "VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional Correctness Validation", "categories": ["cs.AR", "cs.AI", "cs.CL", "cs.LG", "cs.SE"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have sparked growing interest\nin applying them to Electronic Design Automation (EDA) tasks, particularly\nRegister Transfer Level (RTL) code generation. While several RTL datasets have\nbeen introduced, most focus on syntactic validity rather than functional\nvalidation with tests, leading to training examples that compile but may not\nimplement the intended behavior. We present VERICODER, a model for RTL code\ngeneration fine-tuned on a dataset validated for functional correctness. This\nfine-tuning dataset is constructed using a novel methodology that combines unit\ntest generation with feedback-directed refinement. Given a natural language\nspecification and an initial RTL design, we prompt a teacher model\n(GPT-4o-mini) to generate unit tests and iteratively revise the RTL design\nbased on its simulation results using the generated tests. If necessary, the\nteacher model also updates the tests to ensure they comply with the natural\nlanguage specification. As a result of this process, every example in our\ndataset is functionally validated, consisting of a natural language\ndescription, an RTL implementation, and passing tests. Fine-tuned on this\ndataset of over 125,000 examples, VERICODER achieves state-of-the-art metrics\nin functional correctness on VerilogEval and RTLLM, with relative gains of up\nto 71.7% and 27.4% respectively. An ablation study further shows that models\ntrained on our functionally validated dataset outperform those trained on\nfunctionally non-validated datasets, underscoring the importance of\nhigh-quality datasets in RTL code generation."}
{"id": "2504.15929", "pdf": "https://arxiv.org/pdf/2504.15929", "abs": "https://arxiv.org/abs/2504.15929", "authors": ["Saban Ozturk", "Melih B. Yilmaz", "Muti Kara", "M. Talat Yavuz", "Aykut Koç", "Tolga Çukur"], "title": "Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "18 pages, 7 figures, 6 tables", "summary": "Diagnostic imaging relies on interpreting both images and radiology reports,\nbut the growing data volumes place significant pressure on medical experts,\nyielding increased errors and workflow backlogs. Medical vision-language models\n(med-VLMs) have emerged as a powerful framework to efficiently process\nmultimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeit\ntheir performance hinges on how well image and text representations are\naligned. Existing alignment methods, predominantly based on contrastive\nlearning, prioritize separation between disease classes over segregation of\nfine-grained pathology attributes like location, size or severity, leading to\nsuboptimal representations. Here, we propose MedTrim (Meta-entity-driven\nTriplet mining), a novel method that enhances image-text alignment through\nmultimodal triplet learning synergistically guided by disease class as well as\nadjectival and directional pathology descriptors. Unlike common alignment\nmethods that separate broad disease classes, MedTrim leverages structured\nmeta-entity information to preserve subtle but clinically significant\nintra-class variations. For this purpose, we first introduce an ontology-based\nentity recognition module that extracts pathology-specific meta-entities from\nCXR reports, as annotations on pathology attributes are rare in public\ndatasets. For refined sample selection in triplet mining, we then introduce a\nnovel score function that captures an aggregate measure of inter-sample\nsimilarity based on disease classes and adjectival/directional descriptors.\nLastly, we introduce a multimodal triplet alignment objective for explicit\nwithin- and cross-modal alignment between samples sharing detailed pathology\ncharacteristics. Our demonstrations indicate that MedTrim improves performance\nin downstream retrieval and classification tasks compared to state-of-the-art\nalignment methods."}
{"id": "2504.15674", "pdf": "https://arxiv.org/pdf/2504.15674", "abs": "https://arxiv.org/abs/2504.15674", "authors": ["Yanbo Dai", "Songze Li", "Zihan Gan", "Xueluan Gong"], "title": "TrojanDam: Detection-Free Backdoor Defense in Federated Learning through Proactive Model Robustification utilizing OOD Data", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Federated learning (FL) systems allow decentralized data-owning clients to\njointly train a global model through uploading their locally trained updates to\na centralized server. The property of decentralization enables adversaries to\ncraft carefully designed backdoor updates to make the global model misclassify\nonly when encountering adversary-chosen triggers. Existing defense mechanisms\nmainly rely on post-training detection after receiving updates. These methods\neither fail to identify updates which are deliberately fabricated statistically\nclose to benign ones, or show inconsistent performance in different FL training\nstages. The effect of unfiltered backdoor updates will accumulate in the global\nmodel, and eventually become functional. Given the difficulty of ruling out\nevery backdoor update, we propose a backdoor defense paradigm, which focuses on\nproactive robustification on the global model against potential backdoor\nattacks. We first reveal that the successful launching of backdoor attacks in\nFL stems from the lack of conflict between malicious and benign updates on\nredundant neurons of ML models. We proceed to prove the feasibility of\nactivating redundant neurons utilizing out-of-distribution (OOD) samples in\ncentralized settings, and migrating to FL settings to propose a novel backdoor\ndefense mechanism, TrojanDam. The proposed mechanism has the FL server\ncontinuously inject fresh OOD mappings into the global model to activate\nredundant neurons, canceling the effect of backdoor updates during aggregation.\nWe conduct systematic and extensive experiments to illustrate the superior\nperformance of TrojanDam, over several SOTA backdoor defense methods across a\nwide range of FL settings."}
{"id": "2504.15941", "pdf": "https://arxiv.org/pdf/2504.15941", "abs": "https://arxiv.org/abs/2504.15941", "authors": ["Fanny Jourdan", "Yannick Chevalier", "Cécile Favre"], "title": "FairTranslate: An English-French Dataset for Gender Bias Evaluation in Machine Translation by Overcoming Gender Binarity", "categories": ["cs.CL", "cs.AI"], "comment": "FAccT 2025", "summary": "Large Language Models (LLMs) are increasingly leveraged for translation tasks\nbut often fall short when translating inclusive language -- such as texts\ncontaining the singular 'they' pronoun or otherwise reflecting fair linguistic\nprotocols. Because these challenges span both computational and societal\ndomains, it is imperative to critically evaluate how well LLMs handle inclusive\ntranslation with a well-founded framework.\n  This paper presents FairTranslate, a novel, fully human-annotated dataset\ndesigned to evaluate non-binary gender biases in machine translation systems\nfrom English to French. FairTranslate includes 2418 English-French sentence\npairs related to occupations, annotated with rich metadata such as the\nstereotypical alignment of the occupation, grammatical gender indicator\nambiguity, and the ground-truth gender label (male, female, or inclusive).\n  We evaluate four leading LLMs (Gemma2-2B, Mistral-7B, Llama3.1-8B,\nLlama3.3-70B) on this dataset under different prompting procedures. Our results\nreveal substantial biases in gender representation across LLMs, highlighting\npersistent challenges in achieving equitable outcomes in machine translation.\nThese findings underscore the need for focused strategies and interventions\naimed at ensuring fair and inclusive language usage in LLM-based translation\nsystems.\n  We make the FairTranslate dataset publicly available on Hugging Face, and\ndisclose the code for all experiments on GitHub."}
{"id": "2504.15679", "pdf": "https://arxiv.org/pdf/2504.15679", "abs": "https://arxiv.org/abs/2504.15679", "authors": ["Brandon Panos", "Ivan Milic"], "title": "Policy-Based Radiative Transfer: Solving the $2$-Level Atom Non-LTE Problem using Soft Actor-Critic Reinforcement Learning", "categories": ["astro-ph.SR", "cs.LG"], "comment": null, "summary": "We present a novel reinforcement learning (RL) approach for solving the\nclassical 2-level atom non-LTE radiative transfer problem by framing it as a\ncontrol task in which an RL agent learns a depth-dependent source function\n$S(\\tau)$ that self-consistently satisfies the equation of statistical\nequilibrium (SE). The agent's policy is optimized entirely via reward-based\ninteractions with a radiative transfer engine, without explicit knowledge of\nthe ground truth. This method bypasses the need for constructing approximate\nlambda operators ($\\Lambda^*$) common in accelerated iterative schemes.\nAdditionally, it requires no extensive precomputed labeled datasets to extract\na supervisory signal, and avoids backpropagating gradients through the complex\nRT solver itself. Finally, we show through experiment that a simple feedforward\nneural network trained greedily cannot solve for SE, possibly due to the moving\ntarget nature of the problem. Our $\\Lambda^*-\\text{Free}$ method offers\npotential advantages for complex scenarios (e.g., atmospheres with enhanced\nvelocity fields, multi-dimensional geometries, or complex microphysics) where\n$\\Lambda^*$ construction or solver differentiability is challenging.\nAdditionally, the agent can be incentivized to find more efficient policies by\nmanipulating the discount factor, leading to a reprioritization of immediate\nrewards. If demonstrated to generalize past its training data, this RL\nframework could serve as an alternative or accelerated formalism to achieve SE.\nTo the best of our knowledge, this study represents the first application of\nreinforcement learning in solar physics that directly solves for a fundamental\nphysical constraint."}
{"id": "2504.15956", "pdf": "https://arxiv.org/pdf/2504.15956", "abs": "https://arxiv.org/abs/2504.15956", "authors": ["Jerry Yao-Chieh Hu", "Hude Liu", "Hong-Yu Chen", "Weimin Wu", "Han Liu"], "title": "Universal Approximation with Softmax Attention", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We prove that with linear transformations, both (i) two-layer self-attention\nand (ii) one-layer self-attention followed by a softmax function are universal\napproximators for continuous sequence-to-sequence functions on compact domains.\nOur main technique is a new interpolation-based method for analyzing\nattention's internal mechanism. This leads to our key insight: self-attention\nis able to approximate a generalized version of ReLU to arbitrary precision,\nand hence subsumes many known universal approximators. Building on these, we\nshow that two-layer multi-head attention alone suffices as a\nsequence-to-sequence universal approximator. In contrast, prior works rely on\nfeed-forward networks to establish universal approximation in Transformers.\nFurthermore, we extend our techniques to show that, (softmax-)attention-only\nlayers are capable of approximating various statistical models in-context. We\nbelieve these techniques hold independent interest."}
{"id": "2504.15683", "pdf": "https://arxiv.org/pdf/2504.15683", "abs": "https://arxiv.org/abs/2504.15683", "authors": ["Simon Jehnen", "Joaquín Ordieres-Meré", "Javier Villalba-Díez"], "title": "FinTextSim: Enhancing Financial Text Analysis with BERTopic", "categories": ["cs.CL", "cs.LG", "econ.GN", "q-fin.EC", "q-fin.GN", "68T50", "I.2.7; I.5.1; J.4"], "comment": null, "summary": "Recent advancements in information availability and computational\ncapabilities have transformed the analysis of annual reports, integrating\ntraditional financial metrics with insights from textual data. To extract\nvaluable insights from this wealth of textual data, automated review processes,\nsuch as topic modeling, are crucial. This study examines the effectiveness of\nBERTopic, a state-of-the-art topic model relying on contextual embeddings, for\nanalyzing Item 7 and Item 7A of 10-K filings from S&P 500 companies\n(2016-2022). Moreover, we introduce FinTextSim, a finetuned\nsentence-transformer model optimized for clustering and semantic search in\nfinancial contexts. Compared to all-MiniLM-L6-v2, the most widely used\nsentence-transformer, FinTextSim increases intratopic similarity by 81% and\nreduces intertopic similarity by 100%, significantly enhancing organizational\nclarity. We assess BERTopic's performance using embeddings from both FinTextSim\nand all-MiniLM-L6-v2. Our findings reveal that BERTopic only forms clear and\ndistinct economic topic clusters when paired with FinTextSim's embeddings.\nWithout FinTextSim, BERTopic struggles with misclassification and overlapping\ntopics. Thus, FinTextSim is pivotal for advancing financial text analysis.\nFinTextSim's enhanced contextual embeddings, tailored for the financial domain,\nelevate the quality of future research and financial information. This improved\nquality of financial information will enable stakeholders to gain a competitive\nadvantage, streamlining resource allocation and decision-making processes.\nMoreover, the improved insights have the potential to leverage business\nvaluation and stock price prediction models."}
{"id": "2504.15972", "pdf": "https://arxiv.org/pdf/2504.15972", "abs": "https://arxiv.org/abs/2504.15972", "authors": ["Sophie C. Pope", "Andrew Barovic", "Armin Moin"], "title": "Bug Destiny Prediction in Large Open-Source Software Repositories through Sentiment Analysis and BERT Topic Modeling", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "This study explores a novel approach to predicting key bug-related outcomes,\nincluding the time to resolution, time to fix, and ultimate status of a bug,\nusing data from the Bugzilla Eclipse Project. Specifically, we leverage\nfeatures available before a bug is resolved to enhance predictive accuracy. Our\nmethodology incorporates sentiment analysis to derive both an emotionality\nscore and a sentiment classification (positive or negative). Additionally, we\nintegrate the bug's priority level and its topic, extracted using a BERTopic\nmodel, as features for a Convolutional Neural Network (CNN) and a Multilayer\nPerceptron (MLP). Our findings indicate that the combination of BERTopic and\nsentiment analysis can improve certain model performance metrics. Furthermore,\nwe observe that balancing model inputs enhances practical applicability, albeit\nat the cost of a significant reduction in accuracy in most cases. To address\nour primary objectives, predicting time-to-resolution, time-to-fix, and bug\ndestiny, we employ both binary classification and exact time value predictions,\nallowing for a comparative evaluation of their predictive effectiveness.\nResults demonstrate that sentiment analysis serves as a valuable predictor of a\nbug's eventual outcome, particularly in determining whether it will be fixed.\nHowever, its utility is less pronounced when classifying bugs into more complex\nor unconventional outcome categories."}
{"id": "2504.15691", "pdf": "https://arxiv.org/pdf/2504.15691", "abs": "https://arxiv.org/abs/2504.15691", "authors": ["Mingliang Ma Abolfazl Safikhani"], "title": "Transfer Learning for High-dimensional Reduced Rank Time Series Models", "categories": ["stat.ML", "cs.LG"], "comment": "29 pages accepted by AISTATS2025", "summary": "The objective of transfer learning is to enhance estimation and inference in\na target data by leveraging knowledge gained from additional sources. Recent\nstudies have explored transfer learning for independent observations in\ncomplex, high-dimensional models assuming sparsity, yet research on time series\nmodels remains limited. Our focus is on transfer learning for sequences of\nobservations with temporal dependencies and a more intricate model parameter\nstructure. Specifically, we investigate the vector autoregressive model (VAR),\na widely recognized model for time series data, where the transition matrix can\nbe deconstructed into a combination of a sparse matrix and a low-rank one. We\npropose a new transfer learning algorithm tailored for estimating\nhigh-dimensional VAR models characterized by low-rank and sparse structures.\nAdditionally, we present a novel approach for selecting informative\nobservations from auxiliary datasets. Theoretical guarantees are established,\nencompassing model parameter consistency, informative set selection, and the\nasymptotic distribution of estimators under mild conditions. The latter\nfacilitates the construction of entry-wise confidence intervals for model\nparameters. Finally, we demonstrate the empirical efficacy of our methodologies\nthrough both simulated and real-world datasets."}
{"id": "2504.15983", "pdf": "https://arxiv.org/pdf/2504.15983", "abs": "https://arxiv.org/abs/2504.15983", "authors": ["Shang Wang"], "title": "W-PCA Based Gradient-Free Proxy for Efficient Search of Lightweight Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "ICLR 2025", "summary": "The demand for efficient natural language processing (NLP) systems has led to\nthe development of lightweight language models. Previous work in this area has\nprimarily focused on manual design or training-based neural architecture search\n(NAS) methods. Recently, zero-shot NAS methods have been proposed for\nevaluating language models without the need for training. However, prevailing\napproaches to zero-shot NAS often face challenges such as biased evaluation\nmetrics and computational inefficiencies. In this paper, we introduce\nweight-weighted PCA (W-PCA), a novel zero-shot NAS method specifically tailored\nfor lightweight language models. Our approach utilizes two evaluation proxies:\nthe parameter count and the number of principal components with cumulative\ncontribution exceeding $\\eta$ in the feed-forward neural (FFN) layer.\nAdditionally, by eliminating the need for gradient computations, we optimize\nthe evaluation time, thus enhancing the efficiency of designing and evaluating\nlightweight language models. We conduct a comparative analysis on the GLUE and\nSQuAD datasets to evaluate our approach. The results demonstrate that our\nmethod significantly reduces training time compared to one-shot NAS methods and\nachieves higher scores in the testing phase compared to previous\nstate-of-the-art training-based methods. Furthermore, we perform ranking\nevaluations on a dataset sampled from the FlexiBERT search space. Our approach\nexhibits superior ranking correlation and further reduces solving time compared\nto other zero-shot NAS methods that require gradient computation."}
{"id": "2504.15707", "pdf": "https://arxiv.org/pdf/2504.15707", "abs": "https://arxiv.org/abs/2504.15707", "authors": ["Yannic Neuhaus", "Matthias Hein"], "title": "RePOPE: Impact of Annotation Errors on the POPE Benchmark", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Since data annotation is costly, benchmark datasets often incorporate labels\nfrom established image datasets. In this work, we assess the impact of label\nerrors in MSCOCO on the frequently used object hallucination benchmark POPE. We\nre-annotate the benchmark images and identify an imbalance in annotation errors\nacross different subsets. Evaluating multiple models on the revised labels,\nwhich we denote as RePOPE, we observe notable shifts in model rankings,\nhighlighting the impact of label quality. Code and data are available at\nhttps://github.com/YanNeu/RePOPE ."}
{"id": "2504.15995", "pdf": "https://arxiv.org/pdf/2504.15995", "abs": "https://arxiv.org/abs/2504.15995", "authors": ["Sindhuja Madabushi", "Ahmad Faraz Khan", "Haider Ali", "Jin-Hee Cho"], "title": "OPUS-VFL: Incentivizing Optimal Privacy-Utility Tradeoffs in Vertical Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Vertical Federated Learning (VFL) enables organizations with disjoint feature\nspaces but shared user bases to collaboratively train models without sharing\nraw data. However, existing VFL systems face critical limitations: they often\nlack effective incentive mechanisms, struggle to balance privacy-utility\ntradeoffs, and fail to accommodate clients with heterogeneous resource\ncapabilities. These challenges hinder meaningful participation, degrade model\nperformance, and limit practical deployment. To address these issues, we\npropose OPUS-VFL, an Optimal Privacy-Utility tradeoff Strategy for VFL.\nOPUS-VFL introduces a novel, privacy-aware incentive mechanism that rewards\nclients based on a principled combination of model contribution, privacy\npreservation, and resource investment. It employs a lightweight leave-one-out\n(LOO) strategy to quantify feature importance per client, and integrates an\nadaptive differential privacy mechanism that enables clients to dynamically\ncalibrate noise levels to optimize their individual utility. Our framework is\ndesigned to be scalable, budget-balanced, and robust to inference and poisoning\nattacks. Extensive experiments on benchmark datasets (MNIST, CIFAR-10, and\nCIFAR-100) demonstrate that OPUS-VFL significantly outperforms state-of-the-art\nVFL baselines in both efficiency and robustness. It reduces label inference\nattack success rates by up to 20%, increases feature inference reconstruction\nerror (MSE) by over 30%, and achieves up to 25% higher incentives for clients\nthat contribute meaningfully while respecting privacy and cost constraints.\nThese results highlight the practicality and innovation of OPUS-VFL as a\nsecure, fair, and performance-driven solution for real-world VFL."}
{"id": "2504.15722", "pdf": "https://arxiv.org/pdf/2504.15722", "abs": "https://arxiv.org/abs/2504.15722", "authors": ["Zhe Huang", "Simone Rossi", "Rui Yuan", "Thomas Hannagan"], "title": "From predictions to confidence intervals: an empirical study of conformal prediction methods for in-context learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Transformers have become a standard architecture in machine learning,\ndemonstrating strong in-context learning (ICL) abilities that allow them to\nlearn from the prompt at inference time. However, uncertainty quantification\nfor ICL remains an open challenge, particularly in noisy regression tasks. This\npaper investigates whether ICL can be leveraged for distribution-free\nuncertainty estimation, proposing a method based on conformal prediction to\nconstruct prediction intervals with guaranteed coverage. While traditional\nconformal methods are computationally expensive due to repeated model fitting,\nwe exploit ICL to efficiently generate confidence intervals in a single forward\npass. Our empirical analysis compares this approach against ridge\nregression-based conformal methods, showing that conformal prediction with\nin-context learning (CP with ICL) achieves robust and scalable uncertainty\nestimates. Additionally, we evaluate its performance under distribution shifts\nand establish scaling laws to guide model training. These findings bridge ICL\nand conformal prediction, providing a theoretically grounded and new framework\nfor uncertainty quantification in transformer-based models."}
{"id": "2504.16000", "pdf": "https://arxiv.org/pdf/2504.16000", "abs": "https://arxiv.org/abs/2504.16000", "authors": ["Soham Bonnerjee", "Zhen Wei", "Yeon", "Anna Asch", "Sagnik Nandy", "Promit Ghosal"], "title": "How Private is Your Attention? Bridging Privacy with In-Context Learning", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "In-context learning (ICL)-the ability of transformer-based models to perform\nnew tasks from examples provided at inference time-has emerged as a hallmark of\nmodern language models. While recent works have investigated the mechanisms\nunderlying ICL, its feasibility under formal privacy constraints remains\nlargely unexplored. In this paper, we propose a differentially private\npretraining algorithm for linear attention heads and present the first\ntheoretical analysis of the privacy-accuracy trade-off for ICL in linear\nregression. Our results characterize the fundamental tension between\noptimization and privacy-induced noise, formally capturing behaviors observed\nin private training via iterative methods. Additionally, we show that our\nmethod is robust to adversarial perturbations of training prompts, unlike\nstandard ridge regression. All theoretical findings are supported by extensive\nsimulations across diverse settings."}
{"id": "2504.15743", "pdf": "https://arxiv.org/pdf/2504.15743", "abs": "https://arxiv.org/abs/2504.15743", "authors": ["Seung Gyu Jeong", "Sung Woo Nam", "Seong Kwan Jung", "Seong-Eun Kim"], "title": "iMedic: Towards Smartphone-based Self-Auscultation Tool for AI-Powered Pediatric Respiratory Assessment", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "Respiratory auscultation is crucial for early detection of pediatric\npneumonia, a condition that can quickly worsen without timely intervention. In\nareas with limited physician access, effective auscultation is challenging. We\npresent a smartphone-based system that leverages built-in microphones and\nadvanced deep learning algorithms to detect abnormal respiratory sounds\nindicative of pneumonia risk. Our end-to-end deep learning framework employs\ndomain generalization to integrate a large electronic stethoscope dataset with\na smaller smartphone-derived dataset, enabling robust feature learning for\naccurate respiratory assessments without expensive equipment. The accompanying\nmobile application guides caregivers in collecting high-quality lung sound\nsamples and provides immediate feedback on potential pneumonia risks. User\nstudies show strong classification performance and high acceptance,\ndemonstrating the system's ability to facilitate proactive interventions and\nreduce preventable childhood pneumonia deaths. By seamlessly integrating into\nubiquitous smartphones, this approach offers a promising avenue for more\nequitable and comprehensive remote pediatric care."}
{"id": "2504.16005", "pdf": "https://arxiv.org/pdf/2504.16005", "abs": "https://arxiv.org/abs/2504.16005", "authors": ["Tom Zehle", "Moritz Schlager", "Timo Heiß", "Matthias Feurer"], "title": "CAPO: Cost-Aware Prompt Optimization", "categories": ["cs.CL", "cs.AI", "cs.NE", "stat.ML"], "comment": "Submitted to AutoML 2025", "summary": "Large language models (LLMs) have revolutionized natural language processing\nby solving a wide range of tasks simply guided by a prompt. Yet their\nperformance is highly sensitive to prompt formulation. While automated prompt\noptimization addresses this challenge by finding optimal prompts, current\nmethods require a substantial number of LLM calls and input tokens, making\nprompt optimization expensive. We introduce CAPO (Cost-Aware Prompt\nOptimization), an algorithm that enhances prompt optimization efficiency by\nintegrating AutoML techniques. CAPO is an evolutionary approach with LLMs as\noperators, incorporating racing to save evaluations and multi-objective\noptimization to balance performance with prompt length. It jointly optimizes\ninstructions and few-shot examples while leveraging task descriptions for\nimproved robustness. Our extensive experiments across diverse datasets and LLMs\ndemonstrate that CAPO outperforms state-of-the-art discrete prompt optimization\nmethods in 11/15 cases with improvements up to 21%p. Our algorithm achieves\nbetter performances already with smaller budgets, saves evaluations through\nracing, and decreases average prompt length via a length penalty, making it\nboth cost-efficient and cost-aware. Even without few-shot examples, CAPO\noutperforms its competitors and generally remains robust to initial prompts.\nCAPO represents an important step toward making prompt optimization more\npowerful and accessible by improving cost-efficiency."}
{"id": "2504.15753", "pdf": "https://arxiv.org/pdf/2504.15753", "abs": "https://arxiv.org/abs/2504.15753", "authors": ["Alexis M. H. Teter", "Wenqing Wang", "Sachin Shivakumar", "Abhishek Halder"], "title": "Markov Kernels, Distances and Optimal Control: A Parable of Linear Quadratic Non-Gaussian Distribution Steering", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY", "math.PR", "math.ST", "stat.TH"], "comment": null, "summary": "For a controllable linear time-varying (LTV) pair\n$(\\boldsymbol{A}_t,\\boldsymbol{B}_t)$ and $\\boldsymbol{Q}_{t}$ positive\nsemidefinite, we derive the Markov kernel for the It\\^{o} diffusion\n${\\mathrm{d}}\\boldsymbol{x}_{t}=\\boldsymbol{A}_{t}\\boldsymbol{x}_t {\\mathrm{d}}\nt + \\sqrt{2}\\boldsymbol{B}_{t}{\\mathrm{d}}\\boldsymbol{w}_{t}$ with an\naccompanying killing of probability mass at rate\n$\\frac{1}{2}\\boldsymbol{x}^{\\top}\\boldsymbol{Q}_{t}\\boldsymbol{x}$. This Markov\nkernel is the Green's function for an associated linear\nreaction-advection-diffusion partial differential equation. Our result\ngeneralizes the recently derived kernel for the special case\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t\\right)=\\left(\\boldsymbol{0},\\boldsymbol{I}\\right)$,\nand depends on the solution of an associated Riccati matrix ODE. A consequence\nof this result is that the linear quadratic non-Gaussian Schr\\\"{o}dinger bridge\nis exactly solvable. This means that the problem of steering a controlled LTV\ndiffusion from a given non-Gaussian distribution to another over a fixed\ndeadline while minimizing an expected quadratic cost can be solved using\ndynamic Sinkhorn recursions performed with the derived kernel. Our derivation\nfor the\n$\\left(\\boldsymbol{A}_t,\\boldsymbol{B}_t,\\boldsymbol{Q}_t\\right)$-parametrized\nkernel pursues a new idea that relies on finding a state-time dependent\ndistance-like functional given by the solution of a deterministic optimal\ncontrol problem. This technique breaks away from existing methods, such as\ngeneralizing Hermite polynomials or Weyl calculus, which have seen limited\nsuccess in the reaction-diffusion context. Our technique uncovers a new\nconnection between Markov kernels, distances, and optimal control. This\nconnection is of interest beyond its immediate application in solving the\nlinear quadratic Schr\\\"{o}dinger bridge problem."}
{"id": "2504.16020", "pdf": "https://arxiv.org/pdf/2504.16020", "abs": "https://arxiv.org/abs/2504.16020", "authors": ["Soham Sane"], "title": "AlphaGrad: Non-Linear Gradient Normalization Optimizer", "categories": ["cs.LG", "cs.AI", "cs.NE", "stat.ML"], "comment": null, "summary": "We introduce AlphaGrad, a memory-efficient, conditionally stateless optimizer\naddressing the memory overhead and hyperparameter complexity of adaptive\nmethods like Adam. AlphaGrad enforces scale invariance via tensor-wise L2\ngradient normalization followed by a smooth hyperbolic tangent transformation,\n$g' = \\tanh(\\alpha \\cdot \\tilde{g})$, controlled by a single steepness\nparameter $\\alpha$. Our contributions include: (1) the AlphaGrad algorithm\nformulation; (2) a formal non-convex convergence analysis guaranteeing\nstationarity; (3) extensive empirical evaluation on diverse RL benchmarks (DQN,\nTD3, PPO). Compared to Adam, AlphaGrad demonstrates a highly context-dependent\nperformance profile. While exhibiting instability in off-policy DQN, it\nprovides enhanced training stability with competitive results in TD3 (requiring\ncareful $\\alpha$ tuning) and achieves substantially superior performance in\non-policy PPO. These results underscore the critical importance of empirical\n$\\alpha$ selection, revealing strong interactions between the optimizer's\ndynamics and the underlying RL algorithm. AlphaGrad presents a compelling\nalternative optimizer for memory-constrained scenarios and shows significant\npromise for on-policy learning regimes where its stability and efficiency\nadvantages can be particularly impactful."}
{"id": "2504.15777", "pdf": "https://arxiv.org/pdf/2504.15777", "abs": "https://arxiv.org/abs/2504.15777", "authors": ["Shangshang Wang", "Julian Asilis", "Ömer Faruk Akgül", "Enes Burak Bilgin", "Ollie Liu", "Willie Neiswanger"], "title": "Tina: Tiny Reasoning Models via LoRA", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "How cost-effectively can strong reasoning abilities be achieved in language\nmodels? Driven by this fundamental question, we present Tina, a family of tiny\nreasoning models achieved with high cost-efficiency. Notably, Tina demonstrates\nthat substantial reasoning performance can be developed using only minimal\nresources, by applying parameter-efficient updates during reinforcement\nlearning (RL), using low-rank adaptation (LoRA), to an already tiny 1.5B\nparameter base model. This minimalist approach produces models that achieve\nreasoning performance which is competitive with, and sometimes surpasses, SOTA\nRL reasoning models built upon the same base model. Crucially, this is achieved\nat a tiny fraction of the computational post-training cost employed by existing\nSOTA models. In fact, the best Tina model achieves a >20\\% reasoning\nperformance increase and 43.33\\% Pass@1 accuracy on AIME24, at only \\$9 USD\npost-training and evaluation cost (i.e., an estimated 260x cost reduction). Our\nwork reveals the surprising effectiveness of efficient RL reasoning via LoRA.\nWe validate this across multiple open-source reasoning datasets and various\nablation settings starting with a single, fixed set of hyperparameters.\nFurthermore, we hypothesize that this effectiveness and efficiency stem from\nLoRA rapidly adapting the model to the structural format of reasoning rewarded\nby RL, while largely preserving the base model's underlying knowledge. In\nservice of accessibility and open research, we fully open-source all code,\ntraining logs, and model weights \\& checkpoints."}
{"id": "2504.16021", "pdf": "https://arxiv.org/pdf/2504.16021", "abs": "https://arxiv.org/abs/2504.16021", "authors": ["Dinithi Dissanayake", "Suranga Nanayakkara"], "title": "Navigating the State of Cognitive Flow: Context-Aware AI Interventions for Effective Reasoning Support", "categories": ["cs.HC", "cs.AI"], "comment": "Presented at the 2025 ACM Workshop on Human-AI Interaction for\n  Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING", "summary": "Flow theory describes an optimal cognitive state where individuals experience\ndeep focus and intrinsic motivation when a task's difficulty aligns with their\nskill level. In AI-augmented reasoning, interventions that disrupt the state of\ncognitive flow can hinder rather than enhance decision-making. This paper\nproposes a context-aware cognitive augmentation framework that adapts\ninterventions based on three key contextual factors: type, timing, and scale.\nBy leveraging multimodal behavioral cues (e.g., gaze behavior, typing\nhesitation, interaction speed), AI can dynamically adjust cognitive support to\nmaintain or restore flow. We introduce the concept of cognitive flow, an\nextension of flow theory in AI-augmented reasoning, where interventions are\npersonalized, adaptive, and minimally intrusive. By shifting from static\ninterventions to context-aware augmentation, our approach ensures that AI\nsystems support deep engagement in complex decision-making and reasoning\nwithout disrupting cognitive immersion."}
{"id": "2504.15779", "pdf": "https://arxiv.org/pdf/2504.15779", "abs": "https://arxiv.org/abs/2504.15779", "authors": ["Aaron J. Gutknecht", "Fernando E. Rosas", "David A. Ehrlich", "Abdullah Makkeh", "Pedro A. M. Mediano", "Michael Wibral"], "title": "Shannon invariants: A scalable approach to information decomposition", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT", "nlin.AO", "physics.data-an"], "comment": "16 pages, 4 Figures", "summary": "Distributed systems, such as biological and artificial neural networks,\nprocess information via complex interactions engaging multiple subsystems,\nresulting in high-order patterns with distinct properties across scales.\nInvestigating how these systems process information remains challenging due to\ndifficulties in defining appropriate multivariate metrics and ensuring their\nscalability to large systems. To address these challenges, we introduce a novel\nframework based on what we call \"Shannon invariants\" -- quantities that capture\nessential properties of high-order information processing in a way that depends\nonly on the definition of entropy and can be efficiently calculated for large\nsystems. Our theoretical results demonstrate how Shannon invariants can be used\nto resolve long-standing ambiguities regarding the interpretation of widely\nused multivariate information-theoretic measures. Moreover, our practical\nresults reveal distinctive information-processing signatures of various deep\nlearning architectures across layers, which lead to new insights into how these\nsystems process information and how this evolves during training. Overall, our\nframework resolves fundamental limitations in analyzing high-order phenomena\nand offers broad opportunities for theoretical developments and empirical\nanalyses."}
{"id": "2504.16026", "pdf": "https://arxiv.org/pdf/2504.16026", "abs": "https://arxiv.org/abs/2504.16026", "authors": ["Konstantin F. Pilz", "James Sanders", "Robi Rahman", "Lennart Heim"], "title": "Trends in AI Supercomputers", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Frontier AI development relies on powerful AI supercomputers, yet analysis of\nthese systems is limited. We create a dataset of 500 AI supercomputers from\n2019 to 2025 and analyze key trends in performance, power needs, hardware cost,\nownership, and global distribution. We find that the computational performance\nof AI supercomputers has doubled every nine months, while hardware acquisition\ncost and power needs both doubled every year. The leading system in March 2025,\nxAI's Colossus, used 200,000 AI chips, had a hardware cost of \\$7B, and\nrequired 300 MW of power, as much as 250,000 households. As AI supercomputers\nevolved from tools for science to industrial machines, companies rapidly\nexpanded their share of total AI supercomputer performance, while the share of\ngovernments and academia diminished. Globally, the United States accounts for\nabout 75% of total performance in our dataset, with China in second place at\n15%. If the observed trends continue, the leading AI supercomputer in 2030 will\nachieve $2\\times10^{22}$ 16-bit FLOP/s, use two million AI chips, have a\nhardware cost of \\$200 billion, and require 9 GW of power. Our analysis\nprovides visibility into the AI supercomputer landscape, allowing policymakers\nto assess key AI trends like resource needs, ownership, and national\ncompetitiveness."}
{"id": "2504.15796", "pdf": "https://arxiv.org/pdf/2504.15796", "abs": "https://arxiv.org/abs/2504.15796", "authors": ["Jiaqi Tang", "Yinsong Xu", "Qingchao Chen"], "title": "Locating and Mitigating Gradient Conflicts in Point Cloud Domain Adaptation via Saliency Map Skewness", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Object classification models utilizing point cloud data are fundamental for\n3D media understanding, yet they often struggle with unseen or\nout-of-distribution (OOD) scenarios. Existing point cloud unsupervised domain\nadaptation (UDA) methods typically employ a multi-task learning (MTL) framework\nthat combines primary classification tasks with auxiliary self-supervision\ntasks to bridge the gap between cross-domain feature distributions. However,\nour further experiments demonstrate that not all gradients from\nself-supervision tasks are beneficial and some may negatively impact the\nclassification performance. In this paper, we propose a novel solution, termed\nSaliency Map-based Data Sampling Block (SM-DSB), to mitigate these gradient\nconflicts. Specifically, our method designs a new scoring mechanism based on\nthe skewness of 3D saliency maps to estimate gradient conflicts without\nrequiring target labels. Leveraging this, we develop a sample selection\nstrategy that dynamically filters out samples whose self-supervision gradients\nare not beneficial for the classification. Our approach is scalable,\nintroducing modest computational overhead, and can be integrated into all the\npoint cloud UDA MTL frameworks. Extensive evaluations demonstrate that our\nmethod outperforms state-of-the-art approaches. In addition, we provide a new\nperspective on understanding the UDA problem through back-propagation analysis."}
{"id": "2504.16027", "pdf": "https://arxiv.org/pdf/2504.16027", "abs": "https://arxiv.org/abs/2504.16027", "authors": ["Ahmed R. Sadik", "Siddhata Govind"], "title": "Benchmarking LLM for Code Smells Detection: OpenAI GPT-4.0 vs DeepSeek-V3", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL"], "comment": null, "summary": "Determining the most effective Large Language Model for code smell detection\npresents a complex challenge. This study introduces a structured methodology\nand evaluation matrix to tackle this issue, leveraging a curated dataset of\ncode samples consistently annotated with known smells. The dataset spans four\nprominent programming languages Java, Python, JavaScript, and C++; allowing for\ncross language comparison. We benchmark two state of the art LLMs, OpenAI GPT\n4.0 and DeepSeek-V3, using precision, recall, and F1 score as evaluation\nmetrics. Our analysis covers three levels of detail: overall performance,\ncategory level performance, and individual code smell type performance.\nAdditionally, we explore cost effectiveness by comparing the token based\ndetection approach of GPT 4.0 with the pattern-matching techniques employed by\nDeepSeek V3. The study also includes a cost analysis relative to traditional\nstatic analysis tools such as SonarQube. The findings offer valuable guidance\nfor practitioners in selecting an efficient, cost effective solution for\nautomated code smell detection"}
{"id": "2504.15815", "pdf": "https://arxiv.org/pdf/2504.15815", "abs": "https://arxiv.org/abs/2504.15815", "authors": ["Michael A. Hedderich", "Anyi Wang", "Raoyuan Zhao", "Florian Eichin", "Barbara Plank"], "title": "What's the Difference? Supporting Users in Identifying the Effects of Prompt and Model Changes Through Token Patterns", "categories": ["cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "Prompt engineering for large language models is challenging, as even small\nprompt perturbations or model changes can significantly impact the generated\noutput texts. Existing evaluation methods, either automated metrics or human\nevaluation, have limitations, such as providing limited insights or being\nlabor-intensive. We propose Spotlight, a new approach that combines both\nautomation and human analysis. Based on data mining techniques, we\nautomatically distinguish between random (decoding) variations and systematic\ndifferences in language model outputs. This process provides token patterns\nthat describe the systematic differences and guide the user in manually\nanalyzing the effects of their prompt and model changes efficiently. We create\nthree benchmarks to quantitatively test the reliability of token pattern\nextraction methods and demonstrate that our approach provides new insights into\nestablished prompt data. From a human-centric perspective, through\ndemonstration studies and a user study, we show that our token pattern approach\nhelps users understand the systematic differences of language model outputs,\nand we are able to discover relevant differences caused by prompt and model\nchanges (e.g. related to gender or culture), thus supporting the prompt\nengineering process and human-centric model behavior research."}
{"id": "2504.16032", "pdf": "https://arxiv.org/pdf/2504.16032", "abs": "https://arxiv.org/abs/2504.16032", "authors": ["Yazan Otoum", "Arghavan Asad", "Amiya Nayak"], "title": "LLMs meet Federated Learning for Scalable and Secure IoT Management", "categories": ["cs.LG", "cs.AI", "cs.ET"], "comment": "This work has been submitted to the IEEE Global Communications\n  Conference (GLOBECOM) 2025 for possible publication", "summary": "The rapid expansion of IoT ecosystems introduces severe challenges in\nscalability, security, and real-time decision-making. Traditional centralized\narchitectures struggle with latency, privacy concerns, and excessive resource\nconsumption, making them unsuitable for modern large-scale IoT deployments.\nThis paper presents a novel Federated Learning-driven Large Language Model\n(FL-LLM) framework, designed to enhance IoT system intelligence while ensuring\ndata privacy and computational efficiency. The framework integrates Generative\nIoT (GIoT) models with a Gradient Sensing Federated Strategy (GSFS),\ndynamically optimizing model updates based on real-time network conditions. By\nleveraging a hybrid edge-cloud processing architecture, our approach balances\nintelligence, scalability, and security in distributed IoT environments.\nEvaluations on the IoT-23 dataset demonstrate that our framework improves model\naccuracy, reduces response latency, and enhances energy efficiency,\noutperforming traditional FL techniques (i.e., FedAvg, FedOpt). These findings\nhighlight the potential of integrating LLM-powered federated learning into\nlarge-scale IoT ecosystems, paving the way for more secure, scalable, and\nadaptive IoT management solutions."}
{"id": "2504.15826", "pdf": "https://arxiv.org/pdf/2504.15826", "abs": "https://arxiv.org/abs/2504.15826", "authors": ["Xinru Mu", "Omar M. Saad", "Tariq Alkhalifah"], "title": "Full waveform inversion with CNN-based velocity representation extension", "categories": ["physics.geo-ph", "cs.LG"], "comment": "16 pages, 15 figures, Scientific paper", "summary": "Full waveform inversion (FWI) updates the velocity model by minimizing the\ndiscrepancy between observed and simulated data. However, discretization errors\nin numerical modeling and incomplete seismic data acquisition can introduce\nnoise, which propagates through the adjoint operator and affects the accuracy\nof the velocity gradient, thereby impacting the FWI inversion accuracy. To\nmitigate the influence of noise on the gradient, we employ a convolutional\nneural network (CNN) to refine the velocity model before performing the forward\nsimulation, aiming to reduce noise and provide a more accurate velocity update\ndirection. We use the same data misfit loss to update both the velocity and\nnetwork parameters, thereby forming a self-supervised learning procedure. We\npropose two implementation schemes, which differ in whether the velocity update\npasses through the CNN. In both methodologies, the velocity representation is\nextended (VRE) by using a neural network in addition to the grid-based\nvelocities. Thus, we refer to this general approach as VRE-FWI. Synthetic and\nreal data tests demonstrate that the proposed VRE-FWI achieves higher velocity\ninversion accuracy compared to traditional FWI, at a marginal additional\ncomputational cost of approximately 1%."}
{"id": "2504.16041", "pdf": "https://arxiv.org/pdf/2504.16041", "abs": "https://arxiv.org/abs/2504.16041", "authors": ["Amund Tveit", "Bjørn Remseth", "Arve Skogvold"], "title": "Muon Optimizer Accelerates Grokking", "categories": ["cs.LG", "cs.AI", "I.2"], "comment": "8 pages, 4 figures", "summary": "This paper investigates the impact of different optimizers on the grokking\nphenomenon, where models exhibit delayed generalization. We conducted\nexperiments across seven numerical tasks (primarily modular arithmetic) using a\nmodern Transformer architecture. The experimental configuration systematically\nvaried the optimizer (Muon vs. AdamW) and the softmax activation function\n(standard softmax, stablemax, and sparsemax) to assess their combined effect on\nlearning dynamics. Our empirical evaluation reveals that the Muon optimizer,\ncharacterized by its use of spectral norm constraints and second-order\ninformation, significantly accelerates the onset of grokking compared to the\nwidely used AdamW optimizer. Specifically, Muon reduced the mean grokking epoch\nfrom 153.09 to 102.89 across all configurations, a statistically significant\ndifference (t = 5.0175, p = 6.33e-08). This suggests that the optimizer choice\nplays a crucial role in facilitating the transition from memorization to\ngeneralization."}
{"id": "2504.15863", "pdf": "https://arxiv.org/pdf/2504.15863", "abs": "https://arxiv.org/abs/2504.15863", "authors": ["Diego de Oliveira Hitzges", "Suman Ghosh", "Guillermo Gallego"], "title": "DERD-Net: Learning Depth from Event-based Ray Densities", "categories": ["cs.CV", "cs.LG", "cs.RO", "eess.SP"], "comment": "13 pages, 3 figures, 14 tables. Project page:\n  https://github.com/tub-rip/DERD-Net", "summary": "Event cameras offer a promising avenue for multi-view stereo depth estimation\nand Simultaneous Localization And Mapping (SLAM) due to their ability to detect\nblur-free 3D edges at high-speed and over broad illumination conditions.\nHowever, traditional deep learning frameworks designed for conventional cameras\nstruggle with the asynchronous, stream-like nature of event data, as their\narchitectures are optimized for discrete, image-like inputs. We propose a\nscalable, flexible and adaptable framework for pixel-wise depth estimation with\nevent cameras in both monocular and stereo setups. The 3D scene structure is\nencoded into disparity space images (DSIs), representing spatial densities of\nrays obtained by back-projecting events into space via known camera poses. Our\nneural network processes local subregions of the DSIs combining 3D convolutions\nand a recurrent structure to recognize valuable patterns for depth prediction.\nLocal processing enables fast inference with full parallelization and ensures\nconstant ultra-low model complexity and memory costs, regardless of camera\nresolution. Experiments on standard benchmarks (MVSEC and DSEC datasets)\ndemonstrate unprecedented effectiveness: (i) using purely monocular data, our\nmethod achieves comparable results to existing stereo methods; (ii) when\napplied to stereo data, it strongly outperforms all state-of-the-art (SOTA)\napproaches, reducing the mean absolute error by at least 42%; (iii) our method\nalso allows for increases in depth completeness by more than 3-fold while still\nyielding a reduction in median absolute error of at least 30%. Given its\nremarkable performance and effective processing of event-data, our framework\nholds strong potential to become a standard approach for using deep learning\nfor event-based depth estimation and SLAM. Project page:\nhttps://github.com/tub-rip/DERD-Net"}
{"id": "2504.16047", "pdf": "https://arxiv.org/pdf/2504.16047", "abs": "https://arxiv.org/abs/2504.16047", "authors": ["Frank Li", "Hari Trivedi", "Bardia Khosravi", "Theo Dapamede", "Mohammadreza Chavoshi", "Abdulhameed Dere", "Rohan Satya Isaac", "Aawez Mansuri", "Janice Newsome", "Saptarshi Purkayastha", "Judy Gichoya"], "title": "Evaluating Vision Language Models (VLMs) for Radiology: A Comprehensive Analysis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Foundation models, trained on vast amounts of data using self-supervised\ntechniques, have emerged as a promising frontier for advancing artificial\nintelligence (AI) applications in medicine. This study evaluates three\ndifferent vision-language foundation models (RAD-DINO, CheXagent, and\nBiomedCLIP) on their ability to capture fine-grained imaging features for\nradiology tasks. The models were assessed across classification, segmentation,\nand regression tasks for pneumothorax and cardiomegaly on chest radiographs.\nSelf-supervised RAD-DINO consistently excelled in segmentation tasks, while\ntext-supervised CheXagent demonstrated superior classification performance.\nBiomedCLIP showed inconsistent performance across tasks. A custom segmentation\nmodel that integrates global and local features substantially improved\nperformance for all foundation models, particularly for challenging\npneumothorax segmentation. The findings highlight that pre-training methodology\nsignificantly influences model performance on specific downstream tasks. For\nfine-grained segmentation tasks, models trained without text supervision\nperformed better, while text-supervised models offered advantages in\nclassification and interpretability. These insights provide guidance for\nselecting foundation models based on specific clinical applications in\nradiology."}
{"id": "2504.15865", "pdf": "https://arxiv.org/pdf/2504.15865", "abs": "https://arxiv.org/abs/2504.15865", "authors": ["Lotfi Abdelkrim Mecharbat", "Ibrahim Elmakky", "Martin Takac", "Mohammed Yaqub"], "title": "MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep learning (DL) has achieved remarkable progress in the field of medical\nimaging. However, adapting DL models to medical tasks remains a significant\nchallenge, primarily due to two key factors: (1) architecture selection, as\ndifferent tasks necessitate specialized model designs, and (2) weight\ninitialization, which directly impacts the convergence speed and final\nperformance of the models. Although transfer learning from ImageNet is a widely\nadopted strategy, its effectiveness is constrained by the substantial\ndifferences between natural and medical images. To address these challenges, we\nintroduce Medical Neural Network Search (MedNNS), the first Neural Network\nSearch framework for medical imaging applications. MedNNS jointly optimizes\narchitecture selection and weight initialization by constructing a meta-space\nthat encodes datasets and models based on how well they perform together. We\nbuild this space using a Supernetwork-based approach, expanding the model zoo\nsize by 51x times over previous state-of-the-art (SOTA) methods. Moreover, we\nintroduce rank loss and Fr\\'echet Inception Distance (FID) loss into the\nconstruction of the space to capture inter-model and inter-dataset\nrelationships, thereby achieving more accurate alignment in the meta-space.\nExperimental results across multiple datasets demonstrate that MedNNS\nsignificantly outperforms both ImageNet pre-trained DL models and SOTA Neural\nArchitecture Search (NAS) methods, achieving an average accuracy improvement of\n1.7% across datasets while converging substantially faster. The code and the\nprocessed meta-space is available at https://github.com/BioMedIA-MBZUAI/MedNNS."}
{"id": "2504.16053", "pdf": "https://arxiv.org/pdf/2504.16053", "abs": "https://arxiv.org/abs/2504.16053", "authors": ["Zhifan Ye", "Kejing Xia", "Yonggan Fu", "Xin Dong", "Jihoon Hong", "Xiangchi Yuan", "Shizhe Diao", "Jan Kautz", "Pavlo Molchanov", "Yingyan Celine Lin"], "title": "LongMamba: Enhancing Mamba's Long Context Capabilities via Training-Free Receptive Field Enlargement", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ICLR 2025", "summary": "State space models (SSMs) have emerged as an efficient alternative to\nTransformer models for language modeling, offering linear computational\ncomplexity and constant memory usage as context length increases. However,\ndespite their efficiency in handling long contexts, recent studies have shown\nthat SSMs, such as Mamba models, generally underperform compared to\nTransformers in long-context understanding tasks. To address this significant\nshortfall and achieve both efficient and accurate long-context understanding,\nwe propose LongMamba, a training-free technique that significantly enhances the\nlong-context capabilities of Mamba models. LongMamba builds on our discovery\nthat the hidden channels in Mamba can be categorized into local and global\nchannels based on their receptive field lengths, with global channels primarily\nresponsible for long-context capability. These global channels can become the\nkey bottleneck as the input context lengthens. Specifically, when input lengths\nlargely exceed the training sequence length, global channels exhibit\nlimitations in adaptively extend their receptive fields, leading to Mamba's\npoor long-context performance. The key idea of LongMamba is to mitigate the\nhidden state memory decay in these global channels by preventing the\naccumulation of unimportant tokens in their memory. This is achieved by first\nidentifying critical tokens in the global channels and then applying token\nfiltering to accumulate only those critical tokens. Through extensive\nbenchmarking across synthetic and real-world long-context scenarios, LongMamba\nsets a new standard for Mamba's long-context performance, significantly\nextending its operational range without requiring additional training. Our code\nis available at https://github.com/GATECH-EIC/LongMamba."}
{"id": "2504.15933", "pdf": "https://arxiv.org/pdf/2504.15933", "abs": "https://arxiv.org/abs/2504.15933", "authors": ["Anh Truong", "Ahmed H. Mahmoud", "Mina Konaković Luković", "Justin Solomon"], "title": "Low-Rank Adaptation of Neural Fields", "categories": ["cs.GR", "cs.LG"], "comment": null, "summary": "Processing visual data often involves small adjustments or sequences of\nchanges, such as in image filtering, surface smoothing, and video storage.\nWhile established graphics techniques like normal mapping and video compression\nexploit redundancy to encode such small changes efficiently, the problem of\nencoding small changes to neural fields (NF) -- neural network\nparameterizations of visual or physical functions -- has received less\nattention.\n  We propose a parameter-efficient strategy for updating neural fields using\nlow-rank adaptations (LoRA). LoRA, a method from the parameter-efficient\nfine-tuning LLM community, encodes small updates to pre-trained models with\nminimal computational overhead. We adapt LoRA to instance-specific neural\nfields, avoiding the need for large pre-trained models yielding a pipeline\nsuitable for low-compute hardware.\n  We validate our approach with experiments in image filtering, video\ncompression, and geometry editing, demonstrating its effectiveness and\nversatility for representing neural field updates."}
{"id": "2504.16061", "pdf": "https://arxiv.org/pdf/2504.16061", "abs": "https://arxiv.org/abs/2504.16061", "authors": ["Sangeet Khemlani", "Tyler Tran", "Nathaniel Gyory", "Anthony M. Harrison", "Wallace E. Lawson", "Ravenna Thielstrom", "Hunter Thompson", "Taaren Singh", "J. Gregory Trafton"], "title": "Vision language models are unreliable at trivial spatial cognition", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision language models (VLMs) are designed to extract relevant visuospatial\ninformation from images. Some research suggests that VLMs can exhibit humanlike\nscene understanding, while other investigations reveal difficulties in their\nability to process relational information. To achieve widespread applicability,\nVLMs must perform reliably, yielding comparable competence across a wide\nvariety of related tasks. We sought to test how reliable these architectures\nare at engaging in trivial spatial cognition, e.g., recognizing whether one\nobject is left of another in an uncluttered scene. We developed a benchmark\ndataset -- TableTest -- whose images depict 3D scenes of objects arranged on a\ntable, and used it to evaluate state-of-the-art VLMs. Results show that\nperformance could be degraded by minor variations of prompts that use logically\nequivalent descriptions. These analyses suggest limitations in how VLMs may\nreason about spatial relations in real-world applications. They also reveal\nnovel opportunities for bolstering image caption corpora for more efficient\ntraining and testing."}
{"id": "2504.15942", "pdf": "https://arxiv.org/pdf/2504.15942", "abs": "https://arxiv.org/abs/2504.15942", "authors": ["Erik Imgrund", "Thorsten Eisenhofer", "Konrad Rieck"], "title": "Adversarial Observations in Weather Forecasting", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "AI-based systems, such as Google's GenCast, have recently redefined the state\nof the art in weather forecasting, offering more accurate and timely\npredictions of both everyday weather and extreme events. While these systems\nare on the verge of replacing traditional meteorological methods, they also\nintroduce new vulnerabilities into the forecasting process. In this paper, we\ninvestigate this threat and present a novel attack on autoregressive diffusion\nmodels, such as those used in GenCast, capable of manipulating weather\nforecasts and fabricating extreme events, including hurricanes, heat waves, and\nintense rainfall. The attack introduces subtle perturbations into weather\nobservations that are statistically indistinguishable from natural noise and\nchange less than 0.1% of the measurements - comparable to tampering with data\nfrom a single meteorological satellite. As modern forecasting integrates data\nfrom nearly a hundred satellites and many other sources operated by different\ncountries, our findings highlight a critical security risk with the potential\nto cause large-scale disruptions and undermine public trust in weather\nprediction."}
{"id": "2504.16072", "pdf": "https://arxiv.org/pdf/2504.16072", "abs": "https://arxiv.org/abs/2504.16072", "authors": ["Long Lian", "Yifan Ding", "Yunhao Ge", "Sifei Liu", "Hanzi Mao", "Boyi Li", "Marco Pavone", "Ming-Yu Liu", "Trevor Darrell", "Adam Yala", "Yin Cui"], "title": "Describe Anything: Detailed Localized Image and Video Captioning", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://describe-anything.github.io/", "summary": "Generating detailed and accurate descriptions for specific regions in images\nand videos remains a fundamental challenge for vision-language models. We\nintroduce the Describe Anything Model (DAM), a model designed for detailed\nlocalized captioning (DLC). DAM preserves both local details and global context\nthrough two key innovations: a focal prompt, which ensures high-resolution\nencoding of targeted regions, and a localized vision backbone, which integrates\nprecise localization with its broader context. To tackle the scarcity of\nhigh-quality DLC data, we propose a Semi-supervised learning (SSL)-based Data\nPipeline (DLC-SDP). DLC-SDP starts with existing segmentation datasets and\nexpands to unlabeled web images using SSL. We introduce DLC-Bench, a benchmark\ndesigned to evaluate DLC without relying on reference captions. DAM sets new\nstate-of-the-art on 7 benchmarks spanning keyword-level, phrase-level, and\ndetailed multi-sentence localized image and video captioning."}
{"id": "2504.15979", "pdf": "https://arxiv.org/pdf/2504.15979", "abs": "https://arxiv.org/abs/2504.15979", "authors": ["Zhiyuan Zheng", "Jianpeng Qi", "Jiantao Li", "Guoqing Chao", "Junyu Dong", "Yanwei Yu"], "title": "Efficient Discovery of Motif Transition Process for Large-Scale Temporal Graphs", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Understanding the dynamic transition of motifs in temporal graphs is\nessential for revealing how graph structures evolve over time, identifying\ncritical patterns, and predicting future behaviors, yet existing methods often\nfocus on predefined motifs, limiting their ability to comprehensively capture\ntransitions and interrelationships. We propose a parallel motif transition\nprocess discovery algorithm, PTMT, a novel parallel method for discovering\nmotif transition processes in large-scale temporal graphs. PTMT integrates a\ntree-based framework with the temporal zone partitioning (TZP) strategy, which\npartitions temporal graphs by time and structure while preserving lossless\nmotif transitions and enabling massive parallelism. PTMT comprises three\nphases: growth zone parallel expansion, overlap-aware result aggregation, and\ndeterministic encoding of motif transitions, ensuring accurate tracking of\ndynamic transitions and interactions. Results on 10 real-world datasets\ndemonstrate that PTMT achieves speedups ranging from 12.0$\\times$ to\n50.3$\\times$ compared to the SOTA method."}
{"id": "2504.16078", "pdf": "https://arxiv.org/pdf/2504.16078", "abs": "https://arxiv.org/abs/2504.16078", "authors": ["Thomas Schmied", "Jörg Bornschein", "Jordi Grau-Moya", "Markus Wulfmeier", "Razvan Pascanu"], "title": "LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The success of Large Language Models (LLMs) has sparked interest in various\nagentic applications. A key hypothesis is that LLMs, leveraging common sense\nand Chain-of-Thought (CoT) reasoning, can effectively explore and efficiently\nsolve complex domains. However, LLM agents have been found to suffer from\nsub-optimal exploration and the knowing-doing gap, the inability to effectively\nact on knowledge present in the model. In this work, we systematically study\nwhy LLMs perform sub-optimally in decision-making scenarios. In particular, we\nclosely examine three prevalent failure modes: greediness, frequency bias, and\nthe knowing-doing gap. We propose mitigation of these shortcomings by\nfine-tuning via Reinforcement Learning (RL) on self-generated CoT rationales.\nOur experiments across multi-armed bandits, contextual bandits, and\nTic-tac-toe, demonstrate that RL fine-tuning enhances the decision-making\nabilities of LLMs by increasing exploration and narrowing the knowing-doing\ngap. Finally, we study both classic exploration mechanisms, such as\n$\\epsilon$-greedy, and LLM-specific approaches, such as self-correction and\nself-consistency, to enable more effective fine-tuning of LLMs for\ndecision-making."}
{"id": "2504.15991", "pdf": "https://arxiv.org/pdf/2504.15991", "abs": "https://arxiv.org/abs/2504.15991", "authors": ["Leonardo Olivi", "Edoardo Santero Mormile", "Enzo Tartaglione"], "title": "Efficient Adaptation of Deep Neural Networks for Semantic Segmentation in Space Applications", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In recent years, the application of Deep Learning techniques has shown\nremarkable success in various computer vision tasks, paving the way for their\ndeployment in extraterrestrial exploration. Transfer learning has emerged as a\npowerful strategy for addressing the scarcity of labeled data in these novel\nenvironments. This paper represents one of the first efforts in evaluating the\nfeasibility of employing adapters toward efficient transfer learning for rock\nsegmentation in extraterrestrial landscapes, mainly focusing on lunar and\nmartian terrains. Our work suggests that the use of adapters, strategically\nintegrated into a pre-trained backbone model, can be successful in reducing\nboth bandwidth and memory requirements for the target extraterrestrial device.\nIn this study, we considered two memory-saving strategies: layer fusion (to\nreduce to zero the inference overhead) and an ``adapter ranking'' (to also\nreduce the transmission cost). Finally, we evaluate these results in terms of\ntask performance, memory, and computation on embedded devices, evidencing\ntrade-offs that open the road to more research in the field."}
{"id": "2504.15993", "pdf": "https://arxiv.org/pdf/2504.15993", "abs": "https://arxiv.org/abs/2504.15993", "authors": ["Oliver Summerell", "Gerardo Aragon-Camarasa", "Stephanie Ordonez Sanchez"], "title": "Benchmarking machine learning models for predicting aerofoil performance", "categories": ["physics.flu-dyn", "cs.LG"], "comment": "9 pages, 10 figures, submitted to EWTEC", "summary": "This paper investigates the capability of Neural Networks (NNs) as\nalternatives to the traditional methods to analyse the performance of aerofoils\nused in the wind and tidal energy industry. The current methods used to assess\nthe characteristic lift and drag coefficients include Computational Fluid\nDynamics (CFD), thin aerofoil and panel methods, all face trade-offs between\ncomputational speed and the accuracy of the results and as such NNs have been\ninvestigated as an alternative with the aim that it would perform both quickly\nand accurately. As such, this paper provides a benchmark for the windAI_bench\ndataset published by the National Renewable Energy Laboratory (NREL) in the\nUSA. In order to validate the methodology of the benchmarking, the AirfRANS\n{\\tt arXiv:2212.07564v3} dataset is used as both a starting point and a point\nof comparison. This study evaluates four neural networks (MLP, PointNet,\nGraphSAGE, GUNet) trained on a range aerofoils at 25 angles of attack\n(4$^\\circ$ to 20$^\\circ$). to predict fluid flow and calculate lift\ncoefficients ($C_L$) via the panel method. GraphSAGE and GUNet performed well\nduring the testing phase, but underperformed during validation. Accordingly,\nthis paper has identified PointNet and MLP as the two strongest models tested,\nhowever whilst the results from MLP are more commonly correct for predicting\nthe behaviour of the fluid, the results from PointNet provide the more accurate\nresults for calculating $C_L$."}
{"id": "2504.16000", "pdf": "https://arxiv.org/pdf/2504.16000", "abs": "https://arxiv.org/abs/2504.16000", "authors": ["Soham Bonnerjee", "Zhen Wei", "Yeon", "Anna Asch", "Sagnik Nandy", "Promit Ghosal"], "title": "How Private is Your Attention? Bridging Privacy with In-Context Learning", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "In-context learning (ICL)-the ability of transformer-based models to perform\nnew tasks from examples provided at inference time-has emerged as a hallmark of\nmodern language models. While recent works have investigated the mechanisms\nunderlying ICL, its feasibility under formal privacy constraints remains\nlargely unexplored. In this paper, we propose a differentially private\npretraining algorithm for linear attention heads and present the first\ntheoretical analysis of the privacy-accuracy trade-off for ICL in linear\nregression. Our results characterize the fundamental tension between\noptimization and privacy-induced noise, formally capturing behaviors observed\nin private training via iterative methods. Additionally, we show that our\nmethod is robust to adversarial perturbations of training prompts, unlike\nstandard ridge regression. All theoretical findings are supported by extensive\nsimulations across diverse settings."}
{"id": "2504.16010", "pdf": "https://arxiv.org/pdf/2504.16010", "abs": "https://arxiv.org/abs/2504.16010", "authors": ["Tuong Manh Vu", "Ernesto Carrella", "Robert Axtell", "Omar A. Guerrero"], "title": "The Formation of Production Networks: How Supply Chains Arise from Simple Learning with Minimal Information", "categories": ["cs.MA", "cs.LG", "econ.GN", "q-fin.EC"], "comment": null, "summary": "We develop a model where firms determine the price at which they sell their\ndifferentiable goods, the volume that they produce, and the inputs (types and\namounts) that they purchase from other firms. A steady-state production network\nemerges endogenously without resorting to assumptions such as equilibrium or\nperfect knowledge about production technologies. Through a simple version of\nreinforcement learning, firms with heterogeneous technologies cope with\nuncertainty and maximize profits. Due to this learning process, firms can adapt\nto shocks such as demand shifts, suppliers/clients closure, productivity\nchanges, and production technology modifications; effectively reshaping the\nproduction network. To demonstrate the potential of this model, we analyze the\nupstream and downstream impact of demand and productivity shocks."}
{"id": "2504.16027", "pdf": "https://arxiv.org/pdf/2504.16027", "abs": "https://arxiv.org/abs/2504.16027", "authors": ["Ahmed R. Sadik", "Siddhata Govind"], "title": "Benchmarking LLM for Code Smells Detection: OpenAI GPT-4.0 vs DeepSeek-V3", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL"], "comment": null, "summary": "Determining the most effective Large Language Model for code smell detection\npresents a complex challenge. This study introduces a structured methodology\nand evaluation matrix to tackle this issue, leveraging a curated dataset of\ncode samples consistently annotated with known smells. The dataset spans four\nprominent programming languages Java, Python, JavaScript, and C++; allowing for\ncross language comparison. We benchmark two state of the art LLMs, OpenAI GPT\n4.0 and DeepSeek-V3, using precision, recall, and F1 score as evaluation\nmetrics. Our analysis covers three levels of detail: overall performance,\ncategory level performance, and individual code smell type performance.\nAdditionally, we explore cost effectiveness by comparing the token based\ndetection approach of GPT 4.0 with the pattern-matching techniques employed by\nDeepSeek V3. The study also includes a cost analysis relative to traditional\nstatic analysis tools such as SonarQube. The findings offer valuable guidance\nfor practitioners in selecting an efficient, cost effective solution for\nautomated code smell detection"}
{"id": "2504.16068", "pdf": "https://arxiv.org/pdf/2504.16068", "abs": "https://arxiv.org/abs/2504.16068", "authors": ["Chuin Wei Tan", "Marc L. Descoteaux", "Mit Kotak", "Gabriel de Miranda Nascimento", "Seán R. Kavanagh", "Laura Zichi", "Menghang Wang", "Aadit Saluja", "Yizhong R. Hu", "Tess Smidt", "Anders Johansson", "William C. Witt", "Boris Kozinsky", "Albert Musaelian"], "title": "High-performance training and inference for deep equivariant interatomic potentials", "categories": ["physics.comp-ph", "cs.LG", "physics.chem-ph"], "comment": null, "summary": "Machine learning interatomic potentials, particularly those based on deep\nequivariant neural networks, have demonstrated state-of-the-art accuracy and\ncomputational efficiency in atomistic modeling tasks like molecular dynamics\nand high-throughput screening. The size of datasets and demands of downstream\nworkflows are growing rapidly, making robust and scalable software essential.\nThis work presents a major overhaul of the NequIP framework focusing on\nmulti-node parallelism, computational performance, and extensibility. The\nredesigned framework supports distributed training on large datasets and\nremoves barriers preventing full utilization of the PyTorch 2.0 compiler at\ntrain time. We demonstrate this acceleration in a case study by training\nAllegro models on the SPICE 2 dataset of organic molecular systems. For\ninference, we introduce the first end-to-end infrastructure that uses the\nPyTorch Ahead-of-Time Inductor compiler for machine learning interatomic\npotentials. Additionally, we implement a custom kernel for the Allegro model's\nmost expensive operation, the tensor product. Together, these advancements\nspeed up molecular dynamics calculations on system sizes of practical relevance\nby up to a factor of 18."}
{"id": "2504.16075", "pdf": "https://arxiv.org/pdf/2504.16075", "abs": "https://arxiv.org/abs/2504.16075", "authors": ["Joshua S. Harvey", "Joshua Rosaler", "Mingshu Li", "Dhruv Desai", "Dhagash Mehta"], "title": "Explainable Unsupervised Anomaly Detection with Random Forest", "categories": ["stat.ML", "cs.LG"], "comment": "14 pages, 5 figures", "summary": "We describe the use of an unsupervised Random Forest for similarity learning\nand improved unsupervised anomaly detection. By training a Random Forest to\ndiscriminate between real data and synthetic data sampled from a uniform\ndistribution over the real data bounds, a distance measure is obtained that\nanisometrically transforms the data, expanding distances at the boundary of the\ndata manifold. We show that using distances recovered from this transformation\nimproves the accuracy of unsupervised anomaly detection, compared to other\ncommonly used detectors, demonstrated over a large number of benchmark\ndatasets. As well as improved performance, this method has advantages over\nother unsupervised anomaly detection methods, including minimal requirements\nfor data preprocessing, native handling of missing data, and potential for\nvisualizations. By relating outlier scores to partitions of the Random Forest,\nwe develop a method for locally explainable anomaly predictions in terms of\nfeature importance."}
{"id": "2504.16083", "pdf": "https://arxiv.org/pdf/2504.16083", "abs": "https://arxiv.org/abs/2504.16083", "authors": ["Yucheng Li", "Huiqiang Jiang", "Chengruidong Zhang", "Qianhui Wu", "Xufang Luo", "Surin Ahn", "Amir H. Abdi", "Dongsheng Li", "Jianfeng Gao", "Yuqing Yang", "Lili Qiu"], "title": "MMInference: Accelerating Pre-filling for Long-Context VLMs via Modality-Aware Permutation Sparse Attention", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The integration of long-context capabilities with visual understanding\nunlocks unprecedented potential for Vision Language Models (VLMs). However, the\nquadratic attention complexity during the pre-filling phase remains a\nsignificant obstacle to real-world deployment. To overcome this limitation, we\nintroduce MMInference (Multimodality Million tokens Inference), a dynamic\nsparse attention method that accelerates the prefilling stage for long-context\nmulti-modal inputs. First, our analysis reveals that the temporal and spatial\nlocality of video input leads to a unique sparse pattern, the Grid pattern.\nSimultaneously, VLMs exhibit markedly different sparse distributions across\ndifferent modalities. We introduce a permutation-based method to leverage the\nunique Grid pattern and handle modality boundary issues. By offline search the\noptimal sparse patterns for each head, MMInference constructs the sparse\ndistribution dynamically based on the input. We also provide optimized GPU\nkernels for efficient sparse computations. Notably, MMInference integrates\nseamlessly into existing VLM pipelines without any model modifications or\nfine-tuning. Experiments on multi-modal benchmarks-including Video QA,\nCaptioning, VisionNIAH, and Mixed-Modality NIAH-with state-of-the-art\nlong-context VLMs (LongVila, LlavaVideo, VideoChat-Flash, Qwen2.5-VL) show that\nMMInference accelerates the pre-filling stage by up to 8.3x at 1M tokens while\nmaintaining accuracy. Our code is available at https://aka.ms/MMInference."}
{"id": "2504.16084", "pdf": "https://arxiv.org/pdf/2504.16084", "abs": "https://arxiv.org/abs/2504.16084", "authors": ["Yuxin Zuo", "Kaiyan Zhang", "Shang Qu", "Li Sheng", "Xuekai Zhu", "Biqing Qi", "Youbang Sun", "Ganqu Cui", "Ning Ding", "Bowen Zhou"], "title": "TTRL: Test-Time Reinforcement Learning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This paper investigates Reinforcement Learning (RL) on data without explicit\nlabels for reasoning tasks in Large Language Models (LLMs). The core challenge\nof the problem is reward estimation during inference while not having access to\nground-truth information. While this setting appears elusive, we find that\ncommon practices in Test-Time Scaling (TTS), such as majority voting, yield\nsurprisingly effective rewards suitable for driving RL training. In this work,\nwe introduce Test-Time Reinforcement Learning (TTRL), a novel method for\ntraining LLMs using RL on unlabeled data. TTRL enables self-evolution of LLMs\nby utilizing the priors in the pre-trained models. Our experiments demonstrate\nthat TTRL consistently improves performance across a variety of tasks and\nmodels. Notably, TTRL boosts the pass@1 performance of Qwen-2.5-Math-7B by\napproximately 159% on the AIME 2024 with only unlabeled test data. Furthermore,\nalthough TTRL is only supervised by the Maj@N metric, TTRL has demonstrated\nperformance to consistently surpass the upper limit of the initial model, and\napproach the performance of models trained directly on test data with\nground-truth labels. Our experimental findings validate the general\neffectiveness of TTRL across various tasks, and highlight TTRL's potential for\nbroader tasks and domains. GitHub: https://github.com/PRIME-RL/TTRL"}
