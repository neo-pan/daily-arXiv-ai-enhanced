{"id": "2504.11459", "pdf": "https://arxiv.org/pdf/2504.11459", "abs": "https://arxiv.org/abs/2504.11459", "authors": ["Peter Stockinger"], "title": "From Conceptual Data Models to Multimodal Representation", "categories": ["cs.AI", "cs.CL", "cs.IR"], "comment": "in French language", "summary": "1) Introduction and Conceptual Framework: This document explores the concept\nof information design by dividing it into two major practices: defining the\nmeaning of a corpus of textual data and its visual or multimodal\nrepresentation. It draws on expertise in enriching textual corpora,\nparticularly audiovisual ones, and transforming them into multiple narrative\nformats. The text highlights a crucial distinction between the semantic content\nof a domain and the modalities of its graphic expression, illustrating this\napproach with concepts rooted in structural semiotics and linguistics\ntraditions.\n  2) Modeling and Conceptual Design: The article emphasizes the importance of\nsemantic modeling, often achieved through conceptual networks or graphs. These\ntools enable the structuring of knowledge within a domain by accounting for\nrelationships between concepts, contexts of use, and specific objectives.\nStockinger also highlights the constraints and challenges involved in creating\ndynamic and adaptable models, integrating elements such as thesauri or\ninteroperable ontologies to facilitate the analysis and publication of complex\ncorpora.\n  3) Applications and Multimodal Visualization: The text concludes by examining\nthe practical application of these models in work environments like OKAPI,\ndeveloped to analyze, publish, and reuse audiovisual data. It also discusses\ninnovative approaches such as visual storytelling and document reengineering,\nwhich involve transforming existing content into new resources tailored to\nvarious contexts. These methods emphasize interoperability, flexibility, and\nthe intelligence of communication systems, paving the way for richer and more\ncollaborative use of digital data. The content of this document was presented\nduring the \"Semiotics of Information Design\" Day organized by Anne\nBeyaert-Geslin of the University of Bordeaux Montaigne (MICA laboratory) on\nJune 21, 2018, in Bordeaux.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4fe1\u606f\u8bbe\u8ba1\uff0c\u5305\u62ec\u8bed\u4e49\u5185\u5bb9\u4e0e\u89c6\u89c9\u8868\u793a\u7684\u5212\u5206\uff0c\u5e76\u901a\u8fc7\u8bed\u4e49\u5efa\u6a21\u5e94\u7528\u4e8e\u97f3\u89c6\u9891\u6570\u636e\u3002", "motivation": "\u8bba\u6587\u65e8\u5728\u533a\u5206\u8bed\u4e49\u5185\u5bb9\u4e0e\u56fe\u5f62\u8868\u8fbe\uff0c\u5229\u7528\u7ed3\u6784\u7b26\u53f7\u5b66\u548c\u8bed\u8a00\u5b66\u4f20\u7edf\u6765\u4e30\u5bcc\u6587\u672c\u8bed\u6599\u3002", "method": "\u4f7f\u7528\u6982\u5ff5\u7f51\u7edc\u3001\u56fe\u8868\u3001\u8bcd\u5e93\u548c\u672c\u4f53\u8bba\u8fdb\u884c\u8bed\u4e49\u5efa\u6a21\uff0c\u5e76\u5f00\u53d1\u5982OKAPI\u5de5\u5177\u7684\u5e94\u7528\u3002", "result": "\u5f00\u53d1\u4e86\u52a8\u6001\u6a21\u578b\u548c\u53ef\u89c6\u5316\u6545\u4e8b\u8bb2\u8ff0\u65b9\u6cd5\uff0c\u63d0\u9ad8\u6570\u636e\u5206\u6790\u3001\u53d1\u5e03\u548c\u4e92\u64cd\u4f5c\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u65b9\u6cd5\u4fc3\u8fdb\u6570\u5b57\u6570\u636e\u7684\u66f4\u4e30\u5bcc\u548c\u534f\u4f5c\u4f7f\u7528\uff0c\u63d0\u5347\u901a\u4fe1\u7cfb\u7edf\u7684\u667a\u80fd\u6027\u3002"}}
{"id": "2504.11514", "pdf": "https://arxiv.org/pdf/2504.11514", "abs": "https://arxiv.org/abs/2504.11514", "authors": ["Nicolas Baumann", "Cheng Hu", "Paviththiren Sivasothilingam", "Haotong Qin", "Lei Xie", "Michele Magno", "Luca Benini"], "title": "Enhancing Autonomous Driving Systems with On-Board Deployed Large Language Models", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Neural Networks (NNs) trained through supervised learning struggle with\nmanaging edge-case scenarios common in real-world driving due to the\nintractability of exhaustive datasets covering all edge-cases, making\nknowledge-driven approaches, akin to how humans intuitively detect unexpected\ndriving behavior, a suitable complement to data-driven methods. This work\nproposes a hybrid architecture combining low-level Model Predictive Controller\n(MPC) with locally deployed Large Language Models (LLMs) to enhance\ndecision-making and Human Machine Interaction (HMI). The DecisionxLLM module\nevaluates robotic state information against natural language instructions to\nensure adherence to desired driving behavior. The MPCxLLM module then adjusts\nMPC parameters based on LLM-generated insights, achieving control adaptability\nwhile preserving the safety and constraint guarantees of traditional MPC\nsystems. Further, to enable efficient on-board deployment and to eliminate\ndependency on cloud connectivity, we shift processing to the on-board computing\nplatform: We propose an approach that exploits Retrieval Augmented Generation\n(RAG), Low Rank Adaptation (LoRA) fine-tuning, and quantization. Experimental\nresults demonstrate that these enhancements yield significant improvements in\nreasoning accuracy by up to 10.45%, control adaptability by as much as 52.2%,\nand up to 10.5x increase in computational efficiency (tokens/s), validating the\nproposed framework's practicality for real-time deployment even on down-scaled\nrobotic platforms. This work bridges high-level decision-making with low-level\ncontrol adaptability, offering a synergistic framework for knowledge-driven and\nadaptive Autonomous Driving Systems (ADS).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMPC\u548cLLM\u7684\u6df7\u5408\u67b6\u6784\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u6027\u80fd\uff0c\u5b9e\u9a8c\u663e\u793a\u51c6\u786e\u6027\u548c\u6548\u7387\u663e\u8457\u63d0\u9ad8\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u96be\u4ee5\u5904\u7406\u9a7e\u9a76\u8fb9\u7f18\u60c5\u51b5\uff0c\u56e0\u6b64\u9700\u8981\u77e5\u8bc6\u9a71\u52a8\u65b9\u6cd5\u8865\u5145\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408MPC\u548cLLM\u7684\u6df7\u5408\u67b6\u6784\uff0c\u4f7f\u7528DecisionxLLM\u8bc4\u4f30\u72b6\u6001\u3001MPCxLLM\u8c03\u6574\u53c2\u6570\uff0c\u5e76\u91c7\u7528RAG\u3001LoRA\u548c\u91cf\u5316\u6280\u672f\u5b9e\u73b0\u672c\u5730\u90e8\u7f72\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\uff1a\u63a8\u7406\u51c6\u786e\u6027\u63d0\u534710.45%\u3001\u63a7\u5236\u9002\u5e94\u6027\u63d0\u534752.2%\u3001\u8ba1\u7b97\u6548\u7387\u63d0\u9ad810.5\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u6865\u63a5\u9ad8\u5c42\u51b3\u7b56\u548c\u5e95\u5c42\u63a7\u5236\uff0c\u63d0\u4f9b\u77e5\u8bc6\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u3002"}}
{"id": "2504.11524", "pdf": "https://arxiv.org/pdf/2504.11524", "abs": "https://arxiv.org/abs/2504.11524", "authors": ["Haokun Liu", "Sicong Huang", "Jingyu Hu", "Yangqiaoyu Zhou", "Chenhao Tan"], "title": "HypoBench: Towards Systematic and Principled Benchmarking for Hypothesis Generation", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "comment": "29 pages, 6 figures, website link:\n  https://chicagohai.github.io/HypoBench/", "summary": "There is growing interest in hypothesis generation with large language models\n(LLMs). However, fundamental questions remain: what makes a good hypothesis,\nand how can we systematically evaluate methods for hypothesis generation? To\naddress this, we introduce HypoBench, a novel benchmark designed to evaluate\nLLMs and hypothesis generation methods across multiple aspects, including\npractical utility, generalizability, and hypothesis discovery rate. HypoBench\nincludes 7 real-world tasks and 5 synthetic tasks with 194 distinct datasets.\nWe evaluate four state-of-the-art LLMs combined with six existing\nhypothesis-generation methods. Overall, our results suggest that existing\nmethods are capable of discovering valid and novel patterns in the data.\nHowever, the results from synthetic datasets indicate that there is still\nsignificant room for improvement, as current hypothesis generation methods do\nnot fully uncover all relevant or meaningful patterns. Specifically, in\nsynthetic settings, as task difficulty increases, performance significantly\ndrops, with best models and methods only recovering 38.8% of the ground-truth\nhypotheses. These findings highlight challenges in hypothesis generation and\ndemonstrate that HypoBench serves as a valuable resource for improving AI\nsystems designed to assist scientific discovery.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f15\u5165HypoBench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u5047\u8bbe\u751f\u6210\u4e2d\u7684\u6027\u80fd\uff0c\u7ed3\u679c\u663e\u793a\u73b0\u6709\u65b9\u6cd5\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u9488\u5bf9LLM\u5047\u8bbe\u751f\u6210\u7684\u57fa\u672c\u95ee\u9898\uff0c\u5982\u597d\u5047\u8bbe\u7684\u5b9a\u4e49\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1HypoBench\u57fa\u51c6\uff0c\u5305\u62ec7\u4e2a\u771f\u5b9e\u4e16\u754c\u548c5\u4e2a\u5408\u6210\u4efb\u52a1\u3001194\u4e2a\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u56db\u79cdLLM\u548c\u516d\u79cd\u5047\u8bbe\u751f\u6210\u65b9\u6cd5\u3002", "result": "\u73b0\u6709\u65b9\u6cd5\u80fd\u53d1\u73b0\u6a21\u5f0f\uff0c\u4f46\u5408\u6210\u4efb\u52a1\u4e0a\u4ec5\u6062\u590d38.8%\u7684\u771f\u5b9e\u5047\u8bbe\uff0c\u96be\u5ea6\u589e\u52a0\u65f6\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u5f3a\u8c03\u5047\u8bbe\u751f\u6210\u7684\u6311\u6218\uff0c\u5e76\u8bc1\u660eHypoBench\u662f\u6539\u8fdbAI\u79d1\u5b66\u53d1\u73b0\u7cfb\u7edf\u7684\u5b9d\u8d35\u8d44\u6e90\u3002"}}
{"id": "2504.11543", "pdf": "https://arxiv.org/pdf/2504.11543", "abs": "https://arxiv.org/abs/2504.11543", "authors": ["Divyansh Garg", "Shaun VanWeelden", "Diego Caples", "Andis Draguns", "Nikil Ravi", "Pranav Putta", "Naman Garg", "Tomas Abraham", "Michael Lara", "Federico Lopez", "James Liu", "Atharva Gundawar", "Prannay Hebbar", "Youngchul Joo", "Charles London", "Christian Schroeder de Witt", "Sumeet Motwani"], "title": "REAL: Benchmarking Autonomous Agents on Deterministic Simulations of Real Websites", "categories": ["cs.AI"], "comment": null, "summary": "We introduce REAL, a benchmark and framework for multi-turn agent evaluations\non deterministic simulations of real-world websites. REAL comprises\nhigh-fidelity, deterministic replicas of 11 widely-used websites across domains\nsuch as e-commerce, travel, communication, and professional networking. We also\nrelease a benchmark consisting of 112 practical tasks that mirror everyday\ncomplex user interactions requiring both accurate information retrieval and\nstate-changing actions. All interactions occur within this fully controlled\nsetting, eliminating safety risks and enabling robust, reproducible evaluation\nof agent capability and reliability. Our novel evaluation framework combines\nprogrammatic checks of website state for action-based tasks with rubric-guided\nLLM-based judgments for information retrieval. The framework supports both\nopen-source and proprietary agent systems through a flexible evaluation harness\nthat accommodates black-box commands within browser environments, allowing\nresearch labs to test agentic systems without modification. Our empirical\nresults show that frontier language models achieve at most a 41% success rate\non REAL, highlighting critical gaps in autonomous web navigation and task\ncompletion capabilities. Our framework supports easy integration of new tasks,\nreproducible evaluation, and scalable data generation for training web agents.\nThe websites, framework, and leaderboard are available at https://realevals.xyz\nand https://github.com/agi-inc/REAL.", "AI": {"tldr": "REAL\u662f\u4e00\u4e2a\u57fa\u51c6\u548c\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u6a21\u62df\u771f\u5b9e\u7f51\u7ad9\u7684\u73af\u5883\u4e2d\u8bc4\u4f30\u591a\u8f6e\u4ee3\u7406\u6027\u80fd\uff0c\u5305\u62ec11\u4e2a\u7f51\u7ad9\u590d\u5236\u548c112\u4e2a\u4efb\u52a1\uff0c\u8bc4\u4f30\u663e\u793a\u524d\u6cbf\u6a21\u578b\u6210\u529f\u7387\u4ec541%\u3002", "motivation": "\u4e3a\u4e86\u5728\u5b89\u5168\u3001\u53ef\u91cd\u590d\u7684\u53d7\u63a7\u73af\u5883\u4e2d\u8bc4\u4f30\u4ee3\u7406\u7684\u7f51\u7edc\u5bfc\u822a\u548c\u4efb\u52a1\u5b8c\u6210\u80fd\u529b\uff0c\u907f\u514d\u771f\u5b9e\u4e16\u754c\u98ce\u9669\u3002", "method": "\u6784\u5efa\u9ad8\u4fdd\u771f\u7f51\u7ad9\u590d\u5236\u3001\u8bbe\u8ba1\u5b9e\u9645\u4efb\u52a1\u3001\u5f00\u53d1\u8bc4\u4f30\u6846\u67b6\uff08\u7ed3\u5408\u7a0b\u5e8f\u68c0\u67e5\u548cLLM\u5224\u65ad\uff09\u3001\u652f\u6301\u9ed1\u7bb1\u4ee3\u7406\u7cfb\u7edf\u3002", "result": "\u524d\u6cbf\u8bed\u8a00\u6a21\u578b\u5728REAL\u4e0a\u7684\u6210\u529f\u7387\u6700\u9ad8\u4e3a41%\uff0c\u7a81\u663e\u4ee3\u7406\u5728\u81ea\u4e3b\u7f51\u7edc\u5bfc\u822a\u548c\u4efb\u52a1\u5b8c\u6210\u65b9\u9762\u7684\u80fd\u529b\u4e0d\u8db3\u3002", "conclusion": "\u6846\u67b6\u652f\u6301\u65b0\u4efb\u52a1\u96c6\u6210\u3001\u53ef\u91cd\u590d\u8bc4\u4f30\u548c\u53ef\u6269\u5c55\u6570\u636e\u751f\u6210\uff0c\u5e76\u63d0\u4f9b\u5f00\u6e90\u7f51\u7ad9\u3001\u6846\u67b6\u548c\u6392\u884c\u699c\u8d44\u6e90\u3002"}}
{"id": "2504.11476", "pdf": "https://arxiv.org/pdf/2504.11476", "abs": "https://arxiv.org/abs/2504.11476", "authors": ["Ritik Mishra", "Mushir Akhtar", "M. Tanveer"], "title": "CI-RKM: A Class-Informed Approach to Robust Restricted Kernel Machines", "categories": ["cs.LG"], "comment": "Accepted in International Joint Conference on Neural Networks (IJCNN)\n  2025", "summary": "Restricted kernel machines (RKMs) represent a versatile and powerful\nframework within the kernel machine family, leveraging conjugate feature\nduality to address a wide range of machine learning tasks, including\nclassification, regression, and feature learning. However, their performance\ncan degrade significantly in the presence of noise and outliers, which\ncompromises robustness and predictive accuracy. In this paper, we propose a\nnovel enhancement to the RKM framework by integrating a class-informed weighted\nfunction. This weighting mechanism dynamically adjusts the contribution of\nindividual training points based on their proximity to class centers and\nclass-specific characteristics, thereby mitigating the adverse effects of noisy\nand outlier data. By incorporating weighted conjugate feature duality and\nleveraging the Schur complement theorem, we introduce the class-informed\nrestricted kernel machine (CI-RKM), a robust extension of the RKM designed to\nimprove generalization and resilience to data imperfections. Experimental\nevaluations on benchmark datasets demonstrate that the proposed CI-RKM\nconsistently outperforms existing baselines, achieving superior classification\naccuracy and enhanced robustness against noise and outliers. Our proposed\nmethod establishes a significant advancement in the development of kernel-based\nlearning models, addressing a core challenge in the field.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7c7b\u4fe1\u606f\u9650\u5236\u6838\u673a\u5668\uff08CI-RKM\uff09\uff0c\u4ee5\u63d0\u5347RKM\u5bf9\u566a\u58f0\u548c\u5f02\u5e38\u503c\u7684\u9c81\u68d2\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u5206\u7c7b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "RKM\u5728\u566a\u58f0\u548c\u5f02\u5e38\u503c\u5b58\u5728\u65f6\u6027\u80fd\u4e0b\u964d\uff0c\u4e9f\u9700\u6539\u8fdb\u4ee5\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u6574\u5408\u7c7b\u4fe1\u606f\u52a0\u6743\u51fd\u6570\uff0c\u5229\u7528\u52a0\u6743\u5171\u8f6d\u7279\u5f81\u5bf9\u5076\u548cSchur\u8865\u77e9\u9635\u5b9a\u7406\uff0c\u5f15\u5165CI-RKM\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cCI-RKM\u5728\u5206\u7c7b\u51c6\u786e\u6027\u548c\u5bf9\u566a\u58f0\u53ca\u5f02\u5e38\u503c\u7684\u9c81\u68d2\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6838\u57fa\u5b66\u4e60\u6a21\u578b\u4e2d\u53d6\u5f97\u91cd\u5927\u8fdb\u5c55\uff0c\u89e3\u51b3\u4e86\u9886\u57df\u6838\u5fc3\u6311\u6218\uff0c\u63d0\u5347\u4e86\u6cdb\u5316\u80fd\u529b\u548c\u6570\u636e\u9c81\u68d2\u6027\u3002"}}
{"id": "2504.11569", "pdf": "https://arxiv.org/pdf/2504.11569", "abs": "https://arxiv.org/abs/2504.11569", "authors": ["Heming Fu", "Guojun Xiong", "Jian Li", "Shan Lin"], "title": "Multi-Agent Reinforcement Learning for Decentralized Reservoir Management via Murmuration Intelligence", "categories": ["eess.SY", "cs.SY"], "comment": "ACM SIGMETRICS 2025 Workshop", "summary": "Conventional centralized water management systems face critical limitations\nfrom computational complexity and uncertainty propagation. We present MurmuRL,\na novel decentralized framework inspired by starling murmurations intelligence,\nintegrating bio-inspired alignment, separation, and cohesion rules with\nmulti-agent reinforcement learning. MurmuRL enables individual reservoirs to\nmake autonomous local decisions while achieving emergent global coordination.\nExperiments on grid networks demonstrate that MurmuRL achieves 8.8% higher\nfinal performance while using 27% less computing overhead compared to\ncentralized approaches. Notably, strategic diversity scales super-linearly with\nsystem size, exhibiting sophisticated coordination patterns and enhanced\nresilience during extreme events. MurmuRL offers a scalable solution for\nmanaging complex water systems by leveraging principles of natural collective\nbehavior.", "AI": {"tldr": "MurmuRL \u662f\u4e00\u79cd\u53d7\u9e1f\u7fa4\u542f\u53d1\u7684\u53bb\u4e2d\u5fc3\u5316\u6c34\u7ba1\u7406\u7cfb\u7edf\uff0c\u4f7f\u7528\u591a\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u63d0\u9ad8\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u4f20\u7edf\u96c6\u4e2d\u5f0f\u6c34\u7ba1\u7406\u7cfb\u7edf\u5b58\u5728\u8ba1\u7b97\u590d\u6742\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u4f20\u64ad\u7684\u9650\u5236\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6\u3002", "method": "\u6574\u5408\u751f\u7269\u542f\u53d1\u7684\u5bf9\u9f50\u3001\u5206\u79bb\u548c\u51dd\u805a\u89c4\u5219\u4e0e\u591a\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\uff0c\u521b\u5efa MurmuRL \u6846\u67b6\uff0c\u5b9e\u73b0\u6c34\u5e93\u81ea\u4e3b\u51b3\u7b56\u548c\u5168\u5c40\u534f\u8c03\u3002", "result": "\u5b9e\u9a8c\u663e\u793a MurmuRL \u6bd4\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u63d0\u9ad8 8.8% \u6027\u80fd\uff0c\u51cf\u5c11 27% \u8ba1\u7b97\u5f00\u9500\uff1b\u6218\u7565\u591a\u6837\u6027\u8d85\u7ebf\u6027\u589e\u957f\uff0c\u589e\u5f3a\u6781\u7aef\u4e8b\u4ef6\u5f39\u6027\u3002", "conclusion": "MurmuRL \u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u81ea\u7136\u96c6\u4f53\u884c\u4e3a\u539f\u5219\u7ba1\u7406\u590d\u6742\u6c34\u7cfb\u7edf\u3002"}}
{"id": "2504.11544", "pdf": "https://arxiv.org/pdf/2504.11544", "abs": "https://arxiv.org/abs/2504.11544", "authors": ["Tianyang Xu", "Haojie Zheng", "Chengze Li", "Haoxiang Chen", "Yixin Liu", "Ruoxi Chen", "Lichao Sun"], "title": "NodeRAG: Structuring Graph-based RAG with Heterogeneous Nodes", "categories": ["cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) empowers large language models to access\nexternal and private corpus, enabling factually consistent responses in\nspecific domains. By exploiting the inherent structure of the corpus,\ngraph-based RAG methods further enrich this process by building a knowledge\ngraph index and leveraging the structural nature of graphs. However, current\ngraph-based RAG approaches seldom prioritize the design of graph structures.\nInadequately designed graph not only impede the seamless integration of diverse\ngraph algorithms but also result in workflow inconsistencies and degraded\nperformance. To further unleash the potential of graph for RAG, we propose\nNodeRAG, a graph-centric framework introducing heterogeneous graph structures\nthat enable the seamless and holistic integration of graph-based methodologies\ninto the RAG workflow. By aligning closely with the capabilities of LLMs, this\nframework ensures a fully cohesive and efficient end-to-end process. Through\nextensive experiments, we demonstrate that NodeRAG exhibits performance\nadvantages over previous methods, including GraphRAG and LightRAG, not only in\nindexing time, query time, and storage efficiency but also in delivering\nsuperior question-answering performance on multi-hop benchmarks and open-ended\nhead-to-head evaluations with minimal retrieval tokens. Our GitHub repository\ncould be seen at https://github.com/Terry-Xu-666/NodeRAG.", "AI": {"tldr": "NodeRAG \u901a\u8fc7\u5f02\u6784\u56fe\u7ed3\u6784\u63d0\u5347 RAG \u6846\u67b6\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u56fe-based RAG \u65b9\u6cd5\u672a\u91cd\u89c6\u56fe\u7ed3\u6784\u8bbe\u8ba1\uff0c\u5bfc\u81f4\u7b97\u6cd5\u6574\u5408\u4e0d\u7545\u548c\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa NodeRAG \u6846\u67b6\uff0c\u4f7f\u7528\u5f02\u6784\u56fe\u7ed3\u6784\u65e0\u7f1d\u6574\u5408\u56fe\u7b97\u6cd5\u5230 RAG \u5de5\u4f5c\u6d41\u4e2d\uff0c\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7d27\u5bc6\u7ed3\u5408\u3002", "result": "\u5b9e\u9a8c\u663e\u793a NodeRAG \u5728\u7d22\u5f15\u65f6\u95f4\u3001\u67e5\u8be2\u65f6\u95f4\u3001\u5b58\u50a8\u6548\u7387\u548c\u95ee\u7b54\u6027\u80fd\u4e0a\u4f18\u4e8e GraphRAG \u548c LightRAG\u3002", "conclusion": "NodeRAG \u8bc1\u660e\u4e86\u5176\u5728\u591a\u8df3\u57fa\u51c6\u548c\u5f00\u653e\u5f0f\u8bc4\u4f30\u4e2d\u7684\u4f18\u52bf\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u4ed3\u5e93\u3002"}}
{"id": "2504.11497", "pdf": "https://arxiv.org/pdf/2504.11497", "abs": "https://arxiv.org/abs/2504.11497", "authors": ["Chang Liu", "Emmanuel A. Olowe", "Danial Chitnis"], "title": "LLM-based AI Agent for Sizing of Analog and Mixed Signal Circuit", "categories": ["cs.LG", "cs.AR"], "comment": "to be presented in IEEE NEWCAS 2025", "summary": "The design of Analog and Mixed-Signal (AMS) integrated circuits (ICs) often\ninvolves significant manual effort, especially during the transistor sizing\nprocess. While Machine Learning techniques in Electronic Design Automation\n(EDA) have shown promise in reducing complexity and minimizing human\nintervention, they still face challenges such as numerous iterations and a lack\nof knowledge about AMS circuit design. Recently, Large Language Models (LLMs)\nhave demonstrated significant potential across various fields, showing a\ncertain level of knowledge in circuit design and indicating their potential to\nautomate the transistor sizing process. In this work, we propose an LLM-based\nAI agent for AMS circuit design to assist in the sizing process. By integrating\nLLMs with external circuit simulation tools and data analysis functions and\nemploying prompt engineering strategies, the agent successfully optimized\nmultiple circuits to achieve target performance metrics. We evaluated the\nperformance of different LLMs to assess their applicability and optimization\neffectiveness across seven basic circuits, and selected the best-performing\nmodel Claude 3.5 Sonnet for further exploration on an operational amplifier,\nwith complementary input stage and class AB output stage. This circuit was\nevaluated against nine performance metrics, and we conducted experiments under\nthree distinct performance requirement groups. A success rate of up to 60% was\nachieved for reaching the target requirements. Overall, this work demonstrates\nthe potential of LLMs to improve AMS circuit design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684AI\u4ee3\u7406\uff0c\u7528\u4e8e\u81ea\u52a8\u8c03\u6574AMS\u7535\u8def\u7684\u6676\u4f53\u7ba1\u5c3a\u5bf8\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u8fbe60%\u7684\u6210\u529f\u7387\u6765\u6ee1\u8db3\u6027\u80fd\u6307\u6807\u3002", "motivation": "AMS\u96c6\u6210\u7535\u8def\u8bbe\u8ba1\u9700\u8981\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\uff0c\u673a\u5668\u5b66\u4e60\u6280\u672f\u5b58\u5728\u6311\u6218\uff0cLLM\u663e\u793a\u51fa\u5728\u7535\u8def\u8bbe\u8ba1\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u5c06LLM\u4e0e\u5916\u90e8\u7535\u8def\u6a21\u62df\u5de5\u5177\u548c\u6570\u636e\u5206\u6790\u529f\u80fd\u96c6\u6210\uff0c\u5e76\u91c7\u7528\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\uff0c\u4f18\u5316\u4e86\u591a\u4e2a\u7535\u8def\uff0c\u5e76\u8bc4\u4f30\u4e0d\u540cLLM\u6a21\u578b\u3002", "result": "\u5728\u4e03\u4e2a\u57fa\u672c\u7535\u8def\u548c\u4e00\u4e2a\u8fd0\u7b97\u653e\u5927\u5668\u4e0a\u6d4b\u8bd5\uff0c\u6210\u529f\u7387\u6700\u9ad8\u8fbe60%\uff0c\u6ee1\u8db3\u591a\u79cd\u6027\u80fd\u8981\u6c42\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u8bc1\u660e\u4e86LLM\u5728\u6539\u5584AMS\u7535\u8def\u8bbe\u8ba1\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.11592", "pdf": "https://arxiv.org/pdf/2504.11592", "abs": "https://arxiv.org/abs/2504.11592", "authors": ["Saurabh Kumar", "Shashi Ranjan Kumar", "Abhinav Sinha"], "title": "Provably Safe Control for Constrained Nonlinear Systems with Bounded Input", "categories": ["eess.SY", "cs.SY", "math.DS", "math.OC"], "comment": null, "summary": "In real-world control applications, actuator constraints and output\nconstraints (specifically in tracking problems) are inherent and critical to\nensuring safe and reliable operation. However, generally, control strategies\noften neglect these physical limitations, leading to potential instability,\ndegraded performance, or even system failure when deployed on real-world\nsystems. This paper addresses the control design problem for a class of\nnonlinear systems under both actuator saturation and output constraints. First,\na smooth asymmetric saturation model (a more generic representative of\npractical scenarios) is proposed to model actuator saturation, which ensures\nthat the control inputs always remain confined within a predefined set to\nensure safety. Based on the proposed model, we develop a nonlinear control\nframework that guarantees output tracking while ensuring that system output\nremains confined to the predefined set. Later, we integrate this design with\nthe constrained output tracking control problem, wherein we show that the\nsystem output tracks its desired trajectory by simultaneously satisfying input\nand output constraints. The global stabilization of the tracking error is\nachieved in the presence of input constraints, while semi-global stabilization\nis achieved in the presence of both input and output constraints. Additionally,\nwe rigorously establish the boundedness of all closed-loop signals under the\nproposed design. Simulation results demonstrate the effectiveness of the\nproposed methods in handling asymmetric constraints while achieving desirable\ntracking performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u975e\u7ebf\u6027\u7cfb\u7edf\u7ea6\u675f\u63a7\u5236\u8bbe\u8ba1\uff0c\u786e\u4fdd\u5b89\u5168\u8f93\u51fa\u8ddf\u8e2a\u3002", "motivation": "\u5b9e\u9645\u63a7\u5236\u4e2d\u5ffd\u7565\u6267\u884c\u5668\u548c\u8f93\u51fa\u7ea6\u675f\u53ef\u80fd\u5bfc\u81f4\u4e0d\u7a33\u5b9a\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5e73\u6ed1\u975e\u5bf9\u79f0\u9971\u548c\u6a21\u578b\uff0c\u5e76\u5f00\u53d1\u975e\u7ebf\u6027\u63a7\u5236\u6846\u67b6\uff0c\u4fdd\u8bc1\u8ddf\u8e2a\u5e76\u6ee1\u8db3\u7ea6\u675f\u3002", "result": "\u5b9e\u73b0\u8ddf\u8e2a\u8bef\u5dee\u7a33\u5b9a\u548c\u4fe1\u53f7\u6709\u754c\uff0c\u6a21\u62df\u9a8c\u8bc1\u6709\u6548\u3002", "conclusion": "\u65b9\u6cd5\u5904\u7406\u975e\u5bf9\u79f0\u7ea6\u675f\uff0c\u8fbe\u5230\u826f\u597d\u8ddf\u8e2a\u6027\u80fd\u3002"}}
{"id": "2504.11547", "pdf": "https://arxiv.org/pdf/2504.11547", "abs": "https://arxiv.org/abs/2504.11547", "authors": ["Olha Shaposhnyk", "Noor Abid", "Mouri Zakir", "Svetlana Yanushkevich"], "title": "Probabilistic causal graphs as categorical data synthesizers: Do they do better than Gaussian Copulas and Conditional Tabular GANs?", "categories": ["cs.AI"], "comment": null, "summary": "This study investigates the generation of high-quality synthetic categorical\ndata, such as survey data, using causal graph models. Generating synthetic data\naims not only to create a variety of data for training the models but also to\npreserve privacy while capturing relationships between the data. The research\nemploys Structural Equation Modeling (SEM) followed by Bayesian Networks (BN).\nWe used the categorical data that are based on the survey of accessibility to\nservices for people with disabilities. We created both SEM and BN models to\nrepresent causal relationships and to capture joint distributions between\nvariables. In our case studies, such variables include, in particular,\ndemographics, types of disability, types of accessibility barriers and\nfrequencies of encountering those barriers.\n  The study compared the SEM-based BN method with alternative approaches,\nincluding the probabilistic Gaussian copula technique and generative models\nlike the Conditional Tabular Generative Adversarial Network (CTGAN). The\nproposed method outperformed others in statistical metrics, including the\nChi-square test, Kullback-Leibler divergence, and Total Variation Distance\n(TVD). In particular, the BN model demonstrated superior performance, achieving\nthe highest TVD, indicating alignment with the original data. The Gaussian\nCopula ranked second, while CTGAN exhibited moderate performance. These\nanalyses confirmed the ability of the SEM-based BN to produce synthetic data\nthat maintain statistical and relational validity while maintaining\nconfidentiality. This approach is particularly beneficial for research on\nsensitive data, such as accessibility and disability studies.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u548c\u8d1d\u53f6\u65af\u7f51\u7edc\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u5206\u7c7b\u6570\u636e\uff0c\u5e94\u7528\u4e8e\u6b8b\u75be\u670d\u52a1\u53ef\u8bbf\u95ee\u6027\u8c03\u67e5\uff0c\u51fa\u8272\u5730\u4fdd\u6301\u6570\u636e\u5173\u7cfb\u548c\u9690\u79c1\u3002", "motivation": "\u751f\u6210\u5408\u6210\u6570\u636e\u4ee5\u589e\u52a0\u6a21\u578b\u8bad\u7ec3\u591a\u6837\u6027\u3001\u4fdd\u5bc6\u6027\uff0c\u5e76\u6355\u6349\u53d8\u91cf\u95f4\u5173\u7cfb\uff0c\u9488\u5bf9\u6b8b\u75be\u4eba\u7fa4\u670d\u52a1\u53ef\u8bbf\u95ee\u6027\u8c03\u67e5\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\uff08SEM\uff09\u540e\u8ddf\u8d1d\u53f6\u65af\u7f51\u7edc\uff08BN\uff09\uff0c\u5e76\u4e0e\u9ad8\u65afCopula\u548cCTGAN\u7b49\u65b9\u6cd5\u6bd4\u8f83\u3002", "result": "SEM-based BN\u5728Chi-square\u6d4b\u8bd5\u3001KL\u6563\u5ea6\u548cTVD\u7b49\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\uff0cBN\u6a21\u578bTV D\u6700\u9ad8\uff0c\u663e\u793a\u4e0e\u539f\u59cb\u6570\u636e\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u7ef4\u62a4\u7edf\u8ba1\u548c\u5173\u7cfb\u6709\u6548\u6027\u7684\u540c\u65f6\u4fdd\u62a4\u4fdd\u5bc6\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u654f\u611f\u6570\u636e\u5982\u6b8b\u75be\u7814\u7a76\u3002"}}
{"id": "2504.11506", "pdf": "https://arxiv.org/pdf/2504.11506", "abs": "https://arxiv.org/abs/2504.11506", "authors": ["Hongliang Lu", "Shuqi Shen", "Junjie Yang", "Chao Lu", "Xinhu Zheng", "Hai Yang"], "title": "Cross-cultural Deployment of Autonomous Vehicles Using Data-light Inverse Reinforcement Learning", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "More than the adherence to specific traffic regulations, driving culture\ntouches upon a more implicit part - an informal, conventional, collective\nbehavioral pattern followed by drivers - that varies across countries, regions,\nand even cities. Such cultural divergence has become one of the biggest\nchallenges in deploying autonomous vehicles (AVs) across diverse regions today.\nThe current emergence of data-driven methods has shown a potential solution to\nenable culture-compatible driving through learning from data, but what if some\nunderdeveloped regions cannot provide sufficient local data to inform driving\nculture? This issue is particularly significant for a broader global AV market.\nHere, we propose a cross-cultural deployment scheme for AVs, called data-light\ninverse reinforcement learning, designed to re-calibrate culture-specific AVs\nand assimilate them into other cultures. First, we report the divergence in\ndriving cultures through a comprehensive comparative analysis of naturalistic\ndriving datasets on highways from three countries: Germany, China, and the USA.\nThen, we demonstrate the effectiveness of our scheme by testing the expeditious\ncross-cultural deployment across these three countries, with cumulative testing\nmileage of over 56084 km. The performance is particularly advantageous when\ncross-cultural deployment is carried out without affluent local data. Results\nshow that we can reduce the dependence on local data by a margin of 98.67% at\nbest. This study is expected to bring a broader, fairer AV global market,\nparticularly in those regions that lack enough local data to develop\nculture-compatible AVs.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u6570\u636e\u8f7b\u91cf\u5316\u7684\u9006\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e2e\u52a9\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff08AV\uff09\u5728\u4e0d\u540c\u6587\u5316\u80cc\u666f\u4e0b\u5feb\u901f\u90e8\u7f72\uff0c\u51cf\u5c11\u5bf9\u672c\u5730\u6570\u636e\u7684\u4f9d\u8d56\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u90e8\u7f72\u9762\u4e34\u6587\u5316\u5dee\u5f02\u6311\u6218\uff0c\u5c24\u5176\u5728\u6570\u636e\u4e0d\u8db3\u7684\u5730\u533a\uff0c\u65e0\u6cd5\u901a\u8fc7\u6570\u636e\u5b66\u4e60\u672c\u5730\u9a7e\u9a76\u6587\u5316\u3002", "method": "\u63d0\u51fa\u6570\u636e\u8f7b\u91cf\u5316\u7684\u9006\u5f3a\u5316\u5b66\u4e60\u65b9\u6848\uff0c\u901a\u8fc7\u6bd4\u8f83\u5fb7\u56fd\u3001\u4e2d\u56fd\u548c\u7f8e\u56fd\u7684\u81ea\u7136\u9a7e\u9a76\u6570\u636e\u96c6\uff0c\u5e76\u8fdb\u884c\u8de8\u6587\u5316\u90e8\u7f72\u6d4b\u8bd5\uff0c\u603b\u91cc\u7a0b\u8d85\u8fc756084\u516c\u91cc\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u53ef\u5c06\u5bf9\u672c\u5730\u6570\u636e\u7684\u4f9d\u8d56\u51cf\u5c1198.67%\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u6709\u52a9\u4e8e\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u3001\u66f4\u516c\u5e73\u7684\u5168\u7403AV\u5e02\u573a\uff0c\u7279\u522b\u662f\u9488\u5bf9\u6570\u636e\u532e\u4e4f\u5730\u533a\u3002"}}
{"id": "2504.11607", "pdf": "https://arxiv.org/pdf/2504.11607", "abs": "https://arxiv.org/abs/2504.11607", "authors": ["Jan Mietzner", "Cerikh Chakraborty", "Peter A. Hoeher", "Lutz Lampe"], "title": "Comprehensive Signal Modeling for Talkative Power Conversion", "categories": ["eess.SY", "cs.SY"], "comment": "15 pages, 10 figures", "summary": "Talkative power conversion is a switching ripple communication technique that\nintegrates data modulation into a switched-mode power electronics converter,\nenabling simultaneous information transmission and power conversion. Despite\nnumerous research papers published over the last decade on various theoretical\nand practical aspects of this emerging topic, thorough signal modeling suitable\nfor analysis and computer simulations is still lacking. In this article, we\nderive the continuous-time output voltage of a DC/DC switched-mode power\nelectronics converter for a broad range of pulsed-based modulation schemes. We\nalso develop corresponding discrete-time signal models and assess their\naccuracies. Finally, we devise a generic end-to-end signal model for arbitrary\nmodulation signals, discuss implications of continuous-time and discrete-time\nsignal modeling on equalization, and consider generalizations to include\nparasitic effects as well as the influence of general impedance loads.", "AI": {"tldr": "This paper derives signal models for talkative power conversion in DC/DC converters to enable better analysis and simulations.", "motivation": "Despite extensive research on talkative power conversion, a comprehensive signal modeling for analysis and simulations is still lacking.", "method": "Deriving continuous-time and discrete-time signal models for various modulation schemes, assessing their accuracies, and developing a generic end-to-end model.", "result": "Accurate signal models are created, with discussions on equalization implications and generalizations to parasitic effects and impedance loads.", "conclusion": "The models provide a solid foundation for advancing the field of talkative power conversion through improved analysis and simulation capabilities."}}
{"id": "2504.11571", "pdf": "https://arxiv.org/pdf/2504.11571", "abs": "https://arxiv.org/abs/2504.11571", "authors": ["Dayeon Ki", "Tianyi Zhou", "Marine Carpuat", "Gang Wu", "Puneet Mathur", "Viswanathan Swaminathan"], "title": "GraphicBench: A Planning Benchmark for Graphic Design with Language Agents", "categories": ["cs.AI", "cs.CL"], "comment": "41 pages, 11 figures", "summary": "Large Language Model (LLM)-powered agents have unlocked new possibilities for\nautomating human tasks. While prior work has focused on well-defined tasks with\nspecified goals, the capabilities of agents in creative design tasks with\nopen-ended goals remain underexplored. We introduce GraphicBench, a new\nplanning benchmark for graphic design that covers 1,079 user queries and input\nimages across four design types. We further present GraphicTown, an LLM agent\nframework with three design experts and 46 actions (tools) to choose from for\nexecuting each step of the planned workflows in web environments. Experiments\nwith six LLMs demonstrate their ability to generate workflows that integrate\nboth explicit design constraints from user queries and implicit commonsense\nconstraints. However, these workflows often do not lead to successful execution\noutcomes, primarily due to challenges in: (1) reasoning about spatial\nrelationships, (2) coordinating global dependencies across experts, and (3)\nretrieving the most appropriate action per step. We envision GraphicBench as a\nchallenging yet valuable testbed for advancing LLM-agent planning and execution\nin creative design tasks.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165GraphicBench\u57fa\u51c6\u548cGraphicTown\u6846\u67b6\uff0c\u6d4b\u8bd5LLM\u4ee3\u7406\u5728\u56fe\u5f62\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u7684\u89c4\u5212\u80fd\u529b\uff0c\u63ed\u793a\u5176\u4f18\u52bf\u548c\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u805a\u7126\u660e\u786e\u76ee\u6807\u4efb\u52a1\uff0c\u5ffd\u7565\u5f00\u653e\u5f0f\u521b\u610f\u8bbe\u8ba1\u4efb\u52a1\uff0c\u56e0\u6b64\u672c\u6587\u65e8\u5728\u63a2\u7d22LLM\u4ee3\u7406\u5728\u8be5\u9886\u57df\u7684\u6f5c\u529b\u3002", "method": "\u5f15\u5165GraphicBench\u57fa\u51c6\uff08\u542b1079\u4e2a\u67e5\u8be2\u548c\u56fe\u50cf\uff09\u548cGraphicTown\u6846\u67b6\uff08\u542b\u4e09\u4e2a\u8bbe\u8ba1\u4e13\u5bb6\u548c46\u4e2a\u52a8\u4f5c\uff09\uff0c\u7528\u4e8e\u751f\u6210\u548c\u6267\u884c\u5de5\u4f5c\u6d41\u3002", "result": "\u516d\u79cdLLM\u5b9e\u9a8c\u663e\u793a\u80fd\u6574\u5408\u663e\u5f0f\u548c\u9690\u5f0f\u7ea6\u675f\uff0c\u4f46\u5e38\u56e0\u7a7a\u95f4\u5173\u7cfb\u63a8\u7406\u3001\u4e13\u5bb6\u534f\u8c03\u548c\u52a8\u4f5c\u68c0\u7d22\u95ee\u9898\u5bfc\u81f4\u6267\u884c\u5931\u8d25\u3002", "conclusion": "GraphicBench\u88ab\u89c6\u4e3a\u63a8\u8fdbLLM\u4ee3\u7406\u5728\u521b\u610f\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u89c4\u5212\u548c\u6267\u884c\u7684\u5b9d\u8d35\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2504.11508", "pdf": "https://arxiv.org/pdf/2504.11508", "abs": "https://arxiv.org/abs/2504.11508", "authors": ["Clement Nyanhongo", "Bruno Miranda Henrique", "Eugene Santos"], "title": "Reward Distance Comparisons Under Transition Sparsity", "categories": ["cs.LG"], "comment": "Published in the TMLR, https://openreview.net/forum?id=haP586YomL", "summary": "Reward comparisons are vital for evaluating differences in agent behaviors\ninduced by a set of reward functions. Most conventional techniques utilize the\ninput reward functions to learn optimized policies, which are then used to\ncompare agent behaviors. However, learning these policies can be\ncomputationally expensive and can also raise safety concerns. Direct reward\ncomparison techniques obviate policy learning but suffer from transition\nsparsity, where only a small subset of transitions are sampled due to data\ncollection challenges and feasibility constraints. Existing state-of-the-art\ndirect reward comparison methods are ill-suited for these sparse conditions\nsince they require high transition coverage, where the majority of transitions\nfrom a given coverage distribution are sampled. When this requirement is not\nsatisfied, a distribution mismatch between sampled and expected transitions can\noccur, leading to significant errors. This paper introduces the Sparsity\nResilient Reward Distance (SRRD) pseudometric, designed to eliminate the need\nfor high transition coverage by accommodating diverse sample distributions,\nwhich are common under transition sparsity. We provide theoretical\njustification for SRRD's robustness and conduct experiments to demonstrate its\npractical efficacy across multiple domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSRRD\u4f2a\u5ea6\u91cf\uff0c\u7528\u4e8e\u5904\u7406\u5956\u52b1\u6bd4\u8f83\u4e2d\u7684\u8fc7\u6e21\u7a00\u758f\u95ee\u9898\uff0c\u63d0\u9ad8\u9c81\u68d2\u6027\u3002", "motivation": "\u907f\u514d\u7b56\u7565\u5b66\u4e60\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u5b89\u5168\u98ce\u9669\uff0c\u89e3\u51b3\u76f4\u63a5\u5956\u52b1\u6bd4\u8f83\u7684\u8fc7\u6e21\u7a00\u758f\u6027\u95ee\u9898\u3002", "method": "\u5f15\u5165Sparsity Resilient Reward Distance (SRRD)\u4f2a\u5ea6\u91cf\uff0c\u9002\u5e94\u591a\u6837\u6837\u672c\u5206\u5e03\uff0c\u65e0\u9700\u9ad8\u8fc7\u6e21\u8986\u76d6\u7387\u3002", "result": "\u7406\u8bba\u8bc1\u660eSRRD\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u901a\u8fc7\u591a\u9886\u57df\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5b9e\u9645\u6709\u6548\u6027\u3002", "conclusion": "SRRD\u6539\u8fdb\u4e86\u5956\u52b1\u6bd4\u8f83\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u8fc7\u6e21\u7a00\u758f\u6761\u4ef6\u4e0b\u7684\u53ef\u9760\u8bc4\u4f30\u3002"}}
{"id": "2504.11631", "pdf": "https://arxiv.org/pdf/2504.11631", "abs": "https://arxiv.org/abs/2504.11631", "authors": ["Quentin Rommel", "Michael Hibbard", "Pavan Shukla", "Himanshu Save", "Srinivas Bettadpur", "Ufuk Topcu"], "title": "Verifiable Mission Planning For Space Operations", "categories": ["eess.SY", "cs.SY"], "comment": "Initial submission to the 2025 AAS/AIAA Astrodynamics Specialist\n  Conference", "summary": "As space missions become more complex, planning methods must maximize mission\nperformance while rigorously enforcing safety. We develop a probabilistic\napproach based on a finite-horizon Markov decision process to optimize\nspacecraft operations planning with safety guarantees. In the model, states\ncapture essential mission parameters, and actions represent the operational\nadjustments needed to meet mission objectives. By directly incorporating\nuncertainties from environmental conditions and spacecraft dynamics, an optimal\nsequence of actions is computed that maximizes expected rewards and strictly\nenforces safety constraints. Numerical experiments on the GRACE-FO mission\ndemonstrate robust performance under uncertainties while providing\nprobabilistic safety guarantees, offering a reliable solution for autonomous\nspacecraft operations.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6709\u9650\u65f6\u57df\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u6982\u7387\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u822a\u5929\u5668\u64cd\u4f5c\u89c4\u5212\uff0c\u540c\u65f6\u786e\u4fdd\u5b89\u5168\u4fdd\u8bc1\u3002", "motivation": "\u968f\u7740\u592a\u7a7a\u4efb\u52a1\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u89c4\u5212\u65b9\u6cd5\u9700\u6700\u5927\u5316\u4efb\u52a1\u6027\u80fd\u5e76\u4e25\u683c\u6267\u884c\u5b89\u5168\u63aa\u65bd\u3002", "method": "\u91c7\u7528\u6982\u7387\u65b9\u6cd5\uff0c\u5efa\u7acb\u6709\u9650\u65f6\u57df\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u6a21\u578b\uff0c\u72b6\u6001\u6355\u6349\u4efb\u52a1\u53c2\u6570\uff0c\u884c\u52a8\u8868\u793a\u64cd\u4f5c\u8c03\u6574\uff0c\u76f4\u63a5\u7eb3\u5165\u4e0d\u786e\u5b9a\u6027\u8ba1\u7b97\u6700\u4f18\u884c\u52a8\u5e8f\u5217\u3002", "result": "\u5728GRACE-FO\u4efb\u52a1\u7684\u6570\u503c\u5b9e\u9a8c\u4e2d\uff0c\u5c55\u793a\u4e86\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u9c81\u68d2\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u6982\u7387\u5b89\u5168\u4fdd\u8bc1\u3002", "conclusion": "\u4e3a\u81ea\u4e3b\u822a\u5929\u5668\u64cd\u4f5c\u63d0\u4f9b\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.11671", "pdf": "https://arxiv.org/pdf/2504.11671", "abs": "https://arxiv.org/abs/2504.11671", "authors": ["Ji Ma"], "title": "Steering Prosocial AI Agents: Computational Basis of LLM's Decision Making in Social Simulation", "categories": ["cs.AI", "cs.CY", "cs.LG", "econ.GN", "q-fin.EC"], "comment": null, "summary": "Large language models (LLMs) increasingly serve as human-like decision-making\nagents in social science and applied settings. These LLM-agents are typically\nassigned human-like characters and placed in real-life contexts. However, how\nthese characters and contexts shape an LLM's behavior remains underexplored.\nThis study proposes and tests methods for probing, quantifying, and modifying\nan LLM's internal representations in a Dictator Game -- a classic behavioral\nexperiment on fairness and prosocial behavior. We extract ``vectors of variable\nvariations'' (e.g., ``male'' to ``female'') from the LLM's internal state.\nManipulating these vectors during the model's inference can substantially alter\nhow those variables relate to the model's decision-making. This approach offers\na principled way to study and regulate how social concepts can be encoded and\nengineered within transformer-based models, with implications for alignment,\ndebiasing, and designing AI agents for social simulations in both academic and\ncommercial applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5728\u72ec\u88c1\u8005\u6e38\u620f\u4e2d\u63a2\u6d4b\u3001\u91cf\u5316\u548c\u4fee\u6539\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u8868\u793a\uff0c\u4ee5\u7814\u7a76\u793e\u4f1a\u6982\u5ff5\u5982\u4f55\u7f16\u7801\u548c\u88ab\u5de5\u7a0b\u5316\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u51b3\u7b56\u4ee3\u7406\u5728\u793e\u4f1a\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u89d2\u8272\u548c\u4e0a\u4e0b\u6587\u5982\u4f55\u5f71\u54cd\u5176\u884c\u4e3a\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u7814\u7a76\u548c\u8c03\u8282\u793e\u4f1a\u6982\u5ff5\u7684\u7f16\u7801\u3002", "method": "\u63d0\u53d6\u548c\u64cd\u7eb5'\u53d8\u91cf\u53d8\u5316\u5411\u91cf'\uff08\u4f8b\u5982'\u7537\u6027'\u5230'\u5973\u6027'\uff09\u4ece\u6a21\u578b\u5185\u90e8\u72b6\u6001\uff0c\u5e76\u5728\u72ec\u88c1\u8005\u6e38\u620f\u4e2d\u6d4b\u8bd5\u8fd9\u4e9b\u4fee\u6539\u5bf9\u51b3\u7b56\u7684\u5f71\u54cd\u3002", "result": "\u64cd\u7eb5\u8fd9\u4e9b\u5411\u91cf\u53ef\u4ee5\u663e\u8457\u6539\u53d8\u53d8\u91cf\u4e0e\u6a21\u578b\u51b3\u7b56\u7684\u5173\u7cfb\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u7814\u7a76\u548c\u8c03\u8282transformer-based\u6a21\u578b\u4e2d\u7684\u793e\u4f1a\u6982\u5ff5\u63d0\u4f9b\u539f\u7406\u6027\u9014\u5f84\uff0c\u5bf9AI\u5bf9\u9f50\u3001\u53bb\u504f\u89c1\u548c\u4ee3\u7406\u8bbe\u8ba1\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2504.11511", "pdf": "https://arxiv.org/pdf/2504.11511", "abs": "https://arxiv.org/abs/2504.11511", "authors": ["Flint Xiaofeng Fan", "Cheston Tan", "Roger Wattenhofer", "Yew-Soon Ong"], "title": "Position Paper: Rethinking Privacy in RL for Sequential Decision-making in the Age of LLMs", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to IJCNN 2025 Position Paper Track", "summary": "The rise of reinforcement learning (RL) in critical real-world applications\ndemands a fundamental rethinking of privacy in AI systems. Traditional privacy\nframeworks, designed to protect isolated data points, fall short for sequential\ndecision-making systems where sensitive information emerges from temporal\npatterns, behavioral strategies, and collaborative dynamics. Modern RL\nparadigms, such as federated RL (FedRL) and RL with human feedback (RLHF) in\nlarge language models (LLMs), exacerbate these challenges by introducing\ncomplex, interactive, and context-dependent learning environments that\ntraditional methods do not address. In this position paper, we argue for a new\nprivacy paradigm built on four core principles: multi-scale protection,\nbehavioral pattern protection, collaborative privacy preservation, and\ncontext-aware adaptation. These principles expose inherent tensions between\nprivacy, utility, and interpretability that must be navigated as RL systems\nbecome more pervasive in high-stakes domains like healthcare, autonomous\nvehicles, and decision support systems powered by LLMs. To tackle these\nchallenges, we call for the development of new theoretical frameworks,\npractical mechanisms, and rigorous evaluation methodologies that collectively\nenable effective privacy protection in sequential decision-making systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4e3b\u5f20\u5728\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u4e2d\u91c7\u7528\u65b0\u7684\u9690\u79c1\u8303\u5f0f\uff0c\u57fa\u4e8e\u56db\u4e2a\u6838\u5fc3\u539f\u5219\uff0c\u5e76\u547c\u5401\u5f00\u53d1\u65b0\u6846\u67b6\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u5e94\u7528\u5174\u8d77\uff0c\u4f20\u7edf\u9690\u79c1\u6846\u67b6\u65e0\u6cd5\u5904\u7406\u987a\u5e8f\u51b3\u7b56\u7cfb\u7edf\u4e2d\u7684\u654f\u611f\u4fe1\u606f\u3002", "method": "\u4f5c\u4e3a\u4f4d\u7f6e\u8bba\u6587\uff0c\u8bba\u8bc1\u65b0\u9690\u79c1\u539f\u5219\u5e76\u547c\u5401\u5f00\u53d1\u7406\u8bba\u6846\u67b6\u3001\u673a\u5236\u548c\u8bc4\u4ef7\u65b9\u6cd5\u3002", "result": "\u66b4\u9732\u9690\u79c1\u3001\u6548\u7528\u548c\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u5f20\u529b\uff0c\u5e76\u5f3a\u8c03\u5728\u987a\u5e8f\u51b3\u7b56\u7cfb\u7edf\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u9700\u6c42\u3002", "conclusion": "\u9700\u8981\u65b0\u9690\u79c1\u8303\u5f0f\u3001\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u8df5\u673a\u5236\u6765\u4fdd\u62a4\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u7684\u9690\u79c1\u3002"}}
{"id": "2504.11650", "pdf": "https://arxiv.org/pdf/2504.11650", "abs": "https://arxiv.org/abs/2504.11650", "authors": ["Shengyuan Yan", "Farzad Vazinram", "Zeynab Kaseb", "Lindsay Spoor", "Jochen Stiasny", "Betul Mamudi", "Amirhossein Heydarian Ardakani", "Ugochukwu Orji", "Pedro P. Vergara", "Yu Xiang", "Jerry Guo"], "title": "Data driven approach towards more efficient Newton-Raphson power flow calculation for distribution grids", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.NA", "cs.SY", "math.NA", "I.2.8"], "comment": "7 pages, 9 figures, 3 tables, 14 equations, 1 lemma, and 2 theorems.\n  ICT for Industry 2025 Alliander usecase workshop paper. Oral presentation of\n  this paper accepted and to be given on 16th April 2025 in ICT.OPEN 2025\n  conference of Netherlands in the Beatrix Theatre in Utrecht", "summary": "Power flow (PF) calculations are fundamental to power system analysis to\nensure stable and reliable grid operation. The Newton-Raphson (NR) method is\ncommonly used for PF analysis due to its rapid convergence when initialized\nproperly. However, as power grids operate closer to their capacity limits,\nill-conditioned cases and convergence issues pose significant challenges. This\nwork, therefore, addresses these challenges by proposing strategies to improve\nNR initialization, hence minimizing iterations and avoiding divergence. We\nexplore three approaches: (i) an analytical method that estimates the basin of\nattraction using mathematical bounds on voltages, (ii) Two data-driven models\nleveraging supervised learning or physics-informed neural networks (PINNs) to\npredict optimal initial guesses, and (iii) a reinforcement learning (RL)\napproach that incrementally adjusts voltages to accelerate convergence. These\nmethods are tested on benchmark systems. This research is particularly relevant\nfor modern power systems, where high penetration of renewables and\ndecentralized generation require robust and scalable PF solutions. In\nexperiments, all three proposed methods demonstrate a strong ability to provide\nan initial guess for Newton-Raphson method to converge with fewer steps. The\nfindings provide a pathway for more efficient real-time grid operations, which,\nin turn, support the transition toward smarter and more resilient electricity\nnetworks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6539\u8fdb\u725b\u987f-\u62c9\u592b\u68ee\u65b9\u6cd5\u521d\u59cb\u5316\u7684\u7b56\u7565\uff0c\u4ee5\u5904\u7406\u73b0\u4ee3\u7535\u529b\u7535\u7f51\u6536\u655b\u95ee\u9898\u3002", "motivation": "\u7535\u529b\u7535\u7f51\u8fd0\u884c\u63a5\u8fd1\u5bb9\u91cf\u6781\u9650\uff0c\u75c5\u6001\u60c5\u51b5\u548c\u6536\u655b\u6311\u6218\u589e\u52a0\uff0c\u5c24\u5176\u662f\u53ef\u518d\u751f\u80fd\u6e90\u6e17\u900f\u7387\u9ad8\u65f6\u3002", "method": "\u63a2\u7d22\u4e09\u79cd\u65b9\u6cd5\uff1a(i) \u4f7f\u7528\u7535\u538b\u6570\u5b66\u8fb9\u754c\u7684\u5206\u6790\u65b9\u6cd5\uff0c(ii) \u57fa\u4e8e\u76d1\u7763\u5b66\u4e60\u6216\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u636e\u9a71\u52a8\u6a21\u578b\uff0c(iii) \u5f3a\u5316\u5b66\u4e60\u8c03\u6574\u7535\u538b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6240\u6709\u65b9\u6cd5\u5747\u80fd\u63d0\u4f9b\u66f4\u597d\u521d\u59cb\u731c\u6d4b\uff0c\u4f7f\u725b\u987f-\u62c9\u592b\u68ee\u65b9\u6cd5\u4ee5\u66f4\u5c11\u6b65\u6570\u6536\u655b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u9ad8\u6548\u5b9e\u65f6\u7535\u7f51\u64cd\u4f5c\u63d0\u4f9b\u9014\u5f84\uff0c\u652f\u6301\u5411\u66f4\u667a\u80fd\u548c\u575a\u97e7\u7535\u529b\u7f51\u7edc\u8f6c\u578b\u3002"}}
{"id": "2504.11704", "pdf": "https://arxiv.org/pdf/2504.11704", "abs": "https://arxiv.org/abs/2504.11704", "authors": ["Marina Danilevsky", "Kristjan Greenewald", "Chulaka Gunasekara", "Maeda Hanafi", "Lihong He", "Yannis Katsis", "Krishnateja Killamsetty", "Yatin Nandwani", "Lucian Popa", "Dinesh Raghu", "Frederick Reiss", "Vraj Shah", "Khoi-Nguyen Tran", "Huaiyu Zhu", "Luis Lastras"], "title": "A Library of LLM Intrinsics for Retrieval-Augmented Generation", "categories": ["cs.AI", "I.2.7"], "comment": null, "summary": "In the developer community for large language models (LLMs), there is not yet\na clean pattern analogous to a software library, to support very large scale\ncollaboration. Even for the commonplace use case of Retrieval-Augmented\nGeneration (RAG), it is not currently possible to write a RAG application\nagainst a well-defined set of APIs that are agreed upon by different LLM\nproviders. Inspired by the idea of compiler intrinsics, we propose some\nelements of such a concept through introducing a library of LLM Intrinsics for\nRAG. An LLM intrinsic is defined as a capability that can be invoked through a\nwell-defined API that is reasonably stable and independent of how the LLM\nintrinsic itself is implemented. The intrinsics in our library are released as\nLoRA adapters on HuggingFace, and through a software interface with clear\nstructured input/output characteristics on top of vLLM as an inference\nplatform, accompanied in both places with documentation and code. This article\ndescribes the intended usage, training details, and evaluations for each\nintrinsic, as well as compositions of multiple intrinsics.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faLLM Intrinsics\u6982\u5ff5\uff0c\u4ee5\u6807\u51c6\u5316RAG\u5e94\u7528\u7684API\uff0c\u652f\u6301\u5927\u89c4\u6a21\u534f\u4f5c\u3002", "motivation": "LLM\u5f00\u53d1\u8005\u793e\u533a\u7f3a\u4e4f\u7c7b\u4f3c\u4e8e\u8f6f\u4ef6\u5e93\u7684\u534f\u4f5c\u6a21\u5f0f\uff0c\u7279\u522b\u662fRAG\u5e94\u7528API\u4e0d\u7edf\u4e00\u3002", "method": "\u63d0\u51faLLM Intrinsics\u4f5c\u4e3a\u7a33\u5b9aAPI\u7684\u80fd\u529b\uff0c\u901a\u8fc7HuggingFace\u7684LoRA\u9002\u914d\u5668\u548cvLLM\u5e73\u53f0\u53d1\u5e03\uff0c\u5e76\u63d0\u4f9b\u6587\u6863\u3001\u4ee3\u7801\u3001\u4f7f\u7528\u3001\u8bad\u7ec3\u548c\u8bc4\u4f30\u7ec6\u8282\u3002", "result": "\u53d1\u5e03\u4e86\u5185\u5728\u51fd\u6570\u5e93\uff0c\u5e76\u8bc4\u4f30\u4e86\u5176\u4f7f\u7528\u548c\u7ec4\u5408\u6548\u679c\u3002", "conclusion": "\u8fd9\u6709\u52a9\u4e8e\u5efa\u7acbLLM\u9886\u57df\u7684\u6807\u51c6\u5316\u534f\u4f5c\uff0c\u4fc3\u8fdbRAG\u5e94\u7528\u7684\u5f00\u53d1\u3002"}}
{"id": "2504.11513", "pdf": "https://arxiv.org/pdf/2504.11513", "abs": "https://arxiv.org/abs/2504.11513", "authors": ["Wonjun Yi", "Yong-Hwa Park"], "title": "Multi-output Classification Framework and Frequency Layer Normalization for Compound Fault Diagnosis in Motor", "categories": ["cs.LG"], "comment": "Extended version of \"Multi-output Classification for Compound Fault\n  Diagnosis in Motor under Partially Labeled Target Domain\" Will not be\n  published in any conferences or journels", "summary": "This work introduces a multi-output classification (MOC) framework designed\nfor domain adaptation in fault diagnosis, particularly under partially labeled\n(PL) target domain scenarios and compound fault conditions in rotating\nmachinery. Unlike traditional multi-class classification (MCC) methods that\ntreat each fault combination as a distinct class, the proposed approach\nindependently estimates the severity of each fault type, improving both\ninterpretability and diagnostic accuracy. The model incorporates multi-kernel\nmaximum mean discrepancy (MK-MMD) and entropy minimization (EM) losses to\nfacilitate feature transfer from the source to the target domain. In addition,\nfrequency layer normalization (FLN) is applied to preserve structural\nproperties in the frequency domain, which are strongly influenced by system\ndynamics and are often stationary with respect to changes in rpm. Evaluations\nacross six domain adaptation cases with PL data demonstrate that MOC\noutperforms baseline models in macro F1 score. Moreover, MOC consistently\nachieves better classification performance for individual fault types, and FLN\nshows superior adaptability compared to other normalization techniques.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u591a\u8f93\u51fa\u5206\u7c7b\u6846\u67b6\uff0c\u7528\u4e8e\u6545\u969c\u8bca\u65ad\u9886\u57df\u9002\u5e94\uff0c\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u591a\u7c7b\u5206\u7c7b\u65b9\u6cd5\u5728\u90e8\u5206\u6807\u8bb0\u76ee\u6807\u57df\u548c\u590d\u5408\u6545\u969c\u6761\u4ef6\u4e0b\u7684\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u591a\u8f93\u51fa\u5206\u7c7b\u6846\u67b6\u3001MK-MMD\u3001EM\u635f\u5931\u548cFLN\u6280\u672f\u8fdb\u884c\u7279\u5f81\u8f6c\u79fb\u548c\u5f52\u4e00\u5316\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0cMOC\u5728\u5b8fF1\u5206\u6570\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0cFLN\u663e\u793a\u66f4\u597d\u9002\u5e94\u6027\u3002", "conclusion": "\u8bc1\u660eMOC\u6846\u67b6\u5728\u6545\u969c\u8bca\u65ad\u4e2d\u66f4\u6709\u6548\uff0c\u5c24\u5176\u5728\u90e8\u5206\u6807\u8bb0\u6570\u636e\u573a\u666f\u3002"}}
{"id": "2504.11663", "pdf": "https://arxiv.org/pdf/2504.11663", "abs": "https://arxiv.org/abs/2504.11663", "authors": ["Brenner S. Rego", "Guilherme V. Raffo", "Marco H. Terra", "Joseph K. Scott"], "title": "Reachability Analysis of Nonlinear Discrete-Time Systems Using Polyhedral Relaxations and Constrained Zonotopes", "categories": ["eess.SY", "cs.SY", "math.OC"], "comment": "6 pages, 2 figures. This is a preprint of the paper presented at the\n  63rd IEEE Conference on Decision and Control (CDC 2024). arXiv admin note:\n  text overlap with arXiv:2504.00130", "summary": "This paper presents a novel algorithm for reachability analysis of nonlinear\ndiscrete-time systems. The proposed method combines constrained zonotopes (CZs)\nwith polyhedral relaxations of factorable representations of nonlinear\nfunctions to propagate CZs through nonlinear functions, which is normally done\nusing conservative linearization techniques. The new propagation method\nprovides better approximations than those resulting from linearization\nprocedures, leading to significant improvements in the computation of reachable\nsets in comparison to other CZ methods from the literature. Numerical examples\nhighlight the advantages of the proposed algorithm.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u7528\u4e8e\u975e\u7ebf\u6027\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u7684\u53ef\u8fbe\u6027\u5206\u6790\uff0c\u901a\u8fc7\u7ed3\u5408\u7ea6\u675f\u533a\u57df\u548c\u591a\u9762\u4f53\u677e\u5f1b\uff0c\u63d0\u4f9b\u6bd4\u7ebf\u6027\u5316\u65b9\u6cd5\u66f4\u597d\u7684\u8fd1\u4f3c\u3002", "motivation": "\u52a8\u673a\u662f\u514b\u670d\u4fdd\u5b88\u7ebf\u6027\u5316\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u63d0\u9ad8\u975e\u7ebf\u6027\u51fd\u6570\u7684\u53ef\u8fbe\u6027\u5206\u6790\u51c6\u786e\u6027\u3002", "method": "\u65b9\u6cd5\u662f\u5c06\u7ea6\u675f\u533a\u57df\uff08CZs\uff09\u4e0e\u56e0\u5b50\u8868\u793a\u7684\u591a\u9762\u4f53\u677e\u5f1b\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u51fd\u6570\u4f20\u64adCZs\uff0c\u800c\u975e\u4f7f\u7528\u4f20\u7edf\u7ebf\u6027\u5316\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u8ba1\u7b97\u53ef\u8fbe\u96c6\u6709\u663e\u8457\u6539\u8fdb\uff0c\u6570\u503c\u4f8b\u5b50\u9a8c\u8bc1\u4e86\u5176\u4f18\u52bf\u3002", "conclusion": "\u7ed3\u8bba\u662f\u65b0\u7b97\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709CZ\u65b9\u6cd5\u3002"}}
{"id": "2504.11741", "pdf": "https://arxiv.org/pdf/2504.11741", "abs": "https://arxiv.org/abs/2504.11741", "authors": ["Yiyou Sun", "Georgia Zhou", "Hao Wang", "Dacheng Li", "Nouha Dziri", "Dawn Song"], "title": "Climbing the Ladder of Reasoning: What LLMs Can-and Still Can't-Solve after SFT?", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent supervised fine-tuning (SFT) approaches have significantly improved\nlanguage models' performance on mathematical reasoning tasks, even when models\nare trained at a small scale. However, the specific capabilities enhanced\nthrough such fine-tuning remain poorly understood. In this paper, we conduct a\ndetailed analysis of model performance on the AIME24 dataset to understand how\nreasoning capabilities evolve. We discover a ladder-like structure in problem\ndifficulty, categorize questions into four tiers (Easy, Medium, Hard, and\nExtremely Hard (Exh)), and identify the specific requirements for advancing\nbetween tiers. We find that progression from Easy to Medium tier requires\nadopting an R1 reasoning style with minimal SFT (500-1K instances), while\nHard-level questions suffer from frequent model's errors at each step of the\nreasoning chain, with accuracy plateauing at around 65% despite logarithmic\nscaling. Exh-level questions present a fundamentally different challenge; they\nrequire unconventional problem-solving skills that current models uniformly\nstruggle with. Additional findings reveal that carefully curated small-scale\ndatasets offer limited advantage-scaling dataset size proves far more\neffective. Our analysis provides a clearer roadmap for advancing language model\ncapabilities in mathematical reasoning.", "AI": {"tldr": "\u672c\u8bba\u6587\u5206\u6790\u4e86\u76d1\u7763\u5fae\u8c03\u5982\u4f55\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u95ee\u9898\u96be\u5ea6\u9636\u68af\u7ed3\u6784\uff0c\u5e76\u5f3a\u8c03\u6570\u636e\u96c6\u89c4\u6a21\u6269\u5c55\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u6700\u8fd1\u76d1\u7763\u5fae\u8c03\u663e\u8457\u63d0\u9ad8\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4f46\u5177\u4f53\u80fd\u529b\u63d0\u5347\u673a\u5236\u4e0d\u6e05\u695a\uff0c\u56e0\u6b64\u9700\u8981\u6df1\u5165\u5206\u6790\u63a8\u7406\u80fd\u529b\u7684\u6f14\u53d8\u3002", "method": "\u5728AIME24\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8be6\u7ec6\u5206\u6790\uff0c\u5c06\u95ee\u9898\u5206\u4e3a\u6613\u3001\u4e2d\u3001\u96be\u548c\u6781\u96be\u56db\u4e2a\u7b49\u7ea7\uff0c\u8bc6\u522b\u4e0d\u540c\u7b49\u7ea7\u4e4b\u95f4\u7684\u63a8\u7406\u8981\u6c42\u548c\u9519\u8bef\u7c7b\u578b\u3002", "result": "\u53d1\u73b0\u4ece\u6613\u5230\u4e2d\u7ea7\u9700\u8981R1\u63a8\u7406\u98ce\u683c\uff0c\u96be\u7ea7\u95ee\u9898\u63a8\u7406\u94fe\u9519\u8bef\u9891\u53d1\u51c6\u786e\u7387\u505c\u6ede\u572865%\uff0c\u6781\u96be\u95ee\u9898\u9700\u975e\u5e38\u89c4\u6280\u80fd\uff1b\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u4f18\u5316\u6709\u9650\uff0c\u89c4\u6a21\u6269\u5c55\u66f4\u6709\u6548\u3002", "conclusion": "\u4e3a\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u7684\u6539\u8fdb\u8def\u7ebf\u56fe\u3002"}}
{"id": "2504.11521", "pdf": "https://arxiv.org/pdf/2504.11521", "abs": "https://arxiv.org/abs/2504.11521", "authors": ["Wei-Jer Chang", "Wei Zhan", "Masayoshi Tomizuka", "Manmohan Chandraker", "Francesco Pittaluga"], "title": "LANGTRAJ: Diffusion Model and Dataset for Language-Conditioned Trajectory Simulation", "categories": ["cs.LG", "cs.RO", "I.2.9; I.2.6"], "comment": "Dataset and project website in preparation", "summary": "Evaluating autonomous vehicles with controllability enables scalable testing\nin counterfactual or structured settings, enhancing both efficiency and safety.\nWe introduce LangTraj, a language-conditioned scene-diffusion model that\nsimulates the joint behavior of all agents in traffic scenarios. By\nconditioning on natural language inputs, LangTraj provides flexible and\nintuitive control over interactive behaviors, generating nuanced and realistic\nscenarios. Unlike prior approaches that depend on domain-specific guidance\nfunctions, LangTraj incorporates language conditioning during training,\nfacilitating more intuitive traffic simulation control. We propose a novel\nclosed-loop training strategy for diffusion models, explicitly tailored to\nenhance stability and realism during closed-loop simulation. To support\nlanguage-conditioned simulation, we develop Inter-Drive, a large-scale dataset\nwith diverse and interactive labels for training language-conditioned diffusion\nmodels. Our dataset is built upon a scalable pipeline for annotating\nagent-agent interactions and single-agent behaviors, ensuring rich and varied\nsupervision. Validated on the Waymo Motion Dataset, LangTraj demonstrates\nstrong performance in realism, language controllability, and\nlanguage-conditioned safety-critical simulation, establishing a new paradigm\nfor flexible and scalable autonomous vehicle testing.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86LangTraj\uff0c\u4e00\u4e2a\u8bed\u8a00\u6761\u4ef6\u573a\u666f\u6269\u6563\u6a21\u578b\uff0c\u7528\u4e8e\u81ea\u6cbb\u8f66\u8f86\u6d4b\u8bd5\u7684\u6a21\u62df\uff0c\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u7279\u5b9a\u9886\u57df\u6307\u5bfc\u51fd\u6570\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u8bed\u8a00\u6761\u4ef6\u63a7\u5236\u5b9e\u73b0\u66f4\u9ad8\u6548\u3001\u5b89\u5168\u7684\u81ea\u6cbb\u8f66\u8f86\u6d4b\u8bd5\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5f00\u53d1LangTraj\u6a21\u578b\u3001\u63d0\u51fa\u95ed\u73af\u8bad\u7ec3\u7b56\u7565\u548c\u6784\u5efaInter-Drive\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bed\u8a00\u6761\u4ef6\u4e0b\u7684\u4ea4\u901a\u573a\u666f\u6a21\u62df\u3002", "result": "\u7ed3\u679c\u663e\u793aLangTraj\u5728Waymo Motion Dataset\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u9ad8\u73b0\u5b9e\u6027\u3001\u8bed\u8a00\u53ef\u63a7\u6027\u548c\u5b89\u5168\u5173\u952e\u6a21\u62df\u6027\u80fd\u3002", "conclusion": "\u7ed3\u8bba\u662fLangTraj\u5efa\u7acb\u4e86\u81ea\u6cbb\u8f66\u8f86\u6d4b\u8bd5\u7684\u65b0\u7684\u7075\u6d3b\u53ef\u6269\u5c55\u8303\u5f0f\u3002"}}
{"id": "2504.11665", "pdf": "https://arxiv.org/pdf/2504.11665", "abs": "https://arxiv.org/abs/2504.11665", "authors": ["Ryan Greenough", "Kohei Murakami", "Jan Kleissl", "Adil Khurram"], "title": "Optimal SVI-Weighted PSPS Decisions with Decision-Dependent Outage Uncertainty", "categories": ["eess.SY", "cs.SY", "math.OC"], "comment": "10 pages, 7 figures, and 3 tables", "summary": "Public Safety Power Shutoffs (PSPS) are a pre-emptive strategy to mitigate\nthe wildfires caused by power system malfunction. System operators implement\nPSPS to balance wildfire mitigation efforts through de-energization of\ntransmission lines against the risk of widespread blackouts modeled with load\nshedding.\n  Existing approaches do not incorporate decision-dependent wildfire-driven\nfailure probabilities, as modeling outage scenario probabilities requires\nincorporating high-order polynomial terms in the objective. This paper uses\ndistribution shaping to develop an efficient MILP problem representation of the\ndistributionally robust PSPS problem. Building upon the author's prior work,\nthe wildfire risk of operating a transmission line is a function of the\nprobability of a wildfire-driven outage and its subsequent expected impact in\nacres burned.\n  A day-ahead unit commitment and line de-energization PSPS framework is used\nto assess the trade-off between total cost and wildfire risk at different\nlevels of distributional robustness, parameterized by a level of distributional\ndissimilarity $\\kappa$. We perform simulations on the IEEE RTS 24-bus test\nsystem.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u516c\u5171\u5b89\u5168\u7535\u529b\u5173\u95ed\uff08PSPS\uff09\uff0c\u4ee5\u5e73\u8861\u91ce\u706b\u98ce\u9669\u548c\u505c\u7535\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u672a\u8003\u8651\u51b3\u7b56\u76f8\u5173\u7684\u91ce\u706b\u9a71\u52a8\u6545\u969c\u6982\u7387\uff0c\u5bfc\u81f4\u5efa\u6a21\u590d\u6742\u548c\u9ad8\u9636\u591a\u9879\u5f0f\u9879\u3002", "method": "\u4f7f\u7528\u5206\u5e03\u6574\u5f62\u6280\u672f\u5f00\u53d1\u9ad8\u6548\u7684MILP\u95ee\u9898\u8868\u793a\uff0c\u5e76\u57fa\u4e8e\u4f5c\u8005\u5148\u524d\u5de5\u4f5c\u6784\u5efa\u91ce\u706b\u98ce\u9669\u6a21\u578b\uff0c\u91c7\u7528\u65e5ahead\u5355\u4f4d\u627f\u8bfa\u548c\u7ebf\u8def\u53bb\u80fd\u5316\u6846\u67b6\u3002", "result": "\u5728IEEE RTS 24-bus\u6d4b\u8bd5\u7cfb\u7edf\u4e2d\u8fdb\u884c\u6a21\u62df\uff0c\u8bc4\u4f30\u4e0d\u540c\u5206\u5e03\u9c81\u68d2\u6027\u6c34\u5e73\u4e0b\u603b\u6210\u672c\u548c\u91ce\u706b\u98ce\u9669\u7684\u6743\u8861\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5730\u89e3\u51b3\u4e86PSPS\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u98ce\u9669\u7ba1\u7406\u7b56\u7565\u7684trade-off\u3002"}}
{"id": "2504.11765", "pdf": "https://arxiv.org/pdf/2504.11765", "abs": "https://arxiv.org/abs/2504.11765", "authors": ["Hyungwoo Lee", "Kihyun Kim", "Jinwoo Kim", "Jungmin So", "Myung-Hoon Cha", "Hong-Yeon Kim", "James J. Kim", "Youngjae Kim"], "title": "Shared Disk KV Cache Management for Efficient Multi-Instance Inference in RAG-Powered LLMs", "categories": ["cs.AI"], "comment": null, "summary": "Recent large language models (LLMs) face increasing inference latency as\ninput context length and model size continue to grow. In particular, the\nretrieval-augmented generation (RAG) technique, which enhances LLM responses by\nincorporating external knowledge, exacerbates this issue by significantly\nincreasing the number of input tokens. This expansion in token length leads to\na substantial rise in computational overhead, particularly during the prefill\nstage, resulting in prolonged time-to-first-token (TTFT). To address this\nissue, this paper proposes a method to reduce TTFT by leveraging a disk-based\nkey-value (KV) cache to lessen the computational burden during the prefill\nstage. We also introduce a disk-based shared KV cache management system, called\nShared RAG-DCache, for multi-instance LLM RAG service environments. This\nsystem, together with an optimal system configuration, improves both throughput\nand latency under given resource constraints. Shared RAG-DCache exploits the\nlocality of documents related to user queries in RAG, as well as the queueing\ndelay in LLM inference services. It proactively generates and stores disk KV\ncaches for query-related documents and shares them across multiple LLM\ninstances to enhance inference performance. In experiments on a single host\nequipped with 2 GPUs and 1 CPU, Shared RAG-DCache achieved a 15~71% increase in\nthroughput and up to a 12~65% reduction in latency, depending on the resource\nconfiguration.", "AI": {"tldr": "\u7b80\u800c\u8a00\u4e4b\uff0c\u672c\u6587\u63d0\u51faShared RAG-DCache\u7cfb\u7edf\uff0c\u901a\u8fc7\u78c1\u76d8-based KV\u7f13\u5b58\u51cf\u5c11\u5927\u8bed\u8a00\u6a21\u578bRAG\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u5165\u957f\u5ea6\u548c\u6a21\u578b\u5927\u5c0f\u589e\u957f\u5bfc\u81f4\u7684\u63a8\u7406\u5ef6\u8fdf\u589e\u52a0\uff0c\u7279\u522b\u662fRAG\u6280\u672f\u52a0\u5267\u4e86token\u6570\u91cf\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u65b9\u6cd5\u662f\u4f7f\u7528\u78c1\u76d8-based KV\u7f13\u5b58\u51cf\u8f7b\u9884\u586b\u5145\u9636\u6bb5\u8d1f\u62c5\uff0c\u5e76\u5f15\u5165Shared RAG-DCache\u7cfb\u7edf\uff0c\u5728\u591a\u5b9e\u4f8b\u73af\u5883\u4e2d\u7ba1\u7406\u5171\u4eab\u7f13\u5b58\uff0c\u5229\u7528\u67e5\u8be2\u5c40\u90e8\u6027\u548c\u6392\u961f\u5ef6\u8fdf\u3002", "result": "\u7ed3\u679c\u662f\u57282 GPU\u548c1 CPU\u4e3b\u673a\u4e0a\uff0c\u541e\u5410\u91cf\u63d0\u9ad815~71%\uff0c\u5ef6\u8fdf\u51cf\u5c1112~65%\uff0c\u53d6\u51b3\u4e8e\u8d44\u6e90\u914d\u7f6e\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u8be5\u7cfb\u7edf\u5728\u8d44\u6e90\u7ea6\u675f\u4e0b\u63d0\u5347\u4e86\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u6027\u80fd\u3002"}}
{"id": "2504.11558", "pdf": "https://arxiv.org/pdf/2504.11558", "abs": "https://arxiv.org/abs/2504.11558", "authors": ["Mete Erdogan", "Cengiz Pehlevan", "Alper T. Erdogan"], "title": "Error Broadcast and Decorrelation as a Potential Artificial and Natural Learning Mechanism", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce the Error Broadcast and Decorrelation (EBD) algorithm, a novel\nlearning framework that addresses the credit assignment problem in neural\nnetworks by directly broadcasting output error to individual layers. Leveraging\nthe stochastic orthogonality property of the optimal minimum mean square error\n(MMSE) estimator, EBD defines layerwise loss functions to penalize correlations\nbetween layer activations and output errors, offering a principled approach to\nerror broadcasting without the need for weight transport. The optimization\nframework naturally leads to the experimentally observed three-factor learning\nrule and integrates with biologically plausible frameworks to enhance\nperformance and plausibility. Numerical experiments demonstrate that EBD\nachieves performance comparable to or better than known error-broadcast methods\non benchmark datasets. While the scalability of EBD to very large or complex\ndatasets remains to be further explored, our findings suggest it provides a\nbiologically plausible, efficient, and adaptable alternative for neural network\ntraining. This approach could inform future advancements in artificial and\nnatural learning paradigms.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165EBD\u7b97\u6cd5\uff0c\u901a\u8fc7\u5e7f\u64ad\u8f93\u51fa\u9519\u8bef\u5230\u5404\u5c42\u89e3\u51b3\u795e\u7ecf\u7f51\u7edc\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u5e76\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u89e3\u51b3\u795e\u7ecf\u7f51\u7edc\u4e2d\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u79cd\u65e0\u9700\u6743\u91cd\u4f20\u8f93\u7684\u3001\u57fa\u4e8e\u6700\u5c0f\u5747\u65b9\u8bef\u5dee\u4f30\u8ba1\u5668\u7684\u9519\u8bef\u5e7f\u64ad\u65b9\u6cd5\u3002", "method": "\u5f15\u5165EBD\u7b97\u6cd5\uff0c\u5229\u7528\u968f\u673a\u6b63\u4ea4\u6027\u5b9a\u4e49\u5c42\u7ea7\u635f\u5931\u51fd\u6570\uff0c\u60e9\u7f5a\u5c42\u6fc0\u6d3b\u4e0e\u8f93\u51fa\u9519\u8bef\u7684\u76f8\u5173\u6027\uff0c\u5e76\u6574\u5408\u5230\u751f\u7269\u5b66\u5408\u7406\u7684\u6846\u67b6\u4e2d\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cEBD\u6027\u80fd\u4e0e\u5df2\u77e5\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u597d\uff0c\u5c55\u793a\u4e86\u5176\u9ad8\u6548\u548c\u9002\u5e94\u6027\u3002", "conclusion": "EBD\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u751f\u7269\u5b66\u5408\u7406\u7684\u3001\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u53ef\u80fd\u542f\u53d1\u672a\u6765\u4eba\u5de5\u548c\u81ea\u7136\u5b66\u4e60\u7684\u53d1\u5c55\u3002"}}
{"id": "2504.11797", "pdf": "https://arxiv.org/pdf/2504.11797", "abs": "https://arxiv.org/abs/2504.11797", "authors": ["Yongxin Xiong", "Heng Wu", "Yifei Li", "Xiongfei Wang"], "title": "Analysis of Power Swing Characteristics of Grid-Forming VSC System Considering the Current Limitation Mode", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "This paper investigates power swing characteristics of grid-forming voltage\nsource converter (GFM-VSC) systems considering the current limitation mode in\nboth non-inertial and inertial GFM-VSC systems. Following grid faults,\nnon-inertial GFM-VSC systems can re-synchronize with the grid but may\nexperience significant power swings driven by its control dynamics, while\ninertial GFM-VSC systems may exhibit loss of synchronization (LOS),\ncharacterized by the divergence of the output angle in the active power control\nloop. These behaviours are different from conventional synchronous generator\n(SG)-based systems, where power swings are typically characterized by physical\nangle deviations among power sources. Based on these findings, this paper\nexplores the performance of traditional impedance-based swing detection schemes\nin GFM-VSC systems. The theoretical analysis is validated through various\nsimulations using the PSCAD/EMTDC platform, covering both single and\nmulti-machine system scenarios.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u7f51\u683c\u5f62\u6210\u7535\u538b\u6e90\u8f6c\u6362\u5668\uff08GFM-VSC\uff09\u7cfb\u7edf\u7684\u529f\u7387\u6446\u52a8\u7279\u6027\uff0c\u8003\u8651\u7535\u6d41\u9650\u5236\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u4e86\u5176\u884c\u4e3a\u5dee\u5f02\u3002", "motivation": "\u52a8\u673a\u662f\u63a2\u8ba8GFM-VSC\u7cfb\u7edf\u5728\u7535\u7f51\u6545\u969c\u540e\u7684\u884c\u4e3a\u4e0e\u4f20\u7edf\u540c\u6b65\u53d1\u7535\u673a\u7cfb\u7edf\u7684\u5dee\u5f02\uff0c\u4ee5\u6539\u8fdb\u73b0\u4ee3\u7535\u529b\u7cfb\u7edf\u5206\u6790\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u7406\u8bba\u5206\u6790\u548c\u4f7f\u7528PSCAD/EMTDC\u5e73\u53f0\u7684\u6a21\u62df\uff0c\u6db5\u76d6\u5355\u673a\u548c\u591a\u673a\u7cfb\u7edf\u573a\u666f\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u975e\u60ef\u6027GFM-VSC\u7cfb\u7edf\u53ef\u80fd\u91cd\u65b0\u540c\u6b65\u4f46\u4f34\u968f\u663e\u8457\u529f\u7387\u6446\u52a8\uff0c\u60ef\u6027\u7cfb\u7edf\u53ef\u80fd\u5931\u53bb\u540c\u6b65\uff0c\u5e76\u8bc4\u4f30\u4e86\u4f20\u7edf\u963b\u6297-based\u6446\u52a8\u68c0\u6d4b\u65b9\u6848\u7684\u6027\u80fd\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u4e86\u9488\u5bf9GFM-VSC\u7cfb\u7edf\u7684\u6539\u8fdb\u6446\u52a8\u68c0\u6d4b\u65b9\u6848\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u9002\u5e94\u5176\u72ec\u7279\u52a8\u6001\u884c\u4e3a\u3002"}}
{"id": "2504.11792", "pdf": "https://arxiv.org/pdf/2504.11792", "abs": "https://arxiv.org/abs/2504.11792", "authors": ["Md Sultan Al Nahian", "Chris Delcher", "Daniel Harris", "Peter Akpunonu", "Ramakanth Kavuluru"], "title": "Large Language Models for Drug Overdose Prediction from Longitudinal Medical Records", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The ability to predict drug overdose risk from a patient's medical records is\ncrucial for timely intervention and prevention. Traditional machine learning\nmodels have shown promise in analyzing longitudinal medical records for this\ntask. However, recent advancements in large language models (LLMs) offer an\nopportunity to enhance prediction performance by leveraging their ability to\nprocess long textual data and their inherent prior knowledge across diverse\ntasks. In this study, we assess the effectiveness of Open AI's GPT-4o LLM in\npredicting drug overdose events using patients' longitudinal insurance claims\nrecords. We evaluate its performance in both fine-tuned and zero-shot settings,\ncomparing them to strong traditional machine learning methods as baselines. Our\nresults show that LLMs not only outperform traditional models in certain\nsettings but can also predict overdose risk in a zero-shot setting without\ntask-specific training. These findings highlight the potential of LLMs in\nclinical decision support, particularly for drug overdose risk prediction.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528GPT-4o\u9884\u6d4b\u836f\u7269\u8fc7\u91cf\u98ce\u9669\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u53ef\u96f6\u6837\u672c\u9884\u6d4b\u3002", "motivation": "\u9884\u6d4b\u836f\u7269\u8fc7\u91cf\u98ce\u9669\u5bf9\u53ca\u65f6\u5e72\u9884\u548c\u9884\u9632\u81f3\u5173\u91cd\u8981\uff0cLLM\u8fdb\u6b65\u53ef\u63d0\u5347\u6027\u80fd\u3002", "method": "\u8bc4\u4f30GPT-4o\u5728\u5fae\u8c03\u548c\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\uff0c\u4f7f\u7528\u60a3\u8005\u4fdd\u9669\u7d22\u8d54\u8bb0\u5f55\uff0c\u4e0e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6bd4\u8f83\u3002", "result": "LLM\u5728\u67d0\u4e9b\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\uff0c\u53ef\u96f6\u6837\u672c\u9884\u6d4b\u98ce\u9669\u3002", "conclusion": "\u7a81\u663eLLM\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u836f\u7269\u8fc7\u91cf\u98ce\u9669\u9884\u6d4b\u3002"}}
{"id": "2504.11581", "pdf": "https://arxiv.org/pdf/2504.11581", "abs": "https://arxiv.org/abs/2504.11581", "authors": ["Mert Sehri", "Igor Varej\u00e3o", "Zehui Hua", "Vitor Bonella", "Adriano Santos", "Francisco de Assis Boldt", "Patrick Dumond", "Flavio Miguel Varej\u00e3o"], "title": "Towards a Universal Vibration Analysis Dataset: A Framework for Transfer Learning in Predictive Maintenance and Structural Health Monitoring", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "ImageNet has become a reputable resource for transfer learning, allowing the\ndevelopment of efficient ML models with reduced training time and data\nrequirements. However, vibration analysis in predictive maintenance, structural\nhealth monitoring, and fault diagnosis, lacks a comparable large-scale,\nannotated dataset to facilitate similar advancements. To address this, a\ndataset framework is proposed that begins with bearing vibration data as an\ninitial step towards creating a universal dataset for vibration-based\nspectrogram analysis for all machinery. The initial framework includes a\ncollection of bearing vibration signals from various publicly available\ndatasets. To demonstrate the advantages of this framework, experiments were\nconducted using a deep learning architecture, showing improvements in model\nperformance when pre-trained on bearing vibration data and fine-tuned on a\nsmaller, domain-specific dataset. These findings highlight the potential to\nparallel the success of ImageNet in visual computing but for vibration\nanalysis. For future work, this research will include a broader range of\nvibration signals from multiple types of machinery, emphasizing\nspectrogram-based representations of the data. Each sample will be labeled\naccording to machinery type, operational status, and the presence or type of\nfaults, ensuring its utility for supervised and unsupervised learning tasks.\nAdditionally, a framework for data preprocessing, feature extraction, and model\ntraining specific to vibration data will be developed. This framework will\nstandardize methodologies across the research community, allowing for\ncollaboration and accelerating progress in predictive maintenance, structural\nhealth monitoring, and related fields. By mirroring the success of ImageNet in\nvisual computing, this dataset has the potential to improve the development of\nintelligent systems in industrial applications.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u632f\u52a8\u5206\u6790\u6570\u636e\u96c6\u6846\u67b6\uff0c\u7c7b\u4f3c\u4e8eImageNet\uff0c\u7528\u4e8e\u63d0\u5347\u673a\u5668\u6545\u969c\u8bca\u65ad\u7b49\u9886\u57df\u7684\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u632f\u52a8\u5206\u6790\u9886\u57df\u7f3a\u4e4f\u5927\u578b\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u5bfc\u81f4\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u4f4e\u4e0b\uff0c\u65e0\u6cd5\u50cfImageNet\u4e00\u6837\u4fc3\u8fdb\u8f6c\u79fb\u5b66\u4e60\u3002", "method": "\u63d0\u51fa\u4ee5\u8f74\u627f\u632f\u52a8\u6570\u636e\u4e3a\u57fa\u7840\u7684\u6846\u67b6\uff0c\u4ece\u516c\u5f00\u6570\u636e\u96c6\u6536\u96c6\u4fe1\u53f7\uff0c\u5e76\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u540e\uff0c\u6a21\u578b\u6027\u80fd\u5f97\u5230\u6539\u5584\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6f5c\u529b\u63a8\u52a8\u632f\u52a8\u5206\u6790\u9886\u57df\u53d1\u5c55\uff0c\u672a\u6765\u5c06\u6269\u5c55\u5230\u66f4\u591a\u673a\u68b0\u7c7b\u578b\uff0c\u5e76\u6807\u51c6\u5316\u6570\u636e\u5904\u7406\u65b9\u6cd5\u3002"}}
{"id": "2504.11959", "pdf": "https://arxiv.org/pdf/2504.11959", "abs": "https://arxiv.org/abs/2504.11959", "authors": ["Joachim Deutscher", "Tarik Enderes"], "title": "A Koopman Operator Approach to Data-Driven Control of Semilinear Parabolic Systems", "categories": ["eess.SY", "cs.SY"], "comment": "8 pages, 3 figures", "summary": "This paper is concerned with the data-driven stabilization of unknown\nboundary controlled semilinear parabolic systems. The nonlinear dynamics of the\nsystem are lifted using a finite number of eigenfunctionals of the Koopman\noperator related to the autonomous semilinear PDE. This results in a novel\ndata-driven finite-dimensional model of the lifted dynamics, which is amenable\nto apply design procedures for finite-dimensional systems to stabilize the\nsemilinear parabolic system. In order to facilitate this, a bilinearization of\nthe lifted dynamics is considered and feedback linearization is applied for the\ndata-driven stabilization of the semilinear parabolic PDE. This reveals a novel\nconnection between the assignment of eigenfunctionals to the closed-loop\nKoopman operator and feedback linearization. By making use of a modal\nrepresentation, exponential stability of the closed-loop system in the presence\nof errors resulting from the data-driven computation of eigenfunctionals and\nthe bilinearization is verified. The data-driven controller directly follows\nfrom applying generalized eDMD to state data available for the semilinear\nparabolic PDE. An example of an unstable semilinear reaction-diffusion system\nwith finite-time blow up demonstrates the novel data-driven stabilization\napproach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7a33\u5b9a\u672a\u77e5\u8fb9\u754c\u63a7\u5236\u7684\u534a\u7ebf\u6027\u629b\u7269\u7ebf\u7cfb\u7edf\uff0c\u901a\u8fc7Koopman\u7b97\u5b50\u7279\u5f81\u6cdb\u51fd\u63d0\u5347\u52a8\u529b\u5b66\uff0c\u521b\u5efa\u6709\u9650\u7ef4\u6a21\u578b\uff0c\u5e76\u5e94\u7528\u53cd\u9988\u7ebf\u6027\u5316\u3002", "motivation": "\u4e3a\u4e86\u5904\u7406\u672a\u77e5\u52a8\u529b\u5b66\u7684\u534a\u7ebf\u6027\u629b\u7269\u7ebf\u7cfb\u7edf\uff0c\u4f7f\u7528\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u514b\u670d\u975e\u7ebf\u6027\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528Koopman\u7b97\u5b50\u7279\u5f81\u6cdb\u51fd\u63d0\u5347\u7cfb\u7edf\u52a8\u529b\u5b66\uff0c\u8fdb\u884c\u53cc\u7ebf\u6027\u5316\uff0c\u5e94\u7528\u53cd\u9988\u7ebf\u6027\u5316\uff0c\u5e76\u901a\u8fc7\u5e7f\u4e49eDMD\u57fa\u4e8e\u72b6\u6001\u6570\u636e\u8bbe\u8ba1\u63a7\u5236\u5668\u3002", "result": "\u9a8c\u8bc1\u4e86\u95ed\u73af\u7cfb\u7edf\u5728\u8ba1\u7b97\u8bef\u5dee\u4e0b\u7684\u6307\u6570\u7a33\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u4e0d\u7a33\u5b9a\u53cd\u5e94-\u6269\u6563\u7cfb\u7edf\u793a\u4f8b\u6f14\u793a\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u6210\u529f\u7a33\u5b9a\u4e86\u7cfb\u7edf\uff0c\u5e76\u63ed\u793a\u4e86\u7279\u5f81\u6cdb\u51fd\u5206\u914d\u4e0e\u53cd\u9988\u7ebf\u6027\u5316\u4e4b\u95f4\u7684\u5168\u65b0\u8054\u7cfb\u3002"}}
{"id": "2504.11844", "pdf": "https://arxiv.org/pdf/2504.11844", "abs": "https://arxiv.org/abs/2504.11844", "authors": ["Tom Everitt", "Cristina Garbacea", "Alexis Bellot", "Jonathan Richens", "Henry Papadatos", "Sim\u00e9on Campos", "Rohin Shah"], "title": "Evaluating the Goal-Directedness of Large Language Models", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "To what extent do LLMs use their capabilities towards their given goal? We\ntake this as a measure of their goal-directedness. We evaluate\ngoal-directedness on tasks that require information gathering, cognitive\neffort, and plan execution, where we use subtasks to infer each model's\nrelevant capabilities. Our evaluations of LLMs from Google DeepMind, OpenAI,\nand Anthropic show that goal-directedness is relatively consistent across\ntasks, differs from task performance, and is only moderately sensitive to\nmotivational prompts. Notably, most models are not fully goal-directed. We hope\nour goal-directedness evaluations will enable better monitoring of LLM\nprogress, and enable more deliberate design choices of agentic properties in\nLLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u76ee\u6807\u5bfc\u5411\u6027\uff0c\u53d1\u73b0\u5b83\u5728\u4efb\u52a1\u95f4\u76f8\u5bf9\u4e00\u81f4\uff0c\u4f46\u5927\u591a\u6570\u6a21\u578b\u672a\u5b8c\u5168\u76ee\u6807\u5bfc\u5411\uff0c\u5e76\u5efa\u8bae\u7528\u4e8e\u76d1\u63a7\u548c\u8bbe\u8ba1\u3002", "motivation": "\u8bc4\u4f30LLMs\u5728\u7ed9\u5b9a\u76ee\u6807\u4e0b\u4f7f\u7528\u80fd\u529b\u7684\u7a0b\u5ea6\uff0c\u4ee5\u66f4\u597d\u5730\u76d1\u63a7\u5176\u8fdb\u5c55\u548c deliberate \u8bbe\u8ba1\u4ee3\u7406\u5c5e\u6027\u3002", "method": "\u901a\u8fc7\u6d89\u53ca\u4fe1\u606f\u6536\u96c6\u3001\u8ba4\u77e5\u52aa\u529b\u548c\u8ba1\u5212\u6267\u884c\u7684\u4efb\u52a1\uff0c\u4f7f\u7528\u5b50\u4efb\u52a1\u63a8\u65ad\u6a21\u578b\u80fd\u529b\uff0c\u5bf9Google DeepMind\u3001OpenAI\u548cAnthropic\u7684LLMs\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u76ee\u6807\u5bfc\u5411\u6027\u5728\u4efb\u52a1\u95f4\u76f8\u5bf9\u4e00\u81f4\uff0c\u4e0e\u4efb\u52a1\u6027\u80fd\u4e0d\u540c\uff0c\u5bf9\u6fc0\u52b1\u63d0\u793a\u4ec5 moderately \u654f\u611f\uff0c\u4e14\u5927\u591a\u6570\u6a21\u578b\u672a\u5b8c\u5168\u76ee\u6807\u5bfc\u5411\u3002", "conclusion": "\u5e0c\u671b\u8fd9\u79cd\u76ee\u6807\u5bfc\u5411\u6027\u8bc4\u4f30\u80fd\u63d0\u5347LLM\u8fdb\u5c55\u7684\u76d1\u63a7\u548c\u4ee3\u7406\u5c5e\u6027\u7684 deliberate \u8bbe\u8ba1\u3002"}}
{"id": "2504.11601", "pdf": "https://arxiv.org/pdf/2504.11601", "abs": "https://arxiv.org/abs/2504.11601", "authors": ["Bruno Giorgio"], "title": "Dueling Deep Reinforcement Learning for Financial Time Series", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) has emerged as a powerful paradigm for solving\ndecision-making problems in dynamic environments. In this research, we explore\nthe application of Double DQN (DDQN) and Dueling Network Architectures, to\nfinancial trading tasks using historical SP500 index data. Our focus is\ntraining agents capable of optimizing trading strategies while accounting for\npractical constraints such as transaction costs. The study evaluates the model\nperformance across scenarios with and without commissions, highlighting the\nimpact of cost-sensitive environments on reward dynamics. Despite computational\nlimitations and the inherent complexity of financial time series data, the\nagent successfully learned meaningful trading policies. The findings confirm\nthat RL agents, even when trained on limited datasets, can outperform random\nstrategies by leveraging advanced architectures such as DDQN and Dueling\nNetworks. However, significant challenges persist, particularly with a\nsub-optimal policy due to the complexity of data source.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4f7f\u7528Double DQN\u548cDueling Network\u67b6\u6784\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u91d1\u878d\u4ea4\u6613\u4e2d\u7684\u5e94\u7528\uff0c\u57fa\u4e8eSP500\u6570\u636e\uff0c\u8003\u8651\u4ea4\u6613\u6210\u672c\uff0c\u53d1\u73b0RL\u4ee3\u7406\u80fd\u4f18\u4e8e\u968f\u673a\u7b56\u7565\u4f46\u9762\u4e34\u6311\u6218\u3002", "motivation": "\u52a8\u673a\u662f\u5e94\u7528RL\u4f18\u5316\u91d1\u878d\u4ea4\u6613\u7b56\u7565\uff0c\u5904\u7406\u52a8\u6001\u73af\u5883\u548c\u5b9e\u9645\u7ea6\u675f\u5982\u4ea4\u6613\u6210\u672c\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528DDQN\u548cDueling Network\u67b6\u6784\uff0c\u8bad\u7ec3\u4ee3\u7406\u5728\u5386\u53f2SP500\u6307\u6570\u6570\u636e\u4e0a\uff0c\u8bc4\u4f30\u6709\u65e0\u4f63\u91d1\u573a\u666f\u7684\u6027\u80fd\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4ee3\u7406\u5b66\u4f1a\u4e86\u6709\u6548\u7684\u4ea4\u6613\u653f\u7b56\uff0c\u4f18\u4e8e\u968f\u673a\u7b56\u7565\uff0c\u4f46\u6570\u636e\u590d\u6742\u6027\u5bfc\u81f4\u653f\u7b56\u53ef\u80fd\u6b21\u4f18\u3002", "conclusion": "\u7ed3\u8bba\u662fRL\u4ee3\u7406\u5728\u4f7f\u7528\u9ad8\u7ea7\u67b6\u6784\u65f6\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u91d1\u878d\u6570\u636e\u590d\u6742\u6027\u5e26\u6765\u7684\u6311\u6218\u4ecd\u5b58\u5728\u3002"}}
{"id": "2504.12015", "pdf": "https://arxiv.org/pdf/2504.12015", "abs": "https://arxiv.org/abs/2504.12015", "authors": ["Peter A. Hoeher", "Yang Leng", "Maximilian Mewis", "Rongwu Zhu"], "title": "Power Line Communication vs. Talkative Power Conversion: A Benchmarking Study", "categories": ["eess.SY", "cs.SY"], "comment": "6 pages, 4 figures, 2 tables", "summary": "The convergence of energy transmission and data communication has become a\nkey feature of decentralized energy systems across a broad spectrum of\nvoltage/power ranges, including smart grid applications and cyber-physical\npower systems. This paper compares two distinct approaches: Power Line\nCommunications (PLC) and Talkative Power Conversion (TPC). While PLC leverages\nexisting power infrastructure for data transmission by using external data\ntransmitters and receivers, TPC integrates communication capabilities directly\ninto power electronic converters. We present their technical foundations and\napplications, benchmark their strengths and bottlenecks, and outline future\nresearch directions regarding TPC that could bridge the gap between power and\ncommunication technologies.", "AI": {"tldr": "This paper compares Power Line Communications (PLC) and Talkative Power Conversion (TPC) for data communication in energy systems, highlighting their strengths, weaknesses, and future research directions.", "motivation": "To address the convergence of energy transmission and data communication in decentralized energy systems by comparing PLC and TPC approaches.", "method": "Comparison of technical foundations, applications, and benchmarking of strengths and bottlenecks between PLC and TPC.", "result": "Identification of strengths and bottlenecks of PLC and TPC, and outlining future research directions for TPC to integrate power and communication technologies.", "conclusion": "TPC has potential to bridge the gap between power and communication technologies, with suggestions for future research."}}
{"id": "2504.11864", "pdf": "https://arxiv.org/pdf/2504.11864", "abs": "https://arxiv.org/abs/2504.11864", "authors": ["J. Piatek", "M. W. Przewozniczek", "F. Chicano", "R. Tin\u00f3s"], "title": "Moving between high-quality optima using multi-satisfiability characteristics in hard-to-solve Max3Sat instances", "categories": ["cs.AI"], "comment": null, "summary": "Gray-box optimization proposes effective and efficient optimizers of general\nuse. To this end, it leverages information about variable dependencies and the\nsubfunction-based problem representation. These approaches were already shown\neffective by enabling \\textit{tunnelling} between local optima even if these\nmoves require the modification of many dependent variables. Tunnelling is\nuseful in solving the maximum satisfiability problem (MaxSat), which can be\nreformulated to Max3Sat. Since many real-world problems can be brought to\nsolving the MaxSat/Max3Sat instances, it is important to solve them effectively\nand efficiently. Therefore, we focus on Max3Sat instances for which tunnelling\nfails to introduce improving moves between locally optimal high-quality\nsolutions and the region of globally optimal solutions. We analyze the features\nof such instances on the ground of phase transitions. Based on these\nobservations, we propose manipulating clause-satisfiability characteristics\nthat allow connecting high-quality solutions distant in the solution space. We\nutilize multi-satisfiability characteristics in the optimizer built from\ntypical gray-box mechanisms. The experimental study shows that the proposed\noptimizer can solve those Max3Sat instances that are out of the grasp of\nstate-of-the-art gray-box optimizers. At the same time, it remains effective\nfor instances that have already been successfully solved by gray-box.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6539\u8fdb\u7070\u7bb1\u4f18\u5316\u65b9\u6cd5\uff0c\u9488\u5bf9Max3Sat\u95ee\u9898\u4e2d\u96a7\u9053\u5931\u8d25\u7684\u5b9e\u4f8b\uff0c\u901a\u8fc7\u64cd\u7eb5\u5b50\u53e5\u53ef\u6ee1\u8db3\u6027\u7279\u5f81\u63d0\u5347\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u8bb8\u591a\u73b0\u5b9e\u95ee\u9898\u53ef\u8f6c\u5316\u4e3aMaxSat/Max3Sat\u5b9e\u4f8b\uff0c\u9700\u8981\u9ad8\u6548\u6c42\u89e3\uff1b\u73b0\u6709\u96a7\u9053\u6280\u672f\u5728\u67d0\u4e9b\u9ad8\u8d28\u5c40\u90e8\u6700\u4f18\u89e3\u95f4\u5931\u6548\u3002", "method": "\u57fa\u4e8e\u76f8\u53d8\u5206\u6790\uff0c\u64cd\u7eb5\u5b50\u53e5\u53ef\u6ee1\u8db3\u6027\u548c\u591a\u6ee1\u8db3\u6027\u7279\u5f81\uff0c\u6784\u5efa\u7070\u7bb1\u4f18\u5316\u5668\u4ee5\u8fde\u63a5\u89e3\u7a7a\u95f4\u4e2d\u9065\u8fdc\u7684\u9ad8\u8d28\u89e3\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u65b0\u4f18\u5316\u5668\u80fd\u89e3\u51b3\u73b0\u6709\u7070\u7bb1\u4f18\u5316\u5668\u65e0\u6cd5\u5904\u7406\u7684Max3Sat\u5b9e\u4f8b\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u5df2\u53ef\u89e3\u51b3\u5b9e\u4f8b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u7070\u7bb1\u4f18\u5316\u5728Max3Sat\u95ee\u9898\u4e0a\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\uff0c\u5c24\u5176\u5728\u96a7\u9053\u5931\u8d25\u7684\u573a\u666f\u4e2d\u3002"}}
{"id": "2504.11623", "pdf": "https://arxiv.org/pdf/2504.11623", "abs": "https://arxiv.org/abs/2504.11623", "authors": ["Jinsung Jeon", "Jaehyeon Park", "Sewon Park", "Jeongwhan Choi", "Minjung Kim", "Noseong Park"], "title": "Possibility for Proactive Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICLR 2025 I Can't Believe It's Not Better: Challenges in\n  Applied Deep Learning Workshop (ICBINB)", "summary": "Time-series anomaly detection, which detects errors and failures in a\nworkflow, is one of the most important topics in real-world applications. The\npurpose of time-series anomaly detection is to reduce potential damages or\nlosses. However, existing anomaly detection models detect anomalies through the\nerror between the model output and the ground truth (observed) value, which\nmakes them impractical. In this work, we present a \\textit{proactive} approach\nfor time-series anomaly detection based on a time-series forecasting model\nspecialized for anomaly detection and a data-driven anomaly detection model.\nOur proactive approach establishes an anomaly threshold from training data with\na data-driven anomaly detection model, and anomalies are subsequently detected\nby identifying predicted values that exceed the anomaly threshold. In addition,\nwe extensively evaluated the model using four anomaly detection benchmarks and\nanalyzed both predictable and unpredictable anomalies. We attached the source\ncode as supplementary material.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3b\u52a8\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u7528\u9884\u6d4b\u6a21\u578b\u548c\u9608\u503c\u6765\u68c0\u6d4b\u5f02\u5e38\u3002", "motivation": "\u73b0\u6709\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\u4f9d\u8d56\u8f93\u51fa\u4e0e\u771f\u5b9e\u503c\u7684\u8bef\u5dee\uff0c\u4e0d\u5b9e\u7528\uff1b\u672c\u7814\u7a76\u65e8\u5728\u51cf\u5c11\u6f5c\u5728\u635f\u5bb3\u3002", "method": "\u4f7f\u7528\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u548c\u6570\u636e\u9a71\u52a8\u6a21\u578b\u4ece\u8bad\u7ec3\u6570\u636e\u5efa\u7acb\u5f02\u5e38\u9608\u503c\uff0c\u7136\u540e\u901a\u8fc7\u9884\u6d4b\u503c\u8d85\u8fc7\u9608\u503c\u68c0\u6d4b\u5f02\u5e38\u3002", "result": "\u6a21\u578b\u5728\u56db\u4e2a\u57fa\u51c6\u4e0a\u8bc4\u4f30\uff0c\u5206\u6790\u4e86\u53ef\u9884\u6d4b\u548c\u4e0d\u53ef\u9884\u6d4b\u5f02\u5e38\u3002", "conclusion": "\u65b9\u6cd5\u66f4\u5b9e\u7528\uff0c\u5e76\u63d0\u4f9b\u6e90\u4ee3\u7801\u4ee5\u4f9b\u53c2\u8003\u3002"}}
{"id": "2504.12036", "pdf": "https://arxiv.org/pdf/2504.12036", "abs": "https://arxiv.org/abs/2504.12036", "authors": ["Felix Berkel", "Kim Peter Wabersich", "Hongxi Xiang", "Elias Milios"], "title": "Contract-based hierarchical control using predictive feasibility value functions", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "Today's control systems are often characterized by modularity and safety\nrequirements to handle complexity, resulting in hierarchical control\nstructures. Although hierarchical model predictive control offers favorable\nproperties, achieving a provably safe, yet modular design remains a challenge.\nThis paper introduces a contract-based hierarchical control strategy to improve\nthe performance of control systems facing challenges related to model\ninconsistency and independent controller design across hierarchies. We consider\na setup where a higher-level controller generates references that affect the\nconstraints of a lower-level controller, which is based on a soft-constrained\nMPC formulation. The optimal slack variables serve as the basis for a contract\nthat allows the higher-level controller to assess the feasibility of the\nreference trajectory without exact knowledge of the model, constraints, and\ncost of the lower-level controller. To ensure computational efficiency while\nmaintaining model confidentiality, we propose using an explicit function\napproximation, such as a neural network, to represent the cost of optimal slack\nvalues. The approach is tested for a hierarchical control setup consisting of a\nplanner and a motion controller as commonly found in autonomous driving.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5408\u540c\u7684\u5c42\u6b21\u63a7\u5236\u7b56\u7565\uff0c\u4ee5\u63d0\u5347\u6a21\u5757\u5316\u63a7\u5236\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u5b89\u5168\u6027\uff0c\u5e76\u5728\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2d\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5c42\u6b21\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u4e2d\u6a21\u578b\u4e0d\u4e00\u81f4\u548c\u63a7\u5236\u5668\u72ec\u7acb\u8bbe\u8ba1\u7b49\u6311\u6218\uff0c\u5b9e\u73b0\u53ef\u8bc1\u660e\u7684\u5b89\u5168\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\u3002", "method": "\u5f15\u5165\u5408\u540c\u673a\u5236\uff0c\u4f7f\u7528\u8f6f\u7ea6\u675fMPC\u7684\u6700\u4f18\u677e\u5f1b\u53d8\u91cf\uff0c\u9ad8\u5c42\u63a7\u5236\u5668\u751f\u6210\u53c2\u8003\u8f68\u8ff9\uff0c\u5e76\u91c7\u7528\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u663e\u5f0f\u51fd\u6570\u903c\u8fd1\u4ee5\u786e\u4fdd\u8ba1\u7b97\u6548\u7387\u548c\u6a21\u578b\u4fdd\u5bc6\u3002", "result": "\u65b9\u6cd5\u5728\u81ea\u52a8\u9a7e\u9a76\u7684\u89c4\u5212\u5668-\u8fd0\u52a8\u63a7\u5236\u5668\u8bbe\u7f6e\u4e2d\u9a8c\u8bc1\uff0c\u63d0\u9ad8\u4e86\u53c2\u8003\u8f68\u8ff9\u7684\u53ef\u884c\u6027\u8bc4\u4f30\uff0c\u65e0\u9700\u5b8c\u6574\u6a21\u578b\u77e5\u8bc6\u3002", "conclusion": "\u8be5\u7b56\u7565\u63d0\u5347\u4e86\u63a7\u5236\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u5b89\u5168\u6027\uff0c\u4fc3\u8fdb\u4e86\u6a21\u5757\u5316\u5c42\u6b21\u63a7\u5236\u7684\u8bbe\u8ba1\u3002"}}
{"id": "2504.11882", "pdf": "https://arxiv.org/pdf/2504.11882", "abs": "https://arxiv.org/abs/2504.11882", "authors": ["J. Maci\u0105\u017cek", "M. W. Przewozniczek", "J. Schwaab"], "title": "Seeking and leveraging alternative variable dependency concepts in gray-box-elusive bimodal land-use allocation problems", "categories": ["cs.AI"], "comment": null, "summary": "Solving land-use allocation problems can help us to deal with some of the\nmost urgent global environmental issues. Since these problems are NP-hard,\neffective optimizers are needed to handle them. The knowledge about variable\ndependencies allows for proposing such tools. However, in this work, we\nconsider a real-world multi-objective problem for which standard variable\ndependency discovery techniques are inapplicable. Therefore, using\nlinkage-based variation operators is unreachable. To address this issue, we\npropose a definition of problem-dedicated variable dependency. On this base, we\npropose obtaining masks of dependent variables. Using them, we construct three\nnovel crossover operators. The results concerning real-world test cases show\nthat introducing our propositions into two well-known optimizers (NSGA-II,\nMOEA/D) dedicated to multi-objective optimization significantly improves their\neffectiveness.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9NP-hard\u7684\u571f\u5730\u4f7f\u7528\u5206\u914d\u95ee\u9898\uff0c\u63d0\u51fa\u65b0\u53d8\u91cf\u4f9d\u8d56\u5b9a\u4e49\u548c\u4ea4\u53c9\u7b97\u5b50\uff0c\u63d0\u9ad8\u4e86\u591a\u76ee\u6807\u4f18\u5316\u5668\u7684\u6709\u6548\u6027\u3002", "motivation": "\u571f\u5730\u4f7f\u7528\u5206\u914d\u95ee\u9898\u662fNP-hard\uff0c\u6807\u51c6\u53d8\u91cf\u4f9d\u8d56\u6280\u672f\u4e0d\u9002\u7528\uff0c\u9700\u8981\u4e13\u7528\u4f18\u5316\u5de5\u5177\u6765\u5904\u7406\u5168\u7403\u73af\u5883\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u95ee\u9898\u4e13\u7528\u53d8\u91cf\u4f9d\u8d56\u5b9a\u4e49\u3001\u4f9d\u8d56\u53d8\u91cf\u63a9\u7801\uff0c\u5e76\u6784\u5efa\u4e09\u4e2a\u65b0\u4ea4\u53c9\u7b97\u5b50\uff0c\u6574\u5408\u5230NSGA-II\u548cMOEA/D\u4f18\u5316\u5668\u4e2d\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6d4b\u8bd5\u6848\u4f8b\u4e2d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4f18\u5316\u5668\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5f15\u5165\u65b0\u63d0\u8bae\u663e\u8457\u6539\u5584\u4e86\u591a\u76ee\u6807\u4f18\u5316\u5668\u7684\u6027\u80fd\u3002"}}
{"id": "2504.11645", "pdf": "https://arxiv.org/pdf/2504.11645", "abs": "https://arxiv.org/abs/2504.11645", "authors": ["Feng Zhu", "Aritra Mitra", "Robert W. Heath"], "title": "Achieving Tighter Finite-Time Rates for Heterogeneous Federated Stochastic Approximation under Markovian Sampling", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "math.OC"], "comment": null, "summary": "Motivated by collaborative reinforcement learning (RL) and optimization with\ntime-correlated data, we study a generic federated stochastic approximation\nproblem involving $M$ agents, where each agent is characterized by an\nagent-specific (potentially nonlinear) local operator. The goal is for the\nagents to communicate intermittently via a server to find the root of the\naverage of the agents' local operators. The generality of our setting stems\nfrom allowing for (i) Markovian data at each agent and (ii) heterogeneity in\nthe roots of the agents' local operators. The limited recent work that has\naccounted for both these features in a federated setting fails to guarantee\nconvergence to the desired point or to show any benefit of collaboration;\nfurthermore, they rely on projection steps in their algorithms to guarantee\nbounded iterates. Our work overcomes each of these limitations. We develop a\nnovel algorithm titled \\texttt{FedHSA}, and prove that it guarantees\nconvergence to the correct point, while enjoying an $M$-fold linear speedup in\nsample-complexity due to collaboration. To our knowledge, \\emph{this is the\nfirst finite-time result of its kind}, and establishing it (without relying on\na projection step) entails a fairly intricate argument that accounts for the\ninterplay between complex temporal correlations due to Markovian sampling,\nmultiple local steps to save communication, and the drift-effects induced by\nheterogeneous local operators. Our results have implications for a broad class\nof heterogeneous federated RL problems (e.g., policy evaluation and control)\nwith function approximation, where the agents' Markov decision processes can\ndiffer in their probability transition kernels and reward functions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faFedHSA\u7b97\u6cd5\uff0c\u7528\u4e8e\u8054\u90a6\u968f\u673a\u903c\u8fd1\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u534f\u4f5c\u52a0\u901f\u548c\u6b63\u786e\u6536\u655b\u3002", "motivation": "\u53d7\u534f\u4f5c\u5f3a\u5316\u5b66\u4e60\u548c\u65f6\u95f4\u76f8\u5173\u6570\u636e\u4f18\u5316\u7684\u542f\u53d1\uff0c\u7814\u7a76\u5f02\u8d28\u8054\u90a6\u968f\u673a\u903c\u8fd1\u95ee\u9898\u3002", "method": "\u5f00\u53d1FedHSA\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u5176\u6536\u655b\u6027\u3002", "result": "\u4fdd\u8bc1\u6536\u655b\u5230\u6b63\u786e\u70b9\uff0c\u5e76\u83b7\u5f97M\u500d\u7ebf\u6027\u52a0\u901f\u3002", "conclusion": "\u5bf9\u5f02\u8d28\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2504.12123", "pdf": "https://arxiv.org/pdf/2504.12123", "abs": "https://arxiv.org/abs/2504.12123", "authors": ["Fardad Vakilipoor", "Andreas Ettner-Sitter", "Lucas Brand", "Sebastian Lotter", "Thiha Aung", "Silke Harteis", "Robert Schober", "Maximilian Sch\u00e4fer"], "title": "The CAM Model: An in vivo Testbed for Molecular Communication Systems", "categories": ["eess.SY", "cs.SY", "eess.SP"], "comment": "arXiv admin note: text overlap with arXiv:2406.09875", "summary": "Molecular communication (MC) research increasingly focuses on biomedical\napplications like health monitoring and drug delivery, demanding testing in\nrealistic living environments. Elevating MC research requires developing\nadvanced in vivo testbeds. We introduce the chorioallantoic membrane (CAM)\nmodel as the first versatile 3D in vivo MC platform. The CAM, a highly\nvascularized membrane in fertilized chicken eggs, is established in\nbioengineering, cancer research, and drug development. Its biological realism,\nreproducibility, and versatility make it ideal for next-generation MC testbeds,\nbridging proof-of-concept systems and practical applications. We\ncomprehensively characterize the CAM model's properties and MC system\nrelevance. Through experimental studies, we investigate fluorescent molecule\ndistribution in the CAM's closed-loop vascular system. We derive an analytical\nmodel using the wrapped normal distribution to describe particle propagation in\ndispersive closed-loop systems dominated by diffusion and flow. Parametric\nmodels are developed to approximate particle dynamics in the CAM, with\nparameters estimated via nonlinear least squares curve fitting. A dataset of 69\nregions from 25 eggs validates our models. We analyze parameter relationships\nand biological plausibility. Finally, we develop a parametric model for\nlong-term particle behavior and liver accumulation in chick embryos.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165\u7ed2\u6bdb\u5c3f\u56ca\u819c\uff08CAM\uff09\u6a21\u578b\u4f5c\u4e3a\u5206\u5b50\u901a\u4fe1\u76843D\u4f53\u5916\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u548c\u6a21\u578b\u9a8c\u8bc1\u5176\u9002\u7528\u6027\u3002", "motivation": "\u5206\u5b50\u901a\u4fe1\u7814\u7a76\u9700\u8981\u66f4\u771f\u5b9e\u7684\u4f53\u5916\u6d4b\u8bd5\u73af\u5883\u6765\u652f\u6301\u751f\u7269\u533b\u5b66\u5e94\u7528\uff0c\u5982\u5065\u5eb7\u76d1\u6d4b\u548c\u836f\u7269\u9012\u9001\u3002", "method": "\u4f7f\u7528CAM\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7814\u7a76\u8367\u5149\u5206\u5b50\u5206\u5e03\uff0c\u63a8\u5bfc\u57fa\u4e8e\u5305\u88f9\u6b63\u6001\u5206\u5e03\u7684\u5206\u6790\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u975e\u7ebf\u6027\u6700\u5c0f\u4e8c\u4e58\u6cd5\u4f30\u8ba1\u53c2\u6570\u3002", "result": "\u5f00\u53d1\u4e86\u7c92\u5b50\u4f20\u64ad\u53c2\u6570\u6a21\u578b\uff0c\u4f7f\u752869\u4e2a\u533a\u57df\u7684\u6570\u636e\u9a8c\u8bc1\uff0c\u5206\u6790\u53c2\u6570\u5173\u7cfb\u548c\u751f\u7269\u5408\u7406\u6027\uff0c\u5e76\u5efa\u6a21\u957f\u671f\u7c92\u5b50\u884c\u4e3a\u548c\u809d\u810f\u79ef\u7d2f\u3002", "conclusion": "CAM\u6a21\u578b\u56e0\u5176\u751f\u7269\u771f\u5b9e\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u591a\u529f\u80fd\u6027\uff0c\u9002\u5408\u4f5c\u4e3a\u4e0b\u4e00\u4ee3\u5206\u5b50\u901a\u4fe1\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2504.11919", "pdf": "https://arxiv.org/pdf/2504.11919", "abs": "https://arxiv.org/abs/2504.11919", "authors": ["Qianjin Yu", "Keyu Wu", "Zihan Chen", "Chushu Zhang", "Manlin Mei", "Lingjun Huang", "Fang Tan", "Yongsheng Du", "Kunlin Liu", "Yurui Zhu"], "title": "Rethinking the Generation of High-Quality CoT Data from the Perspective of LLM-Adaptive Question Difficulty Grading", "categories": ["cs.AI"], "comment": null, "summary": "Recently, DeepSeek-R1 (671B) (DeepSeek-AIet al., 2025) has demonstrated its\nexcellent reasoning ability in complex tasks and has publiclyshared its\nmethodology. This provides potentially high-quality chain-of-thought (CoT) data\nfor stimulating the reasoning abilities of small-sized large language models\n(LLMs). To generate high-quality CoT data for different LLMs, we seek an\nefficient method for generating high-quality CoT data with LLM-Adaptive\nquestiondifficulty levels. First, we grade the difficulty of the questions\naccording to the reasoning ability of the LLMs themselves and construct a\nLLM-Adaptive question database. Second, we sample the problem database based on\na distribution of difficulty levels of the questions and then use DeepSeek-R1\n(671B) (DeepSeek-AI et al., 2025) to generate the corresponding high-quality\nCoT data with correct answers. Thanks to the construction of CoT data with\nLLM-Adaptive difficulty levels, we have significantly reduced the cost of data\ngeneration and enhanced the efficiency of model supervised fine-tuning (SFT).\nFinally, we have validated the effectiveness and generalizability of the\nproposed method in the fields of complex mathematical competitions and code\ngeneration tasks. Notably, with only 2k high-quality mathematical CoT data, our\nZMath-32B surpasses DeepSeek-Distill-32B in math reasoning task. Similarly,\nwith only 2k high-quality code CoT data, our ZCode-32B surpasses\nDeepSeek-Distill-32B in code reasoning tasks.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u9002\u5e94\u6027\u95ee\u9898\u96be\u5ea6\u7684CoT\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff0c\u4f7f\u7528DeepSeek-R1\u63d0\u5347\u5c0f\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4ee5\u4f4e\u6210\u672c\u83b7\u5f97\u663e\u8457\u6548\u679c\u3002", "motivation": "\u5229\u7528DeepSeek-R1\u7684\u516c\u5f00\u65b9\u6cd5\u751f\u6210\u9ad8\u8d28\u91cfCoT\u6570\u636e\uff0c\u4ee5\u9ad8\u6548\u63d0\u5347\u5c0fLLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u6570\u636e\u751f\u6210\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u6839\u636eLLM\u63a8\u7406\u80fd\u529b\u8bc4\u4f30\u95ee\u9898\u96be\u5ea6\uff0c\u6784\u5efa\u9002\u5e94\u6027\u95ee\u9898\u6570\u636e\u5e93\uff1b\u91c7\u6837\u95ee\u9898\u5e76\u7528DeepSeek-R1\u751f\u6210CoT\u6570\u636e\u3002", "result": "\u5728\u6570\u5b66\u548c\u4ee3\u7801\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528\u4ec52k\u6570\u636e\uff0cZMath-32B\u548cZCode-32B\u5747\u8d85\u8fc7DeepSeek-Distill-32B\u7684\u6027\u80fd\u3002", "conclusion": "\u65b9\u6cd5\u6709\u6548\u964d\u4f4e\u6570\u636e\u751f\u6210\u6210\u672c\uff0c\u63d0\u9ad8SFT\u6548\u7387\uff0c\u5e76\u8bc1\u660e\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u6027\u3002"}}
{"id": "2504.11651", "pdf": "https://arxiv.org/pdf/2504.11651", "abs": "https://arxiv.org/abs/2504.11651", "authors": ["Tianyi Zhang", "Yang Sui", "Shaochen Zhong", "Vipin Chaudhary", "Xia Hu", "Anshumali Shrivastava"], "title": "70% Size, 100% Accuracy: Lossless LLM Compression for Efficient GPU Inference via Dynamic-Length Float", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Large Language Models (LLMs) have grown rapidly in size, creating significant\nchallenges for efficient deployment on resource-constrained hardware. In this\npaper, we introduce Dynamic-Length Float (DFloat11), a lossless compression\nframework that reduces LLM size by 30% while preserving outputs that are\nbit-for-bit identical to the original model. DFloat11 is motivated by the low\nentropy in the BFloat16 weight representation of LLMs, which reveals\nsignificant inefficiency in existing storage format. By applying entropy\ncoding, DFloat11 assigns dynamic-length encodings to weights based on\nfrequency, achieving near information-optimal compression without any loss of\nprecision. To facilitate efficient inference with dynamic-length encodings, we\ndevelop a custom GPU kernel for fast online decompression. Our design\nincorporates the following: (i) decomposition of memory-intensive lookup tables\n(LUTs) into compact LUTs that fit in GPU SRAM, (ii) a two-phase kernel for\ncoordinating thread read/write positions using lightweight auxiliary variables,\nand (iii) transformer-block-level decompression to minimize latency.\nExperiments on recent models, including Llama-3.1, Qwen-2.5, and Gemma-3,\nvalidates our hypothesis that DFloat11 achieves around 30% model size reduction\nwhile preserving bit-for-bit exact outputs. Compared to a potential alternative\nof offloading parts of an uncompressed model to the CPU to meet memory\nconstraints, DFloat11 achieves 1.9-38.8x higher throughput in token generation.\nWith a fixed GPU memory budget, DFloat11 enables 5.3-13.17x longer context\nlengths than uncompressed models. Notably, our method enables lossless\ninference of Llama-3.1-405B, an 810GB model, on a single node equipped with\n8x80GB GPUs. Our code and models are available at\nhttps://github.com/LeanModels/DFloat11.", "AI": {"tldr": "DFloat11 \u662f\u4e00\u79cd\u65e0\u635f\u538b\u7f29\u6846\u67b6\uff0c\u53ef\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5927\u5c0f\u51cf\u5c11 30%\uff0c\u5e76\u901a\u8fc7\u71b5\u7f16\u7801\u548c\u81ea\u5b9a\u4e49 GPU \u5185\u6838\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u3002", "motivation": "\u8bba\u6587\u53d7 BFloat16 \u6743\u91cd\u8868\u793a\u4e2d\u4f4e\u71b5\u7684\u542f\u53d1\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u5b58\u50a8\u683c\u5f0f\u7684\u4f4e\u6548\u6027\u3002", "method": "\u4f7f\u7528\u71b5\u7f16\u7801\u4e3a\u6743\u91cd\u5206\u914d\u52a8\u6001\u957f\u5ea6\u7f16\u7801\uff0c\u5e76\u5f00\u53d1\u81ea\u5b9a\u4e49 GPU \u5185\u6838\uff0c\u5305\u62ec LUT \u5206\u89e3\u3001\u4e24\u9636\u6bb5\u5185\u6838\u534f\u8c03\u548c\u5757\u7ea7\u89e3\u538b\u7f29\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u5927\u5c0f\u51cf\u5c11 30%\uff0c\u8f93\u51fa\u4f4d\u7ea7\u76f8\u540c\uff0c\u751f\u6210\u4ee4\u724c\u541e\u5410\u91cf\u63d0\u9ad8 1.9-38.8 \u500d\uff0c\u4e0a\u4e0b\u6587\u957f\u5ea6\u5ef6\u957f 5.3-13.17 \u500d\uff0c\u5e76\u652f\u6301\u5728\u5355\u8282\u70b9\u4e0a\u63a8\u7406\u5927\u578b\u6a21\u578b\u3002", "conclusion": "DFloat11 \u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65e0\u635f\u538b\u7f29\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u8d44\u6e90\u53d7\u9650\u786c\u4ef6\u4e0a\u7684 LLM \u90e8\u7f72\u6548\u7387\u3002"}}
{"id": "2504.12193", "pdf": "https://arxiv.org/pdf/2504.12193", "abs": "https://arxiv.org/abs/2504.12193", "authors": ["Lukas Zezula", "Matus Kozovsky", "Ludek Buchta", "Petr Blaha"], "title": "Discrete-Time Modeling of Interturn Short Circuits in Interior PMSMs", "categories": ["eess.SY", "cs.SY"], "comment": null, "summary": "This article describes the discrete-time modeling approach for interturn\nshort circuits in interior permanent magnet synchronous motors with\nconcentrated windings that facilitate model-based fault diagnostics and\nmitigation. A continuous-time model incorporating universal series-parallel\nstator winding connection and radial permanent magnet fluxes is developed in\nthe stator variables and transformed into the rotor reference frame, including\nalso the electromagnetic torque. The transformed model undergoes discretization\nusing the matrix exponential-based technique, wherein the electrical angular\nvelocity and angle are considered time-varying parameters. The resulting model\nis subsequently expanded to consider the motor connection resistance via\nperturbation techniques. In the laboratory experiments, we validate the\ndynamical properties of the derived model by comparing its outputs with the\nexperimental data and waveforms generated by the forward Euler-based\ndiscrete-time approximation.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u5185\u90e8\u6c38\u78c1\u540c\u6b65\u7535\u673a\u531d\u95f4\u77ed\u8def\u6545\u969c\u8bca\u65ad\u7684\u79bb\u6563\u65f6\u95f4\u5efa\u6a21\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u4e86\u4fc3\u8fdb\u57fa\u4e8e\u6a21\u578b\u7684\u6545\u969c\u8bca\u65ad\u548c\u7f13\u89e3\uff0c\u9488\u5bf9\u5177\u6709\u96c6\u4e2d\u7ed5\u7ec4\u7684\u5185\u90e8\u6c38\u78c1\u540c\u6b65\u7535\u673a\u4e2d\u7684\u531d\u95f4\u77ed\u8def\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u8fde\u7eed\u65f6\u95f4\u6a21\u578b\u3001\u8f6c\u6362\u4e3a\u8f6c\u5b50\u53c2\u8003\u7cfb\u3001\u4f7f\u7528\u77e9\u9635\u6307\u6570\u6280\u672f\u79bb\u6563\u5316\u3001\u8003\u8651\u7535\u673a\u8fde\u63a5\u7535\u963b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u6a21\u578b\u7684\u52a8\u6001\u7279\u6027\u901a\u8fc7\u4e0e\u5b9e\u9a8c\u6570\u636e\u548c\u524d\u5411Euler\u65b9\u6cd5\u6bd4\u8f83\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u79bb\u6563\u65f6\u95f4\u6a21\u578b\u9002\u7528\u4e8e\u6545\u969c\u8bca\u65ad\u548c\u7f13\u89e3\u3002"}}
{"id": "2504.11942", "pdf": "https://arxiv.org/pdf/2504.11942", "abs": "https://arxiv.org/abs/2504.11942", "authors": ["Nada Shahin", "Leila Ismail"], "title": "ADAT: Time-Series-Aware Adaptive Transformer Architecture for Sign Language Translation", "categories": ["cs.AI", "cs.CL", "cs.CV", "I.2.6; I.2.7; I.2.10; I.4.8; I.4.9; I.4.10"], "comment": null, "summary": "Current sign language machine translation systems rely on recognizing hand\nmovements, facial expressions and body postures, and natural language\nprocessing, to convert signs into text. Recent approaches use Transformer\narchitectures to model long-range dependencies via positional encoding.\nHowever, they lack accuracy in recognizing fine-grained, short-range temporal\ndependencies between gestures captured at high frame rates. Moreover, their\nhigh computational complexity leads to inefficient training. To mitigate these\nissues, we propose an Adaptive Transformer (ADAT), which incorporates\ncomponents for enhanced feature extraction and adaptive feature weighting\nthrough a gating mechanism to emphasize contextually relevant features while\nreducing training overhead and maintaining translation accuracy. To evaluate\nADAT, we introduce MedASL, the first public medical American Sign Language\ndataset. In sign-to-gloss-to-text experiments, ADAT outperforms the\nencoder-decoder transformer, improving BLEU-4 accuracy by 0.1% while reducing\ntraining time by 14.33% on PHOENIX14T and 3.24% on MedASL. In sign-to-text\nexperiments, it improves accuracy by 8.7% and reduces training time by 2.8% on\nPHOENIX14T and achieves 4.7% higher accuracy and 7.17% faster training on\nMedASL. Compared to encoder-only and decoder-only baselines in sign-to-text,\nADAT is at least 6.8% more accurate despite being up to 12.1% slower due to its\ndual-stream structure.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u81ea\u9002\u5e94Transformer\uff08ADAT\uff09\u4ee5\u63d0\u5347\u624b\u8bed\u673a\u5668\u7ffb\u8bd1\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u533b\u7597\u624b\u8bed\u6570\u636e\u96c6MedASL\u3002", "motivation": "\u5f53\u524d\u624b\u8bed\u7ffb\u8bd1\u7cfb\u7edf\u5728\u8bc6\u522b\u7ec6\u7c92\u5ea6\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51faADAT\uff0c\u901a\u8fc7\u589e\u5f3a\u7279\u5f81\u63d0\u53d6\u548c\u81ea\u9002\u5e94\u7279\u5f81\u52a0\u6743\u673a\u5236\u6765\u4f18\u5316\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cADAT\u5728PHOENIX14T\u548cMedASL\u6570\u636e\u96c6\u4e0a\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u5e76\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "ADAT\u5728\u4fdd\u6301\u7ffb\u8bd1\u51c6\u786e\u6027\u7684\u540c\u65f6\u6539\u5584\u4e86\u6548\u7387\uff0c\u4e3a\u624b\u8bed\u7ffb\u8bd1\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u6848\u3002"}}
{"id": "2504.11699", "pdf": "https://arxiv.org/pdf/2504.11699", "abs": "https://arxiv.org/abs/2504.11699", "authors": ["Rui Xue", "Tianfu Wu"], "title": "H$^3$GNNs: Harmonizing Heterophily and Homophily in GNNs via Joint Structural Node Encoding and Self-Supervised Learning", "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "Graph Neural Networks (GNNs) struggle to balance heterophily and homophily in\nrepresentation learning, a challenge further amplified in self-supervised\nsettings. We propose H$^3$GNNs, an end-to-end self-supervised learning\nframework that harmonizes both structural properties through two key\ninnovations: (i) Joint Structural Node Encoding. We embed nodes into a unified\nspace combining linear and non-linear feature projections with K-hop structural\nrepresentations via a Weighted Graph Convolution Network(WGCN). A\ncross-attention mechanism enhances awareness and adaptability to heterophily\nand homophily. (ii) Self-Supervised Learning Using Teacher-Student Predictive\nArchitectures with Node-Difficulty Driven Dynamic Masking Strategies. We use a\nteacher-student model, the student sees the masked input graph and predicts\nnode features inferred by the teacher that sees the full input graph in the\njoint encoding space. To enhance learning difficulty, we introduce two novel\nnode-predictive-difficulty-based masking strategies. Experiments on seven\nbenchmarks (four heterophily datasets and three homophily datasets) confirm the\neffectiveness and efficiency of H$^3$GNNs across diverse graph types. Our\nH$^3$GNNs achieves overall state-of-the-art performance on the four heterophily\ndatasets, while retaining on-par performance to previous state-of-the-art\nmethods on the three homophily datasets.", "AI": {"tldr": "H\u00b3GNNs \u662f\u4e00\u79cd\u7aef\u5230\u7aef\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5e73\u8861\u5f02\u8d28\u6027\u548c\u540c\u8d28\u6027\u6765\u63d0\u5347\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u8868\u793a\u5b66\u4e60\u3002\u521b\u65b0\u5305\u62ec\u8054\u5408\u7ed3\u6784\u8282\u70b9\u7f16\u7801\u548c\u6559\u5e08-\u5b66\u751f\u9884\u6d4b\u67b6\u6784\uff0c\u5b9e\u9a8c\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u8868\u793a\u5b66\u4e60\u4e2d\u96be\u4ee5\u5e73\u8861\u5f02\u8d28\u6027\u548c\u540c\u8d28\u6027\uff0c\u5c24\u5176\u5728\u81ea\u76d1\u7763\u8bbe\u7f6e\u4e2d\u8fd9\u4e00\u6311\u6218\u66f4\u7a81\u51fa\u3002", "method": "\u63d0\u51fa H\u00b3GNNs\uff0c\u5305\u62ec\uff1a(i) \u8054\u5408\u7ed3\u6784\u8282\u70b9\u7f16\u7801\uff0c\u4f7f\u7528\u52a0\u6743\u56fe\u5377\u79ef\u7f51\u7edc\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff1b(ii) \u6559\u5e08-\u5b66\u751f\u6a21\u578b\u7684\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u7ed3\u5408\u8282\u70b9\u96be\u5ea6\u9a71\u52a8\u7684\u52a8\u6001\u63a9\u7801\u7b56\u7565\u3002", "result": "\u5728\u4e03\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0cH\u00b3GNNs \u5728\u56db\u4e2a\u5f02\u8d28\u6027\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u4e09\u4e2a\u540c\u8d28\u6027\u6570\u636e\u96c6\u4e0a\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "H\u00b3GNNs \u5728\u4e0d\u540c\u7c7b\u578b\u56fe\u4e0a\u6709\u6548\u4e14\u9ad8\u6548\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5904\u7406\u5f02\u8d28\u6027\u548c\u540c\u8d28\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002"}}
{"id": "2504.12207", "pdf": "https://arxiv.org/pdf/2504.12207", "abs": "https://arxiv.org/abs/2504.12207", "authors": ["Eugene Lavretsky"], "title": "Integrator Anti-Windup Design for Servo-Controllers with Position Constraints", "categories": ["eess.SY", "cs.SY"], "comment": "This paper was withdrawn from the 2025 AIAA SciTech Conference and as\n  a result not published online", "summary": "A control design modification to prevent integrator windup for position\nsaturated servo-controllers is introduced. The design is based on the formalism\nof Control Barrier Functions and represents an anti-windup integrator\nmodification for position-limited servo-controllers. The method is applicable\nto Linear Time Invariant Multi-Input-Multi-Output open-loop stable continuous\ntime systems. A flight control application example of the developed anti-windup\ncontrol solution is discussed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u7684\u9632\u98ce\u8d77\u63a7\u5236\u8bbe\u8ba1\u4fee\u6539\uff0c\u9488\u5bf9\u4f4d\u7f6e\u9971\u548c\u4f3a\u670d\u63a7\u5236\u5668\uff0c\u5e76\u8ba8\u8bba\u4e86\u98de\u884c\u63a7\u5236\u5e94\u7528\u793a\u4f8b\u3002", "motivation": "\u9632\u6b62\u79ef\u5206\u5668\u98ce\u8d77\uff0c\u8fd9\u662f\u4f4d\u7f6e\u9971\u548c\u4f3a\u670d\u63a7\u5236\u5668\u4e2d\u5e38\u89c1\u95ee\u9898\uff0c\u53ef\u80fd\u5bfc\u81f4\u7cfb\u7edf\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u57fa\u4e8e\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u5f62\u5f0f\u4e3b\u4e49\uff0c\u5f00\u53d1\u9632\u98ce\u8d77\u79ef\u5206\u5668\u4fee\u6539\uff0c\u9002\u7528\u4e8e\u7ebf\u6027\u65f6\u4e0d\u53d8\u591a\u8f93\u5165\u591a\u8f93\u51fa\u5f00\u73af\u7a33\u5b9a\u8fde\u7eed\u65f6\u95f4\u7cfb\u7edf\u3002", "result": "\u65b9\u6cd5\u9002\u7528\u4e8e\u6307\u5b9a\u7cfb\u7edf\u7c7b\u578b\uff0c\u5e76\u901a\u8fc7\u98de\u884c\u63a7\u5236\u5e94\u7528\u793a\u4f8b\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u65b9\u6848\u6709\u6548\u9632\u6b62\u79ef\u5206\u5668\u98ce\u8d77\uff0c\u63d0\u5347\u4e86\u4f4d\u7f6e\u9650\u5236\u4f3a\u670d\u63a7\u5236\u5668\u7684\u6027\u80fd\u3002"}}
{"id": "2504.11977", "pdf": "https://arxiv.org/pdf/2504.11977", "abs": "https://arxiv.org/abs/2504.11977", "authors": ["Sofia Krylova", "Fabian Schmidt", "Vladimir Vlassov"], "title": "Leveraging Machine Learning Models to Predict the Outcome of Digital Medical Triage Interviews", "categories": ["cs.AI"], "comment": "8 pages, 4 figures, 8 tables", "summary": "Many existing digital triage systems are questionnaire-based, guiding\npatients to appropriate care levels based on information (e.g., symptoms,\nmedical history, and urgency) provided by the patients answering\nquestionnaires. Such a system often uses a deterministic model with predefined\nrules to determine care levels. It faces challenges with incomplete triage\ninterviews since it can only assist patients who finish the process. In this\nstudy, we explore the use of machine learning (ML) to predict outcomes of\nunfinished interviews, aiming to enhance patient care and service quality.\nPredicting triage outcomes from incomplete data is crucial for patient safety\nand healthcare efficiency. Our findings show that decision-tree models,\nparticularly LGBMClassifier and CatBoostClassifier, achieve over 80\\% accuracy\nin predicting outcomes from complete interviews while having a linear\ncorrelation between the prediction accuracy and interview completeness degree.\nFor example, LGBMClassifier achieves 88,2\\% prediction accuracy for interviews\nwith 100\\% completeness, 79,6\\% accuracy for interviews with 80\\% completeness,\n58,9\\% accuracy for 60\\% completeness, and 45,7\\% accuracy for 40\\%\ncompleteness. The TabTransformer model demonstrated exceptional accuracy of\nover 80\\% for all degrees of completeness but required extensive training time,\nindicating a need for more powerful computational resources. The study\nhighlights the linear correlation between interview completeness and predictive\npower of the decision-tree models.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u672a\u5b8c\u6210\u6570\u5b57\u5206\u8bca\u8bbf\u8c08\u7684\u7ed3\u679c\uff0c\u4ee5\u63d0\u9ad8\u60a3\u8005\u62a4\u7406\u548c\u533b\u7597\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u95ee\u5377\u7684\u786e\u5b9a\u6027\u5206\u8bca\u7cfb\u7edf\u65e0\u6cd5\u5904\u7406\u672a\u5b8c\u6210\u8bbf\u8c08\uff0c\u5b58\u5728\u5b89\u5168\u548c\u6548\u7387\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u4e0d\u5b8c\u6574\u6570\u636e\u7684\u7ed3\u679c\u3002", "method": "\u4f7f\u7528\u51b3\u7b56\u6811\u6a21\u578b\uff08\u5982LGBMClassifier\u548cCatBoostClassifier\uff09\u53caTabTransformer\u6a21\u578b\uff0c\u9884\u6d4b\u4e0d\u540c\u5b8c\u6574\u5ea6\u8bbf\u8c08\u7684\u5206\u8bca\u7ed3\u679c\u3002", "result": "\u51b3\u7b56\u6811\u6a21\u578b\u5728\u5b8c\u6574\u8bbf\u8c08\u4e2d\u51c6\u786e\u7387\u8d85\u8fc780%\uff0c\u4e0e\u5b8c\u6574\u5ea6\u5448\u7ebf\u6027\u76f8\u5173\uff1bTabTransformer\u5728\u6240\u6709\u5b8c\u6574\u5ea6\u4e0b\u51c6\u786e\u7387\u5747\u8d85\u8fc780%\uff0c\u4f46\u8bad\u7ec3\u65f6\u95f4\u8f83\u957f\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u8bbf\u8c08\u5b8c\u6574\u5ea6\u4e0e\u9884\u6d4b\u51c6\u786e\u7387\u4e4b\u95f4\u7684\u7ebf\u6027\u76f8\u5173\u6027\uff0c\u5c55\u793a\u4e86\u673a\u5668\u5b66\u4e60\u5728\u63d0\u5347\u5206\u8bca\u7cfb\u7edf\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.11702", "pdf": "https://arxiv.org/pdf/2504.11702", "abs": "https://arxiv.org/abs/2504.11702", "authors": ["Dorottya Zelenyanszki", "Zhe Hou", "Kamanashis Biswas", "Vallipuram Muthukkumarasamy"], "title": "Clustering and analysis of user behaviour in blockchain: A case study of Planet IX", "categories": ["cs.LG", "cs.CR"], "comment": "15 pages, 8 figures, submitted to Blockchain: Research and\n  Applications", "summary": "Decentralised applications (dApps) that run on public blockchains have the\nbenefit of trustworthiness and transparency as every activity that happens on\nthe blockchain can be publicly traced through the transaction data. However,\nthis introduces a potential privacy problem as this data can be tracked and\nanalysed, which can reveal user-behaviour information. A user behaviour\nanalysis pipeline was proposed to present how this type of information can be\nextracted and analysed to identify separate behavioural clusters that can\ndescribe how users behave in the game. The pipeline starts with the collection\nof transaction data, involving smart contracts, that is collected from a\nblockchain-based game called Planet IX. Both the raw transaction information\nand the transaction events are considered in the data collection. From this\ndata, separate game actions can be formed and those are leveraged to present\nhow and when the users conducted their in-game activities in the form of user\nflows. An extended version of these user flows also presents how the\nNon-Fungible Tokens (NFTs) are being leveraged in the user actions. The latter\nis given as input for a Graph Neural Network (GNN) model to provide graph\nembeddings for these flows which then can be leveraged by clustering algorithms\nto cluster user behaviours into separate behavioural clusters. We benchmark and\ncompare well-known clustering algorithms as a part of the proposed method. The\nuser behaviour clusters were analysed and visualised in a graph format. It was\nfound that behavioural information can be extracted regarding the users that\nbelong to these clusters. Such information can be exploited by malicious users\nto their advantage. To demonstrate this, a privacy threat model was also\npresented based on the results that correspond to multiple potentially affected\nareas.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u7528\u6237\u884c\u4e3a\u5206\u6790\u7ba1\u9053\uff0c\u4ece\u533a\u5757\u94fe\u6e38\u620f\u4ea4\u6613\u6570\u636e\u4e2d\u63d0\u53d6\u884c\u4e3a\u96c6\u7fa4\uff0c\u5e76\u8ba8\u8bba\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u533a\u5757\u94fedApps\u900f\u660e\u6027\u5bfc\u81f4\u6570\u636e\u53ef\u8ffd\u8e2a\uff0c\u53ef\u80fd\u6cc4\u9732\u7528\u6237\u884c\u4e3a\u4fe1\u606f\uff0c\u9700\u8981\u5206\u6790\u9690\u79c1\u95ee\u9898\u3002", "method": "\u6536\u96c6Planet IX\u6e38\u620f\u4ea4\u6613\u6570\u636e\uff0c\u6784\u5efa\u7528\u6237\u884c\u4e3a\u6d41\uff0c\u4f7f\u7528GNN\u751f\u6210\u5d4c\u5165\uff0c\u5e76\u5e94\u7528\u805a\u7c7b\u7b97\u6cd5\u6bd4\u8f83\u3002", "result": "\u901a\u8fc7\u805a\u7c7b\u7b97\u6cd5\u8bc6\u522b\u884c\u4e3a\u96c6\u7fa4\uff0c\u53d1\u73b0\u53ef\u63d0\u53d6\u7528\u6237\u884c\u4e3a\u4fe1\u606f\uff0c\u5e76\u6784\u5efa\u9690\u79c1\u5a01\u80c1\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u663e\u793a\uff0c\u7528\u6237\u884c\u4e3a\u53ef\u88ab\u6076\u610f\u5229\u7528\uff0c\u5f3a\u8c03\u533a\u5757\u94fe\u6e38\u620f\u7684\u9690\u79c1\u98ce\u9669\u3002"}}
{"id": "2504.12208", "pdf": "https://arxiv.org/pdf/2504.12208", "abs": "https://arxiv.org/abs/2504.12208", "authors": ["Eugene Lavretsky"], "title": "Servo-Controllers with Operational Constraints", "categories": ["eess.SY", "cs.SY"], "comment": "This paper was withdrawn from the 2025 AIAA AciTech Conference and as\n  a result not published online", "summary": "In this paper, a proportional-integral servo-control design method is\ndeveloped for multi-input-multioutput linear time invariant systems with\noperational constraints imposed on the system control input and on an output of\nthe same dimension as the control input. The design is based on min-norm\ncontrollers and Control Barrier Functions. It allows to enforce min/max box\nconstraints by analytically solving Quadratic Programs for min-norm\naugmentation controllers. The method provides an anti-windup protection for the\ncontroller integrator state and enforces the desired operational control and\noutput constraints, component-wise. A simulation example is given to illustrate\npotential benefits of the proposed design methodology for aerial flight\ncritical systems.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u9488\u5bf9\u53d7\u7ea6\u675f\u7684\u591a\u8f93\u5165\u591a\u8f93\u51fa\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf\u7684\u6bd4\u4f8b\u79ef\u5206\u4f3a\u670d\u63a7\u5236\u65b9\u6cd5\uff0c\u4f7f\u7528\u6700\u5c0f\u8303\u6570\u63a7\u5236\u5668\u548c\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff0c\u786e\u4fdd\u7ea6\u675f\u6ee1\u8db3\uff0c\u5e76\u5728\u98de\u884c\u7cfb\u7edf\u4e2d\u9a8c\u8bc1\u3002", "motivation": "\u52a8\u673a\u662f\u5904\u7406\u7cfb\u7edf\u63a7\u5236\u8f93\u5165\u548c\u8f93\u51fa\u7684\u64cd\u4f5c\u7ea6\u675f\uff0c\u63d0\u4f9b\u9632\u98ce\u4fdd\u62a4\uff0c\u5e76\u5e94\u7528\u4e8e\u822a\u7a7a\u98de\u884c\u5173\u952e\u7cfb\u7edf\u4ee5\u63d0\u9ad8\u5b89\u5168\u6027\u3002", "method": "\u65b9\u6cd5\u57fa\u4e8e\u6700\u5c0f\u8303\u6570\u63a7\u5236\u5668\u548c\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff0c\u901a\u8fc7\u89e3\u6790\u6c42\u89e3\u4e8c\u6b21\u89c4\u5212\u6765\u5f3a\u5236\u6267\u884c\u6700\u5c0f/\u6700\u5927\u76d2\u7ea6\u675f\u3002", "result": "\u7ed3\u679c\u662f\u65b9\u6cd5\u63d0\u4f9b\u4e86\u63a7\u5236\u5668\u79ef\u5206\u72b6\u6001\u7684\u9632\u98ce\u4fdd\u62a4\uff0c\u5e76\u9010\u7ec4\u4ef6\u5f3a\u5236\u6267\u884c\u7ea6\u675f\u3002\u6a21\u62df\u793a\u4f8b\u5c55\u793a\u4e86\u5728\u822a\u7a7a\u98de\u884c\u7cfb\u7edf\u4e2d\u7684\u6f5c\u5728\u76ca\u5904\u3002", "conclusion": "\u7ed3\u8bba\u662f\u6240\u63d0\u51fa\u7684\u8bbe\u8ba1\u65b9\u6cd5\u6709\u6548\uff0c\u5e76\u4e3a\u7c7b\u4f3c\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u76ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2504.12012", "pdf": "https://arxiv.org/pdf/2504.12012", "abs": "https://arxiv.org/abs/2504.12012", "authors": ["Kris Pilcher", "Esen K. T\u00fct\u00fcnc\u00fc"], "title": "Purposefully Induced Psychosis (PIP): Embracing Hallucination as Imagination in Large Language Models", "categories": ["cs.AI", "cs.HC"], "comment": "5 pages, 3 figures", "summary": "Hallucinations in Large Language Models (LLMs) are widely regarded as errors\n- outputs that deviate from factual accuracy. However, in creative or\nexploratory contexts, these \"mistakes\" may represent unexpected avenues for\ninnovation. We introduce Purposefully Induced Psychosis (PIP), a novel approach\nthat amplifies LLM hallucinations for imaginative tasks such as speculative\nfiction, interactive storytelling, and mixed-reality simulations. Drawing on\nHerman Melville's Moby-Dick, where Pip's \"madness\" reveals profound insight, we\nreframe hallucinations as a source of computational imagination rather than a\nflaw. Our method fine-tunes LLMs to encourage speculative, metaphorical, and\nsurreal outputs - hallucinations that are useful when factual accuracy is not\nthe chief objective. Inspired by the consensual illusions of theater and stage\nmagic, PIP situates these creative missteps in contexts where users willingly\nsuspend disbelief, thereby transforming \"errors\" into catalysts for new ways of\nthinking. We discuss potential applications, design principles for ensuring\nuser consent, preliminary observations, and implications for broader AI ethics\nand human-AI collaboration.", "AI": {"tldr": "This paper introduces PIP, a method to intentionally induce hallucinations in LLMs for creative tasks, reframing them as innovative tools rather than errors.", "motivation": "To reframe LLM hallucinations from flaws to sources of computational imagination in creative contexts, inspired by literature like Moby-Dick and concepts from theater.", "method": "Fine-tuning LLMs to amplify speculative, metaphorical, and surreal outputs for tasks such as speculative fiction and interactive storytelling.", "result": "Preliminary observations on applications, design principles for user consent, and implications for AI ethics and human-AI collaboration.", "conclusion": "Hallucinations can be transformed into catalysts for innovation when factual accuracy is not primary, emphasizing ethical considerations in AI development."}}
{"id": "2504.11713", "pdf": "https://arxiv.org/pdf/2504.11713", "abs": "https://arxiv.org/abs/2504.11713", "authors": ["Aaron Havens", "Benjamin Kurt Miller", "Bing Yan", "Carles Domingo-Enrich", "Anuroop Sriram", "Brandon Wood", "Daniel Levine", "Bin Hu", "Brandon Amos", "Brian Karrer", "Xiang Fu", "Guan-Horng Liu", "Ricky T. Q. Chen"], "title": "Adjoint Sampling: Highly Scalable Diffusion Samplers via Adjoint Matching", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce Adjoint Sampling, a highly scalable and efficient algorithm for\nlearning diffusion processes that sample from unnormalized densities, or energy\nfunctions. It is the first on-policy approach that allows significantly more\ngradient updates than the number of energy evaluations and model samples,\nallowing us to scale to much larger problem settings than previously explored\nby similar methods. Our framework is theoretically grounded in stochastic\noptimal control and shares the same theoretical guarantees as Adjoint Matching,\nbeing able to train without the need for corrective measures that push samples\ntowards the target distribution. We show how to incorporate key symmetries, as\nwell as periodic boundary conditions, for modeling molecules in both cartesian\nand torsional coordinates. We demonstrate the effectiveness of our approach\nthrough extensive experiments on classical energy functions, and further scale\nup to neural network-based energy models where we perform amortized conformer\ngeneration across many molecular systems. To encourage further research in\ndeveloping highly scalable sampling methods, we plan to open source these\nchallenging benchmarks, where successful methods can directly impact progress\nin computational chemistry.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f15\u5165Adjoint Sampling\u7b97\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u672a\u5f52\u4e00\u5316\u5bc6\u5ea6\u6216\u80fd\u91cf\u51fd\u6570\u4e2d\u5b66\u4e60\u6269\u6563\u8fc7\u7a0b\u7684\u91c7\u6837\u3002", "motivation": "\u52a8\u673a\u662f\u5f00\u53d1\u4e00\u79cdon-policy\u65b9\u6cd5\uff0c\u80fd\u591f\u5141\u8bb8\u66f4\u591a\u68af\u5ea6\u66f4\u65b0\u5e76\u6269\u5c55\u5230\u66f4\u5927\u95ee\u9898\u8bbe\u7f6e\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u91c7\u6837\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "method": "\u65b9\u6cd5\u57fa\u4e8e\u968f\u673a\u6700\u4f18\u63a7\u5236\u7684\u6846\u67b6\uff0c\u662f\u4e00\u79cdon-policy\u65b9\u6cd5\uff0c\u65e0\u9700\u6821\u6b63\u63aa\u65bd\uff0c\u5e76\u6574\u5408\u5bf9\u79f0\u6027\u548c\u5468\u671f\u8fb9\u754c\u6761\u4ef6\u7528\u4e8e\u5206\u5b50\u5efa\u6a21\u3002", "result": "\u7ed3\u679c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5728\u7ecf\u5178\u80fd\u91cf\u51fd\u6570\u548c\u795e\u7ecf\u7f51\u7edc\u80fd\u91cf\u6a21\u578b\u4e0a\u7684\u6709\u6548\u6027\uff0c\u5305\u62ec\u5bf9\u591a\u4e2a\u5206\u5b50\u7cfb\u7edf\u7684\u644a\u9500\u6784\u8c61\u751f\u6210\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u91c7\u6837\u6548\u7387\uff0c\u5e76\u8ba1\u5212\u5f00\u6e90\u57fa\u51c6\u4ee5\u63a8\u52a8\u8ba1\u7b97\u5316\u5b66\u9886\u57df\u7684\u7814\u7a76\u3002"}}
{"id": "2504.12269", "pdf": "https://arxiv.org/pdf/2504.12269", "abs": "https://arxiv.org/abs/2504.12269", "authors": ["Pouya Samanipour", "Hasan Poonawala"], "title": "SEROAISE: Advancing ROA Estimation for ReLU and PWA Dynamics through Estimating Certified Invariant Sets", "categories": ["eess.SY", "cs.SY"], "comment": "Preprint submitted to Automatica", "summary": "This paper presents a novel framework for constructing the Region of\nAttraction (RoA) for dynamics derived either from Piecewise Affine (PWA)\nfunctions or from Neural Networks (NNs) with Rectified Linear Units (ReLU)\nactivation function. This method, described as Sequential Estimation of RoA\nbased on Invariant Set Estimation (SEROAISE), computes a Lyapunov-like PWA\nfunction over a certified PWA invariant set. While traditional approaches\nsearch for Lyapunov functions by enforcing Lyapunov conditions over\npre-selected domains, this framework enforces Lyapunov-like conditions over a\ncertified invariant subset obtained using the Iterative Invariant Set\nEstimator(IISE). Compared to the state-of-the-art, IISE provides systematically\nlarger certified invariant sets. In order to find a larger invariant subset,\nthe IISE utilizes a novel concept known as the Non-Uniform Growth of Invariant\nSet (NUGIS). A number of examples illustrating the efficacy of the proposed\nmethods are provided, including dynamical systems derived from learning\nalgorithms. The implementation is publicly available at:\nhttps://github.com/PouyaSamanipour/SEROAISE.git.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSEROAISE\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efaPWA\u6216ReLU NN\u52a8\u6001\u7cfb\u7edf\u7684\u5438\u5f15\u57df\uff0c\u901a\u8fc7\u5728\u8ba4\u8bc1\u4e0d\u53d8\u96c6\u4e0a\u8ba1\u7b97Lyapunov-like PWA\u51fd\u6570\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u9884\u9009\u57df\u4e0a\u5f3a\u5236Lyapunov\u6761\u4ef6\uff0c\u800c\u672c\u6846\u67b6\u4f7f\u7528IISE\u83b7\u5f97\u66f4\u5927\u4e0d\u53d8\u96c6\uff0c\u4ee5\u63d0\u5347RoA\u4f30\u8ba1\u7cbe\u5ea6\u3002", "method": "SEROAISE\u57fa\u4e8eIISE\u548cNUGIS\u6982\u5ff5\uff0c\u987a\u5e8f\u4f30\u8ba1RoA\uff0c\u901a\u8fc7\u8ba1\u7b97Lyapunov-like PWA\u51fd\u6570\u3002", "result": "\u901a\u8fc7\u4f8b\u5b50\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5305\u62ec\u5b66\u4e60\u7b97\u6cd5\u52a8\u6001\u7cfb\u7edf\uff0c\u5e76\u63d0\u4f9b\u5f00\u6e90\u5b9e\u73b0\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u4f9b\u66f4\u5927\u8ba4\u8bc1\u4e0d\u53d8\u96c6\uff0c\u63d0\u9ad8\u4e86RoA\u6784\u5efa\u80fd\u529b\u3002"}}
{"id": "2504.12090", "pdf": "https://arxiv.org/pdf/2504.12090", "abs": "https://arxiv.org/abs/2504.12090", "authors": ["Jack Preuveneers", "Joseph Ternasky", "Fuat Alican", "Yigit Ihlamur"], "title": "Reasoning-Based AI for Startup Evaluation (R.A.I.S.E.): A Memory-Augmented, Multi-Step Decision Framework", "categories": ["cs.AI", "I.2.7"], "comment": null, "summary": "We present a novel framework that bridges the gap between the\ninterpretability of decision trees and the advanced reasoning capabilities of\nlarge language models (LLMs) to predict startup success. Our approach leverages\nchain-of-thought prompting to generate detailed reasoning logs, which are\nsubsequently distilled into structured, human-understandable logical rules. The\npipeline integrates multiple enhancements - efficient data ingestion, a\ntwo-step refinement process, ensemble candidate sampling, simulated\nreinforcement learning scoring, and persistent memory - to ensure both stable\ndecision-making and transparent output. Experimental evaluations on curated\nstartup datasets demonstrate that our combined pipeline improves precision by\n54% from 0.225 to 0.346 and accuracy by 50% from 0.46 to 0.70 compared to a\nstandalone OpenAI o3 model. Notably, our model achieves over 2x the precision\nof a random classifier (16%). By combining state-of-the-art AI reasoning with\nexplicit rule-based explanations, our method not only augments traditional\ndecision-making processes but also facilitates expert intervention and\ncontinuous policy refinement. This work lays the foundation for the\nimplementation of interpretable LLM-powered decision frameworks in high-stakes\ninvestment environments and other domains that require transparent and\ndata-driven insights.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u51b3\u7b56\u6811\u53ef\u89e3\u91ca\u6027\u548c\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u521b\u4e1a\u6210\u529f\uff0c\u63d0\u9ad8\u7cbe\u5ea6\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5f25\u5408\u51b3\u7b56\u6811\u53ef\u89e3\u91ca\u6027\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4ee5\u5728\u9ad8\u98ce\u9669\u6295\u8d44\u73af\u5883\u4e2d\u63d0\u4f9b\u900f\u660e\u7684\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u3002", "method": "\u5229\u7528\u94fe\u5f0f\u601d\u8003\u63d0\u793a\u751f\u6210\u63a8\u7406\u65e5\u5fd7\uff0c\u5e76\u63d0\u70bc\u6210\u903b\u8f91\u89c4\u5219\uff1b\u6574\u5408\u6570\u636e\u6444\u5165\u3001\u4e24\u6b65\u7cbe\u70bc\u3001\u96c6\u6210\u91c7\u6837\u3001\u5f3a\u5316\u5b66\u4e60\u8bc4\u5206\u548c\u6301\u4e45\u5185\u5b58\u7b49\u589e\u5f3a\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u7cbe\u5ea6\u63d0\u534754%\uff08\u4ece0.225\u52300.346\uff09\uff0c\u51c6\u786e\u6027\u63d0\u534750%\uff08\u4ece0.46\u52300.70\uff09\uff0c\u6bd4\u968f\u673a\u5206\u7c7b\u5668\u9ad8\u51fa2\u500d\u3002", "conclusion": "\u589e\u5f3a\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4fbf\u4e8e\u4e13\u5bb6\u5e72\u9884\u548c\u653f\u7b56\u4f18\u5316\uff0c\u4e3a\u53ef\u89e3\u91caLLM\u6846\u67b6\u5728\u6295\u8d44\u548c\u5176\u4ed6\u9886\u57df\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2504.11726", "pdf": "https://arxiv.org/pdf/2504.11726", "abs": "https://arxiv.org/abs/2504.11726", "authors": ["Yunzhe Li", "Facheng Hu", "Hongzi Zhu", "Shifan Zhang", "Liang Zhang", "Shan Chang", "Minyi Guo"], "title": "Saga: Capturing Multi-granularity Semantics from Massive Unlabelled IMU Data for User Perception", "categories": ["cs.LG", "cs.AI"], "comment": "2025 IEEE 45th International Conference on Distributed Computing\n  Systems (ICDCS)", "summary": "Inertial measurement units (IMUs), have been prevalently used in a wide range\nof mobile perception applications such as activity recognition and user\nauthentication, where a large amount of labelled data are normally required to\ntrain a satisfactory model. However, it is difficult to label micro-activities\nin massive IMU data due to the hardness of understanding raw IMU data and the\nlack of ground truth. In this paper, we propose a novel fine-grained user\nperception approach, called Saga, which only needs a small amount of labelled\nIMU data to achieve stunning user perception accuracy. The core idea of Saga is\nto first pre-train a backbone feature extraction model, utilizing the rich\nsemantic information of different levels embedded in the massive unlabelled IMU\ndata. Meanwhile, for a specific downstream user perception application,\nBayesian Optimization is employed to determine the optimal weights for\npre-training tasks involving different semantic levels. We implement Saga on\nfive typical mobile phones and evaluate Saga on three typical tasks on three\nIMU datasets. Results show that when only using about 100 training samples per\nclass, Saga can achieve over 90% accuracy of the full-fledged model trained on\nover ten thousands training samples with no additional system overhead.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faSaga\u65b9\u6cd5\uff0c\u4f7f\u7528\u5c11\u91cf\u6807\u8bb0\u7684IMU\u6570\u636e\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7528\u6237\u611f\u77e5\uff0c\u51cf\u5c11\u5bf9\u5927\u91cf\u6807\u8bb0\u6570\u636e\u7684\u4f9d\u8d56\u3002", "motivation": "IMU\u6570\u636e\u5728\u79fb\u52a8\u611f\u77e5\u5e94\u7528\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u6807\u8bb0\u5fae\u6d3b\u52a8\u6570\u636e\u56f0\u96be\uff0c\u56e0\u4e3a\u7406\u89e3\u539f\u59cb\u6570\u636e\u4e0d\u6613\u4e14\u7f3a\u4e4f\u5730\u9762\u771f\u76f8\u3002", "method": "\u5148\u5229\u7528\u5927\u91cf\u65e0\u6807\u8bb0IMU\u6570\u636e\u9884\u8bad\u7ec3\u7279\u5f81\u63d0\u53d6\u6a21\u578b\uff0c\u63d0\u53d6\u4e0d\u540c\u7ea7\u522b\u8bed\u4e49\u4fe1\u606f\uff1b\u7136\u540e\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u4e3a\u7279\u5b9a\u5e94\u7528\u786e\u5b9a\u9884\u8bad\u7ec3\u4efb\u52a1\u6743\u91cd\u3002", "result": "\u4f7f\u7528\u6bcf\u7c7b\u7ea6100\u4e2a\u8bad\u7ec3\u6837\u672c\uff0cSaga\u8fbe\u5230\u4f7f\u7528\u4e0a\u4e07\u6837\u672c\u6a21\u578b90%\u4ee5\u4e0a\u7684\u51c6\u786e\u7387\uff0c\u65e0\u989d\u5916\u5f00\u9500\uff1b\u5728\u4e09\u4e2aIMU\u6570\u636e\u96c6\u7684\u4e09\u4e2a\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u3002", "conclusion": "Saga\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u4ee5\u5c11\u91cf\u6807\u8bb0\u6570\u636e\u9ad8\u6548\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u7684\u7528\u6237\u611f\u77e5\u3002"}}
{"id": "2504.11495", "pdf": "https://arxiv.org/pdf/2504.11495", "abs": "https://arxiv.org/abs/2504.11495", "authors": ["Yiting Wang", "Yunxin Fan", "Fei Liu"], "title": "Probabilistic Task Parameterization of Tool-Tissue Interaction via Sparse Landmarks Tracking in Robotic Surgery", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": "Submitted to ICRA'25 Workshop of 3rd Robot-Assisted Medical Imaging", "summary": "Accurate modeling of tool-tissue interactions in robotic surgery requires\nprecise tracking of deformable tissues and integration of surgical domain\nknowledge. Traditional methods rely on labor-intensive annotations or rigid\nassumptions, limiting flexibility. We propose a framework combining sparse\nkeypoint tracking and probabilistic modeling that propagates expert-annotated\nlandmarks across endoscopic frames, even with large tissue deformations.\nClustered tissue keypoints enable dynamic local transformation construction via\nPCA, and tool poses, tracked similarly, are expressed relative to these frames.\nEmbedding these into a Task-Parameterized Gaussian Mixture Model (TP-GMM)\nintegrates data-driven observations with labeled clinical expertise,\neffectively predicting relative tool-tissue poses and enhancing visual\nunderstanding of robotic surgical motions directly from video data.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u6846\u67b6\uff0c\u7ed3\u5408\u7a00\u758f\u5173\u952e\u70b9\u8ddf\u8e2a\u548c\u6982\u7387\u5efa\u6a21\uff0c\u63d0\u9ad8\u673a\u5668\u4eba\u624b\u672f\u5de5\u5177-\u7ec4\u7ec7\u4ea4\u4e92\u7684\u7cbe\u786e\u5efa\u6a21\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u52b3\u52a8\u5bc6\u96c6\u578b\u6807\u6ce8\u6216\u521a\u6027\u5047\u8bbe\uff0c\u9650\u5236\u7075\u6d3b\u6027\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u5efa\u6a21\u3002", "method": "\u4f7f\u7528\u7a00\u758f\u5173\u952e\u70b9\u8ddf\u8e2a\u3001PCA\u6784\u5efa\u52a8\u6001\u53d8\u6362\uff0c\u5e76\u901a\u8fc7TP-GMM\u6574\u5408\u6570\u636e\u9a71\u52a8\u89c2\u5bdf\u4e0e\u4e34\u5e8a\u77e5\u8bc6\u3002", "result": "\u6709\u6548\u9884\u6d4b\u5de5\u5177-\u7ec4\u7ec7\u76f8\u5bf9\u4f4d\u59ff\uff0c\u5e76\u589e\u5f3a\u89c6\u9891\u6570\u636e\u7684\u89c6\u89c9\u7406\u89e3\u3002", "conclusion": "\u6846\u67b6\u63d0\u9ad8\u4e86\u5efa\u6a21\u51c6\u786e\u6027\u548c\u624b\u672f\u52a8\u4f5c\u7406\u89e3\u3002"}}
{"id": "2504.12110", "pdf": "https://arxiv.org/pdf/2504.12110", "abs": "https://arxiv.org/abs/2504.12110", "authors": ["Chia Hsiang Kao", "Wenting Zhao", "Shreelekha Revankar", "Samuel Speas", "Snehal Bhagat", "Rajeev Datta", "Cheng Perng Phoo", "Utkarsh Mall", "Carl Vondrick", "Kavita Bala", "Bharath Hariharan"], "title": "Towards LLM Agents for Earth Observation", "categories": ["cs.AI"], "comment": "36 pages", "summary": "Earth Observation (EO) provides critical planetary data for environmental\nmonitoring, disaster management, climate science, and other scientific domains.\nHere we ask: Are AI systems ready for reliable Earth Observation? We introduce\n\\datasetnamenospace, a benchmark of 140 yes/no questions from NASA Earth\nObservatory articles across 13 topics and 17 satellite sensors. Using Google\nEarth Engine API as a tool, LLM agents can only achieve an accuracy of 33%\nbecause the code fails to run over 58% of the time. We improve the failure rate\nfor open models by fine-tuning synthetic data, allowing much smaller models\n(Llama-3.1-8B) to achieve comparable accuracy to much larger ones (e.g.,\nDeepSeek-R1). Taken together, our findings identify significant challenges to\nbe solved before AI agents can automate earth observation, and suggest paths\nforward. The project page is available at\nhttps://iandrover.github.io/UnivEarth.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30AI\u5728\u5730\u7403\u89c2\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u5f15\u5165\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u51c6\u786e\u7387\u4f4e\u3001\u5931\u8d25\u7387\u9ad8\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u5c55\u793a\u4e86\u6539\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u63a2\u8ba8AI\u7cfb\u7edf\u662f\u5426\u51c6\u5907\u597d\u8fdb\u884c\u53ef\u9760\u7684\u5730\u7403\u89c2\u6d4b\uff0c\u4f7f\u7528NASA\u6570\u636e\u548c\u536b\u661f\u4f20\u611f\u5668\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u5305\u542b140\u4e2a\u662f/\u5426\u95ee\u9898\u7684\u57fa\u51c6\uff0c\u4f7f\u7528Google Earth Engine API\u6d4b\u8bd5LLM\u4ee3\u7406\uff0c\u5e76\u901a\u8fc7\u5408\u6210\u6570\u636e\u5fae\u8c03\u6a21\u578b\u3002", "result": "LLM\u4ee3\u7406\u51c6\u786e\u7387\u4ec533%\uff0c\u4ee3\u7801\u6267\u884c\u5931\u8d25\u7387\u8fbe58%\uff1b\u5fae\u8c03\u540e\uff0c\u5c0f\u6a21\u578b\u6027\u80fd\u53ef\u4e0e\u5927\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "\u6307\u51fa\u4e86AI\u81ea\u52a8\u5316\u5730\u7403\u89c2\u6d4b\u7684\u6311\u6218\uff0c\u5e76\u5efa\u8bae\u901a\u8fc7\u5fae\u8c03\u7b49\u65b9\u6cd5\u6539\u8fdb\u3002"}}
{"id": "2504.11757", "pdf": "https://arxiv.org/pdf/2504.11757", "abs": "https://arxiv.org/abs/2504.11757", "authors": ["Pradeep Singh", "Ashutosh Kumar", "Sutirtha Ghosh", "Hrishit B P", "Balasubramanian Raman"], "title": "Dynamics and Computational Principles of Echo State Networks: A Mathematical Perspective", "categories": ["cs.LG", "cs.NE", "37N35, 37D45, 93C10, 93C35, 93C40, 93C55", "I.2.8; I.5.2"], "comment": "100 pages, 17 tables, 41 figures", "summary": "Reservoir computing (RC) represents a class of state-space models (SSMs)\ncharacterized by a fixed state transition mechanism (the reservoir) and a\nflexible readout layer that maps from the state space. It is a paradigm of\ncomputational dynamical systems that harnesses the transient dynamics of\nhigh-dimensional state spaces for efficient processing of temporal data. Rooted\nin concepts from recurrent neural networks, RC achieves exceptional\ncomputational power by decoupling the training of the dynamic reservoir from\nthe linear readout layer, thereby circumventing the complexities of\ngradient-based optimization. This work presents a systematic exploration of RC,\naddressing its foundational properties such as the echo state property, fading\nmemory, and reservoir capacity through the lens of dynamical systems theory. We\nformalize the interplay between input signals and reservoir states,\ndemonstrating the conditions under which reservoirs exhibit stability and\nexpressive power. Further, we delve into the computational trade-offs and\nrobustness characteristics of RC architectures, extending the discussion to\ntheir applications in signal processing, time-series prediction, and control\nsystems. The analysis is complemented by theoretical insights into\noptimization, training methodologies, and scalability, highlighting open\nchallenges and potential directions for advancing the theoretical underpinnings\nof RC.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u63a2\u8ba8\u4e86Reservoir Computing\uff08RC\uff09\u7684\u7406\u8bba\u57fa\u7840\u3001\u5c5e\u6027\u548c\u5e94\u7528\uff0c\u5f3a\u8c03\u5176\u5728\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u9ad8\u6548\u6027\uff0c\u5e76\u6307\u51fa\u672a\u6765\u6311\u6218\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u4f20\u7edf\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u590d\u6742\u6027\uff0c\u901a\u8fc7\u56fa\u5b9areservoir\u548c\u7ebf\u6027readout\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u6df1\u5316\u52a8\u6001\u7cfb\u7edf\u7406\u8bba\u7406\u89e3\u3002", "method": "\u65b9\u6cd5\u662f\u901a\u8fc7\u52a8\u6001\u7cfb\u7edf\u7406\u8bba\u5f62\u5f0f\u5316RC\u7684\u5c5e\u6027\uff0c\u5982echo state property\u548cfading memory\uff0c\u5e76\u5206\u6790\u8f93\u5165\u4fe1\u53f7\u4e0ereservoir\u72b6\u6001\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u7ed3\u679c\u5c55\u793a\u4e86RC\u7684\u7a33\u5b9a\u6027\u548c\u8868\u73b0\u529b\u6761\u4ef6\u3001\u8ba1\u7b97\u6743\u8861\uff0c\u4ee5\u53ca\u5728\u4fe1\u53f7\u5904\u7406\u3001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u548c\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u7ed3\u8bba\u7a81\u51fa\u4e86RC\u7406\u8bba\u7684\u4f18\u5316\u3001\u8bad\u7ec3\u65b9\u6cd5\u548c\u53ef\u6269\u5c55\u6027\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u53d1\u5c55\u7684\u6f5c\u5728\u65b9\u5411\u3002"}}
{"id": "2504.11555", "pdf": "https://arxiv.org/pdf/2504.11555", "abs": "https://arxiv.org/abs/2504.11555", "authors": ["Yahya Sattar", "Sunmook Choi", "Yassir Jedra", "Maryam Fazel", "Sarah Dean"], "title": "Sub-optimality of the Separation Principle for Quadratic Control from Bilinear Observations", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY", "stat.ML"], "comment": null, "summary": "We consider the problem of controlling a linear dynamical system from\nbilinear observations with minimal quadratic cost. Despite the similarity of\nthis problem to standard linear quadratic Gaussian (LQG) control, we show that\nwhen the observation model is bilinear, neither does the Separation Principle\nhold, nor is the optimal controller affine in the estimated state. Moreover,\nthe cost-to-go is non-convex in the control input. Hence, finding an analytical\nexpression for the optimal feedback controller is difficult in general. Under\ncertain settings, we show that the standard LQG controller locally maximizes\nthe cost instead of minimizing it. Furthermore, the optimal controllers\n(derived analytically) are not unique and are nonlinear in the estimated state.\nWe also introduce a notion of input-dependent observability and derive\nconditions under which the Kalman filter covariance remains bounded. We\nillustrate our theoretical results through numerical experiments in multiple\nsynthetic settings.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e26\u53cc\u7ebf\u6027\u89c2\u6d4b\u7684\u7ebf\u6027\u7cfb\u7edf\u63a7\u5236\uff0c\u5c55\u793a\u4e86\u6807\u51c6LQG\u65b9\u6cd5\u5931\u6548\uff0c\u5e76\u5f15\u5165\u65b0\u6982\u5ff5\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u89c2\u6d4b\u4e3a\u53cc\u7ebf\u6027\u65f6\u7684\u63a7\u5236\u6311\u6218\uff0c\u4e0e\u6807\u51c6LQG\u4e0d\u540c\uff0c\u540e\u8005Separation Principle\u6210\u7acb\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5206\u6790\u8bc1\u660e\u6700\u4f18\u63a7\u5236\u5668\u975e\u7ebf\u6027\uff0c\u5f15\u5165\u8f93\u5165\u4f9d\u8d56\u7684\u53ef\u89c2\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6807\u51c6LQG\u53ef\u80fd\u6700\u5927\u5316\u6210\u672c\uff0c\u6700\u4f18\u63a7\u5236\u5668\u4e0d\u552f\u4e00\u4e14\u975e\u7ebf\u6027\uff0c\u5bfc\u51fa\u4e86\u5361\u5c14\u66fc\u6ee4\u6ce2\u534f\u65b9\u5dee\u6709\u754c\u7684\u6761\u4ef6\u3002", "conclusion": "\u7ed3\u8bba\u662f\u53cc\u7ebf\u6027\u89c2\u6d4b\u4f7f\u63a7\u5236\u66f4\u590d\u6742\uff0c\u9700\u8981\u65b0\u7684\u975e\u7ebf\u6027\u63a7\u5236\u5668\u3002"}}
{"id": "2504.12254", "pdf": "https://arxiv.org/pdf/2504.12254", "abs": "https://arxiv.org/abs/2504.12254", "authors": ["Mahmoud Salhab", "Marwan Elghitany", "Shameed Sait", "Syed Sibghat Ullah", "Mohammad Abusheikh", "Hasan Abusheikh"], "title": "Advancing Arabic Speech Recognition Through Large-Scale Weakly Supervised Learning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Automatic speech recognition (ASR) is crucial for human-machine interaction\nin diverse applications like conversational agents, industrial robotics, call\ncenter automation, and automated subtitling. However, developing\nhigh-performance ASR models remains challenging, particularly for low-resource\nlanguages like Arabic, due to the scarcity of large, labeled speech datasets,\nwhich are costly and labor-intensive to produce. In this work, we employ weakly\nsupervised learning to train an Arabic ASR model using the Conformer\narchitecture. Our model is trained from scratch on 15,000 hours of weakly\nannotated speech data covering both Modern Standard Arabic (MSA) and Dialectal\nArabic (DA), eliminating the need for costly manual transcriptions. Despite the\nabsence of human-verified labels, our approach attains state-of-the-art (SOTA)\nperformance, exceeding all previous efforts in the field of Arabic ASR on the\nstandard benchmarks. By demonstrating the effectiveness of weak supervision as\na scalable, cost-efficient alternative to traditional supervised approaches,\npaving the way for improved ASR systems in low resource settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u5f31\u76d1\u7763\u5b66\u4e60\u8bad\u7ec3\u4e86\u4e00\u4e2a\u963f\u62c9\u4f2f\u8bed\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u6a21\u578b\uff0c\u91c7\u7528Conformer\u67b6\u6784\uff0c\u572815,000\u5c0f\u65f6\u5f31\u6807\u6ce8\u8bed\u97f3\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u800c\u65e0\u9700\u624b\u52a8\u8f6c\u5f55\u3002", "motivation": "\u9488\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u5982\u963f\u62c9\u4f2f\u8bed\uff0c\u5f00\u53d1\u9ad8\u6027\u80fdASR\u6a21\u578b\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u7f3a\u4e4f\u5927\u578b\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u4e14\u91c7\u96c6\u6210\u672c\u9ad8\u3002", "method": "\u91c7\u7528\u5f31\u76d1\u7763\u5b66\u4e60\uff0c\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3Conformer\u67b6\u6784\u6a21\u578b\uff0c\u4f7f\u752815,000\u5c0f\u65f6\u8986\u76d6\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\u548c\u65b9\u8a00\u963f\u62c9\u4f2f\u8bed\u7684\u5f31\u6807\u6ce8\u8bed\u97f3\u6570\u636e\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8d85\u8fc7\u4e86\u4e4b\u524d\u7684\u6240\u6709\u963f\u62c9\u4f2f\u8bedASR\u52aa\u529b\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5f31\u76d1\u7763\u5b66\u4e60\u4f5c\u4e3a\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u6210\u672c\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u7684\u6709\u6548\u6027\uff0c\u4e3a\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684ASR\u7cfb\u7edf\u6539\u8fdb\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2504.11808", "pdf": "https://arxiv.org/pdf/2504.11808", "abs": "https://arxiv.org/abs/2504.11808", "authors": ["Kishan Gurumurthy", "Himanshu Pal", "Charu Sharma"], "title": "Federated Spectral Graph Transformers Meet Neural Ordinary Differential Equations for Non-IID Graphs", "categories": ["cs.LG"], "comment": "The first two listed authors contributed equally to this work", "summary": "Graph Neural Network (GNN) research is rapidly advancing due to GNNs'\ncapacity to learn distributed representations from graph-structured data.\nHowever, centralizing large volumes of real-world graph data for GNN training\nis often impractical due to privacy concerns, regulatory restrictions, and\ncommercial competition. Federated learning (FL), a distributed learning\nparadigm, offers a solution by preserving data privacy with collaborative model\ntraining. Despite progress in training huge vision and language models,\nfederated learning for GNNs remains underexplored. To address this challenge,\nwe present a novel method for federated learning on GNNs based on spectral GNNs\nequipped with neural ordinary differential equations (ODE) for better\ninformation capture, showing promising results across both homophilic and\nheterophilic graphs. Our approach effectively handles non-Independent and\nIdentically Distributed (non-IID) data, while also achieving performance\ncomparable to existing methods that only operate on IID data. It is designed to\nbe privacy-preserving and bandwidth-optimized, making it suitable for\nreal-world applications such as social network analysis, recommendation\nsystems, and fraud detection, which often involve complex, non-IID, and\nheterophilic graph structures. Our results in the area of federated learning on\nnon-IID heterophilic graphs demonstrate significant improvements, while also\nachieving better performance on homophilic graphs. This work highlights the\npotential of federated learning in diverse and challenging graph settings.\nOpen-source code available on GitHub\n(https://github.com/SpringWiz11/Fed-GNODEFormer).", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8054\u90a6\u5b66\u4e60\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u4f7f\u7528\u8c31\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u795e\u7ecfODE\u5904\u7406\u975eIID\u548c\u5f02\u8d28\u56fe\u6570\u636e\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u548c\u9ad8\u6548\u6027\u80fd\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u9762\u4e34\u6570\u636e\u96c6\u4e2d\u5316\u96be\u9898\uff0c\u7531\u4e8e\u9690\u79c1\u3001\u6cd5\u89c4\u548c\u7ade\u4e89\u95ee\u9898\uff0c\u8054\u90a6\u5b66\u4e60\u6210\u4e3a\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5bf9GNN\u7684\u63a2\u7d22\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u8c31\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u795e\u7ecfODE\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u5728\u540c\u8d28\u548c\u5f02\u8d28\u56fe\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5904\u7406\u975eIID\u6570\u636e\uff0c\u6027\u80fd\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\uff0c\u5e76\u4f18\u5316\u5e26\u5bbd\u3002", "conclusion": "\u7a81\u51fa\u4e86\u8054\u90a6\u5b66\u4e60\u5728\u591a\u6837\u56fe\u7ed3\u6784\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u4ee3\u7801\u3002"}}
{"id": "2504.11589", "pdf": "https://arxiv.org/pdf/2504.11589", "abs": "https://arxiv.org/abs/2504.11589", "authors": ["Kevin Weinberger", "Robert-Jeron Reifert", "Aydin Sezgin", "Mehdi Bennis"], "title": "Accelerated Recovery with RIS: Designing Wireless Resilience in Mission-Critical Environments", "categories": ["eess.SP", "cs.SY", "eess.SY"], "comment": "6 pages, 3 figures, submitted to Globecom 2025", "summary": "As 6G and beyond redefine connectivity, wireless networks become the\nfoundation of critical operations, making resilience more essential than ever.\nWith this shift, wireless systems cannot only take on vital services previously\nhandled by wired infrastructures but also enable novel innovative applications\nthat would not be possible with wired systems. As a result, there is a pressing\ndemand for strategies that can adapt to dynamic channel conditions,\ninterference, and unforeseen disruptions, ensuring seamless and reliable\nperformance in an increasingly complex environment. Despite considerable\nresearch, existing resilience assessments lack comprehensive key performance\nindicators (KPIs), especially those quantifying its adaptability, which are\nvital for identifying a system's capacity to rapidly adapt and reallocate\nresources. In this work, we bridge this gap by proposing a novel framework that\nexplicitly quantifies the adaption performance by augmenting the gradient of\nthe system's rate function. To further enhance the network resilience, we\nintegrate Reconfigurable Intelligent Surfaces (RISs) into our framework due to\ntheir capability to dynamically reshape the propagation environment while\nproviding alternative channel paths. Numerical results show that gradient\naugmentation enhances resilience by improving adaptability under adverse\nconditions while proactively preparing for future disruptions.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u65b0\u6846\u67b6\u6765\u63d0\u53476G\u65e0\u7ebf\u7f51\u7edc\u7684\u5f39\u6027\uff0c\u901a\u8fc7\u91cf\u5316\u9002\u5e94\u6027\u80fd\u548c\u6574\u5408\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RISs\uff09\u3002", "motivation": "6G\u7f51\u7edc\u4f7f\u65e0\u7ebf\u7cfb\u7edf\u627f\u62c5\u5173\u952e\u670d\u52a1\uff0c\u4f46\u73b0\u6709\u5f39\u6027\u8bc4\u4f30\u7f3a\u4e4f\u9002\u5e94\u6027\u5173\u952e\u6027\u80fd\u6307\u6807\uff08KPIs\uff09\uff0c\u9700\u8981\u7b56\u7565\u6765\u5e94\u5bf9\u52a8\u6001\u73af\u5883\u3002", "method": "\u63d0\u51fa\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u7cfb\u7edf\u901f\u7387\u51fd\u6570\u68af\u5ea6\u91cf\u5316\u9002\u5e94\u6027\u80fd\uff0c\u5e76\u6574\u5408RISs\u52a8\u6001\u91cd\u5851\u4f20\u64ad\u73af\u5883\u3002", "result": "\u6570\u503c\u7ed3\u679c\u663e\u793a\uff0c\u68af\u5ea6\u589e\u5f3a\u63d0\u9ad8\u4e86\u4e0d\u5229\u6761\u4ef6\u4e0b\u7684\u9002\u5e94\u6027\u548c\u5f39\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u4e2d\u65ad\u505a\u51c6\u5907\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u65e0\u7ebf\u7f51\u7edc\u7684\u5f39\u6027\u6027\u80fd\u3002"}}
{"id": "2504.12299", "pdf": "https://arxiv.org/pdf/2504.12299", "abs": "https://arxiv.org/abs/2504.12299", "authors": ["Marko Tot", "Shu Ishida", "Abdelhak Lemkhenter", "David Bignell", "Pallavi Choudhury", "Chris Lovett", "Luis Fran\u00e7a", "Matheus Ribeiro Furtado de Mendon\u00e7a", "Tarun Gupta", "Darren Gehring", "Sam Devlin", "Sergio Valcarcel Macua", "Raluca Georgescu"], "title": "Adapting a World Model for Trajectory Following in a 3D Game", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Imitation learning is a powerful tool for training agents by leveraging\nexpert knowledge, and being able to replicate a given trajectory is an integral\npart of it. In complex environments, like modern 3D video games, distribution\nshift and stochasticity necessitate robust approaches beyond simple action\nreplay. In this study, we apply Inverse Dynamics Models (IDM) with different\nencoders and policy heads to trajectory following in a modern 3D video game --\nBleeding Edge. Additionally, we investigate several future alignment strategies\nthat address the distribution shift caused by the aleatoric uncertainty and\nimperfections of the agent. We measure both the trajectory deviation distance\nand the first significant deviation point between the reference and the agent's\ntrajectory and show that the optimal configuration depends on the chosen\nsetting. Our results show that in a diverse data setting, a GPT-style policy\nhead with an encoder trained from scratch performs the best, DINOv2 encoder\nwith the GPT-style policy head gives the best results in the low data regime,\nand both GPT-style and MLP-style policy heads had comparable results when\npre-trained on a diverse setting and fine-tuned for a specific behaviour\nsetting.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u57283D\u89c6\u9891\u6e38\u620f\u4e2d\u4f7f\u7528\u9006\u52a8\u6001\u6a21\u578b\u6539\u8fdb\u6a21\u4eff\u5b66\u4e60\uff0c\u4ee5\u5e94\u5bf9\u5206\u5e03\u504f\u79fb\u548c\u968f\u673a\u6027\u3002\u7ed3\u679c\u663e\u793a\u4e0d\u540c\u914d\u7f6e\u5728\u4e0d\u540c\u6570\u636e\u573a\u666f\u4e0b\u4f18\u8d8a\u3002", "motivation": "\u52a8\u673a\u662f\u6a21\u4eff\u5b66\u4e60\u5728\u590d\u6742\u73af\u5883\u4e2d\u9700\u8981\u66f4\u7a33\u5065\u7684\u65b9\u6cd5\u6765\u5904\u7406\u5206\u5e03\u504f\u79fb\u548c\u968f\u673a\u6027\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5e94\u7528\u4e0d\u540c\u7f16\u7801\u5668\u548c\u7b56\u7565\u5934\u7684\u9006\u52a8\u6001\u6a21\u578b\uff0c\u4ee5\u53ca\u672a\u6765\u5bf9\u9f50\u7b56\u7565\uff0c\u5728Bleeding Edge\u6e38\u620f\u4e2d\u6d4b\u8bd5\u8f68\u8ff9\u8ddf\u968f\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u591a\u6837\u6570\u636e\u8bbe\u7f6e\u4e0b\uff0cGPT-style\u7b56\u7565\u5934\u548c\u4ece\u96f6\u8bad\u7ec3\u7f16\u7801\u5668\u6700\u4f73\uff1b\u5728\u4f4e\u6570\u636e\u4e0b\uff0cDINOv2\u7f16\u7801\u5668\u548cGPT-style\u7b56\u7565\u5934\u6700\u4f73\uff1b\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u540e\uff0cGPT\u548cMLP\u7b56\u7565\u5934\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "\u7ed3\u8bba\u662f\u6700\u4f73\u914d\u7f6e\u53d6\u51b3\u4e8e\u5177\u4f53\u8bbe\u7f6e\uff0c\u7a81\u51fa\u4e86\u7ec4\u4ef6\u9009\u62e9\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2504.11811", "pdf": "https://arxiv.org/pdf/2504.11811", "abs": "https://arxiv.org/abs/2504.11811", "authors": ["Marco Forgione", "Ankush Chakrabarty", "Dario Piga", "Matteo Rufolo", "Alberto Bemporad"], "title": "Manifold meta-learning for reduced-complexity neural system identification", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "System identification has greatly benefited from deep learning techniques,\nparticularly for modeling complex, nonlinear dynamical systems with partially\nunknown physics where traditional approaches may not be feasible. However, deep\nlearning models often require large datasets and significant computational\nresources at training and inference due to their high-dimensional\nparameterizations. To address this challenge, we propose a meta-learning\nframework that discovers a low-dimensional manifold within the parameter space\nof an over-parameterized neural network architecture. This manifold is learned\nfrom a meta-dataset of input-output sequences generated by a class of related\ndynamical systems, enabling efficient model training while preserving the\nnetwork's expressive power for the considered system class. Unlike bilevel\nmeta-learning approaches, our method employs an auxiliary neural network to map\ndatasets directly onto the learned manifold, eliminating the need for costly\nsecond-order gradient computations during meta-training and reducing the number\nof first-order updates required in inference, which could be expensive for\nlarge models. We validate our approach on a family of Bouc-Wen oscillators,\nwhich is a well-studied nonlinear system identification benchmark. We\ndemonstrate that we are able to learn accurate models even in small-data\nscenarios.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u53c2\u6570\u7a7a\u95f4\u4f4e\u7ef4\u6d41\u5f62\uff0c\u63d0\u9ad8\u795e\u7ecf\u7f51\u7edc\u5728\u7cfb\u7edf\u8bc6\u522b\u4e2d\u7684\u6570\u636e\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u6df1\u5c42\u5b66\u4e60\u6a21\u578b\u5728\u5efa\u6a21\u590d\u6742\u975e\u7ebf\u6027\u52a8\u6001\u7cfb\u7edf\u65f6\u9700\u8981\u5927\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u4e0d\u53ef\u884c\u3002", "method": "\u63d0\u51fa\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u8f85\u52a9\u795e\u7ecf\u7f51\u7edc\u76f4\u63a5\u6620\u5c04\u6570\u636e\u96c6\u5230\u4f4e\u7ef4\u6d41\u5f62\uff0c\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0c\u907f\u514d\u9ad8\u9636\u68af\u5ea6\u8ba1\u7b97\u3002", "result": "\u5728Bouc-Wen\u632f\u8361\u5668benchmark\u4e0a\u9a8c\u8bc1\uff0c\u5373\u4f7f\u5728\u5c0f\u6570\u636e\u573a\u666f\u4e0b\u4e5f\u80fd\u5b66\u4e60\u51c6\u786e\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u7cfb\u7edf\u8bc6\u522b\u7684\u6548\u7387\uff0c\u9002\u7528\u4e8e\u90e8\u5206\u672a\u77e5\u7269\u7406\u7cfb\u7edf\u7684\u5efa\u6a21\u3002"}}
{"id": "2504.11460", "pdf": "https://arxiv.org/pdf/2504.11460", "abs": "https://arxiv.org/abs/2504.11460", "authors": ["Tobias Hallmen", "Robin-Nico Kampa", "Fabian Deuser", "Norbert Oswald", "Elisabeth Andr\u00e9"], "title": "Semantic Matters: Multimodal Features for Affective Analysis", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "In this study, we present our methodology for two tasks: the Behavioural\nAmbivalence/Hesitancy (BAH) Recognition Challenge and the Emotional Mimicry\nIntensity (EMI) Estimation Challenge, both conducted as part of the 8th\nWorkshop and Competition on Affective & Behavior Analysis in-the-wild. Building\non previous work, we utilize a Wav2Vec 2.0 model pre-trained on a large podcast\ndataset to extract various audio features, capturing both linguistic and\nparalinguistic information. Our approach incorporates a\nvalence-arousal-dominance (VAD) module derived from Wav2Vec 2.0, a BERT-like\nencoder, and a vision transformer (ViT) with predictions subsequently processed\nthrough a long short-term memory (LSTM) architecture for temporal modeling. In\nthis iteration, we integrate the textual and visual modality into our analysis,\nrecognizing that semantic content provides valuable contextual cues and\nunderscoring that the meaning of speech often conveys more critical insights\nthan its acoustic counterpart alone. Fusing in the vision modality helps in\nsome cases to interpret the textual modality more precisely. This combined\napproach yields significant performance improvements over baseline methods.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u97f3\u9891\u3001\u6587\u672c\u548c\u89c6\u89c9\u591a\u6a21\u6001\u65b9\u6cd5\u63d0\u5347BAH\u548cEMI\u6311\u6218\u7684\u8868\u73b0\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u57fa\u4e8e\u5148\u524d\u5de5\u4f5c\uff0c\u6574\u5408\u6587\u672c\u548c\u89c6\u89c9\u6a21\u6001\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u60c5\u611f\u5206\u6790\u4e2d\u7684\u8bed\u5883\u3002", "method": "\u5229\u7528Wav2Vec 2.0\u63d0\u53d6\u97f3\u9891\u7279\u5f81\uff0c\u7ed3\u5408VAD\u6a21\u5757\u3001BERT-like\u7f16\u7801\u5668\u3001ViT\u548cLSTM\u8fdb\u884c\u65f6\u5e8f\u5efa\u6a21\uff0c\u5e76\u878d\u5408\u591a\u79cd\u6a21\u6001\u3002", "result": "\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u6a21\u6001\u7ed3\u5408\u63d0\u9ad8\u4e86\u884c\u4e3a\u77db\u76fe\u8bc6\u522b\u548c\u60c5\u611f\u6a21\u4eff\u5f3a\u5ea6\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2504.11816", "pdf": "https://arxiv.org/pdf/2504.11816", "abs": "https://arxiv.org/abs/2504.11816", "authors": ["Kihyun Kim", "Jinwoo Kim", "Hyunsun Chung", "Myung-Hoon Cha", "Hong-Yeon Kim", "Youngjae Kim"], "title": "Cost-Efficient LLM Serving in the Cloud: VM Selection with KV Cache Offloading", "categories": ["cs.LG", "cs.DC"], "comment": "10 pages, 6 figures", "summary": "LLM inference is essential for applications like text summarization,\ntranslation, and data analysis, but the high cost of GPU instances from Cloud\nService Providers (CSPs) like AWS is a major burden. This paper proposes\nInferSave, a cost-efficient VM selection framework for cloud based LLM\ninference. InferSave optimizes KV cache offloading based on Service Level\nObjectives (SLOs) and workload charac teristics, estimating GPU memory needs,\nand recommending cost-effective VM instances. Additionally, the Compute Time\nCalibration Function (CTCF) improves instance selection accuracy by adjusting\nfor discrepancies between theoretical and actual GPU performance. Experiments\non AWS GPU instances show that selecting lower-cost instances without KV cache\noffloading improves cost efficiency by up to 73.7% for online workloads, while\nKV cache offloading saves up to 20.19% for offline workloads.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faInferSave\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316KV\u7f13\u5b58\u5378\u8f7d\u548cVM\u9009\u62e9\uff0c\u663e\u8457\u964d\u4f4eLLM\u63a8\u7406\u7684\u4e91GPU\u6210\u672c\u3002", "motivation": "LLM\u63a8\u7406\u5e94\u7528\u4e2d\uff0c\u4e91\u670d\u52a1\u63d0\u4f9b\u5546\u5982AWS\u7684GPU\u5b9e\u4f8b\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u6210\u672c\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faInferSave\u6846\u67b6\uff0c\u57fa\u4e8e\u670d\u52a1\u6c34\u5e73\u76ee\u6807(SLO)\u548c\u5de5\u4f5c\u8d1f\u8f7d\u7279\u5f81\u4f18\u5316KV\u7f13\u5b58\u5378\u8f7d\uff0c\u5e76\u4f7f\u7528\u8ba1\u7b97\u65f6\u95f4\u6821\u51c6\u51fd\u6570(CTCF)\u6539\u8fdb\u5b9e\u4f8b\u9009\u62e9\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u5728AWS GPU\u5b9e\u4f8b\u4e0a\u663e\u793a\uff0c\u65e0KV\u7f13\u5b58\u5378\u8f7d\u65f6\u6210\u672c\u6548\u7387\u63d0\u9ad8\u591a\u8fbe73.7%\uff0c\u6709\u5378\u8f7d\u65f6\u4e3a\u79bb\u7ebf\u5de5\u4f5c\u8d1f\u8f7d\u8282\u7701\u591a\u8fbe20.19%\u3002", "conclusion": "InferSave\u6846\u67b6\u6709\u6548\u5730\u63d0\u9ad8\u4e86LLM\u63a8\u7406\u7684\u6210\u672c\u6548\u7387\u3002"}}
{"id": "2504.11653", "pdf": "https://arxiv.org/pdf/2504.11653", "abs": "https://arxiv.org/abs/2504.11653", "authors": ["David Black", "Septimiu Salcudean"], "title": "Linearity, Time Invariance, and Passivity of a Novice Person in Human Teleoperation", "categories": ["cs.HC", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Low-cost teleguidance of medical procedures is becoming essential to provide\nhealthcare to remote and underserved communities. Human teleoperation is a\npromising new method for guiding a novice person with relatively high precision\nand efficiency through a mixed reality (MR) interface. Prior work has shown\nthat the novice, or \"follower\", can reliably track the MR input with\nperformance not unlike a telerobotic system. As a consequence, it is of\ninterest to understand and control the follower's dynamics to optimize the\nsystem performance and permit stable and transparent bilateral teleoperation.\nTo this end, linearity, time-invariance, inter-axis coupling, and passivity are\nimportant in teleoperation and controller design. This paper therefore explores\nthese effects with regard to the follower person in human teleoperation. It is\ndemonstrated through modeling and experiments that the follower can indeed be\ntreated as approximately linear and time invariant, with little coupling and a\nlarge excess of passivity at practical frequencies. Furthermore, a stochastic\nmodel of the follower dynamics is derived. These results will permit controller\ndesign and analysis to improve the performance of human teleoperation.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u5728\u4eba\u7c7b\u9065\u64cd\u4f5c\u4e2d\uff0c\u8ffd\u968f\u8005\u53ef\u89c6\u4e3a\u8fd1\u4f3c\u7ebf\u6027\u548c\u65f6\u4e0d\u53d8\u7684\uff0c\u5177\u6709\u5c0f\u8026\u5408\u548c\u9ad8\u949d\u6027\uff0c\u5e76\u5bfc\u51fa\u4e86\u968f\u673a\u6a21\u578b\u4ee5\u4f18\u5316\u63a7\u5236\u5668\u8bbe\u8ba1\u3002", "motivation": "\u52a8\u673a\u662f\u4e3a\u504f\u8fdc\u548c underserved \u793e\u533a\u63d0\u4f9b\u4f4e\u6210\u672c\u8fdc\u7a0b\u533b\u7597\u6307\u5bfc\uff0c\u5e76\u7406\u89e3\u8ffd\u968f\u8005\u52a8\u6001\u4ee5\u63d0\u5347\u9065\u64cd\u4f5c\u6027\u80fd\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u901a\u8fc7\u5efa\u6a21\u548c\u5b9e\u9a8c\u63a2\u7d22\u8ffd\u968f\u8005\u7684\u7ebf\u6027\u3001\u65f6\u4e0d\u53d8\u6027\u3001\u8f74\u95f4\u8026\u5408\u548c\u949d\u6027\uff0c\u5e76\u63a8\u5bfc\u968f\u673a\u52a8\u529b\u5b66\u6a21\u578b\u3002", "result": "\u7ed3\u679c\u663e\u793a\u8ffd\u968f\u8005\u8fd1\u4f3c\u7ebf\u6027\u4e14\u65f6\u4e0d\u53d8\uff0c\u8026\u5408\u5c0f\uff0c\u949d\u6027\u5145\u8db3\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8fd9\u4e9b\u53d1\u73b0\u53ef\u7528\u4e8e\u8bbe\u8ba1\u63a7\u5236\u5668\uff0c\u63d0\u9ad8\u4eba\u7c7b\u9065\u64cd\u4f5c\u7684\u7a33\u5b9a\u6027\u548c\u900f\u660e\u5ea6\u3002"}}
{"id": "2504.11469", "pdf": "https://arxiv.org/pdf/2504.11469", "abs": "https://arxiv.org/abs/2504.11469", "authors": ["Guillaume Garret", "Antoine Vacavant", "Carole Frindel"], "title": "Do Segmentation Models Understand Vascular Structure? A Blob-Based XAI Framework", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Open access version of an article submitted to Medical Image\n  Understanding and Analysis (MIUA) 2025", "summary": "Deep learning models have achieved impressive performance in medical image\nsegmentation, yet their black-box nature limits clinical adoption. In vascular\napplications, trustworthy segmentation should rely on both local image cues and\nglobal anatomical structures, such as vessel connectivity or branching.\nHowever, the extent to which models leverage such global context remains\nunclear. We present a novel explainability pipeline for 3D vessel segmentation,\ncombining gradient-based attribution with graph-guided point selection and a\nblob-based analysis of Saliency maps. Using vascular graphs extracted from\nground truth, we define anatomically meaningful points of interest (POIs) and\nassess the contribution of input voxels via Saliency maps. These are analyzed\nat both global and local scales using a custom blob detector. Applied to IRCAD\nand Bullitt datasets, our analysis shows that model decisions are dominated by\nhighly localized attribution blobs centered near POIs. Attribution features\nshow little correlation with vessel-level properties such as thickness,\ntubularity, or connectivity -- suggesting limited use of global anatomical\nreasoning. Our results underline the importance of structured explainability\ntools and highlight the current limitations of segmentation models in capturing\nglobal vascular context.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u76843D\u8840\u7ba1\u5206\u5272\u53ef\u89e3\u91ca\u6027\u7ba1\u9053\uff0c\u5206\u6790\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4f9d\u8d56\u5c40\u90e8\u7ebf\u7d22\u800c\u975e\u5168\u5c40\u89e3\u5256\u7ed3\u6784\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u533b\u5b66\u56fe\u50cf\u5206\u5272\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u9ed1\u7bb1\u6027\u8d28\u9650\u5236\u4e34\u5e8a\u5e94\u7528\uff0c\u4e14\u5bf9\u5168\u5c40\u89e3\u5256\u7ed3\u6784\u7684\u5229\u7528\u4e0d\u660e\u3002", "method": "\u7ed3\u5408\u68af\u5ea6\u5f52\u56e0\u3001\u56fe\u6307\u5bfc\u70b9\u9009\u62e9\u548c\u57fa\u4e8e\u6591\u70b9\u7684\u663e\u8457\u6027\u56fe\u5206\u6790\uff0c\u4f7f\u7528ground truth\u63d0\u53d6\u8840\u7ba1\u56fe\u5b9a\u4e49\u5174\u8da3\u70b9\uff0c\u5e76\u8bc4\u4f30\u8f93\u5165\u4f53\u7d20\u8d21\u732e\u3002", "result": "\u5728IRCAD\u548cBullitt\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u51b3\u7b56\u4e3b\u8981\u7531\u5c40\u90e8\u5f52\u56e0\u6591\u70b9\u4e3b\u5bfc\uff0c\u4e0e\u8840\u7ba1\u5c5e\u6027\u76f8\u5173\u6027\u4f4e\uff0c\u8868\u660e\u5168\u5c40\u89e3\u5256\u63a8\u7406\u5229\u7528\u6709\u9650\u3002", "conclusion": "\u5f3a\u8c03\u7ed3\u6784\u5316\u53ef\u89e3\u91ca\u6027\u5de5\u5177\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u5206\u5272\u6a21\u578b\u5728\u6355\u83b7\u5168\u5c40\u8840\u7ba1\u4e0a\u4e0b\u6587\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2504.11830", "pdf": "https://arxiv.org/pdf/2504.11830", "abs": "https://arxiv.org/abs/2504.11830", "authors": ["Rohan Hitchcock", "Gary W. Delaney", "Jonathan H. Manton", "Richard Scalzo", "Jingge Zhu"], "title": "Emergence of Computational Structure in a Neural Network Physics Simulator", "categories": ["cs.LG"], "comment": "35 pages", "summary": "Neural networks often have identifiable computational structures - components\nof the network which perform an interpretable algorithm or task - but the\nmechanisms by which these emerge and the best methods for detecting these\nstructures are not well understood. In this paper we investigate the emergence\nof computational structure in a transformer-like model trained to simulate the\nphysics of a particle system, where the transformer's attention mechanism is\nused to transfer information between particles. We show that (a) structures\nemerge in the attention heads of the transformer which learn to detect particle\ncollisions, (b) the emergence of these structures is associated to degenerate\ngeometry in the loss landscape, and (c) the dynamics of this emergence follows\na power law. This suggests that these components are governed by a degenerate\n\"effective potential\". These results have implications for the convergence time\nof computational structure within neural networks and suggest that the\nemergence of computational structure can be detected by studying the dynamics\nof network components.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86transformer-like\u6a21\u578b\u5728\u6a21\u62df\u7c92\u5b50\u7cfb\u7edf\u65f6\uff0c\u8ba1\u7b97\u7ed3\u6784\u7684\u51fa\u73b0\uff0c\u53d1\u73b0\u6ce8\u610f\u529b\u5934\u5b66\u4f1a\u68c0\u6d4b\u7c92\u5b50\u78b0\u649e\uff0c\u4e0e\u635f\u5931\u666f\u89c2\u7684\u9000\u5316\u51e0\u4f55\u76f8\u5173\uff0c\u5e76\u9075\u5faa\u5e42\u5f8b\u52a8\u6001\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u4e2d\u8ba1\u7b97\u7ed3\u6784\u7684\u51fa\u73b0\u53ca\u5176\u68c0\u6d4b\u673a\u5236\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002", "method": "\u8bad\u7ec3transformer-like\u6a21\u578b\u6a21\u62df\u7c92\u5b50\u7cfb\u7edf\uff0c\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\u4f20\u8f93\u7c92\u5b50\u95f4\u4fe1\u606f\uff0c\u5e76\u5206\u6790\u6ce8\u610f\u529b\u5934\u4e2d\u7ed3\u6784\u7684\u51fa\u73b0\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a(a) \u6ce8\u610f\u529b\u5934\u5b66\u4f1a\u68c0\u6d4b\u7c92\u5b50\u78b0\u649e\uff0c(b) \u7ed3\u6784\u7684\u51fa\u73b0\u4e0e\u635f\u5931\u666f\u89c2\u7684\u9000\u5316\u51e0\u4f55\u76f8\u5173\uff0c(c) \u52a8\u6001\u9075\u5faa\u5e42\u5f8b\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u5bf9\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\u7ed3\u6784\u7684\u6536\u655b\u65f6\u95f4\u6709\u542f\u793a\uff0c\u5e76\u5efa\u8bae\u901a\u8fc7\u7814\u7a76\u7f51\u7edc\u7ec4\u4ef6\u52a8\u6001\u6765\u68c0\u6d4b\u7ed3\u6784\u51fa\u73b0\u3002"}}
{"id": "2504.11696", "pdf": "https://arxiv.org/pdf/2504.11696", "abs": "https://arxiv.org/abs/2504.11696", "authors": ["Kuiyuan Ding", "Caili Guo", "Yang Yang", "Wuxia Hu", "Yonina C. Eldar"], "title": "A New Paradigm of User-Centric Wireless Communication Driven by Large Language Models", "categories": ["cs.NI", "cs.IR", "cs.SY", "eess.SY"], "comment": "8 pages, 5 figures", "summary": "The next generation of wireless communications seeks to deeply integrate\nartificial intelligence (AI) with user-centric communication networks, with the\ngoal of developing AI-native networks that more accurately address user\nrequirements. The rapid development of large language models (LLMs) offers\nsignificant potential in realizing these goals. However, existing efforts that\nleverage LLMs for wireless communication often overlook the considerable gap\nbetween human natural language and the intricacies of real-world communication\nsystems, thus failing to fully exploit the capabilities of LLMs. To address\nthis gap, we propose a novel LLM-driven paradigm for wireless communication\nthat innovatively incorporates the nature language to structured query language\n(NL2SQL) tool. Specifically, in this paradigm, user personal requirements is\nthe primary focus. Upon receiving a user request, LLMs first analyze the user\nintent in terms of relevant communication metrics and system parameters.\nSubsequently, a structured query language (SQL) statement is generated to\nretrieve the specific parameter values from a high-performance real-time\ndatabase. We further utilize LLMs to formulate and solve an optimization\nproblem based on the user request and the retrieved parameters. The solution to\nthis optimization problem then drives adjustments in the communication system\nto fulfill the user's requirements. To validate the feasibility of the proposed\nparadigm, we present a prototype system. In this prototype, we consider\nuser-request centric semantic communication (URC-SC) system in which a dynamic\nsemantic representation network at the physical layer adapts its encoding depth\nto meet user requirements. Additionally, two LLMs are employed to analyze user\nrequests and generate SQL statements, respectively. Simulation results\ndemonstrate the effectiveness.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLLM\u9a71\u52a8\u7684\u65e0\u7ebf\u901a\u4fe1\u8303\u5f0f\uff0c\u4f7f\u7528NL2SQL\u5de5\u5177\u4f18\u5316\u7528\u6237\u9700\u6c42\uff0c\u5b9e\u73b0AI-native\u7f51\u7edc\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u81ea\u7136\u8bed\u8a00\u4e0e\u901a\u4fe1\u7cfb\u7edf\u5dee\u8ddd\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528LLMs\u3002", "method": "LLMs\u5206\u6790\u7528\u6237\u610f\u56fe\uff0c\u751f\u6210SQL\u67e5\u8be2\u6570\u636e\u5e93\uff0c\u5e76\u4f18\u5316\u901a\u4fe1\u7cfb\u7edf\u53c2\u6570\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8bc1\u660e\u4e86\u8303\u5f0f\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u8303\u5f0f\u53ef\u884c\uff0c\u5e76\u4e3a\u7528\u6237\u9700\u6c42\u5bfc\u5411\u901a\u4fe1\u63d0\u4f9b\u65b0\u9014\u5f84\u3002"}}
{"id": "2504.11470", "pdf": "https://arxiv.org/pdf/2504.11470", "abs": "https://arxiv.org/abs/2504.11470", "authors": ["Huaxiang Zhang", "Hao Zhang", "Aoran Mei", "Zhongxue Gan", "Guo-Niu Zhu"], "title": "SO-DETR: Leveraging Dual-Domain Features and Knowledge Distillation for Small Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Detection Transformer-based methods have achieved significant advancements in\ngeneral object detection. However, challenges remain in effectively detecting\nsmall objects. One key difficulty is that existing encoders struggle to\nefficiently fuse low-level features. Additionally, the query selection\nstrategies are not effectively tailored for small objects. To address these\nchallenges, this paper proposes an efficient model, Small Object Detection\nTransformer (SO-DETR). The model comprises three key components: a dual-domain\nhybrid encoder, an enhanced query selection mechanism, and a knowledge\ndistillation strategy. The dual-domain hybrid encoder integrates spatial and\nfrequency domains to fuse multi-scale features effectively. This approach\nenhances the representation of high-resolution features while maintaining\nrelatively low computational overhead. The enhanced query selection mechanism\noptimizes query initialization by dynamically selecting high-scoring anchor\nboxes using expanded IoU, thereby improving the allocation of query resources.\nFurthermore, by incorporating a lightweight backbone network and implementing a\nknowledge distillation strategy, we develop an efficient detector for small\nobjects. Experimental results on the VisDrone-2019-DET and UAVVaste datasets\ndemonstrate that SO-DETR outperforms existing methods with similar\ncomputational demands. The project page is available at\nhttps://github.com/ValiantDiligent/SO_DETR.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSO-DETR\u6a21\u578b\uff0c\u9488\u5bf9\u5c0f\u7269\u4f53\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u901a\u8fc7\u53cc\u57df\u6df7\u5408\u7f16\u7801\u5668\u3001\u589e\u5f3a\u67e5\u8be2\u9009\u62e9\u673a\u5236\u548c\u77e5\u8bc6\u84b8\u998f\u7b56\u7565\uff0c\u63d0\u9ad8\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u68c0\u6d4bTransformer\u65b9\u6cd5\u5728\u5c0f\u7269\u4f53\u68c0\u6d4b\u4e2d\u5b58\u5728\u4f4e\u7ea7\u7279\u5f81\u878d\u5408\u6548\u7387\u4f4e\u548c\u67e5\u8be2\u9009\u62e9\u7b56\u7565\u4e0d\u9002\u914d\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faSO-DETR\u6a21\u578b\uff0c\u5305\u62ec\u53cc\u57df\u6df7\u5408\u7f16\u7801\u5668\u878d\u5408\u591a\u5c3a\u5ea6\u7279\u5f81\u3001\u589e\u5f3a\u67e5\u8be2\u9009\u62e9\u673a\u5236\u4f7f\u7528\u6269\u5c55IoU\u52a8\u6001\u9009\u62e9\u951a\u6846\uff0c\u4ee5\u53ca\u77e5\u8bc6\u84b8\u998f\u7b56\u7565\u3002", "result": "\u5728VisDrone-2019-DET\u548cUAVVaste\u6570\u636e\u96c6\u4e0a\uff0cSO-DETR\u5728\u7c7b\u4f3c\u8ba1\u7b97\u9700\u6c42\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SO-DETR\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5c0f\u7269\u4f53\u68c0\u6d4b\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u7684\u4f18\u52bf\u3002"}}
{"id": "2504.11831", "pdf": "https://arxiv.org/pdf/2504.11831", "abs": "https://arxiv.org/abs/2504.11831", "authors": ["Changming Xu", "Debangshu Banerjee", "Deepak Vasisht", "Gagandeep Singh"], "title": "Support is All You Need for Certified VAE Training", "categories": ["cs.LG", "stat.ML"], "comment": "21 pages, 3 figures, ICLR '25", "summary": "Variational Autoencoders (VAEs) have become increasingly popular and deployed\nin safety-critical applications. In such applications, we want to give\ncertified probabilistic guarantees on performance under adversarial attacks. We\npropose a novel method, CIVET, for certified training of VAEs. CIVET depends on\nthe key insight that we can bound worst-case VAE error by bounding the error on\ncarefully chosen support sets at the latent layer. We show this point\nmathematically and present a novel training algorithm utilizing this insight.\nWe show in an extensive evaluation across different datasets (in both the\nwireless and vision application areas), architectures, and perturbation\nmagnitudes that our method outperforms SOTA methods achieving good standard\nperformance with strong robustness guarantees.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faCIVET\u65b9\u6cd5\uff0c\u7528\u4e8eVAEs\u7684\u8ba4\u8bc1\u8bad\u7ec3\uff0c\u63d0\u4f9b\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u6982\u7387\u6027\u80fd\u4fdd\u8bc1\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "VAEs\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u9700\u8981\u5bf9\u6297\u653b\u51fb\u7684\u8ba4\u8bc1\u6982\u7387\u4fdd\u8bc1\u3002", "method": "\u63d0\u51faCIVET\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed1\u5b9a\u6f5c\u5728\u5c42\u7684\u652f\u6301\u96c6\u9519\u8bef\u6765\u9650\u5236VAE\u7684\u6700\u574f\u60c5\u51b5\u9519\u8bef\uff0c\u5e76\u8bbe\u8ba1\u65b0\u8bad\u7ec3\u7b97\u6cd5\u3002", "result": "\u5728\u4e0d\u540c\u6570\u636e\u96c6\u3001\u67b6\u6784\u548c\u6270\u52a8\u5e45\u5ea6\u4e0b\uff0cCIVET\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u6807\u51c6\u6027\u80fd\u548c\u9c81\u68d2\u6027\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "CIVET\u65b9\u6cd5\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u6807\u51c6\u6027\u80fd\u548c\u5f3a\u9c81\u68d2\u6027\u4fdd\u8bc1\u3002"}}
{"id": "2504.11717", "pdf": "https://arxiv.org/pdf/2504.11717", "abs": "https://arxiv.org/abs/2504.11717", "authors": ["Donggeon David Oh", "Justin Lidard", "Haimin Hu", "Himani Sinhmar", "Elle Lazarski", "Deepak Gopinath", "Emily S. Sumner", "Jonathan A. DeCastro", "Guy Rosman", "Naomi Ehrich Leonard", "Jaime Fern\u00e1ndez Fisac"], "title": "Safety with Agency: Human-Centered Safety Filter with Application to AI-Assisted Motorsports", "categories": ["cs.RO", "cs.SY", "eess.SY"], "comment": "Accepted to Robotics: Science and Systems (RSS) 2025, 22 pages, 16\n  figures, 7 tables", "summary": "We propose a human-centered safety filter (HCSF) for shared autonomy that\nsignificantly enhances system safety without compromising human agency. Our\nHCSF is built on a neural safety value function, which we first learn scalably\nthrough black-box interactions and then use at deployment to enforce a novel\nquality control barrier function (Q-CBF) safety constraint. Since this Q-CBF\nsafety filter does not require any knowledge of the system dynamics for both\nsynthesis and runtime safety monitoring and intervention, our method applies\nreadily to complex, black-box shared autonomy systems. Notably, our HCSF's\nCBF-based interventions modify the human's actions minimally and smoothly,\navoiding the abrupt, last-moment corrections delivered by many conventional\nsafety filters. We validate our approach in a comprehensive in-person user\nstudy using Assetto Corsa-a high-fidelity car racing simulator with black-box\ndynamics-to assess robustness in \"driving on the edge\" scenarios. We compare\nboth trajectory data and drivers' perceptions of our HCSF assistance against\nunassisted driving and a conventional safety filter. Experimental results show\nthat 1) compared to having no assistance, our HCSF improves both safety and\nuser satisfaction without compromising human agency or comfort, and 2) relative\nto a conventional safety filter, our proposed HCSF boosts human agency,\ncomfort, and satisfaction while maintaining robustness.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4eba\u7c7b\u4e2d\u5fc3\u5b89\u5168\u8fc7\u6ee4\u5668\uff08HCSF\uff09\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u548c\u8d28\u91cf\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u63d0\u5347\u5171\u4eab\u81ea\u6cbb\u7cfb\u7edf\u7684\u5b89\u5168\uff0c\u540c\u65f6\u4fdd\u6301\u4eba\u7c7b\u81ea\u4e3b\u6027\uff0c\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u63d0\u5347\u5171\u4eab\u81ea\u6cbb\u7cfb\u7edf\u7684\u5b89\u5168\uff0c\u800c\u4e0d\u635f\u5bb3\u4eba\u7c7b\u81ea\u4e3b\u6027\u3002", "method": "\u901a\u8fc7\u9ed1\u7bb1\u4ea4\u4e92\u5b66\u4e60\u795e\u7ecf\u5b89\u5168\u4ef7\u503c\u51fd\u6570\uff0c\u5e76\u4f7f\u7528\u8d28\u91cf\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff08Q-CBF\uff09\u4f5c\u4e3a\u5b89\u5168\u7ea6\u675f\u3002", "result": "\u7528\u6237\u7814\u7a76\u663e\u793a\uff0cHCSF \u63d0\u9ad8\u4e86\u5b89\u5168\u6027\u548c\u6ee1\u610f\u5ea6\uff0c\u4e0e\u65e0\u8f85\u52a9\u548c\u4f20\u7edf\u8fc7\u6ee4\u5668\u76f8\u6bd4\uff0c\u63d0\u5347\u4e86\u4eba\u7c7b\u81ea\u4e3b\u6027\u3001\u8212\u9002\u5ea6\u548c\u6ee1\u610f\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u6539\u5584\u4e86\u5171\u4eab\u81ea\u6cbb\u7cfb\u7edf\u7684\u5b89\u5168\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2504.11473", "pdf": "https://arxiv.org/pdf/2504.11473", "abs": "https://arxiv.org/abs/2504.11473", "authors": ["Warren Zhu", "Aida Ramezani", "Yang Xu"], "title": "Visual moral inference and communication", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Humans can make moral inferences from multiple sources of input. In contrast,\nautomated moral inference in artificial intelligence typically relies on\nlanguage models with textual input. However, morality is conveyed through\nmodalities beyond language. We present a computational framework that supports\nmoral inference from natural images, demonstrated in two related tasks: 1)\ninferring human moral judgment toward visual images and 2) analyzing patterns\nin moral content communicated via images from public news. We find that models\nbased on text alone cannot capture the fine-grained human moral judgment toward\nvisual stimuli, but language-vision fusion models offer better precision in\nvisual moral inference. Furthermore, applications of our framework to news data\nreveal implicit biases in news categories and geopolitical discussions. Our\nwork creates avenues for automating visual moral inference and discovering\npatterns of visual moral communication in public media.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u652f\u6301\u4ece\u56fe\u50cf\u4e2d\u8fdb\u884c\u9053\u5fb7\u63a8\u7406\uff0c\u5e94\u7528\u4e8e\u63a8\u65ad\u4eba\u7c7b\u5bf9\u89c6\u89c9\u56fe\u50cf\u7684\u9053\u5fb7\u5224\u65ad\u548c\u5206\u6790\u65b0\u95fb\u56fe\u50cf\u4e2d\u7684\u9053\u5fb7\u6a21\u5f0f\u3002\u53d1\u73b0\u6587\u672c\u6a21\u578b\u4e0d\u8db3\uff0c\u8bed\u8a00-\u89c6\u89c9\u878d\u5408\u6a21\u578b\u66f4\u7cbe\u786e\uff0c\u5e76\u63ed\u793a\u65b0\u95fb\u4e2d\u7684\u9690\u542b\u504f\u5dee\u3002", "motivation": "\u4eba\u7c7b\u53ef\u4ece\u591a\u79cd\u8f93\u5165\u6765\u6e90\u8fdb\u884c\u9053\u5fb7\u63a8\u7406\uff0c\u800cAI\u901a\u5e38\u4f9d\u8d56\u6587\u672c\u8f93\u5165\uff0c\u4f46\u9053\u5fb7\u53ef\u901a\u8fc7\u8bed\u8a00\u4ee5\u5916\u7684\u6a21\u6001\u4f20\u8fbe\uff0c\u56e0\u6b64\u9700\u8981\u6269\u5c55\u5230\u89c6\u89c9\u8f93\u5165\u3002", "method": "\u63d0\u51fa\u8ba1\u7b97\u6846\u67b6\uff0c\u4f7f\u7528\u8bed\u8a00-\u89c6\u89c9\u878d\u5408\u6a21\u578b\uff0c\u5e94\u7528\u4e8e\u4e24\u4e2a\u4efb\u52a1\uff1a\u63a8\u65ad\u4eba\u7c7b\u5bf9\u56fe\u50cf\u7684\u9053\u5fb7\u5224\u65ad\u548c\u5206\u6790\u516c\u5171\u65b0\u95fb\u56fe\u50cf\u4e2d\u7684\u9053\u5fb7\u5185\u5bb9\u3002", "result": "\u6587\u672c\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u89c6\u89c9\u523a\u6fc0\u7684\u7ec6\u7c92\u5ea6\u9053\u5fb7\u5224\u65ad\uff0c\u878d\u5408\u6a21\u578b\u63d0\u4f9b\u66f4\u597d\u7cbe\u5ea6\uff1b\u5e94\u7528\u4e8e\u65b0\u95fb\u6570\u636e\u53d1\u73b0\u65b0\u95fb\u7c7b\u522b\u548c\u5730\u7f18\u653f\u6cbb\u8ba8\u8bba\u4e2d\u7684\u9690\u542b\u504f\u5dee\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u81ea\u52a8\u5316\u89c6\u89c9\u9053\u5fb7\u63a8\u7406\u548c\u53d1\u73b0\u516c\u5171\u5a92\u4f53\u4e2d\u89c6\u89c9\u9053\u5fb7\u6c9f\u901a\u6a21\u5f0f\u5f00\u8f9f\u65b0\u9014\u5f84\u3002"}}
{"id": "2504.11866", "pdf": "https://arxiv.org/pdf/2504.11866", "abs": "https://arxiv.org/abs/2504.11866", "authors": ["Houshuang Chen", "Yuchen He", "Chihao Zhang"], "title": "On the Problem of Best Arm Retention", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "This paper presents a comprehensive study on the problem of Best Arm\nRetention (BAR), which has recently found applications in streaming algorithms\nfor multi-armed bandits. In the BAR problem, the goal is to retain $m$ arms\nwith the best arm included from $n$ after some trials, in stochastic\nmulti-armed bandit settings. We first investigate pure exploration for the BAR\nproblem under different criteria, and then minimize the regret with specific\nconstraints, in the context of further exploration in streaming algorithms.\n  - We begin by revisiting the lower bound for the $(\\varepsilon,\\delta)$-PAC\nalgorithm for Best Arm Identification (BAI) and adapt the classical\nKL-divergence argument to derive optimal bounds for $(\\varepsilon,\\delta)$-PAC\nalgorithms for BAR.\n  - We further study another variant of the problem, called $r$-BAR, which\nrequires the expected gap between the best arm and the optimal arm retained is\nless than $r$. We prove tight sample complexity for the problem.\n  - We explore the regret minimization problem for $r$-BAR and develop\nalgorithm beyond pure exploration. We conclude with a conjecture on the optimal\nregret in this setting.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86Best Arm Retention (BAR) \u95ee\u9898\u5728\u591a\u81c2\u8001\u864e\u673a\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u7eaf\u63a2\u7d22\u548c\u9057\u61be\u6700\u5c0f\u5316\u3002", "motivation": "BAR\u95ee\u9898\u5728\u6d41\u5f0f\u7b97\u6cd5\u4e2d\u5e94\u7528\uff0c\u76ee\u6807\u662f\u4fdd\u7559\u5305\u62ec\u6700\u4f73arms\u5728\u5185\u7684m\u4e2aarms\uff0c\u4ee5\u4f18\u5316\u63a2\u7d22\u7b56\u7565\u3002", "method": "\u4f7f\u7528KL-\u6563\u5ea6\u63a8\u5bfcPAC\u7b97\u6cd5\u4e0b\u754c\uff0c\u8bc1\u660er-BAR\u7684\u6837\u672c\u590d\u6742\u5ea6\uff0c\u5e76\u5f00\u53d1\u9057\u61be\u6700\u5c0f\u5316\u7b97\u6cd5\u3002", "result": "\u5bfc\u51fa\u4e86\u6700\u4f73\u4e0b\u754c\uff0c\u8bc1\u660e\u4e86\u7d27\u5bc6\u6837\u672c\u590d\u6742\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u6700\u4f18\u9057\u61be\u7684\u731c\u60f3\u3002", "conclusion": "\u8bba\u6587\u4ee5\u5bf9\u6700\u4f18\u9057\u61be\u7684\u731c\u60f3\u7ed3\u675f\uff0c\u5f3a\u8c03\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2504.11474", "pdf": "https://arxiv.org/pdf/2504.11474", "abs": "https://arxiv.org/abs/2504.11474", "authors": ["Byunggun Kim", "Younghun Kwon"], "title": "Local Temporal Feature Enhanced Transformer with ROI-rank Based Masking for Diagnosis of ADHD", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "In modern society, Attention-Deficit/Hyperactivity Disorder (ADHD) is one of\nthe common mental diseases discovered not only in children but also in adults.\nIn this context, we propose a ADHD diagnosis transformer model that can\neffectively simultaneously find important brain spatiotemporal biomarkers from\nresting-state functional magnetic resonance (rs-fMRI). This model not only\nlearns spatiotemporal individual features but also learns the correlation with\nfull attention structures specialized in ADHD diagnosis. In particular, it\nfocuses on learning local blood oxygenation level dependent (BOLD) signals and\ndistinguishing important regions of interest (ROI) in the brain. Specifically,\nthe three proposed methods for ADHD diagnosis transformer are as follows.\nFirst, we design a CNN-based embedding block to obtain more expressive\nembedding features in brain region attention. It is reconstructed based on the\npreviously CNN-based ADHD diagnosis models for the transformer. Next, for\nindividual spatiotemporal feature attention, we change the attention method to\nlocal temporal attention and ROI-rank based masking. For the temporal features\nof fMRI, the local temporal attention enables to learn local BOLD signal\nfeatures with only simple window masking. For the spatial feature of fMRI,\nROI-rank based masking can distinguish ROIs with high correlation in ROI\nrelationships based on attention scores, thereby providing a more specific\nbiomarker for ADHD diagnosis. The experiment was conducted with various types\nof transformer models. To evaluate these models, we collected the data from 939\nindividuals from all sites provided by the ADHD-200 competition. Through this,\nthe spatiotemporal enhanced transformer for ADHD diagnosis outperforms the\nperformance of other different types of transformer variants. (77.78ACC\n76.60SPE 79.22SEN 79.30AUC)", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u7684ADHD\u8bca\u65ad\u6a21\u578b\uff0c\u901a\u8fc7\u5b66\u4e60\u8111\u90e8\u65f6\u7a7a\u751f\u7269\u6807\u5fd7\u7269\uff0c\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u3002", "motivation": "ADHD\u662f\u4e00\u79cd\u5e38\u89c1\u7cbe\u795e\u75be\u75c5\uff0c\u5f71\u54cd\u513f\u7ae5\u548c\u6210\u4eba\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u8bca\u65ad\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86CNN-based embedding block\u3001local temporal attention\u548cROI-rank based masking\uff0c\u7528\u4e8e\u5b66\u4e60\u8111\u90e8\u5c40\u90e8BOLD\u4fe1\u53f7\u548c\u91cd\u8981ROI\u7279\u5f81\u3002", "result": "\u5728ADHD-200\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u6027\u80fd\u4e3aACC 77.78%\u3001SPE 76.60%\u3001SEN 79.22%\u3001AUC 79.30%\uff0c\u4f18\u4e8e\u5176\u4ed6Transformer\u53d8\u4f53\u3002", "conclusion": "\u65f6\u7a7a\u589e\u5f3aTransformer\u5728ADHD\u8bca\u65ad\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u751f\u7269\u6807\u5fd7\u7269\u3002"}}
{"id": "2504.11873", "pdf": "https://arxiv.org/pdf/2504.11873", "abs": "https://arxiv.org/abs/2504.11873", "authors": ["Weiqiang Jiao", "Suzhi Bi", "Xian Li", "Cheng Guo", "Hao Chen", "Zhi Quan"], "title": "Transferable Deployment of Semantic Edge Inference Systems via Unsupervised Domain Adaption", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "14 pages, 14 figures, the paper is submitted for potential journal\n  publication", "summary": "This paper investigates deploying semantic edge inference systems for\nperforming a common image clarification task. In particular, each system\nconsists of multiple Internet of Things (IoT) devices that first locally encode\nthe sensing data into semantic features and then transmit them to an edge\nserver for subsequent data fusion and task inference. The inference accuracy is\ndetermined by efficient training of the feature encoder/decoder using labeled\ndata samples. Due to the difference in sensing data and communication channel\ndistributions, deploying the system in a new environment may induce high costs\nin annotating data labels and re-training the encoder/decoder models. To\nachieve cost-effective transferable system deployment, we propose an efficient\nDomain Adaptation method for Semantic Edge INference systems (DASEIN) that can\nmaintain high inference accuracy in a new environment without the need for\nlabeled samples. Specifically, DASEIN exploits the task-relevant data\ncorrelation between different deployment scenarios by leveraging the techniques\nof unsupervised domain adaptation and knowledge distillation. It devises an\nefficient two-step adaptation procedure that sequentially aligns the data\ndistributions and adapts to the channel variations. Numerical results show\nthat, under a substantial change in sensing data distributions, the proposed\nDASEIN outperforms the best-performing benchmark method by 7.09% and 21.33% in\ninference accuracy when the new environment has similar or 25 dB lower channel\nsignal to noise power ratios (SNRs), respectively. This verifies the\neffectiveness of the proposed method in adapting both data and channel\ndistributions in practical transfer deployment applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDASEIN\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bed\u4e49\u8fb9\u7f18\u63a8\u7406\u7cfb\u7edf\u5728\u65e0\u9700\u6807\u6ce8\u6570\u636e\u7684\u65b0\u73af\u5883\u4e2d\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u90e8\u7f72\u7cfb\u7edf\u5728\u65b0\u73af\u5883\u65f6\uff0c\u611f\u77e5\u6570\u636e\u548c\u901a\u4fe1\u901a\u9053\u5dee\u5f02\u5bfc\u81f4\u6807\u6ce8\u6570\u636e\u548c\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7684\u9ad8\u6210\u672c\uff0c\u9700\u8981\u6210\u672c\u6709\u6548\u7684\u53ef\u8f6c\u79fb\u90e8\u7f72\u65b9\u6cd5\u3002", "method": "\u63d0\u51faDASEIN\uff0c\u5229\u7528\u65e0\u76d1\u7763\u9886\u57df\u9002\u5e94\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u901a\u8fc7\u4e24\u6b65\u8fc7\u7a0b\u5bf9\u9f50\u6570\u636e\u5206\u5e03\u5e76\u9002\u5e94\u901a\u9053\u53d8\u5316\u3002", "result": "\u6570\u503c\u7ed3\u679c\u663e\u793a\uff0cDASEIN\u5728\u6570\u636e\u5206\u5e03\u53d8\u5316\u4e0b\uff0c\u6bd4\u57fa\u51c6\u65b9\u6cd5\u63d0\u9ad87.09%\u548c21.33%\u7684\u63a8\u7406\u51c6\u786e\u6027\u3002", "conclusion": "\u9a8c\u8bc1DASEIN\u5728\u9002\u5e94\u6570\u636e\u548c\u901a\u9053\u5206\u5e03\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2504.11477", "pdf": "https://arxiv.org/pdf/2504.11477", "abs": "https://arxiv.org/abs/2504.11477", "authors": ["Yunkai Zhang", "Shiyin Wei", "Yong Huang", "Yawu Su", "Shanshan Lu", "Hui Li"], "title": "SDIGLM: Leveraging Large Language Models and Multi-Modal Chain of Thought for Structural Damage Identification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Existing computer vision(CV)-based structural damage identification models\ndemonstrate notable accuracy in categorizing and localizing damage. However,\nthese models present several critical limitations that hinder their practical\napplication in civil engineering(CE). Primarily, their ability to recognize\ndamage types remains constrained, preventing comprehensive analysis of the\nhighly varied and complex conditions encountered in real-world CE structures.\nSecond, these models lack linguistic capabilities, rendering them unable to\narticulate structural damage characteristics through natural language\ndescriptions. With the continuous advancement of artificial intelligence(AI),\nlarge multi-modal models(LMMs) have emerged as a transformative solution,\nenabling the unified encoding and alignment of textual and visual data. These\nmodels can autonomously generate detailed descriptive narratives of structural\ndamage while demonstrating robust generalization across diverse scenarios and\ntasks. This study introduces SDIGLM, an innovative LMM for structural damage\nidentification, developed based on the open-source VisualGLM-6B architecture.\nTo address the challenge of adapting LMMs to the intricate and varied operating\nconditions in CE, this work integrates a U-Net-based semantic segmentation\nmodule to generate defect segmentation maps as visual Chain of Thought(CoT).\nAdditionally, a multi-round dialogue fine-tuning dataset is constructed to\nenhance logical reasoning, complemented by a language CoT formed through prompt\nengineering. By leveraging this multi-modal CoT, SDIGLM surpasses\ngeneral-purpose LMMs in structural damage identification, achieving an accuracy\nof 95.24% across various infrastructure types. Moreover, the model effectively\ndescribes damage characteristics such as hole size, crack direction, and\ncorrosion severity.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faSDIGLM\u6a21\u578b\uff0c\u4f7f\u7528\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u6539\u8fdb\u7ed3\u6784\u635f\u4f24\u8bc6\u522b\uff0c\u89e3\u51b3\u73b0\u6709CV\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709CV\u6a21\u578b\u5728\u635f\u4f24\u7c7b\u578b\u8bc6\u522b\u548c\u8bed\u8a00\u63cf\u8ff0\u65b9\u9762\u5b58\u5728\u9650\u5236\uff0c\u65e0\u6cd5\u9002\u5e94\u590d\u6742\u5de5\u7a0b\u73af\u5883\uff0c\u56e0\u6b64\u9700\u8981LMMs\u6765\u7edf\u4e00\u5904\u7406\u6587\u672c\u548c\u89c6\u89c9\u6570\u636e\u3002", "method": "\u57fa\u4e8eVisualGLM-6B\u5f00\u53d1SDIGLM\uff0c\u6574\u5408U-Net\u8bed\u4e49\u5206\u5272\u751f\u6210\u89c6\u89c9CoT\uff0c\u5e76\u6784\u5efa\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\u96c6\u53ca\u63d0\u793a\u5de5\u7a0b\u5f62\u6210\u8bed\u8a00CoT\u3002", "result": "SDIGLM\u5728\u5404\u79cd\u57fa\u7840\u8bbe\u65bd\u4e0a\u8fbe\u523095.24%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u80fd\u63cf\u8ff0\u635f\u4f24\u7279\u5f81\u5982\u5b54\u6d1e\u5927\u5c0f\u3001\u88c2\u7f1d\u65b9\u5411\u548c\u8150\u8680\u4e25\u91cd\u7a0b\u5ea6\u3002", "conclusion": "SDIGLM\u8d85\u8d8a\u901a\u7528LMMs\uff0c\u5728\u7ed3\u6784\u635f\u4f24\u8bc6\u522b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5b9e\u9645\u5de5\u7a0b\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2504.11874", "pdf": "https://arxiv.org/pdf/2504.11874", "abs": "https://arxiv.org/abs/2504.11874", "authors": ["Ruoyu Sun", "Angelos Stefanidis", "Zhengyong Jiang", "Jionglong Su"], "title": "Factor-MCLS: Multi-agent learning system with reward factor matrix and multi-critic framework for dynamic portfolio optimization", "categories": ["cs.LG"], "comment": null, "summary": "Typical deep reinforcement learning (DRL) agents for dynamic portfolio\noptimization learn the factors influencing portfolio return and risk by\nanalyzing the output values of the reward function while adjusting portfolio\nweights within the training environment. However, it faces a major limitation\nwhere it is difficult for investors to intervene in the training based on\ndifferent levels of risk aversion towards each portfolio asset. This difficulty\narises from another limitation: existing DRL agents may not develop a thorough\nunderstanding of the factors responsible for the portfolio return and risk by\nonly learning from the output of the reward function. As a result, the strategy\nfor determining the target portfolio weights is entirely dependent on the DRL\nagents themselves. To address these limitations, we propose a reward factor\nmatrix for elucidating the return and risk of each asset in the portfolio.\nAdditionally, we propose a novel learning system named Factor-MCLS using a\nmulti-critic framework that facilitates learning of the reward factor matrix.\nIn this way, our DRL-based learning system can effectively learn the factors\ninfluencing portfolio return and risk. Moreover, based on the critic networks\nwithin the multi-critic framework, we develop a risk constraint term in the\ntraining objective function of the policy function. This risk constraint term\nallows investors to intervene in the training of the DRL agent according to\ntheir individual levels of risk aversion towards the portfolio assets.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edfFactor-MCLS\uff0c\u7528\u4e8e\u52a8\u6001\u6295\u8d44\u7ec4\u5408\u4f18\u5316\uff0c\u5141\u8bb8\u6295\u8d44\u8005\u6839\u636e\u98ce\u9669\u504f\u597d\u5e72\u9884\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709DRL\u4ee3\u7406\u96be\u4ee5\u8ba9\u6295\u8d44\u8005\u5e72\u9884\u8bad\u7ec3\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ea\u4ece\u5956\u52b1\u51fd\u6570\u8f93\u51fa\u5b66\u4e60\uff0c\u800c\u4e0d\u5f7b\u5e95\u7406\u89e3\u5f71\u54cd\u56de\u62a5\u548c\u98ce\u9669\u7684\u56e0\u7d20\u3002", "method": "\u63d0\u51fa\u5956\u52b1\u56e0\u7d20\u77e9\u9635\u548c\u591a\u6279\u8bc4\u8005\u6846\u67b6\u7684Factor-MCLS\u7cfb\u7edf\uff0c\u4ee5\u53ca\u5728\u7b56\u7565\u51fd\u6570\u8bad\u7ec3\u76ee\u6807\u4e2d\u6dfb\u52a0\u98ce\u9669\u7ea6\u675f\u9879\u3002", "result": "\u7cfb\u7edf\u80fd\u6709\u6548\u5b66\u4e60\u5f71\u54cd\u6295\u8d44\u7ec4\u5408\u56de\u62a5\u548c\u98ce\u9669\u7684\u56e0\u7d20\uff0c\u5e76\u5b9e\u73b0\u6295\u8d44\u8005\u6839\u636e\u98ce\u9669\u538c\u6076\u6c34\u5e73\u5e72\u9884\u3002", "conclusion": "\u901a\u8fc7\u8fd9\u4e9b\u521b\u65b0\uff0c\u89e3\u51b3\u4e86DRL\u4ee3\u7406\u7684\u5c40\u9650\u6027\uff0c\u63d0\u9ad8\u4e86\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u7684\u7075\u6d3b\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2504.11878", "pdf": "https://arxiv.org/pdf/2504.11878", "abs": "https://arxiv.org/abs/2504.11878", "authors": ["Shaima Abidrabbu", "H\u00fcseyin Arslan"], "title": "A Novel Approach to Secure RSMA Networks", "categories": ["eess.SP", "cs.SY", "eess.SY"], "comment": "5 pages, and 2 figures. This work has been submitted to IEEE Wireless\n  Communication Letter", "summary": "This letter introduces a novel data-dependent interleaving technique designed\nto enhance the security of rate-splitting multiple access (RSMA) networks by\nprotecting the common stream from eavesdropping threats. Specifically, we\nexploit the RSMA structure by interleaving the common bits of each user based\non a sequence derived from their private bits. By decoding its private stream,\nthe legitimate receiver reconstructs the interleaving sequence set by the\ntransmitter and successfully de-interleaves the common stream. Therefore, the\ncommon part is successfully prevented from being intercepted by an eavesdropper\nwho is unable to deduce the dynamic changing interleaving permutations. To\nensure dynamic interleaving sequences, a private bit selection approach that\nbalances the trade-off between security and system efficiency is proposed.\nSimulation findings confirm the effectiveness of the suggested method, showing\nnotable security improvements while maintaining robust overall system\nreliability.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u4f9d\u8d56\u4ea4\u7ec7\u6280\u672f\uff0c\u7528\u4e8e\u63d0\u5347RSMA\u7f51\u7edc\u7684\u5b89\u5168\u6027\uff0c\u4fdd\u62a4\u516c\u5171\u6d41\u514d\u53d7\u7a83\u542c\u5a01\u80c1\u3002\u6a21\u62df\u7ed3\u679c\u663e\u793a\u4e86\u663e\u8457\u7684\u5b89\u5168\u6027\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u52a8\u673a\u662f\u589e\u5f3aRSMA\u7f51\u7edc\u7684\u5b89\u5168\u6027\uff0c\u7279\u522b\u662f\u4fdd\u62a4\u516c\u5171\u6d41\u514d\u53d7\u7a83\u542c\u5a01\u80c1\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5229\u7528RSMA\u7ed3\u6784\uff0c\u901a\u8fc7\u57fa\u4e8e\u79c1\u6709\u6bd4\u7279\u7684\u5e8f\u5217\u5bf9\u516c\u5171\u6bd4\u7279\u8fdb\u884c\u4ea4\u7ec7\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u5e73\u8861\u5b89\u5168\u6027\u548c\u7cfb\u7edf\u6548\u7387\u7684\u79c1\u6709\u6bd4\u7279\u9009\u62e9\u65b9\u6cd5\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8bc1\u5b9e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u663e\u793a\u4e86\u663e\u8457\u7684\u5b89\u5168\u6027\u6539\u8fdb\uff0c\u540c\u65f6\u7ef4\u6301\u4e86\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u7ed3\u8bba\u662f\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u5730\u63d0\u5347\u4e86\u5b89\u5168\u6027\uff0c\u540c\u65f6\u786e\u4fdd\u4e86\u7cfb\u7edf\u7684\u6574\u4f53\u53ef\u9760\u6027\u3002"}}
{"id": "2504.11478", "pdf": "https://arxiv.org/pdf/2504.11478", "abs": "https://arxiv.org/abs/2504.11478", "authors": ["Hao Kang", "Stathi Fotiadis", "Liming Jiang", "Qing Yan", "Yumin Jia", "Zichuan Liu", "Min Jin Chong", "Xin Lu"], "title": "Flux Already Knows - Activating Subject-Driven Image Generation without Training", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We propose a simple yet effective zero-shot framework for subject-driven\nimage generation using a vanilla Flux model. By framing the task as grid-based\nimage completion and simply replicating the subject image(s) in a mosaic\nlayout, we activate strong identity-preserving capabilities without any\nadditional data, training, or inference-time fine-tuning. This \"free lunch\"\napproach is further strengthened by a novel cascade attention design and meta\nprompting technique, boosting fidelity and versatility. Experimental results\nshow that our method outperforms baselines across multiple key metrics in\nbenchmarks and human preference studies, with trade-offs in certain aspects.\nAdditionally, it supports diverse edits, including logo insertion, virtual\ntry-on, and subject replacement or insertion. These results demonstrate that a\npre-trained foundational text-to-image model can enable high-quality,\nresource-efficient subject-driven generation, opening new possibilities for\nlightweight customization in downstream applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u96f6\u6837\u672c\u4e3b\u4f53\u9a71\u52a8\u56fe\u50cf\u751f\u6210\u6846\u67b6\uff0c\u4f7f\u7528 vanilla Flux \u6a21\u578b\uff0c\u901a\u8fc7\u7f51\u683c-based \u56fe\u50cf\u5b8c\u6210\u548c\u9a6c\u8d5b\u514b\u5e03\u5c40\u590d\u5236\u4e3b\u4f53\u56fe\u50cf\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u751f\u6210\u3002", "motivation": "\u52a8\u673a\u662f\u63d0\u4f9b\u4e00\u79cd\u65e0\u9700\u989d\u5916\u6570\u636e\u3001\u8bad\u7ec3\u6216\u5fae\u8c03\u7684\u8d44\u6e90\u9ad8\u6548\u65b9\u6cd5\uff0c\u5f00\u542f\u8f7b\u91cf\u7ea7\u5b9a\u5236\u7684\u53ef\u80fd\u6027\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5c06\u4efb\u52a1\u6846\u67b6\u4e3a\u57fa\u4e8e\u7f51\u683c\u7684\u56fe\u50cf\u5b8c\u6210\uff0c\u7b80\u5355\u590d\u5236\u4e3b\u4f53\u56fe\u50cf\u5728\u9a6c\u8d5b\u514b\u5e03\u5c40\u4e2d\uff0c\u7ed3\u5408\u65b0\u578b\u7ea7\u8054\u6ce8\u610f\u529b\u8bbe\u8ba1\u548c\u5143\u63d0\u793a\u6280\u672f\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5728\u591a\u4e2a\u5173\u952e\u6307\u6807\u548c\u4eba\u7c7b\u504f\u597d\u7814\u7a76\u4e2d\u4f18\u4e8e\u57fa\u7ebf\uff0c\u652f\u6301\u591a\u6837\u7f16\u8f91\u5982\u5fbd\u6807\u63d2\u5165\u3001\u865a\u62df\u8bd5\u7a7f\u7b49\uff0c\u5c3d\u7ba1\u6709\u67d0\u4e9b\u65b9\u9762\u7684\u6743\u8861\u3002", "conclusion": "\u7ed3\u8bba\u662f\u9884\u8bad\u7ec3\u7684\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u8d28\u91cf\u3001\u8d44\u6e90\u9ad8\u6548\u7684\u4e3b\u4f53\u9a71\u52a8\u751f\u6210\uff0c\u4e3a\u4e0b\u6e38\u5e94\u7528\u63d0\u4f9b\u65b0\u53ef\u80fd\u3002"}}
{"id": "2504.11877", "pdf": "https://arxiv.org/pdf/2504.11877", "abs": "https://arxiv.org/abs/2504.11877", "authors": ["Sarang S", "Harsh D. Chothani", "Qilei Li", "Ahmed M. Abdelmoniem", "Arnab K. Paul"], "title": "Benchmarking Mutual Information-based Loss Functions in Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": "6 pages, 4 figures", "summary": "Federated Learning (FL) has attracted considerable interest due to growing\nprivacy concerns and regulations like the General Data Protection Regulation\n(GDPR), which stresses the importance of privacy-preserving and fair machine\nlearning approaches. In FL, model training takes place on decentralized data,\nso as to allow clients to upload a locally trained model and receive a globally\naggregated model without exposing sensitive information. However, challenges\nrelated to fairness-such as biases, uneven performance among clients, and the\n\"free rider\" issue complicates its adoption. In this paper, we examine the use\nof Mutual Information (MI)-based loss functions to address these concerns. MI\nhas proven to be a powerful method for measuring dependencies between variables\nand optimizing deep learning models. By leveraging MI to extract essential\nfeatures and minimize biases, we aim to improve both the fairness and\neffectiveness of FL systems. Through extensive benchmarking, we assess the\nimpact of MI-based losses in reducing disparities among clients while enhancing\nthe overall performance of FL.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4f7f\u7528\u57fa\u4e8e\u4e92\u4fe1\u606f\uff08MI\uff09\u7684\u635f\u5931\u51fd\u6570\u6765\u63d0\u5347\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u516c\u5e73\u6027\u548c\u6709\u6548\u6027\u3002", "motivation": "\u7531\u4e8e\u9690\u79c1\u62c5\u5fe7\u548cGDPR\u7b49\u6cd5\u89c4\uff0c\u8054\u90a6\u5b66\u4e60\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u504f\u5dee\u3001\u4e0d\u5747\u7b49\u6027\u80fd\u548c'\u514d\u8d39\u9a91\u624b'\u95ee\u9898\u7b49\u516c\u5e73\u6027\u6311\u6218\u3002", "method": "\u901a\u8fc7\u91c7\u7528MI-based\u635f\u5931\u51fd\u6570\u6765\u63d0\u53d6\u5173\u952e\u7279\u5f81\u5e76\u6700\u5c0f\u5316\u504f\u5dee\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0cMI-based\u635f\u5931\u51fd\u6570\u51cf\u5c11\u4e86\u5ba2\u6237\u7aef\u95f4\u5dee\u5f02\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "MI-based\u65b9\u6cd5\u53ef\u6709\u6548\u6539\u5584\u8054\u90a6\u5b66\u4e60\u7684\u516c\u5e73\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2504.11905", "pdf": "https://arxiv.org/pdf/2504.11905", "abs": "https://arxiv.org/abs/2504.11905", "authors": ["Sawaira Rafaqat Ali", "Shaima Abidrabbu", "H. M. Furqan", "H\u00fcseyin Arslan"], "title": "A Novel Splitter Design for RSMA Networks", "categories": ["eess.SP", "cs.SY", "eess.SY"], "comment": "5 pages, 3 figures. This work has been accepted in ICC 2025 Workshop\n  - NGMA Proceedings", "summary": "Rate splitting multiple access (RSMA) has firmly established itself as a\npowerful methodology for multiple access, interference management, and\nmulti-user strategy for next-generation communication systems. In this paper,\nwe propose a novel channel-dependent splitter design for multi-carrier RSMA\nsystems, aimed at improving reliability performance. Specifically, the proposed\nsplitter leverages channel state information and the inherent structure of RSMA\nto intelligently replicate segments of the private stream data that are likely\nto encounter deep-faded subchannels into the common stream. Thus, the\nreliability is enhanced within the same transmission slot, minimizing the need\nfor frequent retransmissions and thereby reducing latency. To assess the\neffectiveness of our approach, we conduct comprehensive evaluations using key\nperformance metrics, including achievable sum rate, average packet delay, and\nbit error rate (BER), under both perfect and imperfect channel estimation\nscenarios.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u9053\u7684\u5206\u88c2\u5668\u8bbe\u8ba1\uff0c\u7528\u4e8e\u591a\u8f7d\u6ce2RSMA\u7cfb\u7edf\uff0c\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u5e76\u51cf\u5c11\u5ef6\u8fdf\u3002", "motivation": "RSMA\u5df2\u88ab\u786e\u7acb\u4e3a\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7cfb\u7edf\u7684\u5f3a\u5927\u591a\u5740\u63a5\u5165\u548c\u5e72\u6270\u7ba1\u7406\u65b9\u6cd5\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5229\u7528\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u63d0\u5347\u53ef\u9760\u6027\uff0c\u51cf\u5c11\u91cd\u4f20\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u9053\u4f9d\u8d56\u7684\u5206\u88c2\u5668\u8bbe\u8ba1\uff0c\u5229\u7528\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u5c06\u53ef\u80fd\u9047\u5230\u6df1\u8870\u843d\u5b50\u4fe1\u9053\u7684\u79c1\u6709\u6d41\u6570\u636e\u6bb5\u590d\u5236\u5230\u516c\u5171\u6d41\u4e2d\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u5728\u5b8c\u7f8e\u548c\u4e0d\u5b8c\u7f8e\u4fe1\u9053\u4f30\u8ba1\u573a\u666f\u4e0b\uff0c\u53ef\u5b9e\u73b0\u603b\u901f\u7387\u3001\u5e73\u5747\u5305\u5ef6\u8fdf\u548c\u8bef\u7801\u7387\uff08BER\uff09\u7b49\u6307\u6807\u7684\u6539\u5584\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u53ef\u9760\u6027\uff0c\u964d\u4f4e\u4e86\u5ef6\u8fdf\uff0c\u5e76\u6700\u5c0f\u5316\u4e86\u91cd\u4f20\u9700\u6c42\u3002"}}
{"id": "2504.11482", "pdf": "https://arxiv.org/pdf/2504.11482", "abs": "https://arxiv.org/abs/2504.11482", "authors": ["Vidya Sudevan", "Fakhreddine Zayer", "Rizwana Kausar", "Sajid Javed", "Hamad Karki", "Giulia De Masi", "Jorge Dias"], "title": "snnTrans-DHZ: A Lightweight Spiking Neural Network Architecture for Underwater Image Dehazing", "categories": ["cs.CV", "cs.AI", "cs.PF", "cs.RO", "eess.IV"], "comment": null, "summary": "Underwater image dehazing is critical for vision-based marine operations\nbecause light scattering and absorption can severely reduce visibility. This\npaper introduces snnTrans-DHZ, a lightweight Spiking Neural Network (SNN)\nspecifically designed for underwater dehazing. By leveraging the temporal\ndynamics of SNNs, snnTrans-DHZ efficiently processes time-dependent raw image\nsequences while maintaining low power consumption. Static underwater images are\nfirst converted into time-dependent sequences by repeatedly inputting the same\nimage over user-defined timesteps. These RGB sequences are then transformed\ninto LAB color space representations and processed concurrently. The\narchitecture features three key modules: (i) a K estimator that extracts\nfeatures from multiple color space representations; (ii) a Background Light\nEstimator that jointly infers the background light component from the RGB-LAB\nimages; and (iii) a soft image reconstruction module that produces haze-free,\nvisibility-enhanced outputs. The snnTrans-DHZ model is directly trained using a\nsurrogate gradient-based backpropagation through time (BPTT) strategy alongside\na novel combined loss function. Evaluated on the UIEB benchmark, snnTrans-DHZ\nachieves a PSNR of 21.68 dB and an SSIM of 0.8795, and on the EUVP dataset, it\nyields a PSNR of 23.46 dB and an SSIM of 0.8439. With only 0.5670 million\nnetwork parameters, and requiring just 7.42 GSOPs and 0.0151 J of energy, the\nalgorithm significantly outperforms existing state-of-the-art methods in terms\nof efficiency. These features make snnTrans-DHZ highly suitable for deployment\nin underwater robotics, marine exploration, and environmental monitoring.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNN\uff09\u65b9\u6cd5snnTrans-DHZ\uff0c\u7528\u4e8e\u6c34\u4e0b\u56fe\u50cf\u53bb\u96fe\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u80fd\u8017\u6027\u80fd\u3002", "motivation": "\u6c34\u4e0b\u56fe\u50cf\u53bb\u96fe\u5bf9\u57fa\u4e8e\u89c6\u89c9\u7684\u6d77\u6d0b\u64cd\u4f5c\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5149\u6563\u5c04\u548c\u5438\u6536\u4f1a\u964d\u4f4e\u80fd\u89c1\u5ea6\uff0c\u9700\u8981\u4f4e\u529f\u8017\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528SNN\u5904\u7406\u65f6\u95f4\u4f9d\u8d56\u56fe\u50cf\u5e8f\u5217\uff0c\u5c06\u9759\u6001\u56fe\u50cf\u8f6c\u6362\u4e3a\u5e8f\u5217\uff0c\u8f6c\u6362\u5230LAB\u989c\u8272\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7K\u4f30\u8ba1\u5668\u3001\u80cc\u666f\u5149\u4f30\u8ba1\u5668\u548c\u8f6f\u91cd\u5efa\u6a21\u5757\u8bad\u7ec3\u3002", "result": "\u5728UIEB\u6570\u636e\u96c6\u4e0aPSNR 21.68 dB\u3001SSIM 0.8795\uff1b\u5728EUVP\u4e0aPSNR 23.46 dB\u3001SSIM 0.8439\uff1b\u53c2\u6570\u5c11\u3001\u8ba1\u7b97\u548c\u80fd\u8017\u4f4e\u3002", "conclusion": "snnTrans-DHZ\u9ad8\u6548\u6027\u4f7f\u5176\u9002\u5408\u6c34\u4e0b\u673a\u5668\u4eba\u3001\u6d77\u6d0b\u52d8\u63a2\u548c\u73af\u5883\u76d1\u6d4b\u5e94\u7528\u3002"}}
{"id": "2504.11885", "pdf": "https://arxiv.org/pdf/2504.11885", "abs": "https://arxiv.org/abs/2504.11885", "authors": ["Qiyue Chen", "Shaolin Tan", "Suixiang Gao", "Jinhu L\u00fc"], "title": "HyperSAT: Unsupervised Hypergraph Neural Networks for Weighted MaxSAT Problems", "categories": ["cs.LG"], "comment": null, "summary": "Graph neural networks (GNNs) have shown promising performance in solving both\nBoolean satisfiability (SAT) and Maximum Satisfiability (MaxSAT) problems due\nto their ability to efficiently model and capture the structural dependencies\nbetween literals and clauses. However, GNN methods for solving Weighted MaxSAT\nproblems remain underdeveloped. The challenges arise from the non-linear\ndependency and sensitive objective function, which are caused by the\nnon-uniform distribution of weights across clauses. In this paper, we present\nHyperSAT, a novel neural approach that employs an unsupervised hypergraph\nneural network model to solve Weighted MaxSAT problems. We propose a hypergraph\nrepresentation for Weighted MaxSAT instances and design a cross-attention\nmechanism along with a shared representation constraint loss function to\ncapture the logical interactions between positive and negative literal nodes in\nthe hypergraph. Extensive experiments on various Weighted MaxSAT datasets\ndemonstrate that HyperSAT achieves better performance than state-of-the-art\ncompetitors.", "AI": {"tldr": "This paper introduces HyperSAT, a hypergraph neural network approach for solving Weighted MaxSAT problems, achieving better performance than state-of-the-art methods.", "motivation": "GNN methods for Weighted MaxSAT are underdeveloped due to challenges from non-uniform weight distributions causing non-linear dependencies and sensitive objectives.", "method": "Proposes HyperSAT using unsupervised hypergraph neural networks, hypergraph representation, cross-attention mechanism, and shared representation constraint loss function.", "result": "Outperforms state-of-the-art competitors in extensive experiments on various Weighted MaxSAT datasets.", "conclusion": "HyperSAT effectively addresses the challenges in Weighted MaxSAT solving and demonstrates superior performance."}}
{"id": "2504.11982", "pdf": "https://arxiv.org/pdf/2504.11982", "abs": "https://arxiv.org/abs/2504.11982", "authors": ["Alberto Bemporad", "Roland T\u00f3th"], "title": "Efficient identification of linear, parameter-varying, and nonlinear systems with noise models", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "comment": "28 pages, 3 figures", "summary": "We present a general system identification procedure capable of estimating of\na broad spectrum of state-space dynamical models, including linear\ntime-invariant (LTI), linear parameter-varying} (LPV), and nonlinear (NL)\ndynamics, along with rather general classes of noise models. Similar to the LTI\ncase, we show that for this general class of model structures, including the NL\ncase, the model dynamics can be separated into a deterministic process and a\nstochastic noise part, allowing to seamlessly tune the complexity of the\ncombined model both in terms of nonlinearity and noise modeling. We\nparameterize the involved nonlinear functional relations by means of artificial\nneural-networks (ANNs), although alternative parametric nonlinear mappings can\nalso be used. To estimate the resulting model structures, we optimize a\nprediction-error-based criterion using an efficient combination of a\nconstrained quasi-Newton approach and automatic differentiation, achieving\ntraining times in the order of seconds compared to existing state-of-the-art\nANN methods which may require hours for models of similar complexity. We\nformally establish the consistency guarantees for the proposed approach and\ndemonstrate its superior estimation accuracy and computational efficiency on\nseveral benchmark LTI, LPV, and NL system identification problems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u7cfb\u7edf\u8bc6\u522b\u7a0b\u5e8f\uff0c\u80fd\u591f\u4f30\u8ba1\u5305\u62ec\u7ebf\u6027\u65f6\u4e0d\u53d8\uff08LTI\uff09\u3001\u7ebf\u6027\u53c2\u6570\u53d8\u5316\uff08LPV\uff09\u548c\u975e\u7ebf\u6027\uff08NL\uff09\u52a8\u529b\u5b66\u5728\u5185\u7684\u5404\u79cd\u72b6\u6001\u7a7a\u95f4\u52a8\u6001\u6a21\u578b\uff0c\u4f7f\u7528\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u53c2\u6570\u5316\uff0c\u5e76\u5b9e\u73b0\u4e86\u5feb\u901f\u8bad\u7ec3\u548c\u4e00\u81f4\u6027\u4fdd\u8bc1\u3002", "motivation": "\u4e3a\u4e86\u5904\u7406\u66f4\u5e7f\u6cdb\u7684\u72b6\u6001\u7a7a\u95f4\u52a8\u6001\u6a21\u578b\uff0c\u5305\u62ec\u566a\u58f0\u6a21\u578b\u7684\u9700\u6c42\uff0c\u6269\u5c55\u4e86LTI\u60c5\u51b5\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u901a\u8fc7\u9884\u6d4b\u8bef\u5dee\u51c6\u5219\u4f18\u5316\uff0c\u7ed3\u5408\u7ea6\u675f\u7684\u62df\u725b\u987f\u65b9\u6cd5\u548c\u81ea\u52a8\u5fae\u5206\uff0c\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u793a\u51fa\u4f18\u8d8a\u7684\u4f30\u8ba1\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u8bad\u7ec3\u65f6\u95f4\u4ee5\u79d2\u8ba1\uff0c\u5e76\u5efa\u7acb\u4e86\u5f62\u5f0f\u4e00\u81f4\u6027\u4fdd\u8bc1\u3002", "conclusion": "\u5728LTI\u3001LPV\u548cNL\u7cfb\u7edf\u8bc6\u522b\u95ee\u9898\u4e0a\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2504.11493", "pdf": "https://arxiv.org/pdf/2504.11493", "abs": "https://arxiv.org/abs/2504.11493", "authors": ["Azizul Zahid", "Jie Fan", "Farong Wang", "Ashton Dy", "Sai Swaminathan", "Fei Liu"], "title": "Toward Aligning Human and Robot Actions via Multi-Modal Demonstration Learning", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "ICRA'25 Workshop: Human-Centered Robot Learning in the Era of Big\n  Data and Large Models", "summary": "Understanding action correspondence between humans and robots is essential\nfor evaluating alignment in decision-making, particularly in human-robot\ncollaboration and imitation learning within unstructured environments. We\npropose a multimodal demonstration learning framework that explicitly models\nhuman demonstrations from RGB video with robot demonstrations in voxelized\nRGB-D space. Focusing on the \"pick and place\" task from the RH20T dataset, we\nutilize data from 5 users across 10 diverse scenes. Our approach combines\nResNet-based visual encoding for human intention modeling and a Perceiver\nTransformer for voxel-based robot action prediction. After 2000 training\nepochs, the human model reaches 71.67% accuracy, and the robot model achieves\n71.8% accuracy, demonstrating the framework's potential for aligning complex,\nmultimodal human and robot behaviors in manipulation tasks.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u591a\u6a21\u6001\u6846\u67b6\u5efa\u6a21\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u884c\u4e3a\u5bf9\u5e94\uff0c\u9488\u5bf9'pick and place'\u4efb\u52a1\uff0c\u8fbe\u5230\u7ea671.7%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u7406\u89e3\u4eba\u7c7b\u4e0e\u673a\u5668\u4eba\u884c\u4e3a\u5bf9\u5e94\u4ee5\u8bc4\u4f30\u51b3\u7b56\u5bf9\u9f50\uff0c\u7279\u522b\u662f\u5728\u65e0\u7ed3\u6784\u73af\u5883\u4e2d\u7684\u534f\u4f5c\u548c\u6a21\u4eff\u5b66\u4e60\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u6f14\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528ResNet\u7f16\u7801\u4eba\u7c7b\u610f\u56fe\u548cPerceiver Transformer\u9884\u6d4b\u673a\u5668\u4eba\u52a8\u4f5c\uff0c\u57fa\u4e8eRGB\u89c6\u9891\u548c\u4f53\u7d20\u5316RGB-D\u6570\u636e\uff0c\u4eceRH20T\u6570\u636e\u96c6\u8bad\u7ec3\u3002", "result": "\u4eba\u7c7b\u6a21\u578b\u51c6\u786e\u738771.67%\uff0c\u673a\u5668\u4eba\u6a21\u578b\u51c6\u786e\u738771.8%\u3002", "conclusion": "\u8bc1\u660e\u6846\u67b6\u5728\u5bf9\u9f50\u590d\u6742\u591a\u6a21\u6001\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u884c\u4e3a\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.11903", "pdf": "https://arxiv.org/pdf/2504.11903", "abs": "https://arxiv.org/abs/2504.11903", "authors": ["Yuan Zhou", "Jiachen Zhong", "Xinli Shi", "Guanghui Wen", "Xinghuo Yu"], "title": "FedCanon: Non-Convex Composite Federated Learning with Efficient Proximal Operation on Heterogeneous Data", "categories": ["cs.LG", "cs.DC", "math.OC"], "comment": null, "summary": "Composite federated learning offers a general framework for solving machine\nlearning problems with additional regularization terms. However, many existing\nmethods require clients to perform multiple proximal operations to handle\nnon-smooth terms and their performance are often susceptible to data\nheterogeneity. To overcome these limitations, we propose a novel composite\nfederated learning algorithm called \\textbf{FedCanon}, designed to solve the\noptimization problems comprising a possibly non-convex loss function and a\nweakly convex, potentially non-smooth regularization term. By decoupling\nproximal mappings from local updates, FedCanon requires only a single proximal\nevaluation on the server per iteration, thereby reducing the overall proximal\ncomputation cost. It also introduces control variables that incorporate global\ngradient information into client updates, which helps mitigate the effects of\ndata heterogeneity. Theoretical analysis demonstrates that FedCanon achieves\nsublinear convergence rates under general non-convex settings and linear\nconvergence under the Polyak-{\\L}ojasiewicz condition, without relying on\nbounded heterogeneity assumptions. Experiments demonstrate that FedCanon\noutperforms the state-of-the-art methods in terms of both accuracy and\ncomputational efficiency, particularly under heterogeneous data distributions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFedCanon\uff0c\u4e00\u79cd\u65b0\u7684\u590d\u5408\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\uff0c\u51cf\u5c11\u8fd1\u7aef\u8ba1\u7b97\u5f00\u9500\uff0c\u5904\u7406\u6570\u636e\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9a8c\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u591a\u6b21\u8fd1\u7aef\u64cd\u4f5c\u4e14\u6613\u53d7\u6570\u636e\u5f02\u8d28\u6027\u5f71\u54cd\uff0cFedCanon\u65e8\u5728\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "FedCanon\u89e3\u8026\u8fd1\u7aef\u6620\u5c04\u4e0e\u672c\u5730\u66f4\u65b0\uff0c\u6bcf\u8fed\u4ee3\u4ec5\u670d\u52a1\u5668\u8fdb\u884c\u4e00\u6b21\u8fd1\u7aef\u8bc4\u4f30\uff0c\u5e76\u7528\u63a7\u5236\u53d8\u91cf\u6574\u5408\u5168\u5c40\u68af\u5ea6\u4fe1\u606f\u3002", "result": "\u5728\u975e\u51f8\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u6b21\u7ebf\u6027\u6536\u655b\uff0c\u5728Polyak-\u0141ojasiewicz\u6761\u4ef6\u4e0b\u7ebf\u6027\u6536\u655b\uff0c\u65e0\u9700\u5f02\u8d28\u6027\u5047\u8bbe\uff1b\u5b9e\u9a8c\u4e2d\u51c6\u786e\u6027\u548c\u6548\u7387\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "FedCanon\u5728\u5f02\u8d28\u6570\u636e\u5206\u5e03\u4e0b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2504.12297", "pdf": "https://arxiv.org/pdf/2504.12297", "abs": "https://arxiv.org/abs/2504.12297", "authors": ["Arthur N. Montanari", "Ana Elisa D. Barioni", "Chao Duan", "Adilson E. Motter"], "title": "Optimal flock formation induced by agent heterogeneity", "categories": ["cond-mat.dis-nn", "cs.SY", "eess.SY", "math.DS", "math.OC", "nlin.AO"], "comment": null, "summary": "The study of flocking in biological systems has identified conditions for\nself-organized collective behavior, inspiring the development of decentralized\nstrategies to coordinate the dynamics of swarms of drones and other autonomous\nvehicles. Previous research has focused primarily on the role of the\ntime-varying interaction network among agents while assuming that the agents\nthemselves are identical or nearly identical. Here, we depart from this\nconventional assumption to investigate how inter-individual differences between\nagents affect the stability and convergence in flocking dynamics. We show that\nflocks of agents with optimally assigned heterogeneous parameters significantly\noutperform their homogeneous counterparts, achieving 20-40% faster convergence\nto desired formations across various control tasks. These tasks include target\ntracking, flock formation, and obstacle maneuvering. In systems with\ncommunication delays, heterogeneity can enable convergence even when flocking\nis unstable for identical agents. Our results challenge existing paradigms in\nmulti-agent control and establish system disorder as an adaptive, distributed\nmechanism to promote collective behavior in flocking dynamics.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4ee3\u7406\u5f02\u8d28\u6027\u5bf9\u7fa4\u805a\u52a8\u529b\u5b66\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5f02\u8d28\u4ee3\u7406\u6536\u655b\u66f4\u5feb\uff0c\u63d0\u5347\u96c6\u4f53\u884c\u4e3a\u3002", "motivation": "\u6311\u6218\u4f20\u7edf\u5047\u8bbe\uff0c\u63a2\u8ba8\u5f02\u8d28\u6027\u5982\u4f55\u63d0\u5347\u7fa4\u805a\u7a33\u5b9a\u6027\u548c\u6536\u655b\u6027\uff0c\u4fc3\u8fdb\u96c6\u4f53\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u5f02\u8d28\u548c\u540c\u8d28\u4ee3\u7406\u5728\u76ee\u6807\u8ddf\u8e2a\u3001\u7fa4\u805a\u5f62\u6210\u548c\u969c\u788d\u89c4\u907f\u7b49\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4f18\u5316\u5f02\u8d28\u53c2\u6570\u3002", "result": "\u5f02\u8d28\u4ee3\u7406\u6536\u655b\u901f\u5ea6\u63d0\u9ad820-40%\uff0c\u5728\u901a\u4fe1\u5ef6\u8fdf\u4e0b\u4e5f\u80fd\u6536\u655b\uff0c\u800c\u540c\u8d28\u4ee3\u7406\u53ef\u80fd\u4e0d\u7a33\u5b9a\u3002", "conclusion": "\u5f02\u8d28\u6027\u662f\u4fc3\u8fdb\u96c6\u4f53\u884c\u4e3a\u7684\u9002\u5e94\u6027\u673a\u5236\uff0c\u6311\u6218\u591a\u4ee3\u7406\u63a7\u5236\u7684\u73b0\u6709\u8303\u5f0f\u3002"}}
{"id": "2504.11500", "pdf": "https://arxiv.org/pdf/2504.11500", "abs": "https://arxiv.org/abs/2504.11500", "authors": ["Kaicong Huang", "Talha Azfar", "Jack Reilly", "Ruimin Ke"], "title": "TransitReID: Transit OD Data Collection with Occlusion-Resistant Dynamic Passenger Re-Identification", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "Transit Origin-Destination (OD) data are essential for transit planning,\nparticularly in route optimization and demand-responsive paratransit systems.\nTraditional methods, such as manual surveys, are costly and inefficient, while\nBluetooth and WiFi-based approaches require passengers to carry specific\ndevices, limiting data coverage. On the other hand, most transit vehicles are\nequipped with onboard cameras for surveillance, offering an opportunity to\nrepurpose them for edge-based OD data collection through visual person\nre-identification (ReID). However, such approaches face significant challenges,\nincluding severe occlusion and viewpoint variations in transit environments,\nwhich greatly reduce matching accuracy and hinder their adoption. Moreover,\ndesigning effective algorithms that can operate efficiently on edge devices\nremains an open challenge. To address these challenges, we propose TransitReID,\na novel framework for individual-level transit OD data collection. TransitReID\nconsists of two key components: (1) An occlusion-robust ReID algorithm\nfeaturing a variational autoencoder guided region-attention mechanism that\nadaptively focuses on visible body regions through reconstruction\nloss-optimized weight allocation; and (2) a Hierarchical Storage and Dynamic\nMatching (HSDM) mechanism specifically designed for efficient and robust\ntransit OD matching which balances storage, speed, and accuracy. Additionally,\na multi-threaded design supports near real-time operation on edge devices,\nwhich also ensuring privacy protection. We also introduce a ReID dataset\ntailored for complex bus environments to address the lack of relevant training\ndata. Experimental results demonstrate that TransitReID achieves\nstate-of-the-art performance in ReID tasks, with an accuracy of approximately\n90\\% in bus route simulations.", "AI": {"tldr": "\u63d0\u51faTransitReID\u6846\u67b6\uff0c\u4f7f\u7528\u89c6\u89c9\u91cd\u8bc6\u522b\u4ece\u516c\u4ea4\u8f66\u6444\u50cf\u5934\u6536\u96c6OD\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u7ea690%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u4ea4\u901aOD\u6570\u636e\u6536\u96c6\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u5e76\u514b\u670d\u8f66\u8f7d\u6444\u50cf\u5934\u91cd\u8bc6\u522b\u4e2d\u7684\u906e\u6321\u548c\u89c6\u89d2\u53d8\u5316\u6311\u6218\u3002", "method": "\u5305\u62ec\u906e\u6321\u9c81\u68d2\u7684\u91cd\u8bc6\u522b\u7b97\u6cd5\uff08\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5f15\u5bfc\u7684\u533a\u57df\u6ce8\u610f\u529b\u673a\u5236\uff09\u548c\u5206\u5c42\u5b58\u50a8\u52a8\u6001\u5339\u914d\u673a\u5236\uff0c\u4ee5\u53ca\u591a\u7ebf\u7a0b\u8bbe\u8ba1\u548c\u4e13\u5c5e\u6570\u636e\u96c6\u3002", "result": "\u5728\u516c\u4ea4\u8def\u7ebf\u6a21\u62df\u4e2d\u8fbe\u5230\u7ea690%\u7684\u51c6\u786e\u7387\uff0c\u5904\u4e8e\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "TransitReID\u6846\u67b6\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u4ea4\u901aOD\u6570\u636e\u6536\u96c6\u7684\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2504.11923", "pdf": "https://arxiv.org/pdf/2504.11923", "abs": "https://arxiv.org/abs/2504.11923", "authors": ["Zeyu Dai", "Shengcai Liu", "Rui He", "Jiahao Wu", "Ning Lu", "Wenqi Fan", "Qing Li", "Ke Tang"], "title": "SemDiff: Generating Natural Unrestricted Adversarial Examples via Semantic Attributes Optimization in Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Unrestricted adversarial examples (UAEs), allow the attacker to create\nnon-constrained adversarial examples without given clean samples, posing a\nsevere threat to the safety of deep learning models. Recent works utilize\ndiffusion models to generate UAEs. However, these UAEs often lack naturalness\nand imperceptibility due to simply optimizing in intermediate latent noises. In\nlight of this, we propose SemDiff, a novel unrestricted adversarial attack that\nexplores the semantic latent space of diffusion models for meaningful\nattributes, and devises a multi-attributes optimization approach to ensure\nattack success while maintaining the naturalness and imperceptibility of\ngenerated UAEs. We perform extensive experiments on four tasks on three\nhigh-resolution datasets, including CelebA-HQ, AFHQ and ImageNet. The results\ndemonstrate that SemDiff outperforms state-of-the-art methods in terms of\nattack success rate and imperceptibility. The generated UAEs are natural and\nexhibit semantically meaningful changes, in accord with the attributes'\nweights. In addition, SemDiff is found capable of evading different defenses,\nwhich further validates its effectiveness and threatening.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSemDiff\u65b9\u6cd5\uff0c\u4f7f\u7528\u6269\u6563\u6a21\u578b\u7684\u8bed\u4e49\u6f5c\u7a7a\u95f4\u751f\u6210\u66f4\u81ea\u7136\u7684\u4e0d\u53d7\u9650\u5bf9\u6297\u6837\u672c\uff0c\u63d0\u9ad8\u653b\u51fb\u6210\u529f\u7387\u548c\u9690\u853d\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u4e0d\u53d7\u9650\u5bf9\u6297\u6837\u672c\u751f\u6210\u65b9\u6cd5\uff0c\u751f\u6210\u7684\u6837\u672c\u7f3a\u4e4f\u81ea\u7136\u6027\u548c\u9690\u853d\u6027\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u5e94\u5bf9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u5b89\u5168\u5a01\u80c1\u3002", "method": "\u63d0\u51faSemDiff\uff0c\u901a\u8fc7\u63a2\u7d22\u6269\u6563\u6a21\u578b\u7684\u8bed\u4e49\u6f5c\u7a7a\u95f4\u5e76\u91c7\u7528\u591a\u5c5e\u6027\u4f18\u5316\uff0c\u786e\u4fdd\u653b\u51fb\u6210\u529f\u540c\u65f6\u4fdd\u6301\u6837\u672c\u7684\u81ea\u7136\u6027\u548c\u9690\u853d\u6027\u3002", "result": "\u5728CelebA-HQ\u3001AFHQ\u548cImageNet\u7b49\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cSemDiff\u5728\u653b\u51fb\u6210\u529f\u7387\u548c\u9690\u853d\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u751f\u6210\u8bed\u4e49\u4e0a\u5408\u7406\u7684\u6837\u672c\u5e76\u89c4\u907f\u591a\u79cd\u9632\u5fa1\u3002", "conclusion": "SemDiff\u662f\u4e00\u79cd\u6709\u6548\u4e14\u5177\u6709\u5a01\u80c1\u6027\u7684\u4e0d\u53d7\u9650\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u63d0\u5347\u653b\u51fb\u6027\u80fd\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.11501", "pdf": "https://arxiv.org/pdf/2504.11501", "abs": "https://arxiv.org/abs/2504.11501", "authors": ["Dean W. Ball"], "title": "A Framework for the Private Governance of Frontier Artificial Intelligence", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "This paper presents a proposal for the governance of frontier AI systems\nthrough a hybrid public-private system. Private bodies, authorized and overseen\nby government, provide certifications to developers of frontier AI systems on\nan opt-in basis. In exchange for opting in, frontier AI firms receive\nprotections from tort liability for customer misuse of their models. Before\ndetailing the proposal, the paper explores more commonly discussed approaches\nto AI governance, analyzing their strengths and flaws. It also examines the\nnature of frontier AI governance itself. The paper includes consideration of\nthe political economic, institutional, legal, safety, and other merits and\ntradeoffs inherent in the governance system it proposes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u516c\u79c1\u7cfb\u7edf\u6cbb\u7406\u524d\u6cbfAI\u7684\u63d0\u6848\uff0c\u79c1\u8425\u673a\u6784\u5728\u653f\u5e9c\u76d1\u7763\u4e0b\u63d0\u4f9b\u53ef\u9009\u8ba4\u8bc1\uff0c\u6362\u53d6\u5f00\u53d1\u8005\u8d23\u4efb\u4fdd\u62a4\uff0c\u5e76\u5206\u6790\u5176\u4ed6\u6cbb\u7406\u65b9\u6cd5\u53ca\u5176\u4f18\u7f3a\u70b9\u3002", "motivation": "\u63a2\u8ba8\u5e38\u89c1AI\u6cbb\u7406\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u63d0\u51fa\u65b0\u7cfb\u7edf\u4ee5\u6539\u5584AI\u6cbb\u7406\uff0c\u8003\u8651\u653f\u6cbb\u7ecf\u6d4e\u3001\u673a\u6784\u3001\u6cd5\u5f8b\u3001\u5b89\u5168\u7b49\u56e0\u7d20\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u516c\u79c1\u6cbb\u7406\u6846\u67b6\uff1a\u79c1\u8425\u673a\u6784\u83b7\u653f\u5e9c\u6388\u6743\uff0c\u4e3a\u524d\u6cbfAI\u5f00\u53d1\u8005\u63d0\u4f9b\u53ef\u9009\u8ba4\u8bc1\uff0c\u5f00\u53d1\u8005\u6362\u53d6\u514d\u9664\u5ba2\u6237\u8bef\u7528\u6a21\u578b\u7684\u8d23\u4efb\u3002", "result": "\u5206\u6790\u4e86\u591a\u79cdAI\u6cbb\u7406\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u8bc4\u4f30\u63d0\u6848\u7cfb\u7edf\u7684\u4f18\u7f3a\u70b9\uff0c\u5305\u62ec\u5b89\u5168\u548c\u5176\u4ed6\u65b9\u9762\u7684\u6743\u8861\u3002", "conclusion": "\u63d0\u6848\u63d0\u4f9b\u4e00\u79cd\u5e73\u8861\u7684AI\u6cbb\u7406\u65b9\u5f0f\uff0c\u5f3a\u8c03\u901a\u8fc7\u516c\u79c1\u5408\u4f5c\u63d0\u5347\u5b89\u5168\u6027\u548c\u8d23\u4efb\u673a\u5236\u3002"}}
{"id": "2504.11944", "pdf": "https://arxiv.org/pdf/2504.11944", "abs": "https://arxiv.org/abs/2504.11944", "authors": ["Xuyang Chen", "Guojian Wang", "Keyu Yan", "Lin Zhao"], "title": "VIPO: Value Function Inconsistency Penalized Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Offline reinforcement learning (RL) learns effective policies from\npre-collected datasets, offering a practical solution for applications where\nonline interactions are risky or costly. Model-based approaches are\nparticularly advantageous for offline RL, owing to their data efficiency and\ngeneralizability. However, due to inherent model errors, model-based methods\noften artificially introduce conservatism guided by heuristic uncertainty\nestimation, which can be unreliable. In this paper, we introduce VIPO, a novel\nmodel-based offline RL algorithm that incorporates self-supervised feedback\nfrom value estimation to enhance model training. Specifically, the model is\nlearned by additionally minimizing the inconsistency between the value learned\ndirectly from the offline data and the one estimated from the model. We perform\ncomprehensive evaluations from multiple perspectives to show that VIPO can\nlearn a highly accurate model efficiently and consistently outperform existing\nmethods. It offers a general framework that can be readily integrated into\nexisting model-based offline RL algorithms to systematically enhance model\naccuracy. As a result, VIPO achieves state-of-the-art performance on almost all\ntasks in both D4RL and NeoRL benchmarks.", "AI": {"tldr": "VIPO \u662f\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u503c\u4f30\u8ba1\u4e0d\u4e00\u81f4\u6027\u6765\u63d0\u9ad8\u6a21\u578b\u51c6\u786e\u6027\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u6a21\u578b-based \u79bb\u7ebf RL \u4e2d\u6a21\u578b\u9519\u8bef\u5bfc\u81f4\u7684\u542f\u53d1\u5f0f\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4e0d\u53ef\u9760\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u81ea\u76d1\u7763\u53cd\u9988\u6700\u5c0f\u5316\u76f4\u63a5\u4ece\u79bb\u7ebf\u6570\u636e\u5b66\u4e60\u7684\u503c\u4e0e\u6a21\u578b\u4f30\u8ba1\u7684\u503c\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\u6765\u589e\u5f3a\u6a21\u578b\u8bad\u7ec3\u3002", "result": "VIPO \u9ad8\u6548\u5b66\u4e60\u51c6\u786e\u6a21\u578b\uff0c\u4e00\u81f4\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728 D4RL \u548c NeoRL \u57fa\u51c6\u4e0a\u51e0\u4e4e\u6240\u6709\u4efb\u52a1\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "VIPO \u63d0\u4f9b\u901a\u7528\u6846\u67b6\uff0c\u53ef\u96c6\u6210\u5230\u73b0\u6709\u7b97\u6cd5\u4e2d\u7cfb\u7edf\u63d0\u5347\u6a21\u578b\u51c6\u786e\u6027\u3002"}}
{"id": "2504.11510", "pdf": "https://arxiv.org/pdf/2504.11510", "abs": "https://arxiv.org/abs/2504.11510", "authors": ["Xiaohua Feng", "Yuyuan Li", "Fengyuan Yu", "Ke Xiong", "Junjie Fang", "Li Zhang", "Tianyu Du", "Chaochao Chen"], "title": "RAID: An In-Training Defense against Attribute Inference Attacks in Recommender Systems", "categories": ["cs.IR", "cs.AI", "cs.CR", "cs.CY", "cs.LG"], "comment": "17 pages", "summary": "In various networks and mobile applications, users are highly susceptible to\nattribute inference attacks, with particularly prevalent occurrences in\nrecommender systems. Attackers exploit partially exposed user profiles in\nrecommendation models, such as user embeddings, to infer private attributes of\ntarget users, such as gender and political views. The goal of defenders is to\nmitigate the effectiveness of these attacks while maintaining recommendation\nperformance. Most existing defense methods, such as differential privacy and\nattribute unlearning, focus on post-training settings, which limits their\ncapability of utilizing training data to preserve recommendation performance.\nAlthough adversarial training extends defenses to in-training settings, it\noften struggles with convergence due to unstable training processes. In this\npaper, we propose RAID, an in-training defense method against attribute\ninference attacks in recommender systems. In addition to the recommendation\nobjective, we define a defensive objective to ensure that the distribution of\nprotected attributes becomes independent of class labels, making users\nindistinguishable from attribute inference attacks. Specifically, this\ndefensive objective aims to solve a constrained Wasserstein barycenter problem\nto identify the centroid distribution that makes the attribute\nindistinguishable while complying with recommendation performance constraints.\nTo optimize our proposed objective, we use optimal transport to align users\nwith the centroid distribution. We conduct extensive experiments on four\nreal-world datasets to evaluate RAID. The experimental results validate the\neffectiveness of RAID and demonstrate its significant superiority over existing\nmethods in multiple aspects.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faRAID\uff0c\u4e00\u79cd\u5728\u8bad\u7ec3\u9632\u5fa1\u65b9\u6cd5\uff0c\u7528\u4e8e\u5bf9\u6297\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5c5e\u6027\u63a8\u65ad\u653b\u51fb\uff0c\u901a\u8fc7Wasserstein\u91cd\u5fc3\u95ee\u9898\u4f7f\u5c5e\u6027\u4e0d\u53ef\u533a\u5206\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u4e2d\u7528\u6237\u6613\u53d7\u5c5e\u6027\u63a8\u65ad\u653b\u51fb\uff0c\u73b0\u6709\u7684\u540e\u8bad\u7ec3\u9632\u5fa1\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u5229\u7528\u8bad\u7ec3\u6570\u636e\uff0c\u4e9f\u9700\u5728\u8bad\u7ec3\u4e2d\u8fdb\u884c\u9632\u5fa1\u3002", "method": "RAID\u5b9a\u4e49\u9632\u5fa1\u76ee\u6807\uff0c\u6c42\u89e3\u53d7\u7ea6\u675f\u7684Wasserstein\u91cd\u5fc3\u95ee\u9898\uff0c\u4f7f\u7528\u6700\u4f18\u4f20\u8f93\u5bf9\u7528\u6237\u4e0e\u4e2d\u5fc3\u5206\u5e03\u5bf9\u9f50\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cRAID\u663e\u793a\u51fa\u6709\u6548\u6027\u548c\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "RAID\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5728\u8bad\u7ec3\u9632\u5fa1\u65b9\u6cd5\uff0c\u80fd\u964d\u4f4e\u653b\u51fb\u98ce\u9669\u5e76\u7ef4\u6301\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2504.11981", "pdf": "https://arxiv.org/pdf/2504.11981", "abs": "https://arxiv.org/abs/2504.11981", "authors": ["Sosei Ikeda", "Hiromitsu Awano", "Takashi Sato"], "title": "Hardware-Friendly Delayed-Feedback Reservoir for Multivariate Time-Series Classification", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Reservoir computing (RC) is attracting attention as a machine-learning\ntechnique for edge computing. In time-series classification tasks, the number\nof features obtained using a reservoir depends on the length of the input\nseries. Therefore, the features must be converted to a constant-length\nintermediate representation (IR), such that they can be processed by an output\nlayer. Existing conversion methods involve computationally expensive matrix\ninversion that significantly increases the circuit size and requires processing\npower when implemented in hardware. In this article, we propose a simple but\neffective IR, namely, dot-product-based reservoir representation (DPRR), for RC\nbased on the dot product of data features. Additionally, we propose a\nhardware-friendly delayed-feedback reservoir (DFR) consisting of a nonlinear\nelement and delayed feedback loop with DPRR. The proposed DFR successfully\nclassified multivariate time series data that has been considered particularly\ndifficult to implement efficiently in hardware. In contrast to conventional DFR\nmodels that require analog circuits, the proposed model can be implemented in a\nfully digital manner suitable for high-level syntheses. A comparison with\nexisting machine-learning methods via field-programmable gate array\nimplementation using 12 multivariate time-series classification tasks confirmed\nthe superior accuracy and small circuit size of the proposed method.", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u70b9\u79ef\u7684 reservoir \u8868\u793a\uff08DPRR\uff09\u548c\u786c\u4ef6\u53cb\u597d\u7684\u5ef6\u8fdf\u53cd\u9988 reservoir\uff08DFR\uff09\uff0c\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684 reservoir \u8ba1\u7b97\uff0c\u5c55\u793a\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u5c0f\u7684\u7535\u8def\u89c4\u6a21\u3002", "motivation": "\u73b0\u6709\u7684 reservoir \u8ba1\u7b97\u65b9\u6cd5\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e2d\u9700\u8981\u8ba1\u7b97\u6602\u8d35\u7684\u77e9\u9635\u6c42\u9006\uff0c\u5bfc\u81f4\u786c\u4ef6\u5b9e\u73b0\u65f6\u7535\u8def\u89c4\u6a21\u5927\u548c\u5904\u7406\u80fd\u529b\u9700\u6c42\u9ad8\u3002", "method": "\u63d0\u51fa DPRR \u57fa\u4e8e\u6570\u636e\u7279\u5f81\u70b9\u79ef\uff0c\u4ee5\u53ca\u7531\u975e\u7ebf\u6027\u5143\u7d20\u548c\u5ef6\u8fdf\u53cd\u9988\u56de\u8def\u7ec4\u6210\u7684 DFR\uff0c\u8be5\u65b9\u6cd5\u53ef\u5b8c\u5168\u6570\u5b57\u65b9\u5f0f\u5b9e\u73b0\uff0c\u9002\u5408\u9ad8\u7ea7\u7efc\u5408\u3002", "result": "\u6240\u63d0\u51fa\u7684 DFR \u6210\u529f\u5206\u7c7b\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5728 12 \u4e2a\u4efb\u52a1\u7684 FPGA \u5b9e\u73b0\u4e2d\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u663e\u793a\u51fa\u4f18\u8d8a\u7684\u51c6\u786e\u6027\u548c\u66f4\u5c0f\u7684\u7535\u8def\u89c4\u6a21\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a reservoir \u8ba1\u7b97\u5728\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u786c\u4ef6\u5b9e\u73b0\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u3001\u6709\u6548\u4e14\u53cb\u597d\u7684\u65b9\u6848\u3002"}}
{"id": "2504.11990", "pdf": "https://arxiv.org/pdf/2504.11990", "abs": "https://arxiv.org/abs/2504.11990", "authors": ["Yechao Zhang", "Yuxuan Zhou", "Tianyu Li", "Minghui Li", "Shengshan Hu", "Wei Luo", "Leo Yu Zhang"], "title": "Secure Transfer Learning: Training Clean Models Against Backdoor in (Both) Pre-trained Encoders and Downstream Datasets", "categories": ["cs.LG", "cs.CR"], "comment": "To appear at IEEE Symposium on Security and Privacy 2025, 20 pages", "summary": "Transfer learning from pre-trained encoders has become essential in modern\nmachine learning, enabling efficient model adaptation across diverse tasks.\nHowever, this combination of pre-training and downstream adaptation creates an\nexpanded attack surface, exposing models to sophisticated backdoor embeddings\nat both the encoder and dataset levels--an area often overlooked in prior\nresearch. Additionally, the limited computational resources typically available\nto users of pre-trained encoders constrain the effectiveness of generic\nbackdoor defenses compared to end-to-end training from scratch. In this work,\nwe investigate how to mitigate potential backdoor risks in resource-constrained\ntransfer learning scenarios. Specifically, we conduct an exhaustive analysis of\nexisting defense strategies, revealing that many follow a reactive workflow\nbased on assumptions that do not scale to unknown threats, novel attack types,\nor different training paradigms. In response, we introduce a proactive mindset\nfocused on identifying clean elements and propose the Trusted Core (T-Core)\nBootstrapping framework, which emphasizes the importance of pinpointing\ntrustworthy data and neurons to enhance model security. Our empirical\nevaluations demonstrate the effectiveness and superiority of T-Core,\nspecifically assessing 5 encoder poisoning attacks, 7 dataset poisoning\nattacks, and 14 baseline defenses across five benchmark datasets, addressing\nfour scenarios of 3 potential backdoor threats.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u8f6c\u79fb\u5b66\u4e60\u4e2d\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u7684\u540e\u95e8\u98ce\u9669\uff0c\u63d0\u51faT-Core\u6846\u67b6\u8fdb\u884c\u4e3b\u52a8\u9632\u5fa1\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8f6c\u79fb\u5b66\u4e60\u589e\u52a0\u4e86\u653b\u51fb\u9762\uff0c\u73b0\u6709\u9632\u5fa1\u7b56\u7565\u4e0d\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u573a\u666f\u548c\u672a\u77e5\u5a01\u80c1\u3002", "method": "\u63d0\u51faTrusted Core (T-Core) Bootstrapping\u6846\u67b6\uff0c\u4e13\u6ce8\u4e8e\u8bc6\u522b\u53ef\u4fe1\u6570\u636e\u548c\u795e\u7ecf\u5143\u4ee5\u63d0\u5347\u6a21\u578b\u5b89\u5168\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793aT-Core\u57285\u79cd\u7f16\u7801\u5668\u653b\u51fb\u30017\u79cd\u6570\u636e\u96c6\u653b\u51fb\u548c14\u79cd\u9632\u5fa1\u57fa\u7ebf\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u573a\u666f\u3002", "conclusion": "T-Core\u6846\u67b6\u901a\u8fc7\u4e3b\u52a8\u8bc6\u522b\u53ef\u4fe1\u5143\u7d20\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u7684\u540e\u95e8\u9632\u5fa1\u65b9\u6cd5\u3002"}}
{"id": "2504.11536", "pdf": "https://arxiv.org/pdf/2504.11536", "abs": "https://arxiv.org/abs/2504.11536", "authors": ["Jiazhan Feng", "Shijue Huang", "Xingwei Qu", "Ge Zhang", "Yujia Qin", "Baoquan Zhong", "Chengquan Jiang", "Jinxin Chi", "Wanjun Zhong"], "title": "ReTool: Reinforcement Learning for Strategic Tool Use in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "While reasoning models (e.g., DeepSeek R1) trained with reinforcement\nlearning (RL), excel in textual reasoning, they struggle in scenarios requiring\nstructured problem-solving, such as geometric reasoning, concise computation,\nor complex equation solving-areas where computational tools like code\ninterpreters (CI) demonstrate distinct advantages. To bridge this gap, we\npropose ReTool, which enhances long-form reasoning with tool-integrated\nlearning, including two key features: (1) dynamic interleaving of real-time\ncode execution within natural language reasoning processes, and (2) an\nautomated RL paradigm that allows policy rollouts with multi-turn real-time\ncode execution and teaches the model in learning when and how to invoke tools\nbased on outcome feedback. ReTool employs a systematic training framework,\nbeginning with synthetic cold-start data generation to produce code-augmented\nlong-form reasoning traces for fine-tuning base models. Subsequent RL training\nleverages task outcomes as rewards to iteratively refine the model's tool use\nstrategy, enabling autonomous discovery of optimal tool invocation patterns\nwithout human priors. Experiments on the challenging MATH Olympiad benchmark\nAIME demonstrate ReTool's superiority: Our 32B model achieves 67% accuracy with\n400 training steps, outperforming text-based RL baseline (40% accuracy, 1080\nsteps) in efficiency and performance. Remarkably, ReTool-32B attains 72.5%\naccuracy in extended settings, surpassing OpenAI's o1-preview by 27.9%. Further\nanalysis reveals emergent behaviors such as code self-correction, signaling an\n''aha moment'' in which the model autonomously masters adaptive tool use. These\nfindings highlight the promise of outcome-driven tool integration for advancing\ncomplex mathematical reasoning and offer new insights into hybrid\nneuro-symbolic systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa ReTool \u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u5b9e\u65f6\u4ee3\u7801\u6267\u884c\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u5347\u63a8\u7406\u6a21\u578b\u5728\u7ed3\u6784\u5316\u95ee\u9898\u4e0a\u7684\u6027\u80fd\uff0c\u5728 AIME \u57fa\u51c6\u4e0a\u8fbe\u5230 67% \u51c6\u786e\u7387\uff0c\u5e76\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u6a21\u578b\u5728\u6587\u672c\u63a8\u7406\u4e0a\u51fa\u8272\uff0c\u4f46\u5904\u7406\u51e0\u4f55\u3001\u8ba1\u7b97\u548c\u65b9\u7a0b\u7b49\u7ed3\u6784\u5316\u95ee\u9898\u65f6\u8868\u73b0\u8f83\u5dee\uff0c\u800c\u4ee3\u7801\u89e3\u91ca\u5668\u66f4\u64c5\u957f\uff0c\u56e0\u6b64\u9700\u8981\u6865\u63a5\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa ReTool\uff0c\u5305\u62ec\u52a8\u6001\u4ee3\u7801\u6267\u884c\u4e0e\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4ea4\u7ec7\uff0c\u4ee5\u53ca\u57fa\u4e8e\u7ed3\u679c\u53cd\u9988\u7684 RL \u8bad\u7ec3\u6846\u67b6\uff0c\u4f7f\u7528\u5408\u6210\u6570\u636e\u521d\u59cb\u5316\u5e76\u8fed\u4ee3\u4f18\u5316\u5de5\u5177\u8c03\u7528\u7b56\u7565\u3002", "result": "\u5728 AIME \u4e0a\uff0c32B \u6a21\u578b\u5728 400 \u6b65\u8bad\u7ec3\u540e\u8fbe\u5230 67% \u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u6587\u672c RL \u57fa\u7ebf\uff0840% \u51c6\u786e\u7387\uff0c1080 \u6b65\uff09\uff1b\u5728\u6269\u5c55\u8bbe\u7f6e\u4e2d\u8fbe 72.5%\uff0c\u8d85\u8fc7 OpenAI o1-preview 27.9 \u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u8bc1\u660e\u4e86\u7ed3\u679c\u9a71\u52a8\u5de5\u5177\u6574\u5408\u5728\u590d\u6742\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u4e3a\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u63d0\u4f9b\u65b0\u89c1\u89e3\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u7684\u81ea\u9002\u5e94\u5de5\u5177\u4f7f\u7528\u884c\u4e3a\u3002"}}
{"id": "2504.11992", "pdf": "https://arxiv.org/pdf/2504.11992", "abs": "https://arxiv.org/abs/2504.11992", "authors": ["Pascal Schlachter", "Jonathan Fuss", "Bin Yang"], "title": "Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation", "categories": ["cs.LG", "cs.CV"], "comment": "Submitted to the 33rd European Signal Processing Conference (EUSIPCO\n  2025)", "summary": "A domain (distribution) shift between training and test data often hinders\nthe real-world performance of deep neural networks, necessitating unsupervised\ndomain adaptation (UDA) to bridge this gap. Online source-free UDA has emerged\nas a solution for practical scenarios where access to source data is restricted\nand target data is received as a continuous stream. However, the open-world\nnature of many real-world applications additionally introduces category shifts\nmeaning that the source and target label spaces may differ. Online source-free\nuniversal domain adaptation (SF-UniDA) addresses this challenge. Existing\nmethods mainly rely on self-training with pseudo-labels, yet the relationship\nbetween pseudo-labeling and adaptation outcomes has not been studied yet. To\nbridge this gap, we conduct a systematic analysis through controlled\nexperiments with simulated pseudo-labeling, offering valuable insights into\npseudo-labeling for online SF-UniDA. Our findings reveal a substantial gap\nbetween the current state-of-the-art and the upper bound of adaptation achieved\nwith perfect pseudo-labeling. Moreover, we show that a contrastive loss enables\neffective adaptation even with moderate pseudo-label accuracy, while a\ncross-entropy loss, though less robust to pseudo-label errors, achieves\nsuperior results when pseudo-labeling approaches perfection. Lastly, our\nfindings indicate that pseudo-label accuracy is in general more crucial than\nquantity, suggesting that prioritizing fewer but high-confidence pseudo-labels\nis beneficial. Overall, our study highlights the critical role of\npseudo-labeling in (online) SF-UniDA and provides actionable insights to drive\nfuture advancements in the field. Our code is available at\nhttps://github.com/pascalschlachter/PLAnalysis.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u5206\u6790\u4e86\u5728\u7ebf\u6e90\u65e0\u901a\u7528\u57df\u9002\u5e94\u7684\u4f2a\u6807\u7b7e\u673a\u5236\uff0c\u53d1\u73b0\u4f2a\u6807\u7b7e\u51c6\u786e\u7387\u6bd4\u6570\u91cf\u66f4\u91cd\u8981\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u57df\u79fb\u4f4d\u548c\u7c7b\u522b\u79fb\u4f4d\u95ee\u9898\u5f71\u54cd\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5b9e\u9645\u6027\u80fd\uff0c\u4e9f\u9700\u5728\u7ebf\u6e90\u65e0\u901a\u7528\u57df\u9002\u5e94\u65b9\u6cd5\u6765\u5904\u7406\u6e90\u6570\u636e\u53d7\u9650\u548c\u76ee\u6807\u6570\u636e\u6d41\u5f0f\u8f93\u5165\u7684\u573a\u666f\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u4f2a\u6807\u7b7e\u7684\u63a7\u5236\u5b9e\u9a8c\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5f53\u524d\u65b9\u6cd5\u4e0e\u5b8c\u7f8e\u4f2a\u6807\u7b7e\u4e0a\u754c\u6709\u5dee\u8ddd\uff1b\u5bf9\u6bd4\u635f\u5931\u5728\u4e2d\u7b49\u4f2a\u6807\u7b7e\u51c6\u786e\u7387\u4e0b\u6709\u6548\uff1b\u4ea4\u53c9\u71b5\u635f\u5931\u5728\u9ad8\u51c6\u786e\u7387\u4e0b\u4f18\u8d8a\uff1b\u4f2a\u6807\u7b7e\u51c6\u786e\u7387\u6bd4\u6570\u91cf\u66f4\u5173\u952e\u3002", "conclusion": "\u5f3a\u8c03\u4f2a\u6807\u7b7e\u5728\u5728\u7ebf\u6e90\u65e0\u901a\u7528\u57df\u9002\u5e94\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6539\u8fdb\u5efa\u8bae\u3002"}}
{"id": "2504.11997", "pdf": "https://arxiv.org/pdf/2504.11997", "abs": "https://arxiv.org/abs/2504.11997", "authors": ["Kihyuk Hong", "Ambuj Tewari"], "title": "A Computationally Efficient Algorithm for Infinite-Horizon Average-Reward Linear MDPs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We study reinforcement learning in infinite-horizon average-reward settings\nwith linear MDPs. Previous work addresses this problem by approximating the\naverage-reward setting by discounted setting and employing a value\niteration-based algorithm that uses clipping to constrain the span of the value\nfunction for improved statistical efficiency. However, the clipping procedure\nrequires computing the minimum of the value function over the entire state\nspace, which is prohibitive since the state space in linear MDP setting can be\nlarge or even infinite. In this paper, we introduce a value iteration method\nwith efficient clipping operation that only requires computing the minimum of\nvalue functions over the set of states visited by the algorithm. Our algorithm\nenjoys the same regret bound as the previous work while being computationally\nefficient, with computational complexity that is independent of the size of the\nstate space.", "AI": {"tldr": "\u7b80\u800c\u8a00\u4e4b\uff0c\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u622a\u65ad\u64cd\u4f5c\u7684\u8fed\u4ee3\u503c\u65b9\u6cd5\uff0c\u7528\u4e8e\u65e0\u9650\u5730\u5e73\u5e73\u5747\u5956\u52b1\u7ebf\u6027MDP\u8bbe\u7f6e\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u4e4b\u524d\u7684\u4f5c\u54c1\u901a\u8fc7\u8fd1\u4f3c\u5e73\u5747\u5956\u52b1\u8bbe\u7f6e\u4e3a\u6298\u6263\u8bbe\u7f6e\uff0c\u5e76\u4f7f\u7528\u622a\u65ad\u6765\u7ea6\u675f\u503c\u51fd\u6570\u7684\u8de8\u5ea6\uff0c\u4f46\u8ba1\u7b97\u6700\u5c0f\u503c\u9700\u8981\u904d\u5386\u6574\u4e2a\u72b6\u6001\u7a7a\u95f4\uff0c\u8fd9\u5728\u5927\u578b\u6216\u65e0\u9650\u72b6\u6001\u7a7a\u95f4\u4e2d\u4e0d\u53ef\u884c\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u503c\u8fed\u4ee3\u65b9\u6cd5\uff0c\u53ea\u9700\u5728\u7b97\u6cd5\u8bbf\u95ee\u7684\u72b6\u6001\u96c6\u4e0a\u8ba1\u7b97\u503c\u51fd\u6570\u7684\u6700\u5c0f\u503c\u3002", "result": "\u7b97\u6cd5\u4fdd\u6301\u4e86\u4e0e\u4e4b\u524d\u5de5\u4f5c\u76f8\u540c\u7684\u9057\u61be\u754c\u9650\uff0c\u540c\u65f6\u8ba1\u7b97\u590d\u6742\u5ea6\u72ec\u7acb\u4e8e\u72b6\u6001\u7a7a\u95f4\u5927\u5c0f\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5982\u4f55\u5728\u4fdd\u6301\u7edf\u8ba1\u6548\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2504.11564", "pdf": "https://arxiv.org/pdf/2504.11564", "abs": "https://arxiv.org/abs/2504.11564", "authors": ["Lee Ackerman"], "title": "Perceptions of Agentic AI in Organizations: Implications for Responsible AI and ROI", "categories": ["cs.CY", "cs.AI", "68T99 (Primary), 91D25 (Secondary)", "K.4; I.2; K.4.2; K.4.3"], "comment": "26 pages, 15 figures", "summary": "As artificial intelligence (AI) systems rapidly gain autonomy, the need for\nrobust responsible AI frameworks becomes paramount. This paper investigates how\norganizations perceive and adapt such frameworks amidst the emerging landscape\nof increasingly sophisticated agentic AI. Employing an interpretive qualitative\napproach, the study explores the lived experiences of AI professionals.\nFindings highlight that the inherent complexity of agentic AI systems and their\nresponsible implementation, rooted in the intricate interconnectedness of\nresponsible AI dimensions and the thematic framework (an analytical structure\ndeveloped from the data), combined with the novelty of agentic AI, contribute\nto significant challenges in organizational adaptation, characterized by\nknowledge gaps, a limited emphasis on stakeholder engagement, and a strong\nfocus on control. These factors, by hindering effective adaptation and\nimplementation, ultimately compromise the potential for responsible AI and the\nrealization of ROI.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u7ec4\u7ec7\u5982\u4f55\u5728\u4ee3\u7406\u5f0fAI\u5174\u8d77\u4e2d\u611f\u77e5\u548c\u9002\u5e94\u8d1f\u8d23\u4efbAI\u6846\u67b6\uff0c\u53d1\u73b0\u4e86\u9002\u5e94\u6311\u6218\uff0c\u5305\u62ec\u77e5\u8bc6\u7f3a\u53e3\u548c\u63a7\u5236\u7126\u70b9\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u5feb\u901f\u83b7\u5f97\u81ea\u6cbb\u6027\uff0c\u8feb\u5207\u9700\u8981\u7a33\u5065\u7684\u8d1f\u8d23\u4efbAI\u6846\u67b6\u6765\u5e94\u5bf9\u65b0\u5174\u6311\u6218\u3002", "method": "\u91c7\u7528\u89e3\u91ca\u6027\u5b9a\u6027\u65b9\u6cd5\uff0c\u63a2\u7d22AI\u4e13\u4e1a\u4eba\u5458\u7684\u4eb2\u8eab\u7ecf\u5386\u3002", "result": "\u53d1\u73b0\u4ee3\u7406\u5f0fAI\u7684\u590d\u6742\u6027\u5bfc\u81f4\u7ec4\u7ec7\u9002\u5e94\u56f0\u96be\uff0c\u8868\u73b0\u4e3a\u77e5\u8bc6\u7f3a\u53e3\u3001\u6709\u9650\u7684\u5229\u76ca\u76f8\u5173\u8005\u53c2\u4e0e\u548c\u5bf9\u63a7\u5236\u7684\u5f3a\u8c03\u3002", "conclusion": "\u8fd9\u4e9b\u56e0\u7d20\u963b\u788d\u4e86\u6709\u6548\u5b9e\u65bd\uff0c\u635f\u5bb3\u4e86\u8d1f\u8d23\u4efbAI\u7684\u6f5c\u529b\u548cROI\u7684\u5b9e\u73b0\u3002"}}
{"id": "2504.12011", "pdf": "https://arxiv.org/pdf/2504.12011", "abs": "https://arxiv.org/abs/2504.12011", "authors": ["Heesoo Jung", "Hogun Park"], "title": "Balancing Graph Embedding Smoothness in Self-Supervised Learning via Information-Theoretic Decomposition", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to the Web Conference (WWW) 2025", "summary": "Self-supervised learning (SSL) in graphs has garnered significant attention,\nparticularly in employing Graph Neural Networks (GNNs) with pretext tasks\ninitially designed for other domains, such as contrastive learning and feature\nreconstruction. However, it remains uncertain whether these methods effectively\nreflect essential graph properties, precisely representation similarity with\nits neighbors. We observe that existing methods position opposite ends of a\nspectrum driven by the graph embedding smoothness, with each end corresponding\nto outperformance on specific downstream tasks. Decomposing the SSL objective\ninto three terms via an information-theoretic framework with a neighbor\nrepresentation variable reveals that this polarization stems from an imbalance\namong the terms, which existing methods may not effectively maintain. Further\ninsights suggest that balancing between the extremes can lead to improved\nperformance across a wider range of downstream tasks. A framework, BSG\n(Balancing Smoothness in Graph SSL), introduces novel loss functions designed\nto supplement the representation quality in graph-based SSL by balancing the\nderived three terms: neighbor loss, minimal loss, and divergence loss. We\npresent a theoretical analysis of the effects of these loss functions,\nhighlighting their significance from both the SSL and graph smoothness\nperspectives. Extensive experiments on multiple real-world datasets across node\nclassification and link prediction consistently demonstrate that BSG achieves\nstate-of-the-art performance, outperforming existing methods. Our\nimplementation code is available at https://github.com/steve30572/BSG.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faBSG\u6846\u67b6\uff0c\u901a\u8fc7\u5e73\u8861\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u5e73\u6ed1\u6027\uff0c\u6539\u5584\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u6709\u6548\u53cd\u6620\u56fe\u5c5e\u6027\uff0c\u5bfc\u81f4\u4efb\u52a1\u6027\u80fd\u4e0d\u5747\u8861\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5e73\u8861\u4fe1\u606f\u8bba\u5206\u89e3\u7684\u4e09\u4e2a\u672f\u8bed\u6765\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u4fe1\u606f\u8bba\u6846\u67b6\u5206\u89e3SSL\u76ee\u6807\u4e3a\u4e09\u4e2a\u90e8\u5206\uff0c\u5f15\u5165BSG\u6846\u67b6\u53ca\u5176\u635f\u5931\u51fd\u6570\uff08\u90bb\u5c45\u635f\u5931\u3001\u6700\u5c0f\u635f\u5931\u548c\u53d1\u6563\u635f\u5931\uff09\u6765\u5e73\u8861\u8fd9\u4e9b\u672f\u8bed\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u7684\u8282\u70b9\u5206\u7c7b\u548c\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cBSG\u6846\u67b6\u53d6\u5f97\u4e86state-of-the-art\u6027\u80fd\u3002", "conclusion": "BSG\u6846\u67b6\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5e73\u8861\u5e73\u6ed1\u6027\u80fd\u63d0\u5347\u6574\u4f53\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u5f00\u6e90\u4ee3\u7801\u3002"}}
{"id": "2504.11575", "pdf": "https://arxiv.org/pdf/2504.11575", "abs": "https://arxiv.org/abs/2504.11575", "authors": ["Furqan Rustam", "Islam Obaidat", "Anca Delia Jurcut"], "title": "MULTI-LF: A Unified Continuous Learning Framework for Real-Time DDoS Detection in Multi-Environment Networks", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Detecting Distributed Denial of Service (DDoS) attacks in Multi-Environment\n(M-En) networks presents significant challenges due to diverse malicious\ntraffic patterns and the evolving nature of cyber threats. Existing AI-based\ndetection systems struggle to adapt to new attack strategies and lack real-time\nattack detection capabilities with high accuracy and efficiency. This study\nproposes an online, continuous learning methodology for DDoS detection in M-En\nnetworks, enabling continuous model updates and real-time adaptation to\nemerging threats, including zero-day attacks. First, we develop a unique M-En\nnetwork dataset by setting up a realistic, real-time simulation using the NS-3\ntool, incorporating both victim and bot devices. DDoS attacks with varying\npacket sizes are simulated using the DDoSim application across IoT and\ntraditional IP-based environments under M-En network criteria. Our approach\nemploys a multi-level framework (MULTI-LF) featuring two machine learning\nmodels: a lightweight Model 1 (M1) trained on a selective, critical packet\ndataset for fast and efficient initial detection, and a more complex, highly\naccurate Model 2 (M2) trained on extensive data. When M1 exhibits low\nconfidence in its predictions, the decision is escalated to M2 for verification\nand potential fine-tuning of M1 using insights from M2. If both models\ndemonstrate low confidence, the system flags the incident for human\nintervention, facilitating model updates with human-verified categories to\nenhance adaptability to unseen attack patterns. We validate the MULTI-LF\nthrough real-world simulations, demonstrating superior classification accuracy\nof 0.999 and low prediction latency of 0.866 seconds compared to established\nbaselines. Furthermore, we evaluate performance in terms of memory usage (3.632\nMB) and CPU utilization (10.05%) in real-time scenarios.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7ebf\u8fde\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u73af\u5883\u7f51\u7edc\u4e2d\u7684DDoS\u68c0\u6d4b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u7387\u548c\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709AI\u68c0\u6d4b\u7cfb\u7edf\u65e0\u6cd5\u9002\u5e94\u65b0\u653b\u51fb\u7b56\u7565\uff0c\u7f3a\u4e4f\u5b9e\u65f6\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u3002", "method": "\u5f00\u53d1M-En\u6570\u636e\u96c6\u548cMULTI-LF\u6846\u67b6\uff0c\u4f7f\u7528\u4e24\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u5206\u7ea7\u68c0\u6d4b\u548c\u8fde\u7eed\u5b66\u4e60\u3002", "result": "\u5206\u7c7b\u51c6\u786e\u73870.999\uff0c\u9884\u6d4b\u5ef6\u8fdf0.866\u79d2\uff0c\u5185\u5b58\u4f7f\u75283.632 MB\uff0cCPU\u5229\u7528\u738710.05%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5b9e\u65f6\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u63d0\u9ad8\u4e86DDoS\u68c0\u6d4b\u7684\u9002\u5e94\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2504.12016", "pdf": "https://arxiv.org/pdf/2504.12016", "abs": "https://arxiv.org/abs/2504.12016", "authors": ["Arun Verma", "Xiaoqiang Lin", "Zhongxiang Dai", "Daniela Rus", "Bryan Kian Hsiang Low"], "title": "Active Human Feedback Collection via Neural Contextual Dueling Bandits", "categories": ["cs.LG"], "comment": "Accepted at ICLR 2025 Workshop on Bidirectional Human-AI Alignment\n  (BiAlign)", "summary": "Collecting human preference feedback is often expensive, leading recent works\nto develop principled algorithms to select them more efficiently. However,\nthese works assume that the underlying reward function is linear, an assumption\nthat does not hold in many real-life applications, such as online\nrecommendation and LLM alignment. To address this limitation, we propose\nNeural-ADB, an algorithm based on the neural contextual dueling bandit\nframework that provides a principled and practical method for collecting human\npreference feedback when the underlying latent reward function is non-linear.\nWe theoretically show that when preference feedback follows the\nBradley-Terry-Luce model, the worst sub-optimality gap of the policy learned by\nNeural-ADB decreases at a sub-linear rate as the preference dataset increases.\nOur experimental results on problem instances derived from synthetic preference\ndatasets further validate the effectiveness of Neural-ADB.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faNeural-ADB\u7b97\u6cd5\uff0c\u7528\u4e8e\u975e\u7ebf\u6027\u5956\u52b1\u51fd\u6570\u4e0b\u9ad8\u6548\u6536\u96c6\u4eba\u7c7b\u504f\u597d\u53cd\u9988\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u5956\u52b1\u51fd\u6570\u7ebf\u6027\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u5982\u5728\u7ebf\u63a8\u8350\u548cLLM\u5bf9\u9f50\u4e2d\u4e0d\u6210\u7acb\uff0c\u5bfc\u81f4\u53cd\u9988\u6536\u96c6\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u4e0a\u4e0b\u6587\u53cc\u6253\u5e26\u6846\u67b6\u7684Neural-ADB\u7b97\u6cd5\uff0c\u5904\u7406\u975e\u7ebf\u6027\u6f5c\u5728\u5956\u52b1\u51fd\u6570\u3002", "result": "\u7406\u8bba\u4e0a\uff0c\u5728Bradley-Terry-Luce\u6a21\u578b\u4e0b\uff0c\u5b50\u6700\u4f18\u5dee\u8ddd\u4ee5\u6b21\u7ebf\u6027\u901f\u7387\u4e0b\u964d\uff1b\u5b9e\u9a8c\u4e0a\uff0c\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\u3002", "conclusion": "Neural-ADB\u4e3a\u975e\u7ebf\u6027\u573a\u666f\u4e0b\u6536\u96c6\u4eba\u7c7b\u504f\u597d\u53cd\u9988\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u548c\u5b9e\u7528\u6027\u7684\u65b9\u6cd5\u3002"}}
{"id": "2504.11588", "pdf": "https://arxiv.org/pdf/2504.11588", "abs": "https://arxiv.org/abs/2504.11588", "authors": ["Siteng Ma", "Honghui Du", "Yu An", "Jing Wang", "Qinqin Wang", "Haochang Wu", "Aonghus Lawlor", "Ruihai Dong"], "title": "Deep Learning Approaches for Medical Imaging Under Varying Degrees of Label Availability: A Comprehensive Survey", "categories": ["cs.CV", "cs.AI", "68T07, 68T45, 92C50, 92C55", "I.2.10; I.4.5; I.4.6; I.4.9; J.3"], "comment": "33 pages, 10 figures, 8 tables. Will be submit to Medical Image\n  Analysis", "summary": "Deep learning has achieved significant breakthroughs in medical imaging, but\nthese advancements are often dependent on large, well-annotated datasets.\nHowever, obtaining such datasets poses a significant challenge, as it requires\ntime-consuming and labor-intensive annotations from medical experts.\nConsequently, there is growing interest in learning paradigms such as\nincomplete, inexact, and absent supervision, which are designed to operate\nunder limited, inexact, or missing labels. This survey categorizes and reviews\nthe evolving research in these areas, analyzing around 600 notable\ncontributions since 2018. It covers tasks such as image classification,\nsegmentation, and detection across various medical application areas, including\nbut not limited to brain, chest, and cardiac imaging. We attempt to establish\nthe relationships among existing research studies in related areas. We provide\nformal definitions of different learning paradigms and offer a comprehensive\nsummary and interpretation of various learning mechanisms and strategies,\naiding readers in better understanding the current research landscape and\nideas. We also discuss potential future research challenges.", "AI": {"tldr": "\u8fd9\u7bc7\u8c03\u67e5\u7efc\u8ff0\u4e86\u533b\u7597\u56fe\u50cf\u4e2d\u4e0d\u5b8c\u5168\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u7684\u7814\u7a76\uff0c\u6db5\u76d6\u5206\u7c7b\u3001\u5206\u5272\u548c\u68c0\u6d4b\u4efb\u52a1\u3002", "motivation": "\u7531\u4e8e\u83b7\u53d6\u5927\u578b\u6807\u6ce8\u6570\u636e\u96c6\u7684\u6311\u6218\uff0c\u5305\u62ec\u8017\u65f6\u548c\u52b3\u52a8\u5bc6\u96c6\u578b\u6ce8\u91ca\uff0c\u4fc3\u4f7f\u5bf9\u4e0d\u5b8c\u5168\u3001 inexact \u548c absent \u76d1\u7763\u8303\u5f0f\u7684\u5174\u8da3\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u548c\u5ba1\u9605\u7ea6600\u7bc7\u81ea2018\u5e74\u4ee5\u6765\u7684\u7814\u7a76\uff0c\u6db5\u76d6\u8111\u3001\u5fc3\u810f\u548c\u80f8\u90e8\u6210\u50cf\u7b49\u5e94\u7528\uff0c\u63d0\u4f9b\u6b63\u5f0f\u5b9a\u4e49\u548c\u603b\u7ed3\u3002", "result": "\u63d0\u4f9b\u4e86\u5404\u79cd\u5b66\u4e60\u673a\u5236\u7684\u5168\u9762\u603b\u7ed3\u3001\u7814\u7a76\u5173\u7cfb\u5206\u6790\uff0c\u5e76\u8bc6\u522b\u4e86\u672a\u6765\u6311\u6218\u3002", "conclusion": "\u5e2e\u52a9\u8bfb\u8005\u7406\u89e3\u5f53\u524d\u7814\u7a76\u666f\u89c2\uff0c\u5e76\u8ba8\u8bba\u6f5c\u5728\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2504.12025", "pdf": "https://arxiv.org/pdf/2504.12025", "abs": "https://arxiv.org/abs/2504.12025", "authors": ["Yu Zhang", "Qingfeng Du", "Jiaqi Lv"], "title": "FedEPA: Enhancing Personalization and Modality Alignment in Multimodal Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables decentralized model training across multiple\nparties while preserving privacy. However, most FL systems assume clients hold\nonly unimodal data, limiting their real-world applicability, as institutions\noften possess multimodal data. Moreover, the lack of labeled data further\nconstrains the performance of most FL methods. In this work, we propose FedEPA,\na novel FL framework for multimodal learning. FedEPA employs a personalized\nlocal model aggregation strategy that leverages labeled data on clients to\nlearn personalized aggregation weights, thereby alleviating the impact of data\nheterogeneity. We also propose an unsupervised modality alignment strategy that\nworks effectively with limited labeled data. Specifically, we decompose\nmultimodal features into aligned features and context features. We then employ\ncontrastive learning to align the aligned features across modalities, ensure\nthe independence between aligned features and context features within each\nmodality, and promote the diversity of context features. A multimodal feature\nfusion strategy is introduced to obtain a joint embedding. The experimental\nresults show that FedEPA significantly outperforms existing FL methods in\nmultimodal classification tasks under limited labeled data conditions.", "AI": {"tldr": "FedEPA \u662f\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u5b66\u4e60\uff0c\u5904\u7406\u6570\u636e\u5f02\u8d28\u6027\u548c\u6807\u7b7e\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u5047\u8bbe\u5ba2\u6237\u7aef\u53ea\u6709\u5355\u6a21\u6001\u6570\u636e\uff0c\u4e14\u7f3a\u4e4f\u6807\u7b7e\u6570\u636e\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002\u672c\u6587\u63d0\u51fa FedEPA \u6765\u89e3\u51b3\u591a\u6a21\u6001\u6570\u636e\u548c\u6807\u7b7e\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "FedEPA \u91c7\u7528\u4e2a\u6027\u5316\u7684\u672c\u5730\u6a21\u578b\u805a\u5408\u7b56\u7565\u3001\u65e0\u4eba\u76d1\u7763\u7684\u6a21\u6001\u5bf9\u9f50\u7b56\u7565\uff08\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u7279\u5f81\uff09\u548c\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6807\u7b7e\u6570\u636e\u6709\u9650\u7684\u591a\u6a21\u6001\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cFedEPA \u663e\u8457\u4f18\u4e8e\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "FedEPA \u901a\u8fc7\u4e2a\u6027\u5316\u805a\u5408\u548c\u6a21\u6001\u5bf9\u9f50\u7b56\u7565\uff0c\u7f13\u89e3\u6570\u636e\u5f02\u8d28\u6027\uff0c\u63d0\u9ad8\u4e86\u591a\u6a21\u6001\u8054\u90a6\u5b66\u4e60\u7684\u6027\u80fd\u3002"}}
{"id": "2504.11609", "pdf": "https://arxiv.org/pdf/2504.11609", "abs": "https://arxiv.org/abs/2504.11609", "authors": ["Gemma E. Moran", "Bryon Aragam"], "title": "Towards Interpretable Deep Generative Models via Causal Representation Learning", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.ME"], "comment": null, "summary": "Recent developments in generative artificial intelligence (AI) rely on\nmachine learning techniques such as deep learning and generative modeling to\nachieve state-of-the-art performance across wide-ranging domains. These\nmethods' surprising performance is due in part to their ability to learn\nimplicit \"representations'' of complex, multi-modal data. Unfortunately, deep\nneural networks are notoriously black boxes that obscure these representations,\nmaking them difficult to interpret or analyze. To resolve these difficulties,\none approach is to build new interpretable neural network models from the\nground up. This is the goal of the emerging field of causal representation\nlearning (CRL) that uses causality as a vector for building flexible,\ninterpretable, and transferable generative AI. CRL can be seen as a culmination\nof three intrinsically statistical problems: (i) latent variable models such as\nfactor analysis; (ii) causal graphical models with latent variables; and (iii)\nnonparametric statistics and deep learning. This paper reviews recent progress\nin CRL from a statistical perspective, focusing on connections to classical\nmodels and statistical and causal identifiablity results. This review also\nhighlights key application areas, implementation strategies, and open\nstatistical questions in CRL.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ece\u7edf\u8ba1\u5b66\u89c6\u89d2\u5ba1\u89c6\u56e0\u679c\u8868\u793a\u5b66\u4e60\uff08CRL\uff09\uff0c\u5f3a\u8c03\u5176\u89e3\u51b3AI\u89e3\u91ca\u6027\u95ee\u9898\u7684\u91cd\u8981\u6027\uff0c\u5e76\u8ba8\u8bba\u5176\u4e0e\u7ecf\u5178\u6a21\u578b\u7684\u8054\u7cfb\u3001\u8bc6\u522b\u6027\u7ed3\u679c\u3001\u5e94\u7528\u9886\u57df\u548c\u5f00\u653e\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u89e3\u91ca\u6027\u96be\u9898\uff0c\u901a\u8fc7\u6784\u5efa\u57fa\u4e8e\u56e0\u679c\u6027\u7684\u53ef\u89e3\u91ca\u751f\u6210AI\u6a21\u578b\u3002", "method": "\u91c7\u7528CRL\u65b9\u6cd5\uff0c\u7ed3\u5408\u6f5c\u53d8\u91cf\u6a21\u578b\u3001\u56e0\u679c\u56fe\u5f62\u6a21\u578b\u548c\u975e\u53c2\u6570\u7edf\u8ba1\u5b66\uff0c\u5ba1\u89c6\u5176\u8fdb\u5c55\u3002", "result": "\u56de\u987eCRL\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5305\u62ec\u7edf\u8ba1\u548c\u56e0\u679c\u8bc6\u522b\u6027\u7ed3\u679c\u3001\u5173\u952e\u5e94\u7528\u9886\u57df\u548c\u5b9e\u65bd\u7b56\u7565\u3002", "conclusion": "\u5f3a\u8c03CRL\u5728\u751f\u6210AI\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u6307\u51fa\u7edf\u8ba1\u5b66\u9886\u57df\u7684\u5f00\u653e\u95ee\u9898\u3002"}}
{"id": "2504.12075", "pdf": "https://arxiv.org/pdf/2504.12075", "abs": "https://arxiv.org/abs/2504.12075", "authors": ["Kiran K. Yalamanchi", "Pinaki Pal", "Balaji Mohan", "Abdullah S. AlRamadan", "Jihad A. Badra", "Yuanjiang Pei"], "title": "Generative Deep Learning Framework for Inverse Design of Fuels", "categories": ["cs.LG", "physics.chem-ph"], "comment": null, "summary": "In the present work, a generative deep learning framework combining a\nCo-optimized Variational Autoencoder (Co-VAE) architecture with quantitative\nstructure-property relationship (QSPR) techniques is developed to enable\naccelerated inverse design of fuels. The Co-VAE integrates a property\nprediction component coupled with the VAE latent space, enhancing molecular\nreconstruction and accurate estimation of Research Octane Number (RON) (chosen\nas the fuel property of interest). A subset of the GDB-13 database, enriched\nwith a curated RON database, is used for model training. Hyperparameter tuning\nis further utilized to optimize the balance among reconstruction fidelity,\nchemical validity, and RON prediction. An independent regression model is then\nused to refine RON prediction, while a differential evolution algorithm is\nemployed to efficiently navigate the VAE latent space and identify promising\nfuel molecule candidates with high RON. This methodology addresses the\nlimitations of traditional fuel screening approaches by capturing complex\nstructure-property relationships within a comprehensive latent representation.\nThe generative model provides a flexible tool for systematically exploring vast\nchemical spaces, paving the way for discovering fuels with superior anti-knock\nproperties. The demonstrated approach can be readily extended to incorporate\nadditional fuel properties and synthesizability criteria to enhance\napplicability and reliability for de novo design of new fuels.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u7ed3\u5408Co-optimized Variational Autoencoder (Co-VAE) \u548c\u5b9a\u91cf\u7ed3\u6784-\u5c5e\u6027\u5173\u7cfb (QSPR) \u6280\u672f\u7684\u751f\u6210\u5f0f\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u52a0\u901f\u71c3\u6599\u53cd\u5411\u8bbe\u8ba1\uff0c\u63d0\u9ad8Research Octane Number (RON) \u4f30\u8ba1\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u4f20\u7edf\u71c3\u6599\u7b5b\u9009\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u6355\u6349\u590d\u6742\u7684\u7ed3\u6784-\u5c5e\u6027\u5173\u7cfb\uff0c\u5e76\u52a0\u901f\u53d1\u73b0\u5177\u6709\u4f18\u8d8a\u6297\u7206\u6027\u80fd\u7684\u71c3\u6599\u3002", "method": "\u4f7f\u7528Co-VAE\u67b6\u6784\u6574\u5408\u5c5e\u6027\u9884\u6d4b\u4e0eVAE\u6f5c\u7a7a\u95f4\uff0c\u57fa\u4e8eGDB-13\u6570\u636e\u5e93\u548cRON\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u7ed3\u5408\u8d85\u53c2\u6570\u8c03\u4f18\u3001\u72ec\u7acb\u56de\u5f52\u6a21\u578b\u548c\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\u5bfc\u822a\u6f5c\u7a7a\u95f4\u3002", "result": "\u6a21\u578b\u63d0\u5347\u4e86\u5206\u5b50\u91cd\u6784\u548cRON\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u8bc6\u522b\u51fa\u9ad8RON\u71c3\u6599\u5206\u5b50\u5019\u9009\uff0c\u5e76\u63d0\u4f9b\u5de5\u5177\u63a2\u7d22\u5316\u5b66\u7a7a\u95f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u71c3\u6599\u5c5e\u6027\u548c\u5408\u6210\u6027\u6807\u51c6\uff0c\u4fc3\u8fdb\u65b0\u71c3\u6599\u7684\u4ece\u5934\u8bbe\u8ba1\u3002"}}
{"id": "2504.12086", "pdf": "https://arxiv.org/pdf/2504.12086", "abs": "https://arxiv.org/abs/2504.12086", "authors": ["Mohammadali Moghimi", "Sharu Theresa Jose", "Shana Moothedath"], "title": "Neural Contextual Bandits Under Delayed Feedback Constraints", "categories": ["cs.LG"], "comment": null, "summary": "This paper presents a new algorithm for neural contextual bandits (CBs) that\naddresses the challenge of delayed reward feedback, where the reward for a\nchosen action is revealed after a random, unknown delay. This scenario is\ncommon in applications such as online recommendation systems and clinical\ntrials, where reward feedback is delayed because the outcomes or results of a\nuser's actions (such as recommendations or treatment responses) take time to\nmanifest and be measured. The proposed algorithm, called Delayed NeuralUCB,\nuses an upper confidence bound (UCB)-based exploration strategy. Under the\nassumption of independent and identically distributed sub-exponential reward\ndelays, we derive an upper bound on the cumulative regret over a T-length\nhorizon. We further consider a variant of the algorithm, called Delayed\nNeuralTS, that uses Thompson Sampling-based exploration. Numerical experiments\non real-world datasets, such as MNIST and Mushroom, along with comparisons to\nbenchmark approaches, demonstrate that the proposed algorithms effectively\nmanage varying delays and are well-suited for complex real-world scenarios.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faDelayed NeuralUCB\u548cDelayed NeuralTS\u7b97\u6cd5\uff0c\u5904\u7406\u795e\u7ecf\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\u4e2d\u7684\u5ef6\u8fdf\u5956\u52b1\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8bba\u6587\u9488\u5bf9\u5728\u7ebf\u63a8\u8350\u7cfb\u7edf\u548c\u4e34\u5e8a\u8bd5\u9a8c\u7b49\u5e94\u7528\u4e2d\u5ef6\u8fdf\u5956\u52b1\u53cd\u9988\u7684\u6311\u6218\uff0c\u65e8\u5728\u89e3\u51b3\u884c\u52a8\u7ed3\u679c\u5ef6\u8fdf\u663e\u73b0\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faDelayed NeuralUCB\u7b97\u6cd5\u4f7f\u7528UCB\u63a2\u7d22\u7b56\u7565\uff0c\u4ee5\u53caDelayed NeuralTS\u7b97\u6cd5\u4f7f\u7528Thompson Sampling\u63a2\u7d22\u7b56\u7565\uff1b\u5728\u72ec\u7acb\u540c\u5206\u5e03\u5b50\u6307\u6570\u5956\u52b1\u5ef6\u8fdf\u5047\u8bbe\u4e0b\uff0c\u63a8\u5bfc\u7d2f\u79ef\u9057\u61be\u4e0a\u754c\u3002", "result": "\u63a8\u5bfc\u4e86\u7d2f\u79ef\u9057\u61be\u4e0a\u754c\uff0c\u5e76\u5728MNIST\u548cMushroom\u7b49\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u8bc1\u660e\u7b97\u6cd5\u80fd\u6709\u6548\u5904\u7406\u4e0d\u540c\u5ef6\u8fdf\uff0c\u5e76\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u7b97\u6cd5\u80fd\u826f\u597d\u7ba1\u7406\u5ef6\u8fdf\u5956\u52b1\uff0c\u9002\u5408\u590d\u6742\u771f\u5b9e\u573a\u666f\u7684\u5e94\u7528\u3002"}}
{"id": "2504.11626", "pdf": "https://arxiv.org/pdf/2504.11626", "abs": "https://arxiv.org/abs/2504.11626", "authors": ["Ozan \u0130rsoy", "Pengxiang Cheng", "Jennifer L. Chen", "Daniel Preo\u0163iuc-Pietro", "Shiyue Zhang", "Duccio Pappadopulo"], "title": "Improving Instruct Models for Free: A Study on Partial Adaptation", "categories": ["cs.CL", "cs.AI"], "comment": "Author ordering chosen at random", "summary": "Instruct models, obtained from various instruction tuning or post-training\nsteps, are commonly deemed superior and more usable than their base\ncounterpart. While the model gains instruction following ability, instruction\ntuning may lead to forgetting the knowledge from pre-training or it may\nencourage the model being overly conversational or verbose. This, in turn, can\nlead to degradation of in-context few-shot learning performance. In this work,\nwe study the performance trajectory between base and instruct models by scaling\ndown the strength of instruction-tuning via the partial adaption method. We\nshow that, across several model families and model sizes, reducing the strength\nof instruction-tuning results in material improvement on a few-shot in-context\nlearning benchmark covering a variety of classic natural language tasks. This\ncomes at the cost of losing some degree of instruction following ability as\nmeasured by AlpacaEval. Our study shines light on the potential trade-off\nbetween in-context learning and instruction following abilities that is worth\nconsidering in practice.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u90e8\u5206\u9002\u5e94\u65b9\u6cd5\u51cf\u5c11\u6307\u4ee4\u8c03\u6574\u5f3a\u5ea6\uff0c\u6539\u5584\u4e86\u5c11\u6837\u672c\u5b66\u4e60\u6027\u80fd\uff0c\u4f46\u53ef\u80fd\u964d\u4f4e\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u3002", "motivation": "\u6307\u4ee4\u8c03\u6574\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u5fd8\u8bb0\u9884\u8bad\u7ec3\u77e5\u8bc6\u6216\u53d8\u5f97\u8fc7\u4e8e\u5570\u55e6\uff0c\u4ece\u800c\u964d\u4f4e\u5c11\u6837\u672c\u5b66\u4e60\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u90e8\u5206\u9002\u5e94\u65b9\u6cd5\u6765\u964d\u4f4e\u6307\u4ee4\u8c03\u6574\u7684\u5f3a\u5ea6\u3002", "result": "\u51cf\u5c11\u6307\u4ee4\u8c03\u6574\u5f3a\u5ea6\u540e\uff0c\u5c11\u6837\u672c\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u6027\u80fd\u663e\u8457\u6539\u5584\uff0c\u4f46\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u6709\u6240\u4e0b\u964d\u3002", "conclusion": "\u5b58\u5728\u5c11\u6837\u672c\u5b66\u4e60\u548c\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u9700\u8981\u5728\u5b9e\u8df5\u4e2d\u8003\u8651\u3002"}}
{"id": "2504.12151", "pdf": "https://arxiv.org/pdf/2504.12151", "abs": "https://arxiv.org/abs/2504.12151", "authors": ["Miaosen Luo", "Yuncheng Jiang", "Sijie Mai"], "title": "Towards Explainable Fusion and Balanced Learning in Multimodal Sentiment Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multimodal Sentiment Analysis (MSA) faces two critical challenges: the lack\nof interpretability in the decision logic of multimodal fusion and modality\nimbalance caused by disparities in inter-modal information density. To address\nthese issues, we propose KAN-MCP, a novel framework that integrates the\ninterpretability of Kolmogorov-Arnold Networks (KAN) with the robustness of the\nMultimodal Clean Pareto (MCPareto) framework. First, KAN leverages its\nunivariate function decomposition to achieve transparent analysis of\ncross-modal interactions. This structural design allows direct inspection of\nfeature transformations without relying on external interpretation tools,\nthereby ensuring both high expressiveness and interpretability. Second, the\nproposed MCPareto enhances robustness by addressing modality imbalance and\nnoise interference. Specifically, we introduce the Dimensionality Reduction and\nDenoising Modal Information Bottleneck (DRD-MIB) method, which jointly denoises\nand reduces feature dimensionality. This approach provides KAN with\ndiscriminative low-dimensional inputs to reduce the modeling complexity of KAN\nwhile preserving critical sentiment-related information. Furthermore, MCPareto\ndynamically balances gradient contributions across modalities using the\npurified features output by DRD-MIB, ensuring lossless transmission of\nauxiliary signals and effectively alleviating modality imbalance. This synergy\nof interpretability and robustness not only achieves superior performance on\nbenchmark datasets such as CMU-MOSI, CMU-MOSEI, and CH-SIMS v2 but also offers\nan intuitive visualization interface through KAN's interpretable architecture.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faKAN-MCP\u6846\u67b6\uff0c\u63d0\u5347\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u7684\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u6574\u5408Kolmogorov-Arnold Networks\u548cMultimodal Clean Pareto\u6846\u67b6\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u878d\u5408\u51b3\u7b56\u903b\u8f91\u7f3a\u4e4f\u89e3\u91ca\u6027\u548c\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u8fd9\u4e9b\u7531\u6a21\u6001\u95f4\u4fe1\u606f\u5bc6\u5ea6\u5dee\u5f02\u5f15\u8d77\u3002", "method": "\u63d0\u51faKAN-MCP\u6846\u67b6\uff1aKAN\u7528\u4e8e\u53ef\u89e3\u91ca\u7684\u8de8\u6a21\u6001\u4ea4\u4e92\u5206\u6790\uff0cMCPareto\u901a\u8fc7DRD-MIB\u65b9\u6cd5\u8fdb\u884c\u964d\u566a\u3001\u964d\u7ef4\u548c\u52a8\u6001\u5e73\u8861\u6a21\u6001\u68af\u5ea6\u8d21\u732e\u3002", "result": "\u5728CMU-MOSI\u3001CMU-MOSEI\u548cCH-SIMS v2\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u8d8a\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u76f4\u89c2\u7684\u53ef\u89c6\u5316\u754c\u9762\u3002", "conclusion": "\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u7684\u534f\u540c\u4f5c\u7528\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u7684\u6027\u80fd\u3002"}}
{"id": "2504.12156", "pdf": "https://arxiv.org/pdf/2504.12156", "abs": "https://arxiv.org/abs/2504.12156", "authors": ["Mustafa Cavus"], "title": "Predictive Multiplicity in Survival Models: A Method for Quantifying Model Uncertainty in Predictive Maintenance Applications", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In many applications, especially those involving prediction, models may yield\nnear-optimal performance yet significantly disagree on individual-level\noutcomes. This phenomenon, known as predictive multiplicity, has been formally\ndefined in binary, probabilistic, and multi-target classification, and\nundermines the reliability of predictive systems. However, its implications\nremain unexplored in the context of survival analysis, which involves\nestimating the time until a failure or similar event while properly handling\ncensored data. We frame predictive multiplicity as a critical concern in\nsurvival-based models and introduce formal measures -- ambiguity, discrepancy,\nand obscurity -- to quantify it. This is particularly relevant for downstream\ntasks such as maintenance scheduling, where precise individual risk estimates\nare essential. Understanding and reporting predictive multiplicity helps build\ntrust in models deployed in high-stakes environments. We apply our methodology\nto benchmark datasets from predictive maintenance, extending the notion of\nmultiplicity to survival models. Our findings show that ambiguity steadily\nincreases, reaching up to 40-45% of observations; discrepancy is lower but\nexhibits a similar trend; and obscurity remains mild and concentrated in a few\nmodels. These results demonstrate that multiple accurate survival models may\nyield conflicting estimations of failure risk and degradation progression for\nthe same equipment. This highlights the need to explicitly measure and\ncommunicate predictive multiplicity to ensure reliable decision-making in\nprocess health management.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f15\u5165\u9884\u6d4b\u591a\u91cd\u6027\u7684\u5ea6\u91cf\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u751f\u5b58\u5206\u6790\u4e2d\u7684\u5e94\u7528\uff0c\u5f3a\u8c03\u4e86\u5728\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u6a21\u578b\u53ef\u9760\u6027\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u6a21\u578b\u53ef\u80fd\u5728\u6574\u4f53\u6027\u80fd\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5bf9\u4e2a\u4f53\u9884\u6d4b\u7ed3\u679c\u5b58\u5728\u663e\u8457\u5206\u6b67\uff0c\u8fd9\u5728\u5904\u7406 censored \u6570\u636e\u548c\u4f30\u8ba1\u5931\u8d25\u65f6\u95f4\u7684\u751f\u5b58\u5206\u6790\u4e2d\u4f1a\u524a\u5f31\u53ef\u9760\u6027\uff0c\u5c24\u5176\u5728\u7ef4\u62a4\u8c03\u5ea6\u7b49\u5e94\u7528\u4e2d\u3002", "method": "\u5f15\u5165\u6a21\u7cca\u6027\u3001\u5dee\u5f02\u6027\u548c\u6666\u6da9\u6027\u7b49\u6b63\u5f0f\u5ea6\u91cf\u6765\u91cf\u5316\u9884\u6d4b\u591a\u91cd\u6027\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u9884\u6d4b\u7ef4\u62a4\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6a21\u7cca\u6027\u589e\u52a0\u81f340-45%\uff0c\u5dee\u5f02\u6027\u8f83\u4f4e\u4f46\u8d8b\u52bf\u76f8\u4f3c\uff0c\u6666\u6da9\u6027\u6e29\u548c\u4e14\u96c6\u4e2d\u5728\u5c11\u6570\u6a21\u578b\uff0c\u8868\u660e\u591a\u4e2a\u51c6\u786e\u7684\u751f\u5b58\u6a21\u578b\u53ef\u80fd\u5bf9\u76f8\u540c\u8bbe\u5907\u7ed9\u51fa\u51b2\u7a81\u7684\u5931\u8d25\u98ce\u9669\u4f30\u8ba1\u3002", "conclusion": "\u9700\u8981\u660e\u786e\u6d4b\u91cf\u548c\u4f20\u8fbe\u9884\u6d4b\u591a\u91cd\u6027\uff0c\u4ee5\u786e\u4fdd\u5728\u8fc7\u7a0b\u5065\u5eb7\u7ba1\u7406\u4e2d\u7684\u53ef\u9760\u51b3\u7b56\u3002"}}
{"id": "2504.12181", "pdf": "https://arxiv.org/pdf/2504.12181", "abs": "https://arxiv.org/abs/2504.12181", "authors": ["Eunjeong Jeong", "Nikolaos Pappas"], "title": "Battery-aware Cyclic Scheduling in Energy-harvesting Federated Learning", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "This paper is currently under review for presentation at a\n  peer-reviewed conference", "summary": "Federated Learning (FL) has emerged as a promising framework for distributed\nlearning, but its growing complexity has led to significant energy consumption,\nparticularly from computations on the client side. This challenge is especially\ncritical in energy-harvesting FL (EHFL) systems, where device availability\nfluctuates due to limited and time-varying energy resources. We propose\nFedBacys, a battery-aware FL framework that introduces cyclic client\nparticipation based on users' battery levels to cope with these issues.\nFedBacys enables clients to save energy and strategically perform local\ntraining just before their designated transmission time by clustering clients\nand scheduling their involvement sequentially. This design minimizes redundant\ncomputation, reduces system-wide energy usage, and improves learning stability.\nOur experiments demonstrate that FedBacys outperforms existing approaches in\nterms of energy efficiency and performance consistency, exhibiting robustness\neven under non-i.i.d. training data distributions and with very infrequent\nbattery charging. This work presents the first comprehensive evaluation of\ncyclic client participation in EHFL, incorporating both communication and\ncomputation costs into a unified, resource-aware scheduling strategy.", "AI": {"tldr": "FedBacys\u662f\u4e00\u79cd\u57fa\u4e8e\u7535\u6c60\u611f\u77e5\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5faa\u73af\u5ba2\u6237\u7aef\u53c2\u4e0e\u63d0\u9ad8\u80fd\u91cf\u6548\u7387\u548c\u5b66\u4e60\u7a33\u5b9a\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u7684\u590d\u6742\u5ea6\u589e\u52a0\u5bfc\u81f4\u80fd\u91cf\u6d88\u8017\u9ad8\uff0c\u5c24\u5176\u5728\u80fd\u91cf\u91c7\u96c6\u7cfb\u7edf\u4e2d\uff0c\u8bbe\u5907\u53ef\u7528\u6027\u56e0\u80fd\u91cf\u9650\u5236\u800c\u6ce2\u52a8\u3002", "method": "\u63d0\u51faFedBacys\u6846\u67b6\uff0c\u901a\u8fc7\u6839\u636e\u7535\u6c60\u6c34\u5e73\u805a\u7c7b\u5ba2\u6237\u7aef\u5e76\u987a\u5e8f\u8c03\u5ea6\uff0c\u4f7f\u5176\u5728\u4f20\u8f93\u524d\u8fdb\u884c\u672c\u5730\u8bad\u7ec3\uff0c\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u663e\u793aFedBacys\u5728\u80fd\u91cf\u6548\u7387\u548c\u6027\u80fd\u4e00\u81f4\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5373\u4f7f\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u548c\u5145\u7535\u9891\u7387\u4f4e\u65f6\u4e5f\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u9996\u6b21\u5168\u9762\u8bc4\u4f30\u80fd\u91cf\u91c7\u96c6\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5faa\u73af\u5ba2\u6237\u7aef\u53c2\u4e0e\uff0c\u7edf\u4e00\u8003\u8651\u901a\u4fe1\u548c\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2504.11658", "pdf": "https://arxiv.org/pdf/2504.11658", "abs": "https://arxiv.org/abs/2504.11658", "authors": ["Nanshan Jia", "Chenfei Yuan", "Yuhang Wu", "Zeyu Zheng"], "title": "Improving LLM Interpretability and Performance via Guided Embedding Refinement for Sequential Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "The fast development of Large Language Models (LLMs) offers growing\nopportunities to further improve sequential recommendation systems. Yet for\nsome practitioners, integrating LLMs to their existing base recommendation\nsystems raises questions about model interpretability, transparency and related\nsafety. To partly alleviate challenges from these questions, we propose guided\nembedding refinement, a method that carries out a guided and interpretable\nusage of LLM to enhance the embeddings associated with the base recommendation\nsystem. Instead of directly using LLMs as the backbone of sequential\nrecommendation systems, we utilize them as auxiliary tools to emulate the sales\nlogic of recommendation and generate guided embeddings that capture\ndomain-relevant semantic information on interpretable attributes. Benefiting\nfrom the strong generalization capabilities of the guided embedding, we\nconstruct refined embedding by using the guided embedding and reduced-dimension\nversion of the base embedding. We then integrate the refined embedding into the\nrecommendation module for training and inference. A range of numerical\nexperiments demonstrate that guided embedding is adaptable to various given\nexisting base embedding models, and generalizes well across different\nrecommendation tasks. The numerical results show that the refined embedding not\nonly improves recommendation performance, achieving approximately $10\\%$ to\n$50\\%$ gains in Mean Reciprocal Rank (MRR), Recall rate, and Normalized\nDiscounted Cumulative Gain (NDCG), but also enhances interpretability, as\nevidenced by case studies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528LLM\u63d0\u5347\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\u7684\u5f15\u5bfc\u5d4c\u5165\u7cbe\u70bc\u65b9\u6cd5\uff0c\u63d0\u9ad8\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "LLM\u5feb\u901f\u53d1\u5c55\u4e3a\u63a8\u8350\u7cfb\u7edf\u6539\u8fdb\u63d0\u4f9b\u673a\u4f1a\uff0c\u4f46\u6574\u5408\u65f6\u5b58\u5728\u53ef\u89e3\u91ca\u6027\u3001\u900f\u660e\u5ea6\u548c\u5b89\u5168\u6027\u95ee\u9898\uff0c\u9700\u8981\u7f13\u89e3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u4f7f\u7528LLM\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u751f\u6210\u5f15\u5bfc\u5d4c\u5165\uff0c\u6355\u83b7\u53ef\u89e3\u91ca\u5c5e\u6027\u8bed\u4e49\u4fe1\u606f\uff0c\u4e0e\u57fa\u5d4c\u5165\u964d\u7ef4\u7248\u672c\u7ed3\u5408\uff0c\u6784\u5efa\u7cbe\u70bc\u5d4c\u5165\u5e76\u96c6\u6210\u5230\u63a8\u8350\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u63d0\u534710%\u81f350%\uff08MRR\u3001\u53ec\u56de\u7387\u3001NDCG\uff09\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u53ef\u89e3\u91ca\u6027\u589e\u5f3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u591a\u79cd\u57fa\u6a21\u578b\uff0c\u5177\u6709\u826f\u597d\u6cdb\u5316\u6027\uff0c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2504.12229", "pdf": "https://arxiv.org/pdf/2504.12229", "abs": "https://arxiv.org/abs/2504.12229", "authors": ["David Khachaturov", "Robert Mullins", "Ilia Shumailov", "Sumanth Dathathri"], "title": "Watermarking Needs Input Repetition Masking", "categories": ["cs.LG", "cs.CL", "cs.CR"], "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) raised concerns over\npotential misuse, such as for spreading misinformation. In response two counter\nmeasures emerged: machine learning-based detectors that predict if text is\nsynthetic, and LLM watermarking, which subtly marks generated text for\nidentification and attribution. Meanwhile, humans are known to adjust language\nto their conversational partners both syntactically and lexically. By\nimplication, it is possible that humans or unwatermarked LLMs could\nunintentionally mimic properties of LLM generated text, making counter measures\nunreliable. In this work we investigate the extent to which such conversational\nadaptation happens. We call the concept $\\textit{mimicry}$ and demonstrate that\nboth humans and LLMs end up mimicking, including the watermarking signal even\nin seemingly improbable settings. This challenges current academic assumptions\nand suggests that for long-term watermarking to be reliable, the likelihood of\nfalse positives needs to be significantly lower, while longer word sequences\nshould be used for seeding watermarking mechanisms.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4eba\u7c7b\u548cLLM\u5728\u5bf9\u8bdd\u4e2d\u6a21\u4eff\u751f\u6210\u6587\u672c\u7684\u73b0\u8c61\uff0c\u5305\u62ec\u6c34\u5370\u4fe1\u53f7\uff0c\u8fd9\u6311\u6218\u4e86\u73b0\u6709\u5047\u8bbe\uff0c\u5e76\u5efa\u8bae\u6539\u8fdb\u6c34\u5370\u673a\u5236\u3002", "motivation": "LLM\u53ef\u80fd\u88ab\u7528\u4e8e\u4f20\u64ad\u9519\u8bef\u4fe1\u606f\uff0c\u73b0\u6709\u53cd\u63aa\u65bd\u5982\u68c0\u6d4b\u5668\u548c\u6c34\u5370\u53ef\u80fd\u56e0\u4eba\u7c7b\u6216LLM\u7684\u6a21\u4eff\u800c\u4e0d\u53ef\u9760\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u6f14\u793a\u4eba\u7c7b\u548cLLM\u5728\u5404\u79cd\u8bbe\u7f6e\u4e0b\u7684\u6a21\u4eff\u884c\u4e3a\u3002", "result": "\u4eba\u7c7b\u548cLLM\u786e\u5b9e\u4f1a\u6a21\u4eff\u751f\u6210\u6587\u672c\u7684\u5c5e\u6027\uff0c\u5305\u62ec\u6c34\u5370\u4fe1\u53f7\uff0c\u5373\u4f7f\u5728\u4e0d\u592a\u53ef\u80fd\u7684\u573a\u666f\u4e2d\u3002", "conclusion": "\u9700\u8981\u663e\u8457\u964d\u4f4e\u6c34\u5370\u7684\u5047\u9633\u6027\u7387\uff0c\u5e76\u4f7f\u7528\u66f4\u957f\u7684\u8bcd\u5e8f\u5217\u6765\u63d0\u5347\u53ef\u9760\u6027\u3002"}}
{"id": "2504.11686", "pdf": "https://arxiv.org/pdf/2504.11686", "abs": "https://arxiv.org/abs/2504.11686", "authors": ["Yiran He", "Yun Cao", "Bowen Yang", "Zeyu Zhang"], "title": "Can GPT tell us why these images are synthesized? Empowering Multimodal Large Language Models for Forensics", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 11 figures, 13IHMMSec2025", "summary": "The rapid development of generative AI facilitates content creation and makes\nimage manipulation easier and more difficult to detect. While multimodal Large\nLanguage Models (LLMs) have encoded rich world knowledge, they are not\ninherently tailored for combating AI-generated Content (AIGC) and struggle to\ncomprehend local forgery details. In this work, we investigate the application\nof multimodal LLMs in forgery detection. We propose a framework capable of\nevaluating image authenticity, localizing tampered regions, providing evidence,\nand tracing generation methods based on semantic tampering clues. Our method\ndemonstrates that the potential of LLMs in forgery analysis can be effectively\nunlocked through meticulous prompt engineering and the application of few-shot\nlearning techniques. We conduct qualitative and quantitative experiments and\nshow that GPT4V can achieve an accuracy of 92.1% in Autosplice and 86.3% in\nLaMa, which is competitive with state-of-the-art AIGC detection methods. We\nfurther discuss the limitations of multimodal LLMs in such tasks and propose\npotential improvements.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u591a\u6a21\u6001LLM\u68c0\u6d4bAI\u751f\u6210\u56fe\u50cf\u7684\u4f2a\u9020\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u548c\u5c11\u6837\u672c\u5b66\u4e60\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "generative AI\u5feb\u901f\u53d1\u5c55\u4f7f\u56fe\u50cf\u64cd\u7eb5\u66f4\u6613\u4e14\u66f4\u96be\u68c0\u6d4b\uff0c\u591a\u6a21\u6001LLM\u867d\u6709\u4e30\u5bcc\u77e5\u8bc6\u4f46\u4e0d\u9002\u5408AIGC\u548c\u5c40\u90e8\u4f2a\u9020\u7ec6\u8282\u3002", "method": "\u63d0\u51fa\u6846\u67b6\u8bc4\u4f30\u56fe\u50cf\u771f\u5b9e\u6027\u3001\u5b9a\u4f4d\u7be1\u6539\u533a\u57df\u3001\u63d0\u4f9b\u8bc1\u636e\u548c\u8ffd\u8e2a\u751f\u6210\u65b9\u6cd5\uff0c\u4f7f\u7528\u8bed\u4e49\u7ebf\u7d22\u3001\u63d0\u793a\u5de5\u7a0b\u548c\u5c11\u6837\u672c\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u663e\u793aGPT4V\u5728Autosplice\u4e0a\u51c6\u786e\u738792.1%\uff0c\u5728LaMa\u4e0a86.3%\uff0c\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u7ade\u4e89\u3002", "conclusion": "\u8ba8\u8bba\u591a\u6a21\u6001LLM\u7684\u5c40\u9650\u6027\u5e76\u63d0\u51fa\u6f5c\u5728\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2504.12262", "pdf": "https://arxiv.org/pdf/2504.12262", "abs": "https://arxiv.org/abs/2504.12262", "authors": ["David Keetae Park", "Xihaier Luo", "Guang Zhao", "Seungjun Lee", "Miruna Oprescu", "Shinjae Yoo"], "title": "SCENT: Robust Spatiotemporal Learning for Continuous Scientific Data via Scalable Conditioned Neural Fields", "categories": ["cs.LG", "cs.AI"], "comment": "25 pages, 5 main figures, 3 tables, under review", "summary": "Spatiotemporal learning is challenging due to the intricate interplay between\nspatial and temporal dependencies, the high dimensionality of the data, and\nscalability constraints. These challenges are further amplified in scientific\ndomains, where data is often irregularly distributed (e.g., missing values from\nsensor failures) and high-volume (e.g., high-fidelity simulations), posing\nadditional computational and modeling difficulties. In this paper, we present\nSCENT, a novel framework for scalable and continuity-informed spatiotemporal\nrepresentation learning. SCENT unifies interpolation, reconstruction, and\nforecasting within a single architecture. Built on a transformer-based\nencoder-processor-decoder backbone, SCENT introduces learnable queries to\nenhance generalization and a query-wise cross-attention mechanism to\neffectively capture multi-scale dependencies. To ensure scalability in both\ndata size and model complexity, we incorporate a sparse attention mechanism,\nenabling flexible output representations and efficient evaluation at arbitrary\nresolutions. We validate SCENT through extensive simulations and real-world\nexperiments, demonstrating state-of-the-art performance across multiple\nchallenging tasks while achieving superior scalability.", "AI": {"tldr": "SCENT \u662f\u4e00\u4e2a\u65b0\u578b\u65f6\u7a7a\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u7edf\u4e00\u63d2\u503c\u3001\u91cd\u6784\u548c\u9884\u6d4b\uff0c\u4f7f\u7528 Transformer \u67b6\u6784\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u65f6\u7a7a\u5b66\u4e60\u9762\u4e34\u7a7a\u95f4\u65f6\u95f4\u4f9d\u8d56\u590d\u6742\u4ea4\u4e92\u3001\u9ad8\u7ef4\u6570\u636e\u3001\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u4ee5\u53ca\u79d1\u5b66\u9886\u57df\u6570\u636e\u4e0d\u89c4\u5219\u548c\u9ad8\u4f53\u79ef\u95ee\u9898\u3002", "method": "\u63d0\u51fa SCENT \u6846\u67b6\uff0c\u57fa\u4e8e Transformer \u7f16\u7801\u5668-\u5904\u7406\u5668-\u89e3\u7801\u5668\u7ed3\u6784\uff0c\u5f15\u5165\u53ef\u5b66\u4e60\u67e5\u8be2\u548c\u67e5\u8be2-wise \u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e76\u91c7\u7528\u7a00\u758f\u6ce8\u610f\u529b\u63d0\u5347\u53ef\u6269\u5c55\u6027\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u548c\u771f\u5b9e\u5b9e\u9a8c\u9a8c\u8bc1\uff0cSCENT \u5728\u591a\u4e2a\u6311\u6218\u6027\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e76\u5b9e\u73b0\u4f18\u8d8a\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "SCENT \u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u65f6\u7a7a\u5b66\u4e60\u96be\u9898\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u9ad8\u6548\u7684\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2504.11703", "pdf": "https://arxiv.org/pdf/2504.11703", "abs": "https://arxiv.org/abs/2504.11703", "authors": ["Tianneng Shi", "Jingxuan He", "Zhun Wang", "Linyu Wu", "Hongwei Li", "Wenbo Guo", "Dawn Song"], "title": "Progent: Programmable Privilege Control for LLM Agents", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "LLM agents are an emerging form of AI systems where large language models\n(LLMs) serve as the central component, utilizing a diverse set of tools to\ncomplete user-assigned tasks. Despite their great potential, LLM agents pose\nsignificant security risks. When interacting with the external world, they may\nencounter malicious commands from attackers, leading to the execution of\ndangerous actions. A promising way to address this is by enforcing the\nprinciple of least privilege: allowing only essential actions for task\ncompletion while blocking unnecessary ones. However, achieving this is\nchallenging, as it requires covering diverse agent scenarios while preserving\nboth security and utility.\n  We introduce Progent, the first privilege control mechanism for LLM agents.\nAt its core is a domain-specific language for flexibly expressing privilege\ncontrol policies applied during agent execution. These policies provide\nfine-grained constraints over tool calls, deciding when tool calls are\npermissible and specifying fallbacks if they are not. This enables agent\ndevelopers and users to craft suitable policies for their specific use cases\nand enforce them deterministically to guarantee security. Thanks to its modular\ndesign, integrating Progent does not alter agent internals and requires only\nminimal changes to agent implementation, enhancing its practicality and\npotential for widespread adoption. To automate policy writing, we leverage LLMs\nto generate policies based on user queries, which are then updated dynamically\nfor improved security and utility. Our extensive evaluation shows that it\nenables strong security while preserving high utility across three distinct\nscenarios or benchmarks: AgentDojo, ASB, and AgentPoison. Furthermore, we\nperform an in-depth analysis, showcasing the effectiveness of its core\ncomponents and the resilience of its automated policy generation against\nadaptive attacks.", "AI": {"tldr": "Progent \u662f\u4e00\u79cd\u65b0\u673a\u5236\uff0c\u7528\u4e8e\u901a\u8fc7\u6700\u5c0f\u6743\u9650\u539f\u5219\u548c\u7b56\u7565\u63a7\u5236\u6765\u63d0\u5347 LLM \u4ee3\u7406\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u5b9e\u7528\u6027\u3002", "motivation": "LLM \u4ee3\u7406\u53ef\u80fd\u6267\u884c\u6076\u610f\u547d\u4ee4\uff0c\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u56e0\u6b64\u9700\u8981\u5f3a\u5236\u6700\u5c0f\u6743\u9650\u4ee5\u4ec5\u5141\u8bb8\u5fc5\u8981\u64cd\u4f5c\u3002", "method": "\u5f15\u5165 Progent \u673a\u5236\uff0c\u4f7f\u7528\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u5b9a\u4e49\u6743\u9650\u7b56\u7565\uff0c\u5bf9\u5de5\u5177\u8c03\u7528\u8fdb\u884c\u7ec6\u7c92\u5ea6\u63a7\u5236\uff0c\u5e76\u5229\u7528 LLM \u81ea\u52a8\u751f\u6210\u548c\u52a8\u6001\u66f4\u65b0\u7b56\u7565\u3002", "result": "\u5728 AgentDojo\u3001ASB \u548c AgentPoison \u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5b9e\u73b0\u4e86\u5f3a\u5b89\u5168\u6027\u4e0e\u9ad8\u5b9e\u7528\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u6838\u5fc3\u7ec4\u4ef6\u7684\u6709\u6548\u6027\u548c\u5bf9\u81ea\u9002\u5e94\u653b\u51fb\u7684\u62b5\u6297\u529b\u3002", "conclusion": "Progent \u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u6613\u4e8e\u96c6\u6210\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\uff0c\u5177\u6709\u5e7f\u6cdb\u91c7\u7528\u6f5c\u529b\u3002"}}
{"id": "2504.12270", "pdf": "https://arxiv.org/pdf/2504.12270", "abs": "https://arxiv.org/abs/2504.12270", "authors": ["ChenNingZhi Sheng", "Rafal Kustra", "Davide Chicco"], "title": "Comparative analysis of unsupervised clustering techniques using validation metrics: Study on cognitive features from the Canadian Longitudinal Study on Aging (CLSA)", "categories": ["cs.LG", "stat.AP", "62H30"], "comment": "22 pages,3 figures,5 tables", "summary": "Purpose: The primary goal of this study is to explore the application of\nevaluation metrics to different clustering algorithms using the data provided\nfrom the Canadian Longitudinal Study (CLSA), focusing on cognitive features.\nThe objective of our work is to discover potential clinically relevant clusters\nthat contribute to the development of dementia over time-based on cognitive\nchanges. Method: The CLSA dataset includes 18,891 participants with data\navailable at both baseline and follow-up assessments, to which clustering\nalgorithms were applied. The clustering methodologies employed in this analysis\nare K-means (KM) clustering, Hierarchical Clustering (HC) and Partitioning\nAround Medoids (PAM). We use multiple evaluation metrics to assess our\nanalysis. For internal evaluation metrics, we use: Average silhouette Width,\nWithin and Between the sum of square Ratio (WB.Ratio), Entropy,\nCalinski-Harabasz Index (CH Index), and Separation Index. For clustering\ncomparison metrics, we used: Homogeneity, Completeness, Adjusted Rand Index\n(ARI), Rand Index (RI), and Variation Information. Results: Using evaluation\nmetrics to compare the results of the three clustering techniques, K-means and\nPartitioning Around Medoids (PAM) produced similar results. In contrast, there\nare significant differences between K-means clustering and Hierarchical\nClustering. Our study highlights the importance of the two internal evaluation\nmetrics: entropy and separation index. In between clustering comparison\nmetrics, the Adjusted Rand Index is a key tool. Conclusion: The study results\nhave the potential to contribute to understanding dementia. Researchers can\nalso benefit by applying the suggested evaluation metrics to other areas of\nhealthcare research. Overall, our study improves the understanding of using\nclustering techniques and evaluation metrics to reveal complex patterns in\nmedical data.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u805a\u7c7b\u7b97\u6cd5\u5206\u6790CLSA\u6570\u636e\uff0c\u805a\u7126\u8ba4\u77e5\u7279\u5f81\uff0c\u5bfb\u627e\u4e0e\u75f4\u5446\u76f8\u5173\u7684\u96c6\u7fa4\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u8bc4\u4f30\u6307\u6807\u8fdb\u884c\u6bd4\u8f83\u3002", "motivation": "\u63a2\u7d22\u8bc4\u4f30\u6307\u6807\u5728\u4e0d\u540c\u805a\u7c7b\u7b97\u6cd5\u4e0a\u7684\u5e94\u7528\uff0c\u65e8\u5728\u57fa\u4e8eCLSA\u6570\u636e\u53d1\u73b0\u4e0e\u75f4\u5446\u53d1\u5c55\u7684\u4e34\u5e8a\u76f8\u5173\u96c6\u7fa4\u3002", "method": "\u4f7f\u7528K-means\u3001\u5c42\u6b21\u805a\u7c7b\u548cPAM\u7b97\u6cd5\u5206\u6790CLSA\u768418,891\u540d\u53c2\u4e0e\u8005\u6570\u636e\uff0c\u91c7\u7528\u5185\u90e8\u6307\u6807\uff08\u5982\u8f6e\u5ed3\u5bbd\u5ea6\u3001\u71b5\u7b49\uff09\u548c\u6bd4\u8f83\u6307\u6807\uff08\u5982\u8c03\u6574\u5170\u5fb7\u6307\u6570\uff09\u3002", "result": "K-means\u548cPAM\u7ed3\u679c\u76f8\u4f3c\uff0c\u4e0e\u5c42\u6b21\u805a\u7c7b\u6709\u663e\u8457\u5dee\u5f02\uff1b\u5f3a\u8c03\u71b5\u3001\u5206\u79bb\u6307\u6570\u548c\u8c03\u6574\u5170\u5fb7\u6307\u6570\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u7ed3\u679c\u6709\u52a9\u4e8e\u7406\u89e3\u75f4\u5446\uff0c\u53ef\u5e94\u7528\u4e8e\u5176\u4ed6\u533b\u7597\u9886\u57df\uff0c\u63d0\u9ad8\u805a\u7c7b\u6280\u672f\u548c\u6307\u6807\u5728\u533b\u7597\u6570\u636e\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2504.11707", "pdf": "https://arxiv.org/pdf/2504.11707", "abs": "https://arxiv.org/abs/2504.11707", "authors": ["Muhammad Shahid Muneer", "Simon S. Woo"], "title": "Towards Safe Synthetic Image Generation On the Web: A Multimodal Robust NSFW Defense and Million Scale Dataset", "categories": ["cs.CV", "cs.AI"], "comment": "Short Paper The Web Conference", "summary": "In the past years, we have witnessed the remarkable success of Text-to-Image\n(T2I) models and their widespread use on the web. Extensive research in making\nT2I models produce hyper-realistic images has led to new concerns, such as\ngenerating Not-Safe-For-Work (NSFW) web content and polluting the web society.\nTo help prevent misuse of T2I models and create a safer web environment for\nusers features like NSFW filters and post-hoc security checks are used in these\nmodels. However, recent work unveiled how these methods can easily fail to\nprevent misuse. In particular, adversarial attacks on text and image modalities\ncan easily outplay defensive measures. %Exploiting such leads to the growing\nconcern of preventing adversarial attacks on text and image modalities.\nMoreover, there is currently no robust multimodal NSFW dataset that includes\nboth prompt and image pairs and adversarial examples. This work proposes a\nmillion-scale prompt and image dataset generated using open-source diffusion\nmodels. Second, we develop a multimodal defense to distinguish safe and NSFW\ntext and images, which is robust against adversarial attacks and directly\nalleviates current challenges. Our extensive experiments show that our model\nperforms well against existing SOTA NSFW detection methods in terms of accuracy\nand recall, drastically reducing the Attack Success Rate (ASR) in multimodal\nadversarial attack scenarios. Code:\nhttps://github.com/shahidmuneer/multimodal-nsfw-defense.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u767e\u4e07\u89c4\u6a21\u7684\u63d0\u793a\u548c\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u4e00\u4e2a\u9488\u5bf9\u591a\u6a21\u6001\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2NSFW\u9632\u5fa1\u65b9\u6cd5\uff0c\u4ee5\u9632\u6b62\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7684\u6ee5\u7528\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u751f\u6210NSFW\u5185\u5bb9\u7684\u95ee\u9898\u3001\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u7684\u5931\u6548\u4ee5\u53ca\u7f3a\u4e4f\u9c81\u68d2\u7684\u591a\u6a21\u6001NSFW\u6570\u636e\u96c6\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u5f00\u6e90\u6269\u6563\u6a21\u578b\u751f\u6210\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1\u4e00\u4e2a\u591a\u6a21\u6001\u9632\u5fa1\u6a21\u578b\u6765\u533a\u5206\u5b89\u5168\u548cNSFW\u5185\u5bb9\uff0c\u5e76\u62b5\u6297\u5bf9\u6297\u653b\u51fb\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6a21\u578b\u5728\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u591a\u6a21\u6001\u5bf9\u6297\u653b\u51fb\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8be5\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u4e86\u5f53\u524d\u6311\u6218\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u4ee3\u7801\u5b9e\u73b0\u3002"}}
{"id": "2504.11491", "pdf": "https://arxiv.org/pdf/2504.11491", "abs": "https://arxiv.org/abs/2504.11491", "authors": ["Mansoor Hayat", "Supavadee Aramvith", "Subrata Bhattacharjee", "Nouman Ahmad"], "title": "Attention GhostUNet++: Enhanced Segmentation of Adipose Tissue and Liver in CT Images", "categories": ["eess.IV", "cs.CV", "cs.LG", "cs.MM"], "comment": "Accepted for presentation in the 47th Annual International Conference\n  of the IEEE Engineering in Medicine and Biology Society (EMBC 2025)", "summary": "Accurate segmentation of abdominal adipose tissue, including subcutaneous\n(SAT) and visceral adipose tissue (VAT), along with liver segmentation, is\nessential for understanding body composition and associated health risks such\nas type 2 diabetes and cardiovascular disease. This study proposes Attention\nGhostUNet++, a novel deep learning model incorporating Channel, Spatial, and\nDepth Attention mechanisms into the Ghost UNet++ bottleneck for automated,\nprecise segmentation. Evaluated on the AATTCT-IDS and LiTS datasets, the model\nachieved Dice coefficients of 0.9430 for VAT, 0.9639 for SAT, and 0.9652 for\nliver segmentation, surpassing baseline models. Despite minor limitations in\nboundary detail segmentation, the proposed model significantly enhances feature\nrefinement, contextual understanding, and computational efficiency, offering a\nrobust solution for body composition analysis. The implementation of the\nproposed Attention GhostUNet++ model is available\nat:https://github.com/MansoorHayat777/Attention-GhostUNetPlusPlus.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faAttention GhostUNet++\u6a21\u578b\uff0c\u7528\u4e8e\u8179\u90e8\u8102\u80aa\u548c\u809d\u810f\u7cbe\u786e\u5206\u5272\uff0c\u53d6\u5f97\u4e86\u9ad8Dice\u7cfb\u6570\u3002", "motivation": "\u51c6\u786e\u5206\u5272\u8179\u90e8\u8102\u80aa\u548c\u809d\u810f\u6709\u52a9\u4e8e\u7406\u89e3\u8eab\u4f53\u7ec4\u6210\u53ca\u5065\u5eb7\u98ce\u9669\uff0c\u5982\u7cd6\u5c3f\u75c5\u548c\u5fc3\u8840\u7ba1\u75be\u75c5\u3002", "method": "\u63d0\u51faAttention GhostUNet++\uff0c\u901a\u8fc7\u6574\u5408\u901a\u9053\u3001\u7a7a\u95f4\u548c\u6df1\u5ea6\u6ce8\u610f\u529b\u673a\u5236\u5230Ghost UNet++\u74f6\u9888\u4e2d\u5b9e\u73b0\u81ea\u52a8\u5206\u5272\u3002", "result": "\u5728AATTCT-IDS\u548cLiTS\u6570\u636e\u96c6\u4e0a\uff0cDice\u7cfb\u6570\u5206\u522b\u4e3aVAT 0.9430\u3001SAT 0.9639\u548c\u809d\u810f0.9652\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u63d0\u5347\u4e86\u7279\u5f81\u7ec6\u5316\u548c\u6548\u7387\u3002", "conclusion": "\u5c3d\u7ba1\u8fb9\u754c\u7ec6\u8282\u6709\u8f7b\u5fae\u9650\u5236\uff0c\u4f46\u6a21\u578b\u63d0\u4f9b\u7a33\u5065\u7684\u8eab\u4f53\u7ec4\u6210\u5206\u6790\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2504.11711", "pdf": "https://arxiv.org/pdf/2504.11711", "abs": "https://arxiv.org/abs/2504.11711", "authors": ["Haonan Li", "Hang Zhang", "Kexin Pei", "Zhiyun Qian"], "title": "The Hitchhiker's Guide to Program Analysis, Part II: Deep Thoughts by LLMs", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Static analysis is a cornerstone for software vulnerability detection, yet it\noften struggles with the classic precision-scalability trade-off. In practice,\nsuch tools often produce high false positive rates, particularly in large\ncodebases like the Linux kernel. This imprecision can arise from simplified\nvulnerability modeling and over-approximation of path and data constraints.\nWhile large language models (LLMs) show promise in code understanding, their\nnaive application to program analysis yields unreliable results due to inherent\nreasoning limitations. We introduce BugLens, a post-refinement framework that\nsignificantly improves static analysis precision. BugLens guides an LLM to\nfollow traditional analysis steps by assessing buggy code patterns for security\nimpact and validating the constraints associated with static warnings.\nEvaluated on real-world Linux kernel bugs, BugLens raises precision from 0.10\n(raw) and 0.50 (semi-automated refinement) to 0.72, substantially reducing\nfalse positives and revealing four previously unreported vulnerabilities. Our\nresults suggest that a structured LLM-based workflow can meaningfully enhance\nthe effectiveness of static analysis tools.", "AI": {"tldr": "BugLens \u901a\u8fc7 LLM \u63d0\u5347\u9759\u6001\u5206\u6790\u7cbe\u5ea6\uff0c\u4ece 0.10/0.50 \u63d0\u9ad8\u5230 0.72\u3002", "motivation": "\u9759\u6001\u5206\u6790\u5728\u7cbe\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u95f4\u6743\u8861\uff0c\u5e38\u6709\u9ad8\u5047\u9633\u6027\u7387\uff1bLLM \u5728\u4ee3\u7801\u7406\u89e3\u4e0a\u6709\u6f5c\u529b\u4f46\u76f4\u63a5\u5e94\u7528\u4e0d\u53ef\u9760\u3002", "method": "\u5f15\u5165 BugLens \u6846\u67b6\uff0c\u6307\u5bfc LLM \u9075\u5faa\u4f20\u7edf\u5206\u6790\u6b65\u9aa4\uff0c\u8bc4\u4f30\u9519\u8bef\u4ee3\u7801\u6a21\u5f0f\u7684\u5b89\u5168\u5f71\u54cd\u5e76\u9a8c\u8bc1\u7ea6\u675f\u3002", "result": "\u5728 Linux \u5185\u6838\u6f0f\u6d1e\u4e0a\uff0c\u7cbe\u5ea6\u4ece 0.10 \u548c 0.50 \u63d0\u9ad8\u5230 0.72\uff0c\u51cf\u5c11\u5047\u9633\u6027\uff0c\u53d1\u73b0\u56db\u4e2a\u65b0\u6f0f\u6d1e\u3002", "conclusion": "\u7ed3\u6784\u5316\u7684 LLM \u5de5\u4f5c\u6d41\u53ef\u663e\u8457\u63d0\u5347\u9759\u6001\u5206\u6790\u5de5\u5177\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2504.11502", "pdf": "https://arxiv.org/pdf/2504.11502", "abs": "https://arxiv.org/abs/2504.11502", "authors": ["Jatin Nainani", "Chia-Tung Ho", "Anirudh Dhurka", "Haoxing Ren"], "title": "Timing Analysis Agent: Autonomous Multi-Corner Multi-Mode (MCMM) Timing Debugging with Timing Debug Relation Graph", "categories": ["cs.SE", "cs.LG"], "comment": "7 pages, 7 figures, 2 tables", "summary": "Timing analysis is an essential and demanding verification method for Very\nLarge Scale Integrated (VLSI) circuit design and optimization. In addition, it\nalso serves as the cornerstone of the final sign-off, determining whether the\nchip is ready to be sent to the semiconductor foundry for fabrication.\nRecently, as the technology advance relentlessly, smaller metal pitches and the\nincreasing number of devices have led to greater challenges and longer\nturn-around-time for experienced human designers to debug timing issues from\nthe Multi-Corner Multi-Mode (MCMM) timing reports. As a result, an efficient\nand intelligent methodology is highly necessary and essential for debugging\ntiming issues and reduce the turnaround times. Recently, Large Language Models\n(LLMs) have shown great promise across various tasks in language understanding\nand interactive decision-making, incorporating reasoning and actions. In this\nwork, we propose a timing analysis agent, that is empowered by multi-LLMs task\nsolving, and incorporates a novel hierarchical planning and solving flow to\nautomate the analysis of timing reports from commercial tool. In addition, we\nbuild a Timing Debug Relation Graph (TDRG) that connects the reports with the\nrelationships of debug traces from experienced timing engineers. The timing\nanalysis agent employs the novel Agentic Retrieval Augmented Generation (RAG)\napproach, that includes agent and coding to retrieve data accurately, on the\ndeveloped TDRG. In our studies, the proposed timing analysis agent achieves an\naverage 98% pass-rate on a single-report benchmark and a 90% pass-rate for\nmulti-report benchmark from industrial designs, demonstrating its effectiveness\nand adaptability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65f6\u5e8f\u5206\u6790\u4ee3\u7406\uff0c\u4f7f\u7528\u5206\u5c42\u89c4\u5212\u548cAgentic RAG\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u901a\u8fc7\u7387\u7684VLSI\u7535\u8def\u65f6\u5e8f\u62a5\u544a\u8c03\u8bd5\u3002", "motivation": "\u6280\u672f\u8fdb\u6b65\u5bfc\u81f4VLSI\u7535\u8def\u65f6\u5e8f\u8c03\u8bd5\u6311\u6218\u589e\u5927\uff0c\u9700\u8981\u9ad8\u6548\u667a\u80fd\u65b9\u6cd5\uff1bLLM\u5728\u8bed\u8a00\u7406\u89e3\u548c\u51b3\u7b56\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u65f6\u5e8f\u5206\u6790\u4ee3\u7406\uff0c\u7ed3\u5408\u591aLLM\u5206\u5c42\u89c4\u5212\u3001Timing Debug Relation Graph (TDRG)\u548cAgentic RAG\u65b9\u6cd5\u3002", "result": "\u5728\u5de5\u4e1a\u8bbe\u8ba1\u57fa\u51c6\u4e0a\uff0c\u5355\u62a5\u544a\u5e73\u574798%\u901a\u8fc7\u7387\uff0c\u591a\u62a5\u544a90%\u901a\u8fc7\u7387\u3002", "conclusion": "\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2504.11504", "pdf": "https://arxiv.org/pdf/2504.11504", "abs": "https://arxiv.org/abs/2504.11504", "authors": ["Woojin Kim", "Hyeoncheol Kim"], "title": "Counterfactual Fairness Evaluation of Machine Learning Models on Educational Datasets", "categories": ["cs.CY", "cs.LG"], "comment": "12 pages, 6 figures, accepted to ITS2025", "summary": "As machine learning models are increasingly used in educational settings,\nfrom detecting at-risk students to predicting student performance, algorithmic\nbias and its potential impacts on students raise critical concerns about\nalgorithmic fairness. Although group fairness is widely explored in education,\nworks on individual fairness in a causal context are understudied, especially\non counterfactual fairness. This paper explores the notion of counterfactual\nfairness for educational data by conducting counterfactual fairness analysis of\nmachine learning models on benchmark educational datasets. We demonstrate that\ncounterfactual fairness provides meaningful insight into the causality of\nsensitive attributes and causal-based individual fairness in education.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86counterfactual fairness\u5728\u6559\u80b2\u6570\u636e\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u5206\u6790\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5c55\u793a\u4e86\u5176\u5bf9\u7b97\u6cd5\u516c\u5e73\u6027\u7684\u6d1e\u89c1\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5728\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u5f15\u53d1\u7b97\u6cd5\u504f\u89c1\u548c\u516c\u5e73\u6027\u62c5\u5fe7\uff0c\u7279\u522b\u662f\u4e2a\u4f53\u516c\u5e73\u5c24\u5176\u662fcounterfactual fairness\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u5bf9\u57fa\u51c6\u6559\u80b2\u6570\u636e\u96c6\u8fdb\u884ccounterfactual fairness\u5206\u6790\u3002", "result": "\u8bc1\u660e\u4e86counterfactual fairness\u80fd\u63d0\u4f9b\u654f\u611f\u5c5e\u6027\u56e0\u679c\u6027\u548c\u57fa\u4e8e\u56e0\u679c\u7684\u4e2a\u4f53\u516c\u5e73\u6027\u7684\u6709\u610f\u4e49\u6d1e\u89c1\u3002", "conclusion": "counterfactual fairness\u5728\u6559\u80b2\u4e2d\u5bf9\u7b97\u6cd5\u516c\u5e73\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2504.11750", "pdf": "https://arxiv.org/pdf/2504.11750", "abs": "https://arxiv.org/abs/2504.11750", "authors": ["Prabhu Vellaisamy", "Thomas Labonte", "Sourav Chakraborty", "Matt Turner", "Samantika Sury", "John Paul Shen"], "title": "Characterizing and Optimizing LLM Inference Workloads on CPU-GPU Coupled Architectures", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.PF"], "comment": "Accepted for ISPASS 2025", "summary": "Large language model (LLM)-based inference workloads increasingly dominate\ndata center costs and resource utilization. Therefore, understanding the\ninference workload characteristics on evolving CPU-GPU coupled architectures is\ncrucial for optimization. This paper presents an in-depth analysis of LLM\ninference behavior on loosely-coupled (PCIe A100/H100) and closely-coupled\n(GH200) systems. We analyze performance dynamics using fine-grained\noperator-to-kernel trace analysis, facilitated by our novel profiler SKIP and\nmetrics like Total Kernel Launch and Queuing Time (TKLQT). Results show that\nclosely-coupled (CC) GH200 significantly outperforms loosely-coupled (LC)\nsystems at large batch sizes, achieving 1.9x-2.7x faster prefill latency for\nLlama 3.2-1B. However, our analysis also reveals that GH200 remains CPU-bound\nup to 4x larger batch sizes than LC systems. In this extended CPU-bound region,\nwe identify the performance characteristics of the Grace CPU as a key factor\ncontributing to higher inference latency at low batch sizes on GH200. We\ndemonstrate that TKLQT accurately identifies this CPU/GPU-bound transition\npoint. Based on this analysis, we further show that kernel fusion offers\nsignificant potential to mitigate GH200's low-batch latency bottleneck by\nreducing kernel launch overhead. This detailed kernel-level characterization\nprovides critical insights for optimizing diverse CPU-GPU coupling strategies.\nThis work is an initial effort, and we plan to explore other major AI/DL\nworkloads that demand different degrees of CPU-GPU heterogeneous architectures.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5206\u6790\u4e86LLM\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u5728CPU-GPU\u8026\u5408\u67b6\u6784\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u7a81\u51fa\u4e86\u7d27\u5bc6\u8026\u5408\u7cfb\u7edf\u5728\u5927\u578b\u6279\u6b21\u4e0b\u7684\u4f18\u52bf\uff0c\u5e76\u63d0\u51fa\u4f18\u5316\u5efa\u8bae\u3002", "motivation": "LLM\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u8d8a\u6765\u8d8a\u4e3b\u5bfc\u6570\u636e\u4e2d\u5fc3\u6210\u672c\u548c\u8d44\u6e90\u5229\u7528\uff0c\u56e0\u6b64\u7406\u89e3\u5176\u5728\u6f14\u8fdbCPU-GPU\u8026\u5408\u67b6\u6784\u4e0a\u7684\u7279\u6027\u5bf9\u4f18\u5316\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684\u64cd\u4f5c\u7b26\u5230\u5185\u6838\u8ddf\u8e2a\u5206\u6790\uff0c\u4f7f\u7528\u65b0\u578b\u5206\u6790\u5668SKIP\u548c\u6307\u6807TKLQT\uff0c\u5206\u6790\u677e\u6563\u8026\u5408\uff08PCIe A100/H100\uff09\u548c\u7d27\u5bc6\u8026\u5408\uff08GH200\uff09\u7cfb\u7edf\u7684LLM\u63a8\u7406\u884c\u4e3a\u3002", "result": "\u7d27\u5bc6\u8026\u5408GH200\u5728\u5927\u578b\u6279\u6b21\u4e0b\u6027\u80fd\u4f18\u5f02\uff0c\u9884\u586b\u5145\u5ef6\u8fdf\u5feb1.9x-2.7x\uff1b\u4f46\u5728\u66f4\u5927\u6279\u6b21\u4e0b\u4ecd\u53d7CPU\u9650\u5236\uff0cTKLQT\u80fd\u51c6\u786e\u8bc6\u522bCPU/GPU\u7ed1\u5b9a\u8f6c\u6298\u70b9\u3002", "conclusion": "\u5185\u6838\u878d\u5408\u53ef\u964d\u4f4eGH200\u4f4e\u6279\u6b21\u5ef6\u8fdf\u74f6\u9888\uff0c\u63d0\u4f9b\u4f18\u5316CPU-GPU\u8026\u5408\u7b56\u7565\u7684\u6d1e\u89c1\uff0c\u5e76\u8ba1\u5212\u6269\u5c55\u5230\u5176\u4ed6AI/DL\u5de5\u4f5c\u8d1f\u8f7d\u3002"}}
{"id": "2504.11754", "pdf": "https://arxiv.org/pdf/2504.11754", "abs": "https://arxiv.org/abs/2504.11754", "authors": ["Zihui Zhang", "Yafei Yang", "Hongtao Wen", "Bo Yang"], "title": "GrabS: Generative Embodied Agent for 3D Object Segmentation without Scene Supervision", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "ICLR 2025 Spotlight. Code and data are available at:\n  https://github.com/vLAR-group/GrabS", "summary": "We study the hard problem of 3D object segmentation in complex point clouds\nwithout requiring human labels of 3D scenes for supervision. By relying on the\nsimilarity of pretrained 2D features or external signals such as motion to\ngroup 3D points as objects, existing unsupervised methods are usually limited\nto identifying simple objects like cars or their segmented objects are often\ninferior due to the lack of objectness in pretrained features. In this paper,\nwe propose a new two-stage pipeline called GrabS. The core concept of our\nmethod is to learn generative and discriminative object-centric priors as a\nfoundation from object datasets in the first stage, and then design an embodied\nagent to learn to discover multiple objects by querying against the pretrained\ngenerative priors in the second stage. We extensively evaluate our method on\ntwo real-world datasets and a newly created synthetic dataset, demonstrating\nremarkable segmentation performance, clearly surpassing all existing\nunsupervised methods.", "AI": {"tldr": "This paper introduces GrabS, a new unsupervised method for 3D object segmentation in complex point clouds, using a two-stage approach with generative priors and an embodied agent, outperforming existing methods.", "motivation": "Existing unsupervised methods are limited to simple objects and have inferior performance due to the lack of objectness in pretrained 2D features or external signals.", "method": "A two-stage pipeline: first, learn generative and discriminative object-centric priors from object datasets; second, use an embodied agent to discover objects by querying against these priors.", "result": "The method achieves remarkable segmentation performance on two real-world datasets and a new synthetic dataset, surpassing all existing unsupervised methods.", "conclusion": "GrabS demonstrates significant advancements in unsupervised 3D object segmentation by effectively utilizing pretrained priors and embodied agents."}}
{"id": "2504.11512", "pdf": "https://arxiv.org/pdf/2504.11512", "abs": "https://arxiv.org/abs/2504.11512", "authors": ["Sara Sippola", "Siiri Rautio", "Andreas Hauptmann", "Takanori Ide", "Samuli Siltanen"], "title": "Learned enclosure method for experimental EIT data", "categories": ["eess.IV", "cs.LG", "math.AP"], "comment": null, "summary": "Electrical impedance tomography (EIT) is a non-invasive imaging method with\ndiverse applications, including medical imaging and non-destructive testing.\nThe inverse problem of reconstructing internal electrical conductivity from\nboundary measurements is nonlinear and highly ill-posed, making it difficult to\nsolve accurately. In recent years, there has been growing interest in combining\nanalytical methods with machine learning to solve inverse problems. In this\npaper, we propose a method for estimating the convex hull of inclusions from\nboundary measurements by combining the enclosure method proposed by Ikehata\nwith neural networks. We demonstrate its performance using experimental data.\nCompared to the classical enclosure method with least squares fitting, the\nlearned convex hull achieves superior performance on both simulated and\nexperimental data.", "AI": {"tldr": "\u672c\u8bba\u6587\u7ed3\u5408Ikehata\u7684\u5305\u56f4\u65b9\u6cd5\u4e0e\u795e\u7ecf\u7f51\u7edc\uff0c\u6539\u8fdb\u7535\u963b\u6297\u5c42\u6790\u6210\u50cf\u7684\u9006\u95ee\u9898\u6c42\u89e3\u3002", "motivation": "\u7535\u963b\u6297\u5c42\u6790\u6210\u50cf\u7684\u9006\u95ee\u9898\u662f\u9ad8\u5ea6\u75c5\u6001\u548c\u975e\u7ebf\u6027\u7684\uff0c\u96be\u4e8e\u51c6\u786e\u6c42\u89e3\uff0c\u4e14\u5bf9\u7ed3\u5408\u5206\u6790\u65b9\u6cd5\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u5174\u8da3\u65e5\u76ca\u589e\u52a0\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\uff0c\u5c06Ikehata\u7684\u5305\u56f4\u65b9\u6cd5\u4e0e\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\uff0c\u4ece\u8fb9\u754c\u6d4b\u91cf\u4f30\u8ba1\u5305\u51f8\u58f3\u3002", "result": "\u5728\u6a21\u62df\u548c\u5b9e\u9a8c\u6570\u636e\u4e0a\uff0c\u8868\u73b0\u4f18\u4e8e\u7ecf\u5178\u5305\u56f4\u65b9\u6cd5\u7ed3\u5408\u6700\u5c0f\u4e8c\u4e58\u62df\u5408\u3002", "conclusion": "\u5b66\u5230\u7684\u5305\u51f8\u58f3\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a superior\uff0c\u63d0\u5347\u4e86\u9006\u95ee\u9898\u6c42\u89e3\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2504.11774", "pdf": "https://arxiv.org/pdf/2504.11774", "abs": "https://arxiv.org/abs/2504.11774", "authors": ["Keke Gai", "Ziyue Shen", "Jing Yu", "Liehuang Zhu", "Qi Wu"], "title": "PCDiff: Proactive Control for Ownership Protection in Diffusion Models with Watermark Compatibility", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "With the growing demand for protecting the intellectual property (IP) of\ntext-to-image diffusion models, we propose PCDiff -- a proactive access control\nframework that redefines model authorization by regulating generation quality.\nAt its core, PCDIFF integrates a trainable fuser module and hierarchical\nauthentication layers into the decoder architecture, ensuring that only users\nwith valid encrypted credentials can generate high-fidelity images. In the\nabsence of valid keys, the system deliberately degrades output quality,\neffectively preventing unauthorized exploitation.Importantly, while the primary\nmechanism enforces active access control through architectural intervention,\nits decoupled design retains compatibility with existing watermarking\ntechniques. This satisfies the need of model owners to actively control model\nownership while preserving the traceability capabilities provided by\ntraditional watermarking approaches.Extensive experimental evaluations confirm\na strong dependency between credential verification and image quality across\nvarious attack scenarios. Moreover, when combined with typical post-processing\noperations, PCDIFF demonstrates powerful performance alongside conventional\nwatermarking methods. This work shifts the paradigm from passive detection to\nproactive enforcement of authorization, laying the groundwork for IP management\nof diffusion models.", "AI": {"tldr": "PCDiff \u662f\u4e00\u4e2a\u4e3b\u52a8\u8bbf\u95ee\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u8c03\u8282\u751f\u6210\u8d28\u91cf\uff0c\u786e\u4fdd\u53ea\u6709\u6388\u6743\u7528\u6237\u624d\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u56fe\u50cf\u3002", "motivation": "\u968f\u7740\u5bf9\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u9700\u6c42\u7684\u589e\u957f\uff0c\u9700\u8981\u4e3b\u52a8\u63a7\u5236\u8bbf\u95ee\u4ee5\u9632\u6b62 unauthorized \u5229\u7528\u3002", "method": "\u63d0\u51fa PCDiff \u6846\u67b6\uff0c\u96c6\u6210\u53ef\u8bad\u7ec3\u7684\u878d\u5408\u6a21\u5757\u548c\u5206\u5c42\u8ba4\u8bc1\u5c42\u5230\u89e3\u7801\u5668\u4e2d\uff0c\u5728\u65e0\u6709\u6548\u5bc6\u94a5\u65f6\u964d\u4f4e\u8f93\u51fa\u8d28\u91cf\uff0c\u5e76\u4e0e\u6c34\u5370\u6280\u672f\u517c\u5bb9\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\u51ed\u8bc1\u9a8c\u8bc1\u4e0e\u56fe\u50cf\u8d28\u91cf\u5f3a\u76f8\u5173\uff0c\u5728\u5404\u79cd\u653b\u51fb\u573a\u666f\u4e0b\u6709\u6548\uff0c\u4e0e\u6c34\u5370\u65b9\u6cd5\u7ed3\u5408\u6027\u80fd\u826f\u597d\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c06 IP \u4fdd\u62a4\u4ece\u88ab\u52a8\u68c0\u6d4b\u8f6c\u5411\u4e3b\u52a8\u6388\u6743\u6267\u884c\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u7684 IP \u7ba1\u7406\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2504.11516", "pdf": "https://arxiv.org/pdf/2504.11516", "abs": "https://arxiv.org/abs/2504.11516", "authors": ["Jiajun He", "Yuanqi Du", "Francisco Vargas", "Yuanqing Wang", "Carla P. Gomes", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato", "Eric Vanden-Eijnden"], "title": "FEAT: Free energy Estimators with Adaptive Transport", "categories": ["stat.ML", "cs.LG", "physics.chem-ph", "physics.comp-ph"], "comment": "29 pages, 2 tables, 3 figures", "summary": "We present Free energy Estimators with Adaptive Transport (FEAT), a novel\nframework for free energy estimation -- a critical challenge across scientific\ndomains. FEAT leverages learned transports implemented via stochastic\ninterpolants and provides consistent, minimum-variance estimators based on\nescorted Jarzynski equality and controlled Crooks theorem, alongside\nvariational upper and lower bounds on free energy differences. Unifying\nequilibrium and non-equilibrium methods under a single theoretical framework,\nFEAT establishes a principled foundation for neural free energy calculations.\nExperimental validation on toy examples, molecular simulations, and quantum\nfield theory demonstrates improvements over existing learning-based methods.", "AI": {"tldr": "FEAT \u662f\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u7531\u80fd\u4f30\u8ba1\uff0c\u901a\u8fc7\u5b66\u4e60\u4f20\u8f93\u7edf\u4e00\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u6539\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u81ea\u7531\u80fd\u4f30\u8ba1\u662f\u8de8\u79d1\u5b66\u9886\u57df\u7684\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u7edf\u4e00\u5e73\u8861\u548c\u975e\u5e73\u8861\u65b9\u6cd5\u3002", "method": "FEAT \u4f7f\u7528\u968f\u673a\u63d2\u503c\u5b9e\u73b0\u7684\u5b66\u4e60\u4f20\u8f93\uff0c\u57fa\u4e8e\u62a4\u9001 Jarzynski \u7b49\u5f0f\u548c\u63a7\u5236 Crooks \u5b9a\u7406\uff0c\u63d0\u4f9b\u6700\u5c0f\u65b9\u5dee\u4f30\u8ba1\u5668\u548c\u53d8\u5206\u754c\u9650\u3002", "result": "\u5b9e\u9a8c\u5728\u73a9\u5177\u4f8b\u5b50\u3001\u5206\u5b50\u6a21\u62df\u548c\u91cf\u5b50\u573a\u8bba\u4e0a\u9a8c\u8bc1\uff0c\u663e\u793a\u4e86\u6bd4\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u66f4\u597d\u7684\u6539\u8fdb\u3002", "conclusion": "FEAT \u5efa\u7acb\u4e86\u795e\u7ecf\u81ea\u7531\u80fd\u8ba1\u7b97\u7684\u539f\u7406\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2504.11780", "pdf": "https://arxiv.org/pdf/2504.11780", "abs": "https://arxiv.org/abs/2504.11780", "authors": ["Maria Spichkova", "Hina Lee", "Kevin Iwan", "Madeleine Zwart", "Yuwon Yoon", "Xiaohan Qin"], "title": "Agile Retrospectives: What went well? What didn't go well? What should we do?", "categories": ["cs.SE", "cs.AI"], "comment": "Preprint. Accepted to the 20th International Conference on Evaluation\n  of Novel Approaches to Software Engineering (ENASE 2025). Final version to be\n  published by SCITEPRESS, http://www.scitepress.org", "summary": "In Agile/Scrum software development, the idea of retrospective meetings\n(retros) is one of the core elements of the project process. In this paper, we\npresent our work in progress focusing on two aspects: analysis of potential\nusage of generative AI for information interaction within retrospective\nmeetings, and visualisation of retros' information to software development\nteams. We also present our prototype tool RetroAI++, focusing on retros-related\nfunctionalities.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u654f\u6377/Scrum\u56de\u987e\u4f1a\u8bae\u4e2d\u4f7f\u7528\u751f\u6210\u5f0fAI\u8fdb\u884c\u4fe1\u606f\u4ea4\u4e92\u548c\u53ef\u89c6\u5316\uff0c\u5e76\u4ecb\u7ecd\u4e86\u539f\u578b\u5de5\u5177RetroAI++\u3002", "motivation": "\u52a8\u673a\u662f\u5206\u6790\u751f\u6210\u5f0fAI\u5728\u56de\u987e\u4f1a\u8bae\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\uff0c\u4ee5\u63d0\u5347\u8f6f\u4ef6\u5f00\u53d1\u56e2\u961f\u7684\u4fe1\u606f\u4ea4\u4e92\u548c\u53ef\u89c6\u5316\u6548\u679c\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5bf9AI\u4f7f\u7528\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u5f00\u53d1\u539f\u578b\u5de5\u5177RetroAI++\uff0c\u4e13\u6ce8\u4e8e\u56de\u987e\u4f1a\u8bae\u7684\u76f8\u5173\u529f\u80fd\u3002", "result": "\u7ed3\u679c\u662f\u5448\u73b0\u4e86\u539f\u578b\u5de5\u5177RetroAI++\uff0c\u5c55\u793a\u4e86\u5de5\u4f5c\u7684\u8fdb\u5c55\uff0c\u4f46\u672a\u63d0\u4f9b\u5177\u4f53\u6210\u679c\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8fd9\u9879\u5de5\u4f5c\u4ecd\u5728\u8fdb\u884c\u4e2d\uff0c\u65e8\u5728\u5c55\u793aAI\u5728\u56de\u987e\u4f1a\u8bae\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.11519", "pdf": "https://arxiv.org/pdf/2504.11519", "abs": "https://arxiv.org/abs/2504.11519", "authors": ["Mohammad Farahmand", "Amoon Jamzad", "Fahimeh Fooladgar", "Laura Connolly", "Martin Kaufmann", "Kevin Yi Mi Ren", "John Rudan", "Doug McKay", "Gabor Fichtinger", "Parvin Mousavi"], "title": "FACT: Foundation Model for Assessing Cancer Tissue Margins with Mass Spectrometry", "categories": ["physics.med-ph", "cs.CV", "cs.LG"], "comment": null, "summary": "Purpose: Accurately classifying tissue margins during cancer surgeries is\ncrucial for ensuring complete tumor removal. Rapid Evaporative Ionization Mass\nSpectrometry (REIMS), a tool for real-time intraoperative margin assessment,\ngenerates spectra that require machine learning models to support clinical\ndecision-making. However, the scarcity of labeled data in surgical contexts\npresents a significant challenge. This study is the first to develop a\nfoundation model tailored specifically for REIMS data, addressing this\nlimitation and advancing real-time surgical margin assessment. Methods: We\npropose FACT, a Foundation model for Assessing Cancer Tissue margins. FACT is\nan adaptation of a foundation model originally designed for text-audio\nassociation, pretrained using our proposed supervised contrastive approach\nbased on triplet loss. An ablation study is performed to compare our proposed\nmodel against other models and pretraining methods. Results: Our proposed model\nsignificantly improves the classification performance, achieving\nstate-of-the-art performance with an AUROC of $82.4\\% \\pm 0.8$. The results\ndemonstrate the advantage of our proposed pretraining method and selected\nbackbone over the self-supervised and semi-supervised baselines and alternative\nmodels. Conclusion: Our findings demonstrate that foundation models, adapted\nand pretrained using our novel approach, can effectively classify REIMS data\neven with limited labeled examples. This highlights the viability of foundation\nmodels for enhancing real-time surgical margin assessment, particularly in\ndata-scarce clinical environments.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f00\u53d1\u4e86FACT\u6a21\u578b\uff0c\u7528\u4e8eREIMS\u6570\u636e\u7684\u5b9e\u65f6\u764c\u75c7\u7ec4\u7ec7\u8fb9\u7f18\u5206\u7c7b\uff0c\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "motivation": "\u764c\u75c7\u624b\u672f\u4e2d\u51c6\u786e\u5206\u7c7b\u7ec4\u7ec7\u8fb9\u7f18\u81f3\u5173\u91cd\u8981\uff0c\u4f46REIMS\u6570\u636e\u6807\u8bb0\u7a00\u7f3a\uff0c\u672c\u7814\u7a76\u9996\u6b21\u9488\u5bf9\u6b64\u5f00\u53d1\u57fa\u91d1\u4f1a\u6a21\u578b\u3002", "method": "\u63d0\u51faFACT\u6a21\u578b\uff0c\u6539\u7f16\u81ea\u6587\u672c-\u97f3\u9891\u5173\u8054\u6a21\u578b\uff0c\u4f7f\u7528\u57fa\u4e8e\u4e09\u5143\u7ec4\u635f\u5931\u7684\u76d1\u7763\u5bf9\u6bd4\u9884\u8bad\u7ec3\uff0c\u5e76\u8fdb\u884c\u6d88\u878d\u7814\u7a76\u6bd4\u8f83\u3002", "result": "\u6a21\u578b\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0cAUROC\u4e3a82.4% \u00b1 0.8%\uff0c\u4f18\u4e8e\u81ea\u76d1\u7763\u548c\u534a\u76d1\u7763\u57fa\u7ebf\u3002", "conclusion": "\u57fa\u91d1\u4f1a\u6a21\u578b\u901a\u8fc7\u65b0\u65b9\u6cd5\u6539\u7f16\uff0c\u53ef\u6709\u6548\u5206\u7c7bREIMS\u6570\u636e\uff0c\u5373\u4f7f\u6807\u8bb0\u6570\u636e\u6709\u9650\uff0c\u63d0\u5347\u5b9e\u65f6\u624b\u672f\u8fb9\u7f18\u8bc4\u4f30\u3002"}}
{"id": "2504.11781", "pdf": "https://arxiv.org/pdf/2504.11781", "abs": "https://arxiv.org/abs/2504.11781", "authors": ["Guanchun Wang", "Xiangrong Zhang", "Yifei Zhang", "Zelin Peng", "Tianyang Zhang", "Xu Tang", "Licheng Jiao"], "title": "ACMamba: Fast Unsupervised Anomaly Detection via An Asymmetrical Consensus State Space Model", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "15 pages, 9 figures", "summary": "Unsupervised anomaly detection in hyperspectral images (HSI), aiming to\ndetect unknown targets from backgrounds, is challenging for earth surface\nmonitoring. However, current studies are hindered by steep computational costs\ndue to the high-dimensional property of HSI and dense sampling-based training\nparadigm, constraining their rapid deployment. Our key observation is that,\nduring training, not all samples within the same homogeneous area are\nindispensable, whereas ingenious sampling can provide a powerful substitute for\nreducing costs. Motivated by this, we propose an Asymmetrical Consensus State\nSpace Model (ACMamba) to significantly reduce computational costs without\ncompromising accuracy. Specifically, we design an asymmetrical anomaly\ndetection paradigm that utilizes region-level instances as an efficient\nalternative to dense pixel-level samples. In this paradigm, a low-cost\nMamba-based module is introduced to discover global contextual attributes of\nregions that are essential for HSI reconstruction. Additionally, we develop a\nconsensus learning strategy from the optimization perspective to simultaneously\nfacilitate background reconstruction and anomaly compression, further\nalleviating the negative impact of anomaly reconstruction. Theoretical analysis\nand extensive experiments across eight benchmarks verify the superiority of\nACMamba, demonstrating a faster speed and stronger performance over the\nstate-of-the-art.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faACMamba\u6a21\u578b\uff0c\u51cf\u5c11\u9ad8\u5149\u8c31\u56fe\u50cf\u5f02\u5e38\u68c0\u6d4b\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u9ad8\u5149\u8c31\u56fe\u50cf\u5f02\u5e38\u68c0\u6d4b\u56e0\u8ba1\u7b97\u6210\u672c\u9ad8\u800c\u90e8\u7f72\u7f13\u6162\uff0c\u672c\u6587\u901a\u8fc7\u5de7\u5999\u91c7\u6837\u7b56\u7565\u6765\u964d\u4f4e\u6210\u672c\u3002", "method": "\u63d0\u51fa\u4e0d\u5bf9\u79f0\u5171\u8bc6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08ACMamba\uff09\uff0c\u4f7f\u7528\u533a\u57df\u7ea7\u5b9e\u4f8b\u3001Mamba-based\u6a21\u5757\u548c\u5171\u8bc6\u5b66\u4e60\u7b56\u7565\u8fdb\u884c\u80cc\u666f\u91cd\u5efa\u548c\u5f02\u5e38\u538b\u7f29\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u516b\u4e2a\u57fa\u51c6\u5b9e\u9a8c\u9a8c\u8bc1\uff0cACMamba\u5728\u901f\u5ea6\u548c\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "ACMamba\u663e\u8457\u63d0\u9ad8\u4e86\u9ad8\u5149\u8c31\u56fe\u50cf\u5f02\u5e38\u68c0\u6d4b\u7684\u6548\u7387\u548c\u6548\u679c\u3002"}}
{"id": "2504.11520", "pdf": "https://arxiv.org/pdf/2504.11520", "abs": "https://arxiv.org/abs/2504.11520", "authors": ["Adam Banda", "Charanjit K. Khosa", "Veronica Sanz"], "title": "Strengthening Anomaly Awareness", "categories": ["hep-ph", "cs.LG"], "comment": "16 pages, 5 figures", "summary": "We present a refined version of the Anomaly Awareness framework for enhancing\nunsupervised anomaly detection. Our approach introduces minimal supervision\ninto Variational Autoencoders (VAEs) through a two-stage training strategy: the\nmodel is first trained in an unsupervised manner on background data, and then\nfine-tuned using a small sample of labeled anomalies to encourage larger\nreconstruction errors for anomalous samples.\n  We validate the method across diverse domains, including the MNIST dataset\nwith synthetic anomalies, network intrusion data from the CICIDS benchmark,\ncollider physics data from the LHCO2020 dataset, and simulated events from the\nStandard Model Effective Field Theory (SMEFT). The latter provides a realistic\nexample of subtle kinematic deviations in Higgs boson production. In all cases,\nthe model demonstrates improved sensitivity to unseen anomalies, achieving\nbetter separation between normal and anomalous samples. These results indicate\nthat even limited anomaly information, when incorporated through targeted\nfine-tuning, can substantially improve the generalization and performance of\nunsupervised models for anomaly detection.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684Anomaly Awareness\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u76d1\u7763\u63d0\u5347\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u5728\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u4f7f\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u3002", "motivation": "\u52a8\u673a\u662f\u6539\u8fdb\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5bf9\u672a\u89c1\u5f02\u5e38\u7684\u654f\u611f\u6027\uff0c\u901a\u8fc7\u5c11\u91cf\u6807\u8bb0\u7684\u5f02\u5e38\u6837\u672c\u589e\u5f3a\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u7b2c\u4e00\u9636\u6bb5\u65e0\u76d1\u7763\u5728\u80cc\u666f\u6570\u636e\u4e0a\u8bad\u7ec3VAE\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u5c11\u91cf\u6807\u8bb0\u7684\u5f02\u5e38\u6837\u672c\u5fae\u8c03\uff0c\u4ee5\u589e\u52a0\u5f02\u5e38\u6837\u672c\u7684\u91cd\u5efa\u9519\u8bef\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728MNIST\u3001CICIDS\u3001LHCO2020\u548cSMEFT\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u5bf9\u672a\u89c1\u5f02\u5e38\u7684\u654f\u611f\u6027\u63d0\u9ad8\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6b63\u5e38\u548c\u5f02\u5e38\u6837\u672c\u5206\u79bb\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u5373\u4f7f\u6709\u9650\u7684\u5f02\u5e38\u4fe1\u606f\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u5fae\u8c03\uff0c\u4e5f\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u65e0\u76d1\u7763\u6a21\u578b\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2504.11788", "pdf": "https://arxiv.org/pdf/2504.11788", "abs": "https://arxiv.org/abs/2504.11788", "authors": ["Zhisong Zhang", "Tianqing Fang", "Kaixin Ma", "Wenhao Yu", "Hongming Zhang", "Haitao Mi", "Dong Yu"], "title": "Enhancing Web Agents with Explicit Rollback Mechanisms", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "With recent advancements in large language models, web agents have been\ngreatly improved. However, dealing with complex and dynamic web environments\nrequires more advanced planning and search abilities. Previous studies usually\nadopt a greedy one-way search strategy, which may struggle to recover from\nerroneous states. In this work, we enhance web agents with an explicit rollback\nmechanism, enabling the agent to revert back to a previous state in its\nnavigation trajectory. This mechanism gives the model the flexibility to\ndirectly control the search process, leading to an effective and efficient web\nnavigation method. We conduct experiments on two live web navigation benchmarks\nwith zero-shot and fine-tuning settings. The results demonstrate the\neffectiveness of our proposed approach.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e26\u56de\u6eda\u673a\u5236\u7684\u7f51\u7edc\u4ee3\u7406\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u5728\u590d\u6742\u52a8\u6001\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u6b65\u63d0\u5347\u4e86\u7f51\u7edc\u4ee3\u7406\uff0c\u4f46\u8d2a\u5a6a\u5355\u5411\u641c\u7d22\u7b56\u7565\u96be\u4ee5\u4ece\u9519\u8bef\u72b6\u6001\u6062\u590d\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u5148\u8fdb\u7684\u89c4\u5212\u548c\u641c\u7d22\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u663e\u5f0f\u56de\u6eda\u673a\u5236\uff0c\u5141\u8bb8\u4ee3\u7406\u56de\u9000\u5230\u4e4b\u524d\u7684\u5bfc\u822a\u72b6\u6001\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u63a7\u5236\u641c\u7d22\u8fc7\u7a0b\u3002", "result": "\u5728\u4e24\u4e2a\u5b9e\u65f6\u7f51\u7edc\u5bfc\u822a\u57fa\u51c6\u4e0a\u8fdb\u884c\u96f6\u6837\u672c\u548c\u5fae\u8c03\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u7f51\u7edc\u5bfc\u822a\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u5347\u4e86\u4ee3\u7406\u7684\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2504.11793", "pdf": "https://arxiv.org/pdf/2504.11793", "abs": "https://arxiv.org/abs/2504.11793", "authors": ["Yue Li", "Lihong Zhang"], "title": "Selective Attention Federated Learning: Improving Privacy and Efficiency for Clinical Text Classification", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Federated Learning (FL) faces major challenges regarding communication\noverhead and model privacy when training large language models (LLMs),\nespecially in healthcare applications. To address these, we introduce Selective\nAttention Federated Learning (SAFL), a novel approach that dynamically\nfine-tunes only those transformer layers identified as attention-critical. By\nemploying attention patterns to determine layer importance, SAFL significantly\nreduces communication bandwidth and enhances differential privacy resilience.\nEvaluations on clinical NLP benchmarks (i2b2 Clinical Concept Extraction and\nMIMIC-III discharge summaries) demonstrate that SAFL achieves competitive\nperformance with centralized models while substantially improving communication\nefficiency and privacy preservation.", "AI": {"tldr": "SAFL\u901a\u8fc7\u52a8\u6001\u5fae\u8c03\u6ce8\u610f\u529b\u5173\u952etransformer\u5c42\uff0c\u51cf\u5c11\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u5f00\u9500\u548c\u63d0\u5347\u9690\u79c1\uff0c\u5728\u4e34\u5e8aNLP\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u5728\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u7684\u901a\u4fe1\u5f00\u9500\u548c\u6a21\u578b\u9690\u79c1\u6311\u6218\uff0c\u5c24\u5176\u5728\u533b\u7597\u5e94\u7528\u4e2d\u3002", "method": "\u5f15\u5165SAFL\u65b9\u6cd5\uff0c\u4f7f\u7528\u6ce8\u610f\u529b\u6a21\u5f0f\u786e\u5b9a\u5c42\u91cd\u8981\u6027\uff0c\u4ec5\u5fae\u8c03\u5173\u952etransformer\u5c42\uff0c\u51cf\u5c11\u901a\u4fe1\u5e26\u5bbd\u5e76\u589e\u5f3a\u5dee\u5206\u9690\u79c1\u3002", "result": "\u5728i2b2\u548cMIMIC-III\u4e34\u5e8aNLP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSAFL\u4e0e\u96c6\u4e2d\u5f0f\u6a21\u578b\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u901a\u4fe1\u6548\u7387\u548c\u9690\u79c1\u4fdd\u62a4\u3002", "conclusion": "SAFL\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u6539\u5584\u901a\u4fe1\u6548\u7387\u548c\u9690\u79c1\u4fdd\u5b58\uff0c\u9002\u7528\u4e8e\u533b\u7597\u9886\u57df\u7684\u8054\u90a6\u5b66\u4e60\u3002"}}
{"id": "2504.11554", "pdf": "https://arxiv.org/pdf/2504.11554", "abs": "https://arxiv.org/abs/2504.11554", "authors": ["Chengkun Li", "Bobby Huggins", "Petrus Mikkola", "Luigi Acerbi"], "title": "Normalizing Flow Regression for Bayesian Inference with Offline Likelihood Evaluations", "categories": ["stat.ML", "cs.LG"], "comment": "Accepted at the Proceedings track of the 7th Symposium on Advances in\n  Approximate Bayesian Inference (AABI 2025). 40 pages, 10 figures", "summary": "Bayesian inference with computationally expensive likelihood evaluations\nremains a significant challenge in many scientific domains. We propose\nnormalizing flow regression (NFR), a novel offline inference method for\napproximating posterior distributions. Unlike traditional surrogate approaches\nthat require additional sampling or inference steps, NFR directly yields a\ntractable posterior approximation through regression on existing log-density\nevaluations. We introduce training techniques specifically for flow regression,\nsuch as tailored priors and likelihood functions, to achieve robust posterior\nand model evidence estimation. We demonstrate NFR's effectiveness on synthetic\nbenchmarks and real-world applications from neuroscience and biology, showing\nsuperior or comparable performance to existing methods. NFR represents a\npromising approach for Bayesian inference when standard methods are\ncomputationally prohibitive or existing model evaluations can be recycled.", "AI": {"tldr": "\u63d0\u51faNFR\u65b9\u6cd5\u9ad8\u6548\u8fd1\u4f3cBayesian\u540e\u9a8c\u5206\u5e03\uff0c\u9002\u7528\u4e8e\u8ba1\u7b97\u5bc6\u96c6\u578b\u63a8\u7406\u573a\u666f\u3002", "motivation": "Bayesian\u63a8\u7406\u4e2d\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u4f3c\u7136\u8bc4\u4f30\u662f\u79d1\u5b66\u9886\u57df\u7684\u4e3b\u8981\u6311\u6218\u3002", "method": "\u5f15\u5165normalizing flow regression (NFR)\uff0c\u901a\u8fc7\u56de\u5f52\u73b0\u6709log-density\u8bc4\u4f30\u76f4\u63a5\u83b7\u5f97\u53ef\u5904\u7406\u7684\u540e\u9a8c\u8fd1\u4f3c\uff0c\u5e76\u4f18\u5316\u8bad\u7ec3\u6280\u5de7\u5982\u5b9a\u5236\u5148\u9a8c\u548c\u4f3c\u7136\u51fd\u6570\u3002", "result": "\u5728\u5408\u6210\u57fa\u51c6\u548c\u795e\u7ecf\u79d1\u5b66\u3001\u751f\u7269\u5b66\u5e94\u7528\u4e2d\uff0cNFR\u6027\u80fd\u4f18\u8d8a\u6216\u76f8\u5f53\u3002", "conclusion": "NFR\u662f\u4e3a\u8ba1\u7b97\u4e0a\u4e0d\u53ef\u884c\u6216\u53ef\u56de\u6536\u6a21\u578b\u8bc4\u4f30\u7684Bayesian\u63a8\u7406\u63d0\u4f9b\u7684\u4e00\u79cd\u6709\u524d\u666f\u65b9\u6cd5\u3002"}}
{"id": "2504.11812", "pdf": "https://arxiv.org/pdf/2504.11812", "abs": "https://arxiv.org/abs/2504.11812", "authors": ["Dikshit Chauhan", "Shivani", "P. N. Suganthan"], "title": "Learning Strategies in Particle Swarm Optimizer: A Critical Review and Performance Analysis", "categories": ["cs.NE", "cs.AI"], "comment": "53 pages, 14 figures", "summary": "Nature has long inspired the development of swarm intelligence (SI), a key\nbranch of artificial intelligence that models collective behaviors observed in\nbiological systems for solving complex optimization problems. Particle swarm\noptimization (PSO) is widely adopted among SI algorithms due to its simplicity\nand efficiency. Despite numerous learning strategies proposed to enhance PSO's\nperformance in terms of convergence speed, robustness, and adaptability, no\ncomprehensive and systematic analysis of these strategies exists. We review and\nclassify various learning strategies to address this gap, assessing their\nimpact on optimization performance. Additionally, a comparative experimental\nevaluation is conducted to examine how these strategies influence PSO's search\ndynamics. Finally, we discuss open challenges and future directions,\nemphasizing the need for self-adaptive, intelligent PSO variants capable of\naddressing increasingly complex real-world problems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5ba1\u9605\u5e76\u5206\u7c7b\u7c92\u5b50\u7fa4\u4f18\u5316\uff08PSO\uff09\u7684\u5b66\u4e60\u7b56\u7565\uff0c\u8bc4\u4f30\u5176\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u5206\u6790\u641c\u7d22\u52a8\u6001\uff0c\u5e76\u8ba8\u8bba\u672a\u6765\u6311\u6218\u3002", "motivation": "\u586b\u8865PSO\u5b66\u4e60\u7b56\u7565\u7f3a\u4e4f\u5168\u9762\u5206\u6790\u7684\u7a7a\u767d\u3002", "method": "\u5ba1\u9605\u5206\u7c7b\u7b56\u7565\u3001\u8bc4\u4f30\u5f71\u54cd\u548c\u6bd4\u8f83\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u7b56\u7565\u5bf9PSO\u641c\u7d22\u52a8\u6001\u7684\u5f71\u54cd\u3002", "conclusion": "\u5f3a\u8c03\u5f00\u53d1\u81ea\u9002\u5e94PSO\u4ee5\u5e94\u5bf9\u590d\u6742\u95ee\u9898\u3002"}}
{"id": "2504.11820", "pdf": "https://arxiv.org/pdf/2504.11820", "abs": "https://arxiv.org/abs/2504.11820", "authors": ["Delong Suzhang", "Meng Yang"], "title": "Real-World Depth Recovery via Structure Uncertainty Modeling and Inaccurate GT Depth Fitting", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The low-quality structure in raw depth maps is prevalent in real-world RGB-D\ndatasets, which makes real-world depth recovery a critical task in recent\nyears. However, the lack of paired raw-ground truth (raw-GT) data in the real\nworld poses challenges for generalized depth recovery. Existing methods\ninsufficiently consider the diversity of structure misalignment in raw depth\nmaps, which leads to poor generalization in real-world depth recovery. Notably,\nrandom structure misalignments are not limited to raw depth data but also\naffect GT depth in real-world datasets. In the proposed method, we tackle the\ngeneralization problem from both input and output perspectives. For input, we\nenrich the diversity of structure misalignment in raw depth maps by designing a\nnew raw depth generation pipeline, which helps the network avoid overfitting to\na specific condition. Furthermore, a structure uncertainty module is designed\nto explicitly identify the misaligned structure for input raw depth maps to\nbetter generalize in unseen scenarios. Notably the well-trained depth\nfoundation model (DFM) can help the structure uncertainty module estimate the\nstructure uncertainty better. For output, a robust feature alignment module is\ndesigned to precisely align with the accurate structure of RGB images avoiding\nthe interference of inaccurate GT depth. Extensive experiments on multiple\ndatasets demonstrate the proposed method achieves competitive accuracy and\ngeneralization capabilities across various challenging raw depth maps.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u6df1\u5ea6\u6062\u590d\u6cdb\u5316\u6027\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5904\u7406\u539f\u59cb\u6df1\u5ea6\u56fe\u7684\u7ed3\u6784\u5931\u8c03\uff0c\u4f7f\u7528\u65b0\u7684\u751f\u6210\u7ba1\u9053\u3001\u4e0d\u786e\u5b9a\u6027\u6a21\u5757\u548c\u7279\u5f81\u5bf9\u9f50\u6a21\u5757\u3002", "motivation": "\u539f\u59cb\u6df1\u5ea6\u56fe\u4e2d\u4f4e\u8d28\u91cf\u7ed3\u6784\u666e\u904d\u5b58\u5728\uff0c\u7f3a\u4e4f\u914d\u5bf9\u7684\u539f\u59cb-\u771f\u5b9e\u6570\u636e\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u8003\u8651\u7ed3\u6784\u5931\u8c03\u7684\u591a\u6837\u6027\uff0c\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u5dee\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65b0\u7684\u539f\u59cb\u6df1\u5ea6\u751f\u6210\u7ba1\u9053\u6765\u4e30\u5bcc\u7ed3\u6784\u5931\u8c03\u7684\u591a\u6837\u6027\uff1b\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u6784\u4e0d\u786e\u5b9a\u6027\u6a21\u5757\uff0c\u4f7f\u7528\u6df1\u5ea6\u57fa\u7840\u6a21\u578b\uff08DFM\uff09\u6765\u66f4\u597d\u5730\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\uff1b\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u9c81\u68d2\u7684\u7279\u5f81\u5bf9\u9f50\u6a21\u5757\uff0c\u4e0eRGB\u56fe\u50cf\u7cbe\u786e\u5bf9\u9f50\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u7ade\u4e89\u6027\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u6311\u6218\u6027\u7684\u539f\u59cb\u6df1\u5ea6\u56fe\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2504.11570", "pdf": "https://arxiv.org/pdf/2504.11570", "abs": "https://arxiv.org/abs/2504.11570", "authors": ["Haozhe Lei", "Ya-Ting Yang", "Tao Li", "Zilin Bian", "Fan Zuo", "Sundeep Rangan", "Kaan Ozbay"], "title": "Traffic Adaptive Moving-window Service Patrolling for Real-time Incident Management during High-impact Events", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "This paper presents the Traffic Adaptive Moving-window Patrolling Algorithm\n(TAMPA), designed to improve real-time incident management during major events\nlike sports tournaments and concerts. Such events significantly stress\ntransportation networks, requiring efficient and adaptive patrol solutions.\nTAMPA integrates predictive traffic modeling and real-time complaint\nestimation, dynamically optimizing patrol deployment. Using dynamic\nprogramming, the algorithm continuously adjusts patrol strategies within short\nplanning windows, effectively balancing immediate response and efficient\nrouting. Leveraging the Dvoretzky-Kiefer-Wolfowitz inequality, TAMPA detects\nsignificant shifts in complaint patterns, triggering proactive adjustments in\npatrol routes. Theoretical analyses ensure performance remains closely aligned\nwith optimal solutions. Simulation results from an urban traffic network\ndemonstrate TAMPA's superior performance, showing improvements of approximately\n87.5\\% over stationary methods and 114.2\\% over random strategies. Future work\nincludes enhancing adaptability and incorporating digital twin technology for\nimproved predictive accuracy, particularly relevant for events like the 2026\nFIFA World Cup at MetLife Stadium.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTAMPA\u7b97\u6cd5\uff0c\u63d0\u9ad8\u91cd\u5927\u4e8b\u4ef6\u671f\u95f4\u4ea4\u901a\u5de1\u903b\u6548\u7387\uff0c\u6a21\u62df\u7ed3\u679c\u663e\u793a\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u52a8\u673a\u662f\u6539\u5584\u4f53\u80b2\u8d5b\u4e8b\u548c\u97f3\u4e50\u4f1a\u7b49\u4e8b\u4ef6\u5bf9\u4ea4\u901a\u7f51\u7edc\u7684\u538b\u529b\uff0c\u9700\u8981\u9ad8\u6548\u81ea\u9002\u5e94\u5de1\u903b\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u65b9\u6cd5\u6574\u5408\u9884\u6d4b\u4ea4\u901a\u5efa\u6a21\u3001\u5b9e\u65f6\u6295\u8bc9\u4f30\u8ba1\uff0c\u4f7f\u7528\u52a8\u6001\u89c4\u5212\u4f18\u5316\u90e8\u7f72\uff0c\u5e76\u901a\u8fc7Dvoretzky-Kiefer-Wolfowitz\u4e0d\u7b49\u5f0f\u68c0\u6d4b\u6a21\u5f0f\u53d8\u5316\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0cTAMPA\u6bd4\u9759\u6001\u65b9\u6cd5\u6539\u558487.5%\uff0c\u6bd4\u968f\u673a\u7b56\u7565\u6539\u5584114.2%\u3002", "conclusion": "\u7ed3\u8bba\u662f\u6027\u80fd\u63a5\u8fd1\u6700\u4f18\uff0c\u672a\u6765\u5de5\u4f5c\u5305\u62ec\u589e\u5f3a\u9002\u5e94\u6027\u548c\u6574\u5408\u6570\u5b57\u5b6a\u751f\u6280\u672f\u3002"}}
{"id": "2504.11829", "pdf": "https://arxiv.org/pdf/2504.11829", "abs": "https://arxiv.org/abs/2504.11829", "authors": ["Julia Kreutzer", "Eleftheria Briakou", "Sweta Agrawal", "Marzieh Fadaee", "Kocmi Tom"], "title": "D\u00e9j\u00e0 Vu: Multilingual LLM Evaluation through the Lens of Machine Translation Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Generation capabilities and language coverage of multilingual large language\nmodels (mLLMs) are advancing rapidly. However, evaluation practices for\ngenerative abilities of mLLMs are still lacking comprehensiveness, scientific\nrigor, and consistent adoption across research labs, which undermines their\npotential to meaningfully guide mLLM development. We draw parallels with\nmachine translation (MT) evaluation, a field that faced similar challenges and\nhas, over decades, developed transparent reporting standards and reliable\nevaluations for multilingual generative models. Through targeted experiments\nacross key stages of the generative evaluation pipeline, we demonstrate how\nbest practices from MT evaluation can deepen the understanding of quality\ndifferences between models. Additionally, we identify essential components for\nrobust meta-evaluation of mLLMs, ensuring the evaluation methods themselves are\nrigorously assessed. We distill these insights into a checklist of actionable\nrecommendations for mLLM research and development.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u501f\u9274\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u6539\u8fdb\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u884c\u52a8\u5efa\u8bae\u3002", "motivation": "\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u80fd\u529b\u548c\u8bed\u8a00\u8986\u76d6\u7387\u5feb\u901f\u8fdb\u6b65\uff0c\u4f46\u8bc4\u4f30\u5b9e\u8df5\u7f3a\u4e4f\u5168\u9762\u6027\u3001\u79d1\u5b66\u6027\u548c\u4e00\u81f4\u6027\uff0c\u9700\u8981\u501f\u9274\u6210\u719f\u9886\u57df\u7ecf\u9a8c\u6765\u63d0\u5347\u3002", "method": "\u901a\u8fc7\u9488\u5bf9\u751f\u6210\u8bc4\u4f30\u7ba1\u9053\u5173\u952e\u9636\u6bb5\u7684\u5b9e\u9a8c\uff0c\u501f\u9274\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u7684\u900f\u660e\u62a5\u544a\u6807\u51c6\u548c\u53ef\u9760\u65b9\u6cd5\u3002", "result": "\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u8fd9\u4e9b\u6700\u4f73\u5b9e\u8df5\u52a0\u6df1\u5bf9\u6a21\u578b\u8d28\u91cf\u5dee\u5f02\u7684\u7406\u89e3\uff0c\u5e76\u8bc6\u522b\u4e86\u7528\u4e8emLLM\u7a33\u5065\u5143\u8bc4\u4f30\u7684\u57fa\u672c\u7ec4\u4ef6\u3002", "conclusion": "\u63d0\u70bc\u89c1\u89e3\u6210\u4e00\u4e2a\u53ef\u64cd\u4f5c\u7684\u63a8\u8350\u6e05\u5355\uff0c\u4ee5\u6307\u5bfcmLLM\u7684\u7814\u7a76\u548c\u5f00\u53d1\u3002"}}
{"id": "2504.11837", "pdf": "https://arxiv.org/pdf/2504.11837", "abs": "https://arxiv.org/abs/2504.11837", "authors": ["Yue Zhao", "Qingqing Gu", "Xiaoyu Wang", "Teng Chen", "Zhonglin Jiang", "Yong Chen", "Luo Ji"], "title": "FiSMiness: A Finite State Machine Based Paradigm for Emotional Support Conversations", "categories": ["cs.CL", "cs.AI"], "comment": "accepted by CMCL", "summary": "Emotional support conversation (ESC) aims to alleviate the emotional distress\nof individuals through effective conversations. Although large language models\n(LLMs) have obtained remarkable progress on ESC, most of these studies might\nnot define the diagram from the state model perspective, therefore providing a\nsuboptimal solution for long-term satisfaction. To address such an issue, we\nleverage the Finite State Machine (FSM) on LLMs, and propose a framework called\nFiSMiness. Our framework allows a single LLM to bootstrap the planning during\nESC, and self-reason the seeker's emotion, support strategy and the final\nresponse upon each conversational turn. Substantial experiments on ESC datasets\nsuggest that FiSMiness outperforms many baselines, including direct inference,\nself-refine, chain of thought, finetuning, and external-assisted methods, even\nthose with many more parameters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFiSMiness\u6846\u67b6\uff0c\u4f7f\u7528\u6709\u9650\u72b6\u6001\u673a\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u591a\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u4e2d\u53ef\u80fd\u672a\u4ece\u72b6\u6001\u6a21\u578b\u89c6\u89d2\u5b9a\u4e49\u6d41\u7a0b\uff0c\u5bfc\u81f4\u957f\u671f\u6ee1\u610f\u5ea6\u4e0d\u4f73\u3002", "method": "\u5229\u7528\u6709\u9650\u72b6\u6001\u673a\uff08FSM\uff09\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\uff0c\u63d0\u51faFiSMiness\u6846\u67b6\uff0c\u4f7fLLM\u5728\u5bf9\u8bdd\u4e2d\u81ea\u6211\u89c4\u5212\u548c\u63a8\u7406\u60c5\u7eea\u3001\u652f\u6301\u7b56\u7565\u53ca\u54cd\u5e94\u3002", "result": "\u5b9e\u9a8c\u663e\u793aFiSMiness\u5728\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u76f4\u63a5\u63a8\u7406\u3001\u81ea\u6211\u4f18\u5316\u3001\u601d\u7ef4\u94fe\u3001\u5fae\u8c03\u548c\u5916\u90e8\u8f85\u52a9\u65b9\u6cd5\uff0c\u751a\u81f3\u53c2\u6570\u66f4\u5927\u7684\u6a21\u578b\u3002", "conclusion": "\u4f7f\u7528FSM\u589e\u5f3aLLM\u53ef\u663e\u8457\u63d0\u5347\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u7684\u957f\u671f\u6548\u679c\u548c\u6027\u80fd\u3002"}}
{"id": "2504.11855", "pdf": "https://arxiv.org/pdf/2504.11855", "abs": "https://arxiv.org/abs/2504.11855", "authors": ["Etienne Guichard", "Felix Reimers", "Mia Kvalsund", "Mikkel Lepper\u00f8d", "Stefano Nichele"], "title": "EngramNCA: a Neural Cellular Automaton Model of Memory Transfer", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "This study introduces EngramNCA, a neural cellular automaton (NCA) that\nintegrates both publicly visible states and private, cell-internal memory\nchannels, drawing inspiration from emerging biological evidence suggesting that\nmemory storage extends beyond synaptic modifications to include intracellular\nmechanisms. The proposed model comprises two components: GeneCA, an NCA trained\nto develop distinct morphologies from seed cells containing immutable \"gene\"\nencodings, and GenePropCA, an auxiliary NCA that modulates the private\n\"genetic\" memory of cells without altering their visible states. This\narchitecture enables the encoding and propagation of complex morphologies\nthrough the interaction of visible and private channels, facilitating the\ngrowth of diverse structures from a shared \"genetic\" substrate. EngramNCA\nsupports the emergence of hierarchical and coexisting morphologies, offering\ninsights into decentralized memory storage and transfer in artificial systems.\nThese findings have potential implications for the development of adaptive,\nself-organizing systems and may contribute to the broader understanding of\nmemory mechanisms in both biological and synthetic contexts.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u5f15\u5165\u4e86EngramNCA\uff0c\u4e00\u4e2a\u6574\u5408\u4e86\u516c\u5f00\u53ef\u89c1\u72b6\u6001\u548c\u79c1\u6709\u5185\u90e8\u8bb0\u5fc6\u901a\u9053\u7684\u795e\u7ecf\u5143\u7ec6\u80de\u81ea\u52a8\u673a\uff0c\u7075\u611f\u6765\u6e90\u4e8e\u751f\u7269\u5b66\u8bc1\u636e\uff0c\u652f\u6301\u590d\u6742\u5f62\u6001\u7684\u751f\u957f\u548c\u5bf9\u8bb0\u5fc6\u673a\u5236\u7684\u7406\u89e3\u3002", "motivation": "\u53d7\u751f\u7269\u5b66\u8bc1\u636e\u542f\u53d1\uff0c\u8868\u660e\u8bb0\u5fc6\u5b58\u50a8\u4e0d\u4ec5\u9650\u4e8e\u7a81\u89e6\u6539\u53d8\uff0c\u8fd8\u5305\u62ec\u7ec6\u80de\u5185\u673a\u5236\uff0c\u65e8\u5728\u63a2\u7d22\u4eba\u5de5\u7cfb\u7edf\u4e2d\u53bb\u4e2d\u5fc3\u5316\u7684\u8bb0\u5fc6\u5b58\u50a8\u3002", "method": "\u63d0\u51faEngramNCA\u6a21\u578b\uff0c\u5305\u62ecGeneCA\uff08\u4ece\u79cd\u5b50\u7ec6\u80de\u53d1\u5c55\u4e0d\u540c\u5f62\u6001\uff09\u548cGenePropCA\uff08\u8c03\u8282\u79c1\u6709\u9057\u4f20\u8bb0\u5fc6\u800c\u4e0d\u6539\u53d8\u53ef\u89c1\u72b6\u6001\uff09\u3002", "result": "\u5b9e\u73b0\u4e86\u590d\u6742\u5f62\u6001\u7684\u7f16\u7801\u548c\u4f20\u64ad\uff0c\u652f\u6301\u5206\u5c42\u548c\u5171\u5b58\u5f62\u6001\u7684\u51fa\u73b0\uff0c\u4e3a\u4eba\u5de5\u7cfb\u7edf\u7684\u8bb0\u5fc6\u5b58\u50a8\u63d0\u4f9b\u6d1e\u89c1\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u5f00\u53d1\u9002\u5e94\u6027\u81ea\u7ec4\u7ec7\u7cfb\u7edf\u6709\u6f5c\u5728\u5f71\u54cd\uff0c\u5e76\u6709\u52a9\u4e8e\u7406\u89e3\u751f\u7269\u548c\u5408\u6210\u4e0a\u4e0b\u6587\u4e2d\u7684\u8bb0\u5fc6\u673a\u5236\u3002"}}
{"id": "2504.11610", "pdf": "https://arxiv.org/pdf/2504.11610", "abs": "https://arxiv.org/abs/2504.11610", "authors": ["Tianjian Yang", "Wei Vivian Li"], "title": "Generalized probabilistic canonical correlation analysis for multi-modal data integration with full or partial observations", "categories": ["stat.ML", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Background: The integration and analysis of multi-modal data are increasingly\nessential across various domains including bioinformatics. As the volume and\ncomplexity of such data grow, there is a pressing need for computational models\nthat not only integrate diverse modalities but also leverage their\ncomplementary information to improve clustering accuracy and insights,\nespecially when dealing with partial observations with missing data. Results:\nWe propose Generalized Probabilistic Canonical Correlation Analysis (GPCCA), an\nunsupervised method for the integration and joint dimensionality reduction of\nmulti-modal data. GPCCA addresses key challenges in multi-modal data analysis\nby handling missing values within the model, enabling the integration of more\nthan two modalities, and identifying informative features while accounting for\ncorrelations within individual modalities. The model demonstrates robustness to\nvarious missing data patterns and provides low-dimensional embeddings that\nfacilitate downstream clustering and analysis. In a range of simulation\nsettings, GPCCA outperforms existing methods in capturing essential patterns\nacross modalities. Additionally, we demonstrate its applicability to\nmulti-omics data from TCGA cancer datasets and a multi-view image dataset.\nConclusion: GPCCA offers a useful framework for multi-modal data integration,\neffectively handling missing data and providing informative low-dimensional\nembeddings. Its performance across cancer genomics and multi-view image data\nhighlights its robustness and potential for broad application. To make the\nmethod accessible to the wider research community, we have released an R\npackage, GPCCA, which is available at https://github.com/Kaversoniano/GPCCA.", "AI": {"tldr": "GPCCA \u662f\u4e00\u79cd\u5904\u7406\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u80fd\u5e94\u5bf9\u7f3a\u5931\u503c\u5e76\u63d0\u5347\u805a\u7c7b\u6027\u80fd\u3002", "motivation": "\u591a\u6a21\u6001\u6570\u636e\u91cf\u589e\u5927\uff0c\u5c24\u5176\u5728\u751f\u7269\u4fe1\u606f\u5b66\u9886\u57df\uff0c\u9700\u8981\u6a21\u578b\u6574\u5408\u4e0d\u540c\u6a21\u6001\u3001\u5904\u7406\u7f3a\u5931\u503c\u5e76\u63d0\u9ad8\u805a\u7c7b\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa GPCCA \u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u6570\u636e\u7684\u6574\u5408\u548c\u964d\u7ef4\uff0c\u5904\u7406\u7f3a\u5931\u503c\u3001\u652f\u6301\u591a\u4e2a\u6a21\u6001\u5e76\u8003\u8651\u5185\u90e8\u76f8\u5173\u6027\u3002", "result": "GPCCA \u5bf9\u7f3a\u5931\u6570\u636e\u6a21\u5f0f\u9c81\u68d2\uff0c\u63d0\u4f9b\u4f4e\u7ef4\u5d4c\u5165\uff0c\u6a21\u62df\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5e94\u7528\u4e8e TCGA \u764c\u75c7\u548c\u591a\u89c6\u56fe\u56fe\u50cf\u6570\u636e\u96c6\u3002", "conclusion": "GPCCA \u63d0\u4f9b\u6709\u6548\u6846\u67b6\u5904\u7406\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u548c\u7f3a\u5931\u503c\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u53d1\u5e03 R \u5305\u4ee5\u4fbf\u4f7f\u7528\u3002"}}
{"id": "2504.11896", "pdf": "https://arxiv.org/pdf/2504.11896", "abs": "https://arxiv.org/abs/2504.11896", "authors": ["Xingxing Yang", "Jie Chen", "Zaifeng Yang"], "title": "Learning Physics-Informed Color-Aware Transforms for Low-Light Image Enhancement", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ICME 2025", "summary": "Image decomposition offers deep insights into the imaging factors of visual\ndata and significantly enhances various advanced computer vision tasks. In this\nwork, we introduce a novel approach to low-light image enhancement based on\ndecomposed physics-informed priors. Existing methods that directly map\nlow-light to normal-light images in the sRGB color space suffer from\ninconsistent color predictions and high sensitivity to spectral power\ndistribution (SPD) variations, resulting in unstable performance under diverse\nlighting conditions. To address these challenges, we introduce a\nPhysics-informed Color-aware Transform (PiCat), a learning-based framework that\nconverts low-light images from the sRGB color space into deep\nillumination-invariant descriptors via our proposed Color-aware Transform\n(CAT). This transformation enables robust handling of complex lighting and SPD\nvariations. Complementing this, we propose the Content-Noise Decomposition\nNetwork (CNDN), which refines the descriptor distributions to better align with\nwell-lit conditions by mitigating noise and other distortions, thereby\neffectively restoring content representations to low-light images. The CAT and\nthe CNDN collectively act as a physical prior, guiding the transformation\nprocess from low-light to normal-light domains. Our proposed PiCat framework\ndemonstrates superior performance compared to state-of-the-art methods across\nfive benchmark datasets.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u89e3\u7684\u7269\u7406\u4fe1\u606f\u5148\u9a8c\u7684\u4f4e\u5149\u7167\u56fe\u50cf\u589e\u5f3a\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u989c\u8272\u611f\u77e5\u53d8\u6362\u548c\u5185\u5bb9-\u566a\u58f0\u5206\u89e3\u7f51\u7edc\u5904\u7406\u7167\u660e\u53d8\u5316\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728sRGB\u989c\u8272\u7a7a\u95f4\u76f4\u63a5\u6620\u5c04\u4f4e\u5149\u7167\u56fe\u50cf\u65f6\uff0c\u5b58\u5728\u989c\u8272\u9884\u6d4b\u4e0d\u4e00\u81f4\u548c\u5bf9\u5149\u8c31\u529f\u7387\u5206\u5e03\u53d8\u5316\u9ad8\u5ea6\u654f\u611f\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u7a33\u5b9a\u3002", "method": "\u5f15\u5165PiCat\u6846\u67b6\uff0c\u5305\u62ec\u989c\u8272\u611f\u77e5\u53d8\u6362\uff08CAT\uff09\u5c06\u56fe\u50cf\u8f6c\u6362\u4e3a\u7167\u660e\u4e0d\u53d8\u63cf\u8ff0\u7b26\uff0c\u4ee5\u53ca\u5185\u5bb9-\u566a\u58f0\u5206\u89e3\u7f51\u7edc\uff08CNDN\uff09\u51cf\u5c11\u566a\u58f0\uff0c\u5171\u540c\u4f5c\u4e3a\u7269\u7406\u5148\u9a8c\u6307\u5bfc\u53d8\u6362\u8fc7\u7a0b\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u7167\u660e\u548c\u5149\u8c31\u53d8\u5316\u7684\u6311\u6218\uff0c\u63d0\u9ad8\u4e86\u4f4e\u5149\u7167\u56fe\u50cf\u589e\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u6548\u679c\u3002"}}
{"id": "2504.11621", "pdf": "https://arxiv.org/pdf/2504.11621", "abs": "https://arxiv.org/abs/2504.11621", "authors": ["Samin Aref", "Sanchaai Mathiyarasan"], "title": "Robust Markov stability for community detection at a scale learned based on the structure", "categories": ["cs.SI", "cond-mat.stat-mech", "cs.LG", "90C90, 90C10, 90C57, 90C59, 90C35, 05C15, 65K05", "I.2.6; G.2.2"], "comment": "This is the author copy of an article accepted for publication by\n  ACM. The publisher's verified version and full citation details are available\n  on the ACM website", "summary": "Community detection, the unsupervised task of clustering nodes of a graph,\nfinds applications across various fields. The common approaches for community\ndetection involve optimizing an objective function to partition the nodes into\ncommunities at a single scale of granularity. However, the single-scale\napproaches often fall short of producing partitions that are robust and at a\nsuitable scale. The existing algorithm, PyGenStability, returns multiple robust\npartitions for a network by optimizing the multi-scale Markov stability\nfunction. However, in cases where the suitable scale is not known or assumed by\nthe user, there is no principled method to select a single robust partition at\na suitable scale from the multiple partitions that PyGenStability produces. Our\nproposed method combines the Markov stability framework with a pre-trained\nmachine learning model for scale selection to obtain one robust partition at a\nscale that is learned based on the graph structure. This automatic scale\nselection involves using a gradient boosting model pre-trained on hand-crafted\nand embedding-based network features from a labeled dataset of 10k benchmark\nnetworks. This model was trained to predicts the scale value that maximizes the\nsimilarity of the output partition to the planted partition of the benchmark\nnetwork. Combining our scale selection algorithm with the PyGenStability\nalgorithm results in PyGenStabilityOne (PO): a hyperparameter-free multi-scale\ncommunity detection algorithm that returns one robust partition at a suitable\nscale without the need for any assumptions, input, or tweaking from the user.\nWe compare the performance of PO against 29 algorithms and show that it\noutperforms 25 other algorithms by statistically meaningful margins. Our\nresults facilitate choosing between community detection algorithms, among which\nPO stands out as the accurate, robust, and hyperparameter-free method.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faPyGenStabilityOne\uff08PO\uff09\u7b97\u6cd5\uff0c\u5b83\u662f\u4e00\u79cd\u65e0\u8d85\u53c2\u6570\u7684\u591a\u5c3a\u5ea6\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\uff0c\u80fd\u591f\u81ea\u52a8\u9009\u62e9\u5408\u9002\u7684\u89c4\u6a21\u5e76\u8fd4\u56de\u4e00\u4e2a\u7a33\u5065\u7684\u5206\u533a\u3002", "motivation": "\u73b0\u6709\u7684\u793e\u533a\u68c0\u6d4b\u65b9\u6cd5\u5728\u89c4\u6a21\u9009\u62e9\u4e0a\u5b58\u5728\u95ee\u9898\uff0cPyGenStability\u867d\u80fd\u4ea7\u751f\u591a\u4e2a\u7a33\u5065\u5206\u533a\uff0c\u4f46\u7f3a\u4e4f\u81ea\u52a8\u9009\u62e9\u5408\u9002\u89c4\u6a21\u7684\u539f\u7406\u65b9\u6cd5\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u81ea\u52a8\u89c4\u6a21\u9009\u62e9\u673a\u5236\u3002", "method": "\u7ed3\u5408Markov\u7a33\u5b9a\u6027\u6846\u67b6\u4e0e\u9884\u8bad\u7ec3\u7684\u68af\u5ea6\u63d0\u5347\u6a21\u578b\uff0c\u4f7f\u7528\u57fa\u51c6\u7f51\u7edc\u7684\u624b\u5de5\u7279\u5f81\u548c\u5d4c\u5165\u7279\u5f81\u8bad\u7ec3\u6a21\u578b\u9884\u6d4b\u6700\u4f73\u89c4\u6a21\uff0c\u5e76\u4e0ePyGenStability\u7b97\u6cd5\u6574\u5408\u5f62\u6210PO\u7b97\u6cd5\u3002", "result": "PO\u7b97\u6cd5\u4e0e\u5176\u4ed629\u4e2a\u7b97\u6cd5\u6bd4\u8f83\uff0c\u4f18\u4e8e25\u4e2a\u7b97\u6cd5\uff0c\u5177\u6709\u7edf\u8ba1\u5b66\u610f\u4e49\u4e0a\u7684\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "PO\u7b97\u6cd5\u4f5c\u4e3a\u4e00\u79cd\u51c6\u786e\u3001\u7a33\u5065\u4e14\u65e0\u8d85\u53c2\u6570\u7684\u793e\u533a\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4fbf\u4e8e\u7b97\u6cd5\u9009\u62e9\u3002"}}
{"id": "2504.11901", "pdf": "https://arxiv.org/pdf/2504.11901", "abs": "https://arxiv.org/abs/2504.11901", "authors": ["Luca Castri", "Gloria Beraldo", "Nicola Bellotto"], "title": "Causality-enhanced Decision-Making for Autonomous Mobile Robots in Dynamic Environments", "categories": ["cs.RO", "cs.AI"], "comment": "Under review at The International Journal of Robotics Research (IJRR)", "summary": "The growing integration of robots in shared environments -- such as\nwarehouses, shopping centres, and hospitals -- demands a deep understanding of\nthe underlying dynamics and human behaviours, including how, when, and where\nindividuals engage in various activities and interactions. This knowledge goes\nbeyond simple correlation studies and requires a more comprehensive causal\nanalysis. By leveraging causal inference to model cause-and-effect\nrelationships, we can better anticipate critical environmental factors and\nenable autonomous robots to plan and execute tasks more effectively. To this\nend, we propose a novel causality-based decision-making framework that reasons\nover a learned causal model to predict battery usage and human obstructions,\nunderstanding how these factors could influence robot task execution. Such\nreasoning framework assists the robot in deciding when and how to complete a\ngiven task. To achieve this, we developed also PeopleFlow, a new Gazebo-based\nsimulator designed to model context-sensitive human-robot spatial interactions\nin shared workspaces. PeopleFlow features realistic human and robot\ntrajectories influenced by contextual factors such as time, environment layout,\nand robot state, and can simulate a large number of agents. While the simulator\nis general-purpose, in this paper we focus on a warehouse-like environment as a\ncase study, where we conduct an extensive evaluation benchmarking our causal\napproach against a non-causal baseline. Our findings demonstrate the efficacy\nof the proposed solutions, highlighting how causal reasoning enables autonomous\nrobots to operate more efficiently and safely in dynamic environments shared\nwith humans.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u56e0\u679c\u63a8\u7406\u7684\u51b3\u7b56\u6846\u67b6\uff0c\u5e2e\u52a9\u673a\u5668\u4eba\u66f4\u597d\u5730\u5904\u7406\u4e0e\u4eba\u7c7b\u5171\u4eab\u7684\u73af\u5883\uff0c\u5e76\u5f00\u53d1\u4e86PeopleFlow\u6a21\u62df\u5668\u3002", "motivation": "\u673a\u5668\u4eba\u65e5\u76ca\u878d\u5165\u5171\u4eab\u73af\u5883\uff08\u5982\u4ed3\u5e93\u3001\u533b\u9662\uff09\uff0c\u9700\u8981\u901a\u8fc7\u56e0\u679c\u5206\u6790\u6df1\u5165\u7406\u89e3\u4eba\u7c7b\u884c\u4e3a\u548c\u73af\u5883\u52a8\u6001\uff0c\u4ee5\u63d0\u5347\u673a\u5668\u4eba\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u56e0\u679c\u6a21\u578b\u51b3\u7b56\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u7535\u6c60\u4f7f\u7528\u548c\u4eba\u7c7b\u969c\u788d\uff0c\u5e76\u5f00\u53d1PeopleFlow\u6a21\u62df\u5668\u6a21\u62df\u4eba\u7c7b-\u673a\u5668\u4eba\u4ea4\u4e92\u3002", "result": "\u5728\u4ed3\u5e93\u73af\u5883\u4e2d\uff0c\u8bc4\u4f30\u663e\u793a\u56e0\u679c\u65b9\u6cd5\u6bd4\u975e\u56e0\u679c\u57fa\u7ebf\u66f4\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u6548\u7387\u548c\u5b89\u5168\u6027\u3002", "conclusion": "\u56e0\u679c\u63a8\u7406\u4f7f\u81ea\u4e3b\u673a\u5668\u4eba\u80fd\u591f\u5728\u52a8\u6001\u4eba\u7c7b\u5171\u4eab\u73af\u5883\u4e2d\u66f4\u6709\u6548\u5730\u548c\u5b89\u5168\u5730\u6267\u884c\u4efb\u52a1\u3002"}}
{"id": "2504.11667", "pdf": "https://arxiv.org/pdf/2504.11667", "abs": "https://arxiv.org/abs/2504.11667", "authors": ["Cemil Vahapoglu", "Timothy J. O'Shea", "Wan Liu", "Tamoghna Roy", "Sennur Ulukus"], "title": "Transformer-Driven Neural Beamforming with Imperfect CSI in Urban Macro Wireless Channels", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "comment": null, "summary": "The literature is abundant with methodologies focusing on using transformer\narchitectures due to their prominence in wireless signal processing and their\ncapability to capture long-range dependencies via attention mechanisms. In\nparticular, depthwise separable convolutions enhance parameter efficiency for\nthe process of high-dimensional data characteristics of MIMO systems. In this\nwork, we introduce a novel unsupervised deep learning framework that integrates\ndepthwise separable convolutions and transformers to generate beamforming\nweights under imperfect channel state information (CSI) for a multi-user\nsingle-input multiple-output (MU-SIMO) system in dense urban environments. The\nprimary goal is to enhance throughput by maximizing sum-rate while ensuring\nreliable communication. Spectral efficiency and block error rate (BLER) are\nconsidered as performance metrics. Experiments are carried out under various\nconditions to compare the performance of the proposed NNBF framework against\nbaseline methods zero-forcing beamforming (ZFBF) and minimum mean square error\n(MMSE) beamforming. Experimental results demonstrate the superiority of the\nproposed framework over the baseline techniques.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u65e0\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u548cTransformer\uff0c\u7528\u4e8e\u5728\u4e0d\u5b8c\u7f8eCSI\u6761\u4ef6\u4e0b\u751f\u6210MU-SIMO\u7cfb\u7edf\u7684\u6ce2\u675f\u5f62\u6210\u6743\u91cd\uff0c\u5e76\u5c55\u793a\u4e86\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u4e2d\u5145\u65a5\u7740\u4f7f\u7528Transformer\u67b6\u6784\u7684\u65b9\u6cd5\uff0c\u56e0\u4e3a\u5b83\u4eec\u5728\u65e0\u7ebf\u4fe1\u53f7\u5904\u7406\u4e2d\u7a81\u51fa\uff0c\u5e76\u80fd\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u6355\u83b7\u957f\u7a0b\u4f9d\u8d56\u3002\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u63d0\u9ad8\u4e86\u53c2\u6570\u6548\u7387\uff0c\u9002\u7528\u4e8eMIMO\u7cfb\u7edf\u7684\u9ad8\u7ef4\u6570\u636e\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6700\u5927\u5316\u603b\u901f\u7387\u6765\u63d0\u9ad8\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u541e\u5410\u91cf\uff0c\u540c\u65f6\u786e\u4fdd\u53ef\u9760\u901a\u4fe1\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u65e0\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u548cTransformer\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u5728\u4e0d\u5b8c\u7f8e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff08CSI\uff09\u4e0b\u4e3a\u591a\u7528\u6237\u5355\u8f93\u5165\u591a\u8f93\u51fa\uff08MU-SIMO\uff09\u7cfb\u7edf\u751f\u6210\u6ce2\u675f\u5f62\u6210\u6743\u91cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u6846\u67b6\u5728\u5149\u8c31\u6548\u7387\u548c\u5757\u9519\u8bef\u7387\uff08BLER\uff09\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u96f6\u5f3a\u8feb\u6ce2\u675f\u5f62\u6210\uff08ZFBF\uff09\u548c\u6700\u5c0f\u5747\u65b9\u8bef\u5dee\uff08MMSE\uff09\u6ce2\u675f\u5f62\u6210\u3002", "conclusion": "\u6240\u63d0\u51fa\u6846\u67b6\u901a\u8fc7\u6700\u5927\u5316\u603b\u901f\u7387\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\uff0c\u5e76\u786e\u4fdd\u4e86\u53ef\u9760\u901a\u4fe1\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2504.11952", "pdf": "https://arxiv.org/pdf/2504.11952", "abs": "https://arxiv.org/abs/2504.11952", "authors": ["Ram Mohan Rao Kadiyala", "Siddartha Pullakhandam", "Kanwal Mehreen", "Drishti Sharma", "Siddhant Gupta", "Jebish Purbey", "Ashay Srivastava", "Subhasya TippaReddy", "Arvind Reddy Bobbili", "Suraj Telugara Chandrashekhar", "Modabbir Adeeb", "Srinadh Vura", "Hamza Farooq"], "title": "Robust and Fine-Grained Detection of AI Generated Texts", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ACL 2025 Feb ARR Submission", "summary": "An ideal detection system for machine generated content is supposed to work\nwell on any generator as many more advanced LLMs come into existence day by\nday. Existing systems often struggle with accurately identifying AI-generated\ncontent over shorter texts. Further, not all texts might be entirely authored\nby a human or LLM, hence we focused more over partial cases i.e human-LLM\nco-authored texts. Our paper introduces a set of models built for the task of\ntoken classification which are trained on an extensive collection of\nhuman-machine co-authored texts, which performed well over texts of unseen\ndomains, unseen generators, texts by non-native speakers and those with\nadversarial inputs. We also introduce a new dataset of over 2.4M such texts\nmostly co-authored by several popular proprietary LLMs over 23 languages. We\nalso present findings of our models' performance over each texts of each domain\nand generator. Additional findings include comparison of performance against\neach adversarial method, length of input texts and characteristics of generated\ntexts compared to the original human authored texts.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165\u4e86\u65b0\u7684\u6807\u8bb0\u5206\u7c7b\u6a21\u578b\u548c\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u68c0\u6d4b\u4eba\u7c7b\u4e0eAI\u5171\u540c\u7f16\u5199\u7684\u6587\u672c\uff0c\u6a21\u578b\u5728\u5404\u79cd\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u68c0\u6d4b\u7cfb\u7edf\u5728\u77ed\u6587\u672c\u548c\u90e8\u5206AI\u751f\u6210\u5185\u5bb9\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u5904\u7406\u5404\u79cd\u751f\u6210\u5668\u3001\u672a\u89c1\u9886\u57df\u548c\u5bf9\u6297\u8f93\u5165\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u6807\u8bb0\u5206\u7c7b\u7684\u6a21\u578b\uff0c\u8bad\u7ec3\u4e8e\u5927\u89c4\u6a21\u7684\u4eba\u673a\u5171\u540c\u7f16\u5199\u6587\u672c\u6570\u636e\u96c6\uff1b\u5e76\u53d1\u5e03\u4e86\u4e00\u4e2a\u5305\u542b240\u4e07\u6587\u672c\u7684\u65b0\u6570\u636e\u96c6\uff0c\u8986\u76d623\u79cd\u8bed\u8a00\u3002", "result": "\u6a21\u578b\u5728\u672a\u89c1\u9886\u57df\u3001\u751f\u6210\u5668\u3001\u975e\u6bcd\u8bed\u6587\u672c\u548c\u5bf9\u6297\u8f93\u5165\u4e0a\u6027\u80fd\u826f\u597d\uff1b\u6bd4\u8f83\u4e86\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\uff0c\u5305\u62ec\u9886\u57df\u3001\u751f\u6210\u5668\u3001\u5bf9\u6297\u65b9\u6cd5\u3001\u6587\u672c\u957f\u5ea6\u548c\u6587\u672c\u7279\u5f81\u3002", "conclusion": "\u65b0\u6a21\u578b\u548c\u6570\u636e\u96c6\u63d0\u9ad8\u4e86AI\u751f\u6210\u5185\u5bb9\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u573a\u666f\u3002"}}
{"id": "2504.11967", "pdf": "https://arxiv.org/pdf/2504.11967", "abs": "https://arxiv.org/abs/2504.11967", "authors": ["Yifei Dong", "Fengyi Wu", "Sanjian Zhang", "Guangyu Chen", "Yuzhi Hu", "Masumi Yano", "Jingdong Sun", "Siyu Huang", "Feng Liu", "Qi Dai", "Zhi-Qi Cheng"], "title": "Securing the Skies: A Comprehensive Survey on Anti-UAV Methods, Benchmarking, and Future Directions", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "Accepted at CVPR Workshop Anti-UAV 2025. 15 pages", "summary": "Unmanned Aerial Vehicles (UAVs) are indispensable for infrastructure\ninspection, surveillance, and related tasks, yet they also introduce critical\nsecurity challenges. This survey provides a wide-ranging examination of the\nanti-UAV domain, centering on three core objectives-classification, detection,\nand tracking-while detailing emerging methodologies such as diffusion-based\ndata synthesis, multi-modal fusion, vision-language modeling, self-supervised\nlearning, and reinforcement learning. We systematically evaluate\nstate-of-the-art solutions across both single-modality and multi-sensor\npipelines (spanning RGB, infrared, audio, radar, and RF) and discuss\nlarge-scale as well as adversarially oriented benchmarks. Our analysis reveals\npersistent gaps in real-time performance, stealth detection, and swarm-based\nscenarios, underscoring pressing needs for robust, adaptive anti-UAV systems.\nBy highlighting open research directions, we aim to foster innovation and guide\nthe development of next-generation defense strategies in an era marked by the\nextensive use of UAVs.", "AI": {"tldr": "\u672c\u6587\u8c03\u67e5\u53cd\u65e0\u4eba\u673a\u6280\u672f\uff0c\u7126\u70b9\u5728\u5206\u7c7b\u3001\u68c0\u6d4b\u548c\u8ddf\u8e2a\uff0c\u8bc4\u4f30\u65b0\u5174\u65b9\u6cd5\u548c\u57fa\u51c6\uff0c\u6307\u51fa\u6027\u80fd\u5dee\u8ddd\u5e76\u5efa\u8bae\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u65e0\u4eba\u673a\u5728\u57fa\u7840\u8bbe\u65bd\u68c0\u67e5\u548c\u76d1\u89c6\u4e2d\u7684\u91cd\u8981\u6027\u53ca\u5176\u5b89\u5168\u6311\u6218\uff0c\u9700\u5f00\u53d1\u53cd\u65e0\u4eba\u673a\u7cfb\u7edf\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u5206\u7c7b\u3001\u68c0\u6d4b\u548c\u8ddf\u8e2a\uff0c\u4f7f\u7528\u6269\u6563\u57fa\u6570\u636e\u5408\u6210\u3001\u591a\u6a21\u6001\u878d\u5408\u7b49\u65b9\u6cd5\uff0c\u8de8RGB\u3001\u7ea2\u5916\u3001\u97f3\u9891\u3001\u96f7\u8fbe\u548cRF\u4f20\u611f\u5668\u7ba1\u9053\u3002", "result": "\u53d1\u73b0\u5b9e\u65f6\u6027\u80fd\u3001\u9690\u853d\u68c0\u6d4b\u548c\u7fa4\u96c6\u573a\u666f\u4e2d\u7684\u6301\u4e45\u5dee\u8ddd\u3002", "conclusion": "\u5f3a\u8c03\u9700\u8981\u9c81\u68d2\u7684\u81ea\u9002\u5e94\u7cfb\u7edf\uff0c\u5e76\u6307\u5bfc\u521b\u65b0\u9632\u5fa1\u7b56\u7565\u7684\u53d1\u5c55\u3002"}}
{"id": "2504.11714", "pdf": "https://arxiv.org/pdf/2504.11714", "abs": "https://arxiv.org/abs/2504.11714", "authors": ["Karthik Shivashankar", "Antonio Martini"], "title": "Unravelling Technical debt topics through Time, Programming Languages and Repository", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "This study explores the dynamic landscape of Technical Debt (TD) topics in\nsoftware engineering by examining its evolution across time, programming\nlanguages, and repositories. Despite the extensive research on identifying and\nquantifying TD, there remains a significant gap in understanding the diversity\nof TD topics and their temporal development. To address this, we have conducted\nan explorative analysis of TD data extracted from GitHub issues spanning from\n2015 to September 2023. We employed BERTopic for sophisticated topic modelling.\nThis study categorises the TD topics and tracks their progression over time.\nFurthermore, we have incorporated sentiment analysis for each identified topic,\nproviding a deeper insight into the perceptions and attitudes associated with\nthese topics. This offers a more nuanced understanding of the trends and shifts\nin TD topics through time, programming language, and repository.", "AI": {"tldr": "\u7b80\u800c\u8a00\u4e4b\uff0c\u672c\u7814\u7a76\u901a\u8fc7\u5206\u67902015\u5e74\u81f32023\u5e74GitHub\u95ee\u9898\uff0c\u4f7f\u7528BERTopic\u4e3b\u9898\u5efa\u6a21\u548c\u60c5\u611f\u5206\u6790\uff0c\u63a2\u7d22\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u6280\u672f\u503a\u52a1\u4e3b\u9898\u7684\u6f14\u53d8\u3001\u591a\u6837\u6027\u548c\u8d8b\u52bf\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u7814\u7a76\u5e7f\u6cdb\u6d89\u53ca\u6280\u672f\u503a\u52a1\u7684\u8bc6\u522b\u548c\u91cf\u5316\uff0c\u4f46\u5bf9\u6280\u672f\u503a\u52a1\u4e3b\u9898\u591a\u6837\u6027\u548c\u65f6\u95f4\u53d1\u5c55\u7684\u7406\u89e3\u4ecd\u5b58\u5728\u663e\u8457\u7a7a\u767d\u3002", "method": "\u91c7\u7528BERTopic\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21\uff0c\u5e76\u5bf92015\u5e749\u6708\u81f32023\u5e74GitHub\u95ee\u9898\u4e2d\u63d0\u53d6\u7684\u6280\u672f\u503a\u52a1\u6570\u636e\u8fdb\u884c\u63a2\u7d22\u6027\u5206\u6790\uff0c\u540c\u65f6\u878d\u5165\u60c5\u611f\u5206\u6790\u3002", "result": "\u7814\u7a76\u5206\u7c7b\u4e86\u6280\u672f\u503a\u52a1\u4e3b\u9898\uff0c\u8ddf\u8e2a\u5176\u65f6\u95f4\u6f14\u53d8\uff0c\u5e76\u901a\u8fc7\u60c5\u611f\u5206\u6790\u63ed\u793a\u4e86\u8fd9\u4e9b\u4e3b\u9898\u5728\u65f6\u95f4\u3001\u7f16\u7a0b\u8bed\u8a00\u548c\u4ed3\u5e93\u4e2d\u7684\u611f\u77e5\u8d8b\u52bf\u548c\u53d8\u5316\u3002", "conclusion": "\u672c\u7814\u7a76\u6df1\u5316\u4e86\u5bf9\u6280\u672f\u503a\u52a1\u52a8\u6001\u666f\u89c2\u7684\u7406\u89e3\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u6280\u672f\u503a\u52a1\u7ba1\u7406\u3002"}}
{"id": "2504.11986", "pdf": "https://arxiv.org/pdf/2504.11986", "abs": "https://arxiv.org/abs/2504.11986", "authors": ["Jose Manuel Guevara-Vela"], "title": "Language Models as Quasi-Crystalline Thought: Structure, Constraint, and Emergence in Generative Systems", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This essay proposes an analogy between large language models (LLMs) and\nquasicrystals: systems that exhibit global coherence without periodic\nrepetition and that are generated through local constraints. While LLMs are\noften evaluated in terms of predictive accuracy, factuality, or alignment, this\nstructural perspective suggests that their most characteristic behavior is the\nproduction of internally resonant linguistic patterns. Just as quasicrystals\nforced a redefinition of order in physical systems, viewing LLMs as generators\nof quasi-structured language opens new paths for evaluation and design:\nprivileging propagation of constraint over token-level accuracy, and coherence\nof form over fixed meaning. LLM outputs should be read not only for what they\nsay, but for the patterns of constraint and coherence that organize them. This\nshift reframes generative language as a space of emergent patterning: LLMs are\nneither fully random nor strictly rule-based, but defined by a logic of\nconstraint, resonance, and structural depth.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u51c6\u6676\u4f53\u7c7b\u6bd4\uff0c\u63d0\u51faLLMs\u751f\u6210\u5185\u90e8\u5171\u632f\u8bed\u8a00\u6a21\u5f0f\u7684\u65b0\u89c6\u89d2\u3002", "motivation": "\u4e3a\u4e86\u91cd\u65b0\u5b9a\u4e49LLMs\u7684\u8bc4\u4f30\u548c\u8bbe\u8ba1\uff0c\u5f3a\u8c03\u7ea6\u675f\u4f20\u64ad\u4e0e\u5f62\u5f0f\u8fde\u8d2f\u6027\uff0c\u800c\u975e\u4f20\u7edf\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u7c7b\u6bd4\u65b9\u6cd5\uff0c\u5206\u6790LLMs\u7684\u751f\u6210\u673a\u5236\u3002", "result": "\u5efa\u8bae\u5173\u6ce8LLMs\u8f93\u51fa\u7684\u7ea6\u675f\u4e0e\u8fde\u8d2f\u6a21\u5f0f\uff0c\u91cd\u65b0\u6846\u67b6\u751f\u6210\u8bed\u8a00\u4e3a\u6d8c\u73b0\u6a21\u5f0f\u3002", "conclusion": "LLMs\u901a\u8fc7\u5c40\u90e8\u7ea6\u675f\u4ea7\u751f\u5168\u5c40\u8fde\u8d2f\u7684\u8bed\u8a00\u6a21\u5f0f\uff0c\u7c7b\u4f3c\u4e8e\u51c6\u6676\u4f53\u3002"}}
{"id": "2504.12007", "pdf": "https://arxiv.org/pdf/2504.12007", "abs": "https://arxiv.org/abs/2504.12007", "authors": ["Haohao Qu", "Wenqi Fan", "Shanru Lin"], "title": "Generative Recommendation with Continuous-Token Diffusion", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "In recent years, there has been a significant trend toward using large\nlanguage model (LLM)-based recommender systems (RecSys). Current research\nprimarily focuses on representing complex user-item interactions within a\ndiscrete space to align with the inherent discrete nature of language models.\nHowever, this approach faces limitations due to its discrete nature: (i)\ninformation is often compressed during discretization; (ii) the tokenization\nand generation for the vast number of users and items in real-world scenarios\nare constrained by a limited vocabulary. Embracing continuous data presents a\npromising alternative to enhance expressive capabilities, though this approach\nis still in its early stages. To address this gap, we propose a novel\nframework, DeftRec, which incorporates \\textbf{de}noising di\\textbf{f}fusion\nmodels to enable LLM-based RecSys to seamlessly support continuous\n\\textbf{t}oken as input and target. First, we introduce a robust tokenizer with\na masking operation and an additive K-way architecture to index users and\nitems, capturing their complex collaborative relationships into continuous\ntokens. Crucially, we develop a denoising diffusion model to process user\npreferences within continuous domains by conditioning on reasoning content from\npre-trained large language model. During the denoising process, we reformulate\nthe objective to include negative interactions, building a comprehensive\nunderstanding of user preferences for effective and accurate recommendation\ngeneration. Finally, given a continuous token as output, recommendations can be\neasily generated through score-based retrieval. Extensive experiments\ndemonstrate the effectiveness of the proposed methods, showing that DeftRec\nsurpasses competitive benchmarks, including both traditional and emerging\nLLM-based RecSys.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faDeftRec\u6846\u67b6\uff0c\u4f7f\u7528\u53bb\u566a\u6269\u6563\u6a21\u578b\u63d0\u5347LLM-based\u63a8\u8350\u7cfb\u7edf\u7684\u8fde\u7eed\u6570\u636e\u5904\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u79bb\u6563\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524dLLM-based\u63a8\u8350\u7cfb\u7edf\u4f9d\u8d56\u79bb\u6563\u7a7a\u95f4\uff0c\u5b58\u5728\u4fe1\u606f\u538b\u7f29\u548c\u8bcd\u6c47\u9650\u5236\u95ee\u9898\uff0c\u8fde\u7eed\u6570\u636e\u65b9\u6cd5\u6709\u6f5c\u529b\u4f46\u5f00\u53d1\u4e0d\u8db3\u3002", "method": "\u63d0\u51faDeftRec\u6846\u67b6\uff0c\u5305\u62ec\u5e26\u63a9\u7801\u548cK-way\u67b6\u6784\u7684\u6807\u8bb0\u5668\u3001\u6761\u4ef6\u4e8eLLM\u63a8\u7406\u7684\u53bb\u566a\u6269\u6563\u6a21\u578b\u3001\u5305\u542b\u8d1f\u4ea4\u4e92\u7684\u76ee\u6807\u91cd\u6784\uff0c\u4ee5\u53ca\u57fa\u4e8e\u5206\u6570\u7684\u63a8\u8350\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u663e\u793aDeftRec\u4f18\u4e8e\u4f20\u7edf\u548c\u65b0\u5174LLM-based\u63a8\u8350\u7cfb\u7edf\u57fa\u51c6\u3002", "conclusion": "DeftRec\u6846\u67b6\u6709\u6548\u6539\u5584\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u63a8\u8350\u3002"}}
{"id": "2504.11775", "pdf": "https://arxiv.org/pdf/2504.11775", "abs": "https://arxiv.org/abs/2504.11775", "authors": ["Tianhe Zhang", "Suhan Liu", "Peng Shi"], "title": "Discrimination-free Insurance Pricing with Privatized Sensitive Attributes", "categories": ["stat.ML", "cs.CY", "cs.LG", "q-fin.RM"], "comment": null, "summary": "Fairness has emerged as a critical consideration in the landscape of machine\nlearning algorithms, particularly as AI continues to transform decision-making\nacross societal domains. To ensure that these algorithms are free from bias and\ndo not discriminate against individuals based on sensitive attributes such as\ngender and race, the field of algorithmic bias has introduced various fairness\nconcepts, along with methodologies to achieve these notions in different\ncontexts. Despite the rapid advancement, not all sectors have embraced these\nfairness principles to the same extent. One specific sector that merits\nattention in this regard is insurance. Within the realm of insurance pricing,\nfairness is defined through a distinct and specialized framework. Consequently,\nachieving fairness according to established notions does not automatically\nensure fair pricing in insurance. In particular, regulators are increasingly\nemphasizing transparency in pricing algorithms and imposing constraints on\ninsurance companies on the collection and utilization of sensitive consumer\nattributes. These factors present additional challenges in the implementation\nof fairness in pricing algorithms. To address these complexities and comply\nwith regulatory demands, we propose an efficient method for constructing fair\nmodels that are tailored to the insurance domain, using only privatized\nsensitive attributes. Notably, our approach ensures statistical guarantees,\ndoes not require direct access to sensitive attributes, and adapts to varying\ntransparency requirements, addressing regulatory demands while ensuring\nfairness in insurance pricing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u4f7f\u7528\u79c1\u6709\u5316\u654f\u611f\u5c5e\u6027\u7684\u65b9\u6cd5\uff0c\u786e\u4fdd\u4fdd\u9669\u5b9a\u4ef7\u516c\u5e73\u6027\uff0c\u5e76\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u516c\u5e73\u6027\u91cd\u8981\uff0c\u4f46\u4fdd\u9669\u9886\u57df\u6709\u72ec\u7279\u6311\u6218\uff0c\u6807\u51c6\u516c\u5e73\u6982\u5ff5\u4e0d\u76f4\u63a5\u9002\u7528\uff0c\u4e14\u9762\u4e34\u76d1\u7ba1\u900f\u660e\u5ea6\u548c\u654f\u611f\u5c5e\u6027\u9650\u5236\u3002", "method": "\u63d0\u51fa\u9ad8\u6548\u65b9\u6cd5\uff0c\u4f7f\u7528\u79c1\u6709\u5316\u654f\u611f\u5c5e\u6027\u6784\u5efa\u516c\u5e73\u6a21\u578b\uff0c\u786e\u4fdd\u7edf\u8ba1\u4fdd\u8bc1\u3001\u4e0d\u76f4\u63a5\u8bbf\u95ee\u654f\u611f\u5c5e\u6027\uff0c\u5e76\u9002\u5e94\u4e0d\u540c\u900f\u660e\u5ea6\u8981\u6c42\u3002", "result": "\u65b9\u6cd5\u89e3\u51b3\u4e86\u4fdd\u9669\u5b9a\u4ef7\u7684\u590d\u6742\u6027\uff0c\u7b26\u5408\u76d1\u7ba1\u9700\u6c42\uff0c\u5e76\u786e\u4fdd\u516c\u5e73\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u4fdd\u9669\u5b9a\u4ef7\u7684\u516c\u5e73\u6027\uff0c\u540c\u65f6\u6ee1\u8db3\u76d1\u7ba1\u900f\u660e\u6027\u548c\u9650\u5236\u8981\u6c42\u3002"}}
{"id": "2504.11777", "pdf": "https://arxiv.org/pdf/2504.11777", "abs": "https://arxiv.org/abs/2504.11777", "authors": ["Yongpei Ma", "Pengyu Wang", "Adam Dunn", "Usman Naseem", "Jinman Kim"], "title": "Bridging the Semantic Gaps: Improving Medical VQA Consistency with LLM-Augmented Question Sets", "categories": ["cs.CV", "cs.LG"], "comment": "The first two listed authors contributed equally to this work", "summary": "Medical Visual Question Answering (MVQA) systems can interpret medical images\nin response to natural language queries. However, linguistic variability in\nquestion phrasing often undermines the consistency of these systems. To address\nthis challenge, we propose a Semantically Equivalent Question Augmentation\n(SEQA) framework, which leverages large language models (LLMs) to generate\ndiverse yet semantically equivalent rephrasings of questions. Specifically,\nthis approach enriches linguistic diversity while preserving semantic meaning.\nWe further introduce an evaluation metric, Total Agreement Rate with\nSemantically Equivalent Input and Correct Answer (TAR-SC), which assesses a\nmodel's capability to generate consistent and correct responses to semantically\nequivalent linguistic variations. In addition, we also propose three other\ndiversity metrics - average number of QA items per image (ANQI), average number\nof questions per image with the same answer (ANQA), and average number of\nopen-ended questions per image with the same semantics (ANQS). Using the SEQA\nframework, we augmented the benchmarked MVQA public datasets of SLAKE, VQA-RAD,\nand PathVQA. As a result, all three datasets achieved significant improvements\nby incorporating more semantically equivalent questions: ANQI increased by an\naverage of 86.1, ANQA by 85.1, and ANQS by 46. Subsequent experiments evaluate\nthree MVQA models (M2I2, MUMC, and BiomedGPT) under both zero-shot and\nfine-tuning settings on the enhanced datasets. Experimental results in MVQA\ndatasets show that fine-tuned models achieve an average accuracy improvement of\n19.35%, while our proposed TAR-SC metric shows an average improvement of 11.\n61%, indicating a substantial enhancement in model consistency.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51faSEQA\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u533b\u7597\u89c6\u89c9\u95ee\u7b54\u7cfb\u7edf\u7684\u8bed\u4e49\u7b49\u4ef7\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u65b0\u6307\u6807\u8bc4\u4f30\u4e00\u81f4\u6027\u3002", "motivation": "\u89e3\u51b3MVQA\u7cfb\u7edf\u56e0\u95ee\u9898\u8868\u8ff0\u8bed\u8a00\u53d8\u5f02\u6027\u5bfc\u81f4\u7684\u4e00\u81f4\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faSEQA\u6846\u67b6\u5229\u7528LLMs\u751f\u6210\u8bed\u4e49\u7b49\u4ef7\u95ee\u9898\u91cd\u8ff0\uff0c\u5f15\u5165TAR-SC\u7b49\u6307\u6807\uff0c\u5e76\u589e\u5f3aSLAKE\u3001VQA-RAD\u548cPathVQA\u6570\u636e\u96c6\u3002", "result": "\u6570\u636e\u96c6\u591a\u6837\u6027\u6307\u6807\u63d0\u5347\uff1aANQI\u5e73\u5747\u589e\u52a086.1\uff0cANQA\u589e\u52a085.1\uff0cANQS\u589e\u52a046\uff1b\u6a21\u578b\u51c6\u786e\u7387\u5e73\u5747\u63d0\u9ad819.35%\uff0cTAR-SC\u63d0\u534711.61%\u3002", "conclusion": "\u6846\u67b6\u663e\u8457\u6539\u5584MVQA\u6a21\u578b\u7684\u4e00\u81f4\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2504.12031", "pdf": "https://arxiv.org/pdf/2504.12031", "abs": "https://arxiv.org/abs/2504.12031", "authors": ["Ekaterina Komendantskaya"], "title": "Proof-Carrying Neuro-Symbolic Code", "categories": ["cs.PL", "cs.AI", "cs.LO", "F.3.1; F.3.2; F.3.3; I.2.0"], "comment": "Invited paper at CiE 2025. arXiv admin note: text overlap with\n  arXiv:2501.05867", "summary": "This invited paper introduces the concept of \"proof-carrying neuro-symbolic\ncode\" and explains its meaning and value, from both the \"neural\" and the\n\"symbolic\" perspectives. The talk outlines the first successes and challenges\nthat this new area of research faces.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd'\u8bc1\u660e\u643a\u5e26\u795e\u7ecf\u7b26\u53f7\u4ee3\u7801'\u7684\u6982\u5ff5\uff0c\u4ece\u795e\u7ecf\u548c\u7b26\u53f7\u89d2\u5ea6\u89e3\u91ca\u5176\u610f\u4e49\u548c\u4ef7\u503c\uff0c\u5e76\u6982\u8ff0\u8fd9\u4e00\u65b0\u7814\u7a76\u9886\u57df\u7684\u521d\u6b65\u6210\u529f\u548c\u6311\u6218\u3002", "motivation": "\u6865\u63a5\u795e\u7ecf\u548c\u7b26\u53f7AI\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u901a\u8fc7\u5f15\u5165\u786e\u4fdd\u53ef\u8bc1\u660e\u6b63\u786e\u6027\u7684\u6982\u5ff5\uff0c\u4ee5\u6ee1\u8db3\u53ef\u9760AI\u7cfb\u7edf\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u6982\u5ff5\u4ecb\u7ecd\u3001\u4ece\u4e0d\u540c\u89c6\u89d2\u7684\u89e3\u91ca\u4ee5\u53ca\u6210\u529f\u548c\u6311\u6218\u7684\u6982\u8ff0\uff0c\u53ef\u80fd\u6d89\u53ca\u7406\u8bba\u8ba8\u8bba\u6216\u6848\u4f8b\u5206\u6790\u3002", "result": "\u6982\u8ff0\u4e86\u6982\u5ff5\u5e94\u7528\u7684\u521d\u6b65\u6210\u529f\uff0c\u5e76\u6307\u51fa\u4e86\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\u3002", "conclusion": "\u8fd9\u4e00\u65b0\u7814\u7a76\u9886\u57df\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u514b\u670d\u6311\u6218\u4ee5\u5b9e\u73b0\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2504.12039", "pdf": "https://arxiv.org/pdf/2504.12039", "abs": "https://arxiv.org/abs/2504.12039", "authors": ["Yizhuo Wu", "Francesco Fioranelli", "Chang Gao"], "title": "RadMamba: Efficient Human Activity Recognition through Radar-based Micro-Doppler-Oriented Mamba State-Space Model", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Under Review", "summary": "Radar-based HAR has emerged as a promising alternative to conventional\nmonitoring approaches, such as wearable devices and camera-based systems, due\nto its unique privacy preservation and robustness advantages. However, existing\nsolutions based on convolutional and recurrent neural networks, although\neffective, are computationally demanding during deployment. This limits their\napplicability in scenarios with constrained resources or those requiring\nmultiple sensors. Advanced architectures, such as ViT and SSM architectures,\noffer improved modeling capabilities and have made efforts toward lightweight\ndesigns. However, their computational complexity remains relatively high. To\nleverage the strengths of transformer architectures while simultaneously\nenhancing accuracy and reducing computational complexity, this paper introduces\nRadMamba, a parameter-efficient, radar micro-Doppler-oriented Mamba SSM\nspecifically tailored for radar-based HAR. Across three diverse datasets,\nRadMamba matches the top-performing previous model's 99.8% classification\naccuracy on Dataset DIAT with only 1/400 of its parameters and equals the\nleading models' 92.0% accuracy on Dataset CI4R with merely 1/10 of their\nparameters. In scenarios with continuous sequences of actions evaluated on\nDataset UoG2020, RadMamba surpasses other models with significantly higher\nparameter counts by at least 3%, achieving this with only 6.7k parameters. Our\ncode is available at: https://github.com/lab-emi/AIRHAR.", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u5f15\u5165RadMamba\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7Mamba SSM\uff0c\u7528\u4e8e\u57fa\u4e8e\u96f7\u8fbe\u7684\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\uff08HAR\uff09\uff0c\u4ee5\u5c11\u91cf\u53c2\u6570\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u96f7\u8fbe-based HAR\u6a21\u578b\u8ba1\u7b97\u9700\u6c42\u9ad8\u3001\u8d44\u6e90\u53d7\u9650\u95ee\u9898\uff0c\u5e76\u5229\u7528transformer\u4f18\u52bf\u63d0\u5347\u6548\u7387\u3002", "method": "\u5f00\u53d1RadMamba\uff0c\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u7684Mamba SSM\uff0c\u9488\u5bf9\u96f7\u8fbe\u5fae\u591a\u666e\u52d2\u6570\u636e\u4f18\u5316\u8bbe\u8ba1\u3002", "result": "\u5728DIAT\u6570\u636e\u96c6\u4e0a\u8fbe\u523099.8%\u51c6\u786e\u7387\uff0c\u4ec5\u7528\u524d\u6a21\u578b1/400\u53c2\u6570\uff1b\u5728CI4R\u6570\u636e\u96c6\u4e0a\u8fbe\u523092.0%\u51c6\u786e\u7387\uff0c\u4ec5\u7528\u5176\u4ed6\u6a21\u578b1/10\u53c2\u6570\uff1b\u5728UoG2020\u6570\u636e\u96c6\u4e0a\u4ee56.7k\u53c2\u6570\u8d85\u8d8a\u5176\u4ed6\u6a21\u578b\u81f3\u5c113%\u3002", "conclusion": "RadMamba\u63d0\u4f9b\u9ad8\u6548\u7684\u96f7\u8fbe-based HAR\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u573a\u666f\u3002"}}
{"id": "2504.12063", "pdf": "https://arxiv.org/pdf/2504.12063", "abs": "https://arxiv.org/abs/2504.12063", "authors": ["Harrie Oosterhuis", "Rolf Jagerman", "Zhen Qin", "Xuanhui Wang"], "title": "Optimizing Compound Retrieval Systems", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "SIGIR 2025", "summary": "Modern retrieval systems do not rely on a single ranking model to construct\ntheir rankings. Instead, they generally take a cascading approach where a\nsequence of ranking models are applied in multiple re-ranking stages. Thereby,\nthey balance the quality of the top-K ranking with computational costs by\nlimiting the number of documents each model re-ranks. However, the cascading\napproach is not the only way models can interact to form a retrieval system.\n  We propose the concept of compound retrieval systems as a broader class of\nretrieval systems that apply multiple prediction models. This encapsulates\ncascading models but also allows other types of interactions than top-K\nre-ranking. In particular, we enable interactions with large language models\n(LLMs) which can provide relative relevance comparisons. We focus on the\noptimization of compound retrieval system design which uniquely involves\nlearning where to apply the component models and how to aggregate their\npredictions into a final ranking. This work shows how our compound approach can\ncombine the classic BM25 retrieval model with state-of-the-art (pairwise) LLM\nrelevance predictions, while optimizing a given ranking metric and efficiency\ntarget. Our experimental results show optimized compound retrieval systems\nprovide better trade-offs between effectiveness and efficiency than cascading\napproaches, even when applied in a self-supervised manner.\n  With the introduction of compound retrieval systems, we hope to inspire the\ninformation retrieval field to more out-of-the-box thinking on how prediction\nmodels can interact to form rankings.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165\u590d\u5408\u68c0\u7d22\u7cfb\u7edf\u6982\u5ff5\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u4e2a\u6a21\u578b\u5982BM25\u548cLLM\uff0c\u4f18\u5316\u68c0\u7d22\u6548\u7387\u548c\u6548\u679c\uff0c\u6bd4\u7ea7\u8054\u65b9\u6cd5\u66f4\u597d\u3002", "motivation": "\u73b0\u6709\u68c0\u7d22\u7cfb\u7edf\u4f7f\u7528\u7ea7\u8054\u65b9\u6cd5\uff0c\u4f46\u4f5c\u8005\u63d0\u51fa\u9700\u8981\u66f4\u5e7f\u6cdb\u7684\u6a21\u578b\u4ea4\u4e92\u65b9\u5f0f\uff0c\u7279\u522b\u662f\u6574\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u4f18\u5316\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u590d\u5408\u68c0\u7d22\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u6a21\u578b\u5e94\u7528\u4f4d\u7f6e\u548c\u9884\u6d4b\u805a\u5408\u65b9\u5f0f\uff0c\u7ed3\u5408BM25\u548cLLM\u7684\u76f8\u5bf9\u76f8\u5173\u6027\u9884\u6d4b\uff0c\u4f18\u5316\u6392\u540d\u6307\u6807\u548c\u6548\u7387\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u590d\u5408\u68c0\u7d22\u7cfb\u7edf\u5728\u6709\u6548\u6027\u548c\u6548\u7387\u4e4b\u95f4\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6743\u8861\uff0c\u5373\u4f7f\u5728\u81ea\u76d1\u7763\u65b9\u5f0f\u4e0b\u4e5f\u4f18\u4e8e\u7ea7\u8054\u65b9\u6cd5\u3002", "conclusion": "\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u8fd9\u4e00\u6982\u5ff5\uff0c\u6fc0\u52b1\u4fe1\u606f\u68c0\u7d22\u9886\u57df\u8fdb\u884c\u66f4\u591a\u521b\u65b0\u6027\u7684\u6a21\u578b\u4ea4\u4e92\u8bbe\u8ba1\u3002"}}
{"id": "2504.11840", "pdf": "https://arxiv.org/pdf/2504.11840", "abs": "https://arxiv.org/abs/2504.11840", "authors": ["Huizhe Zhang", "Jintang Li", "Yuchang Zhu", "Liang Chen", "Zibin Zheng"], "title": "GT-SVQ: A Linear-Time Graph Transformer for Node Classification Using Spiking Vector Quantization", "categories": ["cs.NE", "cs.LG"], "comment": "work in progress", "summary": "Graph Transformers (GTs), which simultaneously integrate message-passing and\nself-attention mechanisms, have achieved promising empirical results in some\ngraph prediction tasks. Although these approaches show the potential of\nTransformers in capturing long-range graph topology information, issues\nconcerning the quadratic complexity and high computing energy consumption\nseverely limit the scalability of GTs on large-scale graphs. Recently, as\nbrain-inspired neural networks, Spiking Neural Networks (SNNs), facilitate the\ndevelopment of graph representation learning methods with lower computational\nand storage overhead through the unique event-driven spiking neurons. Inspired\nby these characteristics, we propose a linear-time Graph Transformer using\nSpiking Vector Quantization (GT-SVQ) for node classification. GT-SVQ\nreconstructs codebooks based on rate coding outputs from spiking neurons, and\ninjects the codebooks into self-attention blocks to aggregate global\ninformation in linear complexity. Besides, spiking vector quantization\neffectively alleviates codebook collapse and the reliance on complex machinery\n(distance measure, auxiliary loss, etc.) present in previous vector\nquantization-based graph learning methods. In experiments, we compare GT-SVQ\nwith other state-of-the-art baselines on node classification datasets ranging\nfrom small to large. Experimental results show that GT-SVQ has achieved\ncompetitive performances on most datasets while maintaining up to 130x faster\ninference speed compared to other GTs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGT-SVQ\uff0c\u4f7f\u7528Spiking Neural Networks\u5b9e\u73b0\u7ebf\u6027\u65f6\u95f4Graph Transformer\uff0c\u63d0\u9ad8\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u7684\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "Graph Transformers\u5b58\u5728\u4e8c\u6b21\u590d\u6742\u5ea6\u548c\u9ad8\u8ba1\u7b97\u80fd\u8017\u95ee\u9898\uff0cSpiking Neural Networks\u53ef\u964d\u4f4e\u5f00\u9500\uff0c\u56e0\u6b64\u63d0\u51faGT-SVQ\u4ee5\u63d0\u5347\u53ef\u6269\u5c55\u6027\u3002", "method": "GT-SVQ\u57fa\u4e8eSpiking Vector Quantization\u91cd\u5efacodebooks\uff0c\u5e76\u6ce8\u5165self-attention\u5757\uff0c\u4ee5\u7ebf\u6027\u590d\u6742\u5ea6\u805a\u5408\u4fe1\u606f\uff0c\u5e76\u7f13\u89e3codebook collapse\u95ee\u9898\u3002", "result": "\u5728\u8282\u70b9\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\uff0cGT-SVQ\u4e0e\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6027\u80fd\u7ade\u4e89\u6027\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe130\u500d\u3002", "conclusion": "GT-SVQ\u8bc1\u660e\u4e86\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86Graph Transformers\u7684\u6548\u7387\u548c\u9002\u7528\u6027\u3002"}}
{"id": "2504.12082", "pdf": "https://arxiv.org/pdf/2504.12082", "abs": "https://arxiv.org/abs/2504.12082", "authors": ["Yumin Kim", "Hwanhee Lee"], "title": "Selective Demonstration Retrieval for Improved Implicit Hate Speech Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Hate speech detection is a crucial area of research in natural language\nprocessing, essential for ensuring online community safety. However, detecting\nimplicit hate speech, where harmful intent is conveyed in subtle or indirect\nways, remains a major challenge. Unlike explicit hate speech, implicit\nexpressions often depend on context, cultural subtleties, and hidden biases,\nmaking them more challenging to identify consistently. Additionally, the\ninterpretation of such speech is influenced by external knowledge and\ndemographic biases, resulting in varied detection results across different\nlanguage models. Furthermore, Large Language Models often show heightened\nsensitivity to toxic language and references to vulnerable groups, which can\nlead to misclassifications. This over-sensitivity results in false positives\n(incorrectly identifying harmless statements as hateful) and false negatives\n(failing to detect genuinely harmful content). Addressing these issues requires\nmethods that not only improve detection precision but also reduce model biases\nand enhance robustness. To address these challenges, we propose a novel method,\nwhich utilizes in-context learning without requiring model fine-tuning. By\nadaptively retrieving demonstrations that focus on similar groups or those with\nthe highest similarity scores, our approach enhances contextual comprehension.\nExperimental results show that our method outperforms current state-of-the-art\ntechniques. Implementation details and code are available at TBD.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u9690\u6027\u4ec7\u6068\u8a00\u8bba\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u51cf\u5c11\u504f\u5dee\uff0c\u800c\u4e0d\u9700\u8981\u6a21\u578b\u5fae\u8c03\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u9690\u6027\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u4f9d\u8d56\u3001\u6587\u5316\u7ec6\u5fae\u5dee\u522b\u3001\u6a21\u578b\u504f\u5dee\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8fc7\u5ea6\u654f\u611f\u95ee\u9898\uff0c\u4ee5\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u9700\u6a21\u578b\u5fae\u8c03\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u68c0\u7d22\u76f8\u4f3c\u7fa4\u7ec4\u6216\u9ad8\u76f8\u4f3c\u5ea6\u6f14\u793a\u6765\u589e\u5f3a\u4e0a\u4e0b\u6587\u7406\u89e3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6280\u672f\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u5730\u51cf\u5c11\u4e86\u8bef\u5206\u7c7b\uff0c\u63d0\u9ad8\u4e86\u9690\u6027\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2504.12088", "pdf": "https://arxiv.org/pdf/2504.12088", "abs": "https://arxiv.org/abs/2504.12088", "authors": ["Mirza Samad Ahmed Baig", "Syeda Anshrah Gillani", "Abdul Akbar Khan", "Shahid Munir Shah"], "title": "AttentionDrop: A Novel Regularization Method for Transformer Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "26 pages", "summary": "Transformer-based architectures achieve state-of-the-art performance across a\nwide range of tasks in natural language processing, computer vision, and\nspeech. However, their immense capacity often leads to overfitting, especially\nwhen training data is limited or noisy. We propose AttentionDrop, a unified\nfamily of stochastic regularization techniques that operate directly on the\nself-attention distributions. We introduces three variants: 1. Hard Attention\nMasking: randomly zeroes out top-k attention logits per query to encourage\ndiverse context utilization. 2. Blurred Attention Smoothing: applies a dynamic\nGaussian convolution over attention logits to diffuse overly peaked\ndistributions. 3. Consistency-Regularized AttentionDrop: enforces output\nstability under multiple independent AttentionDrop perturbations via a KL-based\nconsistency loss.", "AI": {"tldr": "\u63d0\u51faAttentionDrop\uff0c\u4e00\u79cd\u9488\u5bf9Transformer\u6a21\u578b\u7684\u81ea\u6ce8\u610f\u529b\u6b63\u5219\u5316\u6280\u672f\uff0c\u4ee5\u51cf\u5c11\u8fc7\u62df\u5408\u3002", "motivation": "Transformer\u6a21\u578b\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5de8\u5927\u5bb9\u91cf\u6613\u5bfc\u81f4\u8fc7\u62df\u5408\uff0c\u5c24\u5176\u5728\u8bad\u7ec3\u6570\u636e\u6709\u9650\u6216\u566a\u58f0\u5927\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u5f15\u5165AttentionDrop\u5bb6\u65cf\u7684\u4e09\u79cd\u53d8\u4f53\uff1aHard Attention Masking\uff08\u968f\u673a\u5c4f\u853dtop-k\u6ce8\u610f\u529blogits\uff09\u3001Blurred Attention Smoothing\uff08\u52a8\u6001\u9ad8\u65af\u5377\u79ef\u5e73\u6ed1\u6ce8\u610f\u529blogits\uff09\u548cConsistency-Regularized AttentionDrop\uff08\u901a\u8fc7KL\u4e00\u81f4\u6027\u635f\u5931\u5f3a\u5236\u8f93\u51fa\u7a33\u5b9a\uff09\u3002", "result": "\u65b9\u6cd5\u65e8\u5728\u901a\u8fc7\u64cd\u4f5c\u81ea\u6ce8\u610f\u529b\u5206\u5e03\u63d0\u9ad8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\uff0c\u6f5c\u5728\u6539\u5584\u6027\u80fd\uff08\u6458\u8981\u672a\u8be6\u8ff0\u5177\u4f53\u7ed3\u679c\uff09\u3002", "conclusion": "AttentionDrop\u6280\u672f\u53ef\u589e\u5f3aTransformer\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6548\u679c\u3002"}}
{"id": "2504.12137", "pdf": "https://arxiv.org/pdf/2504.12137", "abs": "https://arxiv.org/abs/2504.12137", "authors": ["Laura Fieback", "Nishilkumar Balar", "Jakob Spiegelberg", "Hanno Gottschalk"], "title": "Efficient Contrastive Decoding with Probabilistic Hallucination Detection - Mitigating Hallucinations in Large Vision Language Models -", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Despite recent advances in Large Vision Language Models (LVLMs), these models\nstill suffer from generating hallucinatory responses that do not align with the\nvisual input provided. To mitigate such hallucinations, we introduce Efficient\nContrastive Decoding (ECD), a simple method that leverages probabilistic\nhallucination detection to shift the output distribution towards contextually\naccurate answers at inference time. By contrasting token probabilities and\nhallucination scores, ECD subtracts hallucinated concepts from the original\ndistribution, effectively suppressing hallucinations. Notably, our proposed\nmethod can be applied to any open-source LVLM and does not require additional\nLVLM training. We evaluate our method on several benchmark datasets and across\ndifferent LVLMs. Our experiments show that ECD effectively mitigates\nhallucinations, outperforming state-of-the-art methods with respect to\nperformance on LVLM benchmarks and computation time.", "AI": {"tldr": "\u63d0\u51faECD\u65b9\u6cd5\u7f13\u89e3LVLM\u7684\u5e7b\u89c9\u751f\u6210\u95ee\u9898\u3002", "motivation": "LVLM\u5728\u751f\u6210\u54cd\u5e94\u65f6\u6613\u51fa\u73b0\u4e0e\u89c6\u89c9\u8f93\u5165\u4e0d\u7b26\u7684\u5e7b\u89c9\uff0c\u9700\u8981\u6709\u6548\u7f13\u89e3\u3002", "method": "\u5f15\u5165Efficient Contrastive Decoding (ECD)\uff0c\u901a\u8fc7\u5bf9\u6bd4token\u6982\u7387\u548c\u5e7b\u89c9\u5206\u6570\u6291\u5236\u5e7b\u89c9\uff0c\u4e0d\u9700\u989d\u5916\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u663e\u793aECD\u6709\u6548\u51cf\u5c11\u5e7b\u89c9\uff0c\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u65f6\u95f4\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ECD\u662f\u4e00\u4e2a\u7b80\u5355\u3001\u6709\u6548\u7684\u5e7b\u89c9\u7f13\u89e3\u65b9\u6cd5\uff0c\u53ef\u5e94\u7528\u4e8e\u5404\u79cd\u5f00\u6e90LVLM\u3002"}}
{"id": "2504.11966", "pdf": "https://arxiv.org/pdf/2504.11966", "abs": "https://arxiv.org/abs/2504.11966", "authors": ["Linjuan Fan", "Di Wen", "Kunyu Peng", "Kailun Yang", "Jiaming Zhang", "Ruiping Liu", "Yufan Chen", "Junwei Zheng", "Jiamin Wu", "Xudong Han", "Rainer Stiefelhagen"], "title": "Exploring Video-Based Driver Activity Recognition under Noisy Labels", "categories": ["cs.CV", "cs.LG", "cs.RO", "eess.IV"], "comment": "The source code is available at\n  https://github.com/ilonafan/DAR-noisy-labels", "summary": "As an open research topic in the field of deep learning, learning with noisy\nlabels has attracted much attention and grown rapidly over the past ten years.\nLearning with label noise is crucial for driver distraction behavior\nrecognition, as real-world video data often contains mislabeled samples,\nimpacting model reliability and performance. However, label noise learning is\nbarely explored in the driver activity recognition field. In this paper, we\npropose the first label noise learning approach for the driver activity\nrecognition task. Based on the cluster assumption, we initially enable the\nmodel to learn clustering-friendly low-dimensional representations from given\nvideos and assign the resultant embeddings into clusters. We subsequently\nperform co-refinement within each cluster to smooth the classifier outputs.\nFurthermore, we propose a flexible sample selection strategy that combines two\nselection criteria without relying on any hyperparameters to filter clean\nsamples from the training dataset. We also incorporate a self-adaptive\nparameter into the sample selection process to enforce balancing across\nclasses. A comprehensive variety of experiments on the public Drive&Act dataset\nfor all granularity levels demonstrates the superior performance of our method\nin comparison with other label-denoising methods derived from the image\nclassification field. The source code is available at\nhttps://github.com/ilonafan/DAR-noisy-labels.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u9a7e\u9a76\u5458\u6d3b\u52a8\u8bc6\u522b\u7684\u6807\u7b7e\u566a\u58f0\u5b66\u4e60\u65b9\u6cd5\uff0c\u57fa\u4e8e\u805a\u7c7b\u5047\u8bbe\u4f18\u5316\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u5728\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u771f\u5b9e\u4e16\u754c\u89c6\u9891\u6570\u636e\u5e38\u6709\u9519\u8bef\u6807\u7b7e\uff0c\u5f71\u54cd\u6a21\u578b\u53ef\u9760\u6027\u548c\u6027\u80fd\uff0c\u800c\u9a7e\u9a76\u5458\u6d3b\u52a8\u8bc6\u522b\u9886\u57df\u5bf9\u6b64\u9c9c\u6709\u63a2\u7d22\u3002", "method": "\u57fa\u4e8e\u805a\u7c7b\u5047\u8bbe\uff0c\u5b66\u4e60\u4f4e\u7ef4\u8868\u793a\u5e76\u8fdb\u884c\u96c6\u7fa4\u5185\u5171\u7cbe\u70bc\uff0c\u63d0\u51fa\u7075\u6d3b\u6837\u672c\u9009\u62e9\u7b56\u7565\u5e76\u52a0\u5165\u81ea\u9002\u5e94\u53c2\u6570\u3002", "result": "\u5728Drive&Act\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u65b9\u6cd5\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u56fe\u50cf\u5206\u7c7b\u53bb\u566a\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u9a7e\u9a76\u5458\u6d3b\u52a8\u8bc6\u522b\u4e2d\u6807\u7b7e\u566a\u58f0\u95ee\u9898\u7684\u5904\u7406\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2504.12143", "pdf": "https://arxiv.org/pdf/2504.12143", "abs": "https://arxiv.org/abs/2504.12143", "authors": ["Matteo Lupinacci", "Francesco Blefari", "Francesco Romeo", "Francesco Aurelio Pironti", "Angelo Furfaro"], "title": "ARCeR: an Agentic RAG for the Automated Definition of Cyber Ranges", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The growing and evolving landscape of cybersecurity threats necessitates the\ndevelopment of supporting tools and platforms that allow for the creation of\nrealistic IT environments operating within virtual, controlled settings as\nCyber Ranges (CRs). CRs can be exploited for analyzing vulnerabilities and\nexperimenting with the effectiveness of devised countermeasures, as well as\nserving as training environments for building cyber security skills and\nabilities for IT operators. This paper proposes ARCeR as an innovative solution\nfor the automatic generation and deployment of CRs, starting from user-provided\ndescriptions in a natural language. ARCeR relies on the Agentic RAG paradigm,\nwhich allows it to fully exploit state-of-art AI technologies. Experimental\nresults show that ARCeR is able to successfully process prompts even in cases\nthat LLMs or basic RAG systems are not able to cope with. Furthermore, ARCeR is\nable to target any CR framework provided that specific knowledge is made\navailable to it.", "AI": {"tldr": "ARCeR \u662f\u4e00\u4e2a\u57fa\u4e8e AI \u7684\u7cfb\u7edf\uff0c\u80fd\u591f\u4ece\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u81ea\u52a8\u751f\u6210\u548c\u90e8\u7f72\u7f51\u7edc\u5b89\u5168\u8303\u56f4\uff08Cyber Ranges\uff09\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u6807\u51c6\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c RAG \u7cfb\u7edf\u3002", "motivation": "\u5e94\u5bf9\u65e5\u76ca\u589e\u957f\u548c\u6f14\u53d8\u7684\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\uff0c\u9700\u8981\u5f00\u53d1\u5de5\u5177\u6765\u521b\u5efa\u865a\u62df\u7684\u53d7\u63a7 IT \u73af\u5883\uff0c\u7528\u4e8e\u6f0f\u6d1e\u5206\u6790\u3001\u6d4b\u8bd5\u5bf9\u7b56\u7684\u6709\u6548\u6027\u4ee5\u53ca\u4f5c\u4e3a\u57f9\u8bad\u73af\u5883\u3002", "method": "\u672c\u6587\u63d0\u51fa ARCeR\uff0c\u4f7f\u7528 Agentic RAG \u8303\u5f0f\uff0c\u5145\u5206\u5229\u7528\u6700\u5148\u8fdb\u7684 AI \u6280\u672f\uff0c\u4ece\u7528\u6237\u63d0\u4f9b\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u5f00\u59cb\u81ea\u52a8\u751f\u6210\u548c\u90e8\u7f72 Cyber Ranges\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cARCeR \u80fd\u591f\u6210\u529f\u5904\u7406\u5373\u4f7f LLM \u6216\u57fa\u672c RAG \u7cfb\u7edf\u65e0\u6cd5\u5e94\u5bf9\u7684\u63d0\u793a\u3002\u6b64\u5916\uff0cARCeR \u80fd\u591f\u9488\u5bf9\u4efb\u4f55 Cyber Range \u6846\u67b6\uff0c\u53ea\u8981\u63d0\u4f9b\u7279\u5b9a\u7684\u77e5\u8bc6\u3002", "conclusion": "ARCeR \u662f\u4e00\u4e2a\u521b\u65b0\u7684\u3001\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u81ea\u52a8\u751f\u6210\u548c\u90e8\u7f72 Cyber Ranges\u3002"}}
{"id": "2504.12000", "pdf": "https://arxiv.org/pdf/2504.12000", "abs": "https://arxiv.org/abs/2504.12000", "authors": ["Thorben Markmann", "Michiel Straat", "Sebastian Peitz", "Barbara Hammer"], "title": "Control of Rayleigh-B\u00e9nard Convection: Effectiveness of Reinforcement Learning in the Turbulent Regime", "categories": ["physics.flu-dyn", "cs.LG"], "comment": null, "summary": "Data-driven flow control has significant potential for industry, energy\nsystems, and climate science. In this work, we study the effectiveness of\nReinforcement Learning (RL) for reducing convective heat transfer in the 2D\nRayleigh-B\\'enard Convection (RBC) system under increasing turbulence. We\ninvestigate the generalizability of control across varying initial conditions\nand turbulence levels and introduce a reward shaping technique to accelerate\nthe training. RL agents trained via single-agent Proximal Policy Optimization\n(PPO) are compared to linear proportional derivative (PD) controllers from\nclassical control theory. The RL agents reduced convection, measured by the\nNusselt Number, by up to 33% in moderately turbulent systems and 10% in highly\nturbulent settings, clearly outperforming PD control in all settings. The\nagents showed strong generalization performance across different initial\nconditions and to a significant extent, generalized to higher degrees of\nturbulence. The reward shaping improved sample efficiency and consistently\nstabilized the Nusselt Number to higher turbulence levels.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u51cf\u5c112D Rayleigh-B\u00e9nard\u5bf9\u6d41\u7cfb\u7edf\u4e2d\u5bf9\u6d41\u70ed\u4f20\u8f93\uff0c\u5728\u4e2d\u7b49\u6e4d\u6d41\u6761\u4ef6\u4e0b\u964d\u4f4eNusselt\u657033%\uff0c\u9ad8\u6e4d\u6d41\u4e0b\u964d\u4f4e10%\uff0c\u4f18\u4e8e\u4f20\u7edfPD\u63a7\u5236\uff0c\u5e76\u5c55\u793a\u826f\u597d\u6cdb\u5316\u6027\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u7684\u6d41\u52a8\u63a7\u5236\u5728\u5de5\u4e1a\u3001\u80fd\u6e90\u7cfb\u7edf\u548c\u6c14\u5019\u79d1\u5b66\u4e2d\u5177\u6709\u91cd\u8981\u6f5c\u529b\uff0c\u672c\u6587\u7814\u7a76\u5f3a\u5316\u5b66\u4e60\u5728\u589e\u52a0\u6e4d\u6d41\u6761\u4ef6\u4e0b\u51cf\u5c11\u5bf9\u6d41\u70ed\u4f20\u8f93\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528\u5355\u4ee3\u7406Proximal Policy Optimization (PPO)\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\uff0c\u4e0e\u7ebf\u6027\u6bd4\u4f8b\u5fae\u5206(PD)\u63a7\u5236\u5668\u6bd4\u8f83\uff1b\u5f15\u5165\u5956\u52b1\u6574\u5f62\u6280\u672f\u52a0\u901f\u8bad\u7ec3\uff0c\u5e76\u6d4b\u8bd5\u5bf9\u4e0d\u540c\u521d\u59cb\u6761\u4ef6\u548c\u6e4d\u6d41\u6c34\u5e73\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "RL\u4ee3\u7406\u5728\u4e2d\u7b49\u6e4d\u6d41\u7cfb\u7edf\u4e2d\u5c06Nusselt\u6570\u51cf\u5c11\u6700\u591a33%\uff0c\u9ad8\u6e4d\u6d41\u4e0b\u51cf\u5c1110%\uff0c\u5728\u6240\u6709\u8bbe\u7f6e\u4e2d\u4f18\u4e8ePD\u63a7\u5236\uff1b\u4ee3\u7406\u5bf9\u521d\u59cb\u6761\u4ef6\u548c\u8f83\u9ad8\u6e4d\u6d41\u7a0b\u5ea6\u6709\u5f3a\u6cdb\u5316\u6027\u80fd\uff0c\u5956\u52b1\u6574\u5f62\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u5e76\u7a33\u5b9a\u4e86Nusselt\u6570\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5728\u51cf\u5c11\u5bf9\u6d41\u70ed\u4f20\u8f93\u65b9\u9762\u6709\u6548\uff0c\u5177\u6709\u826f\u597d\u6cdb\u5316\u80fd\u529b\uff0c\u5956\u52b1\u6574\u5f62\u6280\u672f\u6709\u52a9\u4e8e\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2504.12172", "pdf": "https://arxiv.org/pdf/2504.12172", "abs": "https://arxiv.org/abs/2504.12172", "authors": ["Maged S. Al-Shaibani", "Zaid Alyafeai", "Irfan Ahmad"], "title": "Poem Meter Classification of Recited Arabic Poetry: Integrating High-Resource Systems for a Low-Resource Task", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Arabic poetry is an essential and integral part of Arabic language and\nculture. It has been used by the Arabs to spot lights on their major events\nsuch as depicting brutal battles and conflicts. They also used it, as in many\nother languages, for various purposes such as romance, pride, lamentation, etc.\nArabic poetry has received major attention from linguistics over the decades.\nOne of the main characteristics of Arabic poetry is its special rhythmic\nstructure as opposed to prose. This structure is referred to as a meter.\nMeters, along with other poetic characteristics, are intensively studied in an\nArabic linguistic field called \"\\textit{Aroud}\". Identifying these meters for a\nverse is a lengthy and complicated process. It also requires technical\nknowledge in \\textit{Aruod}. For recited poetry, it adds an extra layer of\nprocessing. Developing systems for automatic identification of poem meters for\nrecited poems need large amounts of labelled data. In this study, we propose a\nstate-of-the-art framework to identify the poem meters of recited Arabic\npoetry, where we integrate two separate high-resource systems to perform the\nlow-resource task. To ensure generalization of our proposed architecture, we\npublish a benchmark for this task for future research.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u5148\u8fdb\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u4e24\u4e2a\u9ad8\u8d44\u6e90\u7cfb\u7edf\u81ea\u52a8\u8bc6\u522b\u6717\u8bf5\u963f\u62c9\u4f2f\u8bd7\u6b4c\u7684\u97f5\u5f8b\uff0c\u5e76\u53d1\u5e03\u57fa\u51c6\u4ee5\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u3002", "motivation": "\u8bc6\u522b\u963f\u62c9\u4f2f\u8bd7\u6b4c\u97f5\u5f8b\u8fc7\u7a0b\u590d\u6742\u6f2b\u957f\uff0c\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e14\u6717\u8bf5\u8bd7\u6b4c\u4efb\u52a1\u66f4\u5177\u6311\u6218\uff0c\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u72b6\u6001-of-the-art\u6846\u67b6\uff0c\u6574\u5408\u4e24\u4e2a\u72ec\u7acb\u7684\u3001\u9ad8\u8d44\u6e90\u7684\u7cfb\u7edf\u6765\u5904\u7406\u4f4e\u8d44\u6e90\u4efb\u52a1\uff0c\u5373\u81ea\u52a8\u8bc6\u522b\u6717\u8bf5\u963f\u62c9\u4f2f\u8bd7\u6b4c\u7684\u97f5\u5f8b\u3002", "result": "\u5f00\u53d1\u4e86\u6846\u67b6\u5e76\u53d1\u5e03\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u786e\u4fdd\u4e86\u67b6\u6784\u7684\u6cdb\u5316\u6027\u548c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002", "conclusion": "\u6574\u5408\u73b0\u6709\u7cfb\u7edf\u5b9e\u73b0\u4e86\u81ea\u52a8\u8bc6\u522b\u6717\u8bf5\u8bd7\u6b4c\u97f5\u5f8b\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u6570\u636e\u96c6\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2504.12005", "pdf": "https://arxiv.org/pdf/2504.12005", "abs": "https://arxiv.org/abs/2504.12005", "authors": ["Soobin Suh", "Dabi Ahn", "Heewoong Park", "Jonghun Park"], "title": "Voice Conversion with Diverse Intonation using Conditional Variational Auto-Encoder", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "2 pages, Machine Learning in Speech and Language Processing Workshop\n  (MLSLP) 2018", "summary": "Voice conversion is a task of synthesizing an utterance with target speaker's\nvoice while maintaining linguistic information of the source utterance. While a\nspeaker can produce varying utterances from a single script with different\nintonations, conventional voice conversion models were limited to producing\nonly one result per source input. To overcome this limitation, we propose a\nnovel approach for voice conversion with diverse intonations using conditional\nvariational autoencoder (CVAE). Experiments have shown that the speaker's style\nfeature can be mapped into a latent space with Gaussian distribution. We have\nalso been able to convert voices with more diverse intonation by making the\nposterior of the latent space more complex with inverse autoregressive flow\n(IAF). As a result, the converted voice not only has a diversity of\nintonations, but also has better sound quality than the model without CVAE.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08CVAE\uff09\u548c\u9006\u81ea\u56de\u5f52\u6d41\uff08IAF\uff09\u6765\u5b9e\u73b0\u8bed\u97f3\u8f6c\u6362\u4e2d\u591a\u6837\u5316\u8bed\u8c03\u7684\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u8bed\u97f3\u8f6c\u6362\u6a21\u578b\u4ec5\u80fd\u4e3a\u6bcf\u4e2a\u6e90\u8f93\u5165\u4ea7\u751f\u4e00\u4e2a\u7ed3\u679c\uff0c\u800c\u8bf4\u8bdd\u8005\u53ef\u4ece\u5355\u4e00\u811a\u672c\u4ea7\u751f\u4e0d\u540c\u8bed\u8c03\u7684 utterances\uff0c\u56e0\u6b64\u9700\u8981\u514b\u670d\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4f7f\u7528CVAE\u5c06\u8bf4\u8bdd\u8005\u98ce\u683c\u7279\u5f81\u6620\u5c04\u5230\u9ad8\u65af\u5206\u5e03\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7IAF\u4f7f\u6f5c\u5728\u7a7a\u95f4\u540e\u9a8c\u66f4\u590d\u6742\uff0c\u4ee5\u5b9e\u73b0\u591a\u6837\u5316\u8bed\u8c03\u7684\u8bed\u97f3\u8f6c\u6362\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8f6c\u6362\u8bed\u97f3\u4e0d\u4ec5\u5177\u6709\u591a\u6837\u5316\u8bed\u8c03\uff0c\u8fd8\u6bd4\u65e0CVAE\u6a21\u578b\u6709\u66f4\u597d\u7684\u97f3\u8d28\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u63d0\u5347\u4e86\u8bed\u97f3\u8f6c\u6362\u7684\u8bed\u8c03\u591a\u6837\u6027\u548c\u97f3\u8d28\u3002"}}
{"id": "2504.12177", "pdf": "https://arxiv.org/pdf/2504.12177", "abs": "https://arxiv.org/abs/2504.12177", "authors": ["Victor Manuel Hernandez Lopez", "Jaime E. Cuellar"], "title": "Mapping Controversies Using Artificial Intelligence: An Analysis of the Hamas-Israel Conflict on YouTube", "categories": ["cs.CL", "cs.AI"], "comment": "in Spanish language", "summary": "This article analyzes the Hamas-Israel controversy through 253,925\nSpanish-language YouTube comments posted between October 2023 and January 2024,\nfollowing the October 7 attack that escalated the conflict. Adopting an\ninterdisciplinary approach, the study combines the analysis of controversies\nfrom Science and Technology Studies (STS) with advanced computational\nmethodologies, specifically Natural Language Processing (NLP) using the BERT\n(Bidirectional Encoder Representations from Transformers) model. Using this\napproach, the comments were automatically classified into seven categories,\nreflecting pro-Palestinian, pro-Israeli, anti- Palestinian, anti-Israeli\npositions, among others. The results show a predominance of pro- Palestinian\ncomments, although pro-Israeli and anti-Palestinian comments received more\n\"likes.\" This study also applies the agenda-setting theory to demonstrate how\nmedia coverage significantly influences public perception, observing a notable\nshift in public opinion, transitioning from a pro- Palestinian stance to a more\ncritical position towards Israel. This work highlights the importance of\ncombining social science perspectives with technological tools in the analysis\nof controversies, presenting a methodological innovation by integrating\ncomputational analysis with critical social theories to address complex public\nopinion phenomena and media narratives.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5206\u6790\u4e8625.3\u4e07\u6761\u897f\u73ed\u7259\u8bedYouTube\u8bc4\u8bba\uff0c\u63a2\u8ba8Hamas-Israel\u51b2\u7a81\uff0c\u4f7f\u7528NLP\u548cBERT\u6a21\u578b\u5206\u7c7b\u8bc4\u8bba\uff0c\u53d1\u73b0\u4eb2\u5df4\u52d2\u65af\u5766\u8bc4\u8bba\u5c45\u591a\u4f46\u4eb2\u4ee5\u8272\u5217\u8bc4\u8bba\u83b7\u66f4\u591a\u70b9\u8d5e\uff0c\u5e76\u5c55\u793a\u4e86\u5a92\u4f53\u5982\u4f55\u5f71\u54cd\u610f\u89c1\u8f6c\u53d8\u3002", "motivation": "\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u8de8\u5b66\u79d1\u65b9\u6cd5\u7ed3\u5408STS\u548c\u8ba1\u7b97\u6280\u672f\uff0c\u5206\u6790\u516c\u4f17\u610f\u89c1\u548c\u5a92\u4f53\u53d9\u4e8b\uff0c\u4ee5\u5e94\u5bf9\u590d\u6742\u7684\u4e89\u8bae\u73b0\u8c61\u3002", "method": "\u91c7\u7528NLP\u7684BERT\u6a21\u578b\u81ea\u52a8\u5206\u7c7b\u8bc4\u8bba\u4e3a\u4e03\u4e2a\u7c7b\u522b\uff0c\u5e76\u5e94\u7528\u8bae\u7a0b\u8bbe\u7f6e\u7406\u8bba\u6765\u7814\u7a76\u5a92\u4f53\u5bf9\u516c\u4f17\u611f\u77e5\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4eb2\u5df4\u52d2\u65af\u5766\u8bc4\u8bba\u5360\u4e3b\u5bfc\uff0c\u4f46\u4eb2\u4ee5\u8272\u5217\u548c\u53cd\u5df4\u52d2\u65af\u5766\u8bc4\u8bba\u83b7\u5f97\u66f4\u591a\u70b9\u8d5e\uff1b\u89c2\u5bdf\u5230\u516c\u4f17\u610f\u89c1\u4ece\u4eb2\u5df4\u52d2\u65af\u5766\u8f6c\u5411\u66f4\u6279\u8bc4\u4ee5\u8272\u5217\u7684\u8f6c\u53d8\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u4e86\u7ed3\u5408\u793e\u4f1a\u79d1\u5b66\u89c6\u89d2\u548c\u6280\u672f\u5de5\u5177\u7684\u91cd\u8981\u6027\uff0c\u5c55\u793a\u4e86\u65b9\u6cd5\u8bba\u521b\u65b0\u5728\u5206\u6790\u516c\u4f17\u610f\u89c1\u548c\u5a92\u4f53\u53d9\u4e8b\u4e2d\u7684\u4ef7\u503c\u3002"}}
{"id": "2504.12180", "pdf": "https://arxiv.org/pdf/2504.12180", "abs": "https://arxiv.org/abs/2504.12180", "authors": ["Jaime E. Cuellar", "Oscar Moreno-Martinez", "Paula Sofia Torres-Rodriguez", "Jaime Andres Pavlich-Mariscal", "Andres Felipe Mican-Castiblanco", "Juan Guillermo Torres-Hurtado"], "title": "Trusting CHATGPT: how minor tweaks in the prompts lead to major differences in sentiment classification", "categories": ["cs.CL", "cs.AI"], "comment": "in Spanish language", "summary": "One fundamental question for the social sciences today is: how much can we\ntrust highly complex predictive models like ChatGPT? This study tests the\nhypothesis that subtle changes in the structure of prompts do not produce\nsignificant variations in the classification results of sentiment polarity\nanalysis generated by the Large Language Model GPT-4o mini. Using a dataset of\n100.000 comments in Spanish on four Latin American presidents, the model\nclassified the comments as positive, negative, or neutral on 10 occasions,\nvarying the prompts slightly each time. The experimental methodology included\nexploratory and confirmatory analyses to identify significant discrepancies\namong classifications.\n  The results reveal that even minor modifications to prompts such as lexical,\nsyntactic, or modal changes, or even their lack of structure impact the\nclassifications. In certain cases, the model produced inconsistent responses,\nsuch as mixing categories, providing unsolicited explanations, or using\nlanguages other than Spanish. Statistical analysis using Chi-square tests\nconfirmed significant differences in most comparisons between prompts, except\nin one case where linguistic structures were highly similar.\n  These findings challenge the robustness and trust of Large Language Models\nfor classification tasks, highlighting their vulnerability to variations in\ninstructions. Moreover, it was evident that the lack of structured grammar in\nprompts increases the frequency of hallucinations. The discussion underscores\nthat trust in Large Language Models is based not only on technical performance\nbut also on the social and institutional relationships underpinning their use.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u6d4b\u8bd5\u5fae\u5c0f\u63d0\u793a\u53d8\u5316\u662f\u5426\u5f71\u54cdGPT-4o mini\u7684\u60c5\u611f\u5206\u6790\uff0c\u4f7f\u752810\u4e07\u6761\u897f\u73ed\u7259\u8bed\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u7ed3\u679c\u663e\u793a\u5206\u7c7b\u7ed3\u679c\u4e0d\u7a33\u5b9a\u3002", "motivation": "\u63a2\u8ba8\u5bf9\u590d\u6742\u9884\u6d4b\u6a21\u578b\u5982ChatGPT\u7684\u4fe1\u4efb\u5ea6\uff0c\u7126\u70b9\u662f\u6d4b\u8bd5\u63d0\u793a\u5fae\u5c0f\u53d8\u5316\u662f\u5426\u5bfc\u81f4\u60c5\u611f\u5206\u7c7b\u7ed3\u679c\u663e\u8457\u5dee\u5f02\u3002", "method": "\u4f7f\u752810\u4e07\u6761\u897f\u73ed\u7259\u8bed\u603b\u7edf\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u6a21\u578b\u572810\u6b21\u8f7b\u5fae\u63d0\u793a\u53d8\u5316\u4e0b\u5206\u7c7b\u60c5\u611f\uff0c\u91c7\u7528\u63a2\u7d22\u6027\u548c\u786e\u8ba4\u6027\u5206\u6790\u53caChi-square\u6d4b\u8bd5\u3002", "result": "\u63d0\u793a\u5fae\u8c03\u5bfc\u81f4\u5206\u7c7b\u5dee\u5f02\u663e\u8457\uff0c\u51fa\u73b0\u4e0d\u4e00\u81f4\u54cd\u5e94\u5982\u6df7\u5408\u7c7b\u522b\u6216\u5e7b\u89c9\uff0c\u7edf\u8ba1\u5206\u6790\u786e\u8ba4\u5927\u90e8\u5206\u6bd4\u8f83\u6709\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u6311\u6218\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7a33\u5065\u6027\uff0c\u5f3a\u8c03\u5176\u5bf9\u63d0\u793a\u53d8\u5316\u7684\u8106\u5f31\u6027\uff0c\u4fe1\u4efb\u9700\u8003\u8651\u793e\u4f1a\u548c\u673a\u6784\u56e0\u7d20\u3002"}}
{"id": "2504.12045", "pdf": "https://arxiv.org/pdf/2504.12045", "abs": "https://arxiv.org/abs/2504.12045", "authors": ["Jonas Myhre Schi\u00f8tt", "Viktor Sebastian Petersen", "Dimitrios P. Papadopoulos"], "title": "pix2pockets: Shot Suggestions in 8-Ball Pool from a Single Image in the Wild", "categories": ["cs.CV", "cs.LG", "I.2.1; I.4.6"], "comment": "15 pages, 7 figures, to be published in SCIA 2025", "summary": "Computer vision models have seen increased usage in sports, and reinforcement\nlearning (RL) is famous for beating humans in strategic games such as Chess and\nGo. In this paper, we are interested in building upon these advances and\nexamining the game of classic 8-ball pool. We introduce pix2pockets, a\nfoundation for an RL-assisted pool coach. Given a single image of a pool table,\nwe first aim to detect the table and the balls and then propose the optimal\nshot suggestion. For the first task, we build a dataset with 195 diverse images\nwhere we manually annotate all balls and table dots, leading to 5748 object\nsegmentation masks. For the second task, we build a standardized RL environment\nthat allows easy development and benchmarking of any RL algorithm. Our object\ndetection model yields an AP50 of 91.2 while our ball location pipeline obtains\nan error of only 0.4 cm. Furthermore, we compare standard RL algorithms to set\na baseline for the shot suggestion task and we show that all of them fail to\npocket all balls without making a foul move. We also present a simple baseline\nthat achieves a per-shot success rate of 94.7% and clears a full game in a\nsingle turn 30% of the time.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f00\u53d1\u4e86pix2pockets\u7cfb\u7edf\uff0c\u4f7f\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u5f3a\u5316\u5b66\u4e60\u68c0\u6d4b\u53f0\u7403\u684c\u548c\u7403\uff0c\u5e76\u5efa\u8bae\u6700\u4f73\u51fb\u7403\u3002", "motivation": "\u8bba\u6587\u65e8\u5728\u5229\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u5f3a\u5316\u5b66\u4e60\u5728\u4f53\u80b2\u9886\u57df\u7684\u8fdb\u5c55\uff0c\u6784\u5efaRL\u8f85\u52a9\u76848\u7403\u53f0\u7403\u6559\u7ec3\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u6784\u5efa195\u5f20\u56fe\u50cf\u7684\u6570\u636e\u96c6\u3001\u624b\u52a8\u6807\u6ce8\u5bf9\u8c61\u3001\u5f00\u53d1\u5bf9\u8c61\u68c0\u6d4b\u6a21\u578b\u548c\u6807\u51c6\u5316RL\u73af\u5883\uff0c\u5e76\u6bd4\u8f83RL\u7b97\u6cd5\u548c\u7b80\u5355\u57fa\u7ebf\u3002", "result": "\u5bf9\u8c61\u68c0\u6d4bAP50\u4e3a91.2\uff0c\u7403\u4f4d\u7f6e\u8bef\u5dee0.4 cm\uff1bRL\u7b97\u6cd5\u65e0\u6cd5\u65e0\u72af\u89c4\u6e05\u53f0\uff1b\u57fa\u7ebf\u6bcf\u51fb\u6210\u529f\u738794.7%\uff0c30%\u6982\u7387\u5355\u56de\u5408\u6e05\u53f0\u3002", "conclusion": "\u8bba\u6587\u8bbe\u5b9a\u4e86\u57fa\u7ebf\uff0c\u5e76\u663e\u793aRL\u5728\u51fb\u7403\u5efa\u8bae\u4efb\u52a1\u4e0a\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2504.12185", "pdf": "https://arxiv.org/pdf/2504.12185", "abs": "https://arxiv.org/abs/2504.12185", "authors": ["Suyoung Bae", "Hyojun Kim", "YunSeok Choi", "Jee-Hyong Lee"], "title": "SALAD: Improving Robustness and Generalization through Contrastive Learning with Structure-Aware and LLM-Driven Augmented Data", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to NAACL 2025 main. 15 pages, 4 figures", "summary": "In various natural language processing (NLP) tasks, fine-tuning Pre-trained\nLanguage Models (PLMs) often leads to the issue of spurious correlations, which\nnegatively impacts performance, particularly when dealing with\nout-of-distribution data. To address this problem, we propose SALAD}(Structure\nAware and LLM-driven Augmented Data), a novel approach designed to enhance\nmodel robustness and generalization by generating structure-aware and\ncounterfactually augmented data for contrastive learning. Our method leverages\na tagging-based approach to generate structure-aware positive samples and\nutilizes large language models (LLMs) to generate counterfactual negative\nsamples with diverse sentence patterns. By applying contrastive learning, SALAD\nenables the model to focus on learning the structural relationships between key\nsentence components while minimizing reliance on spurious correlations. We\nvalidate our approach through experiments on three tasks: Sentiment\nClassification, Sexism Detection, and Natural Language Inference. The results\ndemonstrate that SALAD not only improves model robustness and performance\nacross different environments but also enhances generalization to\nout-of-distribution datasets and cross-domain scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSALAD\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u548c\u53cd\u4e8b\u5b9e\u589e\u5f3a\u6570\u636e\u6539\u5584NLP\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5fae\u8c03\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5e38\u5bfc\u81f4\u865a\u5047\u76f8\u5173\u6027\uff0c\u5f71\u54cd\u5206\u5e03\u5916\u6570\u636e\u7684\u6027\u80fd\u3002", "method": "SALAD\u4f7f\u7528\u57fa\u4e8e\u6807\u8bb0\u7684\u65b9\u6cd5\u751f\u6210\u7ed3\u6784\u611f\u77e5\u6b63\u6837\u672c\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u591a\u6837\u53cd\u4e8b\u5b9e\u8d1f\u6837\u672c\uff0c\u7136\u540e\u5e94\u7528\u5bf9\u6bd4\u5b66\u4e60\u3002", "result": "\u5728\u60c5\u611f\u5206\u7c7b\u3001\u6027\u522b\u6b67\u89c6\u68c0\u6d4b\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0cSALAD\u63d0\u5347\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3001\u6027\u80fd\u548c\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SALAD\u65b9\u6cd5\u88ab\u9a8c\u8bc1\u6709\u6548\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u73af\u5883\u4e0b\u7684\u6027\u80fd\u548c\u6cdb\u5316\u3002"}}
{"id": "2504.12051", "pdf": "https://arxiv.org/pdf/2504.12051", "abs": "https://arxiv.org/abs/2504.12051", "authors": ["Xhulja Shahini", "Jone Bartel", "Klaus Pohl"], "title": "On the calibration of Just-in-time Defect Prediction", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Just in time defect prediction (JIT DP) leverages ML to identify defect-prone\ncode commits, enabling quality assurance (QA) teams to allocate resources more\nefficiently by focusing on commits that are most likely to contain defects.\nAlthough JIT DP techniques have introduced improvements in terms of predictive\naccuracy, they are still susceptible to misclassification errors such as false\npositives and negatives. This can lead to wasted resources or undetected\ndefects, a particularly critical concern when QA resources are limited. To\nmitigate these challenges and preserve the practical utility of JIT DP tools,\nit becomes essential to estimate the reliability of the predictions, i.e.,\ncomputing confidence scores. Such scores can help practitioners determine the\ntrustworthiness of predictions and thus prioritize them efficiently. A simple\napproach to computing confidence scores is to extract, alongside each\nprediction, the corresponding prediction probabilities and use them as\nindicators of confidence. However, for these probabilities to reliably serve as\nconfidence scores, the predictive model must be well-calibrated. This means\nthat the prediction probabilities must accurately represent the true likelihood\nof each prediction being correct. Miscalibration, common in modern ML models,\ndistorts probability scores such that they do not align with the actual\ncorrectness probability. In this study, we evaluate the calibration of three\nJIT DP techniques to determine whether and to what extent they exhibit poor\ncalibration. Furthermore, we assess whether post-calibration methods can\nimprove the calibration of existing JIT defect prediction models. Our results\nreveal that all evaluated JIT DP models exhibit some level of miscalibration,\nwith ECE ranging from 2-35%. Furthermore, post-calibration methods do not\nconsistently improve the calibration.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86Just in Time\u7f3a\u9677\u9884\u6d4b\uff08JIT DP\uff09\u6a21\u578b\u7684\u6821\u51c6\u95ee\u9898\uff0c\u53d1\u73b0\u5b58\u5728\u5931\u51c6\u73b0\u8c61\uff0c\u4e14\u540e\u6821\u51c6\u65b9\u6cd5\u672a\u80fd\u4e00\u81f4\u6539\u5584\u3002", "motivation": "\u52a8\u673a\u662f\u51cf\u8f7bJIT DP\u4e2d\u9519\u8bef\u5206\u7c7b\u9519\u8bef\uff0c\u63d0\u9ad8\u9884\u6d4b\u53ef\u9760\u6027\u548c\u8d44\u6e90\u5206\u914d\u6548\u7387\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u8bc4\u4f30\u4e09\u4e2aJIT DP\u6280\u672f\u7684\u6821\u51c6\u6c34\u5e73\uff0c\u5e76\u6d4b\u8bd5\u540e\u6821\u51c6\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6a21\u578b\u7684ECE\u57282-35%\u8303\u56f4\u5185\u6709\u5931\u51c6\uff0c\u540e\u6821\u51c6\u65b9\u6cd5\u4e0d\u4e00\u81f4\u5730\u6539\u5584\u6821\u51c6\u3002", "conclusion": "\u7ed3\u8bba\u662fJIT DP\u6a21\u578b\u5b58\u5728\u6821\u51c6\u95ee\u9898\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u63d0\u5347\u9884\u6d4b\u53ef\u9760\u6027\u3002"}}
{"id": "2504.12187", "pdf": "https://arxiv.org/pdf/2504.12187", "abs": "https://arxiv.org/abs/2504.12187", "authors": ["C\u00e9line Budding"], "title": "What Do Large Language Models Know? Tacit Knowledge as a Potential Causal-Explanatory Structure", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted for publication in Philosophy of Science", "summary": "It is sometimes assumed that Large Language Models (LLMs) know language, or\nfor example that they know that Paris is the capital of France. But what -- if\nanything -- do LLMs actually know? In this paper, I argue that LLMs can acquire\ntacit knowledge as defined by Martin Davies (1990). Whereas Davies himself\ndenies that neural networks can acquire tacit knowledge, I demonstrate that\ncertain architectural features of LLMs satisfy the constraints of semantic\ndescription, syntactic structure, and causal systematicity. Thus, tacit\nknowledge may serve as a conceptual framework for describing, explaining, and\nintervening on LLMs and their behavior.", "AI": {"tldr": "\u672c\u8bba\u6587\u8bba\u8bc1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53ef\u4ee5\u83b7\u5f97\u9a6c\u4e01\u00b7\u6234\u7ef4\u65af\uff081990\uff09\u5b9a\u4e49\u7684\u9ed8\u4f1a\u77e5\u8bc6\uff0c\u5c3d\u7ba1\u6234\u7ef4\u65af\u5426\u8ba4\u795e\u7ecf\u7f51\u7edc\u80fd\u83b7\u5f97\u8fd9\u79cd\u77e5\u8bc6\u3002\u4f5c\u8005\u5c55\u793a\u4e86LLMs\u7684\u67b6\u6784\u7279\u5f81\u6ee1\u8db3\u8bed\u4e49\u63cf\u8ff0\u3001\u53e5\u6cd5\u7ed3\u6784\u548c\u56e0\u679c\u7cfb\u7edf\u6027\u7684\u7ea6\u675f\uff0c\u4ece\u800c\u63d0\u51fa\u9ed8\u4f1a\u77e5\u8bc6\u53ef\u4f5c\u4e3a\u63cf\u8ff0\u3001\u89e3\u91ca\u548c\u5e72\u9884LLMs\u884c\u4e3a\u7684\u6846\u67b6\u3002", "motivation": "\u8d28\u7591LLMs\u662f\u5426\u771f\u6b63'\u77e5\u9053'\u8bed\u8a00\u6216\u4e8b\u5b9e\uff0c\u6311\u6218\u5e38\u89c1\u7684\u5047\u8bbe\uff0c\u63a2\u8ba8LLMs\u5b9e\u9645\u77e5\u9053\u4ec0\u4e48\u3002", "method": "\u901a\u8fc7\u8bba\u8bc1\u548c\u5c55\u793aLLMs\u7684\u67b6\u6784\u7279\u5f81\u662f\u5426\u6ee1\u8db3\u9ed8\u4f1a\u77e5\u8bc6\u7684\u7ea6\u675f\uff0c\u5305\u62ec\u8bed\u4e49\u63cf\u8ff0\u3001\u53e5\u6cd5\u7ed3\u6784\u548c\u56e0\u679c\u7cfb\u7edf\u6027\u3002", "result": "LLMs\u53ef\u4ee5\u83b7\u5f97\u9ed8\u4f1a\u77e5\u8bc6\uff0c\u56e0\u4e3a\u5176\u67b6\u6784\u6ee1\u8db3\u8bed\u4e49\u63cf\u8ff0\u3001\u53e5\u6cd5\u7ed3\u6784\u548c\u56e0\u679c\u7cfb\u7edf\u6027\u7684\u7ea6\u675f\u3002", "conclusion": "\u9ed8\u4f1a\u77e5\u8bc6\u53ef\u4f5c\u4e3a\u63cf\u8ff0\u3001\u89e3\u91ca\u548c\u5e72\u9884LLMs\u884c\u4e3a\u7684\u6982\u5ff5\u6846\u67b6\u3002"}}
{"id": "2504.12192", "pdf": "https://arxiv.org/pdf/2504.12192", "abs": "https://arxiv.org/abs/2504.12192", "authors": ["Tobias Eisenreich"], "title": "From Requirements to Architecture: Semi-Automatically Generating Software Architectures", "categories": ["cs.SE", "cs.AI", "D.2.2"], "comment": "to be published in EMISA 2025", "summary": "To support junior and senior architects, I propose developing a new\narchitecture creation method that leverages LLMs' evolving capabilities to\nsupport the architect. This method involves the architect's close collaboration\nwith LLM-fueled tooling over the whole process. The architect is guided through\nDomain Model creation, Use Case specification, architectural decisions, and\narchitecture evaluation. While the architect can take complete control of the\nprocess and the results, and use the tooling as a building set, they can follow\nthe intended process for maximum tooling support. The preliminary results\nsuggest the feasibility of this process and indicate major time savings for the\narchitect.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u652f\u6301\u5efa\u7b51\u5e08\u521b\u5efa\u67b6\u6784\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5de5\u5177\u534f\u4f5c\u5b9e\u73b0\u65f6\u95f4\u8282\u7701\u3002", "motivation": "\u4e3a\u4e86\u652f\u6301\u521d\u7ea7\u548c\u9ad8\u7ea7\u5efa\u7b51\u5e08\uff0c\u5145\u5206\u5229\u7528LLMs\u7684\u6f14\u8fdb\u80fd\u529b\u6765\u63d0\u5347\u67b6\u6784\u8bbe\u8ba1\u8fc7\u7a0b\u3002", "method": "\u65b9\u6cd5\u6d89\u53ca\u5efa\u7b51\u5e08\u4e0eLLM\u9a71\u52a8\u5de5\u5177\u7684\u7d27\u5bc6\u5408\u4f5c\uff0c\u6db5\u76d6\u9886\u57df\u6a21\u578b\u521b\u5efa\u3001\u7528\u4f8b\u89c4\u8303\u3001\u67b6\u6784\u51b3\u7b56\u548c\u67b6\u6784\u8bc4\u4f30\uff0c\u5efa\u7b51\u5e08\u53ef\u5b8c\u5168\u63a7\u5236\u6216\u9075\u5faa\u8fc7\u7a0b\u4ee5\u83b7\u5f97\u652f\u6301\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u53ef\u884c\uff0c\u5e76\u80fd\u4e3a\u5efa\u7b51\u5e08\u8282\u7701\u5927\u91cf\u65f6\u95f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u53ef\u884c\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u67b6\u6784\u8bbe\u8ba1\u4e2d\u5e94\u7528LLMs\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.12210", "pdf": "https://arxiv.org/pdf/2504.12210", "abs": "https://arxiv.org/abs/2504.12210", "authors": ["Tingyang Sun", "Tuan Nguyen", "Ting He"], "title": "Communication Optimization for Decentralized Learning atop Bandwidth-limited Edge Networks", "categories": ["cs.NI", "cs.AI", "cs.DC", "cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2408.04705", "summary": "Decentralized federated learning (DFL) is a promising machine learning\nparadigm for bringing artificial intelligence (AI) capabilities to the network\nedge. Running DFL on top of edge networks, however, faces severe performance\nchallenges due to the extensive parameter exchanges between agents. Most\nexisting solutions for these challenges were based on simplistic communication\nmodels, which cannot capture the case of learning over a multi-hop\nbandwidth-limited network. In this work, we address this problem by jointly\ndesigning the communication scheme for the overlay network formed by the agents\nand the mixing matrix that controls the communication demands between the\nagents. By carefully analyzing the properties of our problem, we cast each\ndesign problem into a tractable optimization and develop an efficient algorithm\nwith guaranteed performance. Our evaluations based on real topology and data\nshow that the proposed algorithm can reduce the total training time by over\n$80\\%$ compared to the baseline without sacrificing accuracy, while\nsignificantly improving the computational efficiency over the state of the art.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\uff08DFL\uff09\u7684\u901a\u4fe1\u65b9\u6848\uff0c\u901a\u8fc7\u8054\u5408\u8bbe\u8ba1\u7f51\u7edc\u548c\u6df7\u5408\u77e9\u9635\uff0c\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f480%\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "DFL\u5728\u8fb9\u7f18\u7f51\u7edc\u4e0a\u8fd0\u884c\u65f6\uff0c\u7531\u4e8e\u53c2\u6570\u4ea4\u6362\u91cf\u5927\u548c\u591a\u8df3\u5e26\u5bbd\u9650\u5236\uff0c\u6027\u80fd\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u57fa\u4e8e\u7b80\u5355\u6a21\u578b\uff0c\u65e0\u6cd5\u5904\u7406\u591a\u8df3\u7f51\u7edc\u60c5\u51b5\u3002", "method": "\u901a\u8fc7\u5206\u6790\u95ee\u9898\u7279\u6027\uff0c\u5c06\u901a\u4fe1\u65b9\u6848\u548c\u6df7\u5408\u77e9\u9635\u8bbe\u8ba1\u8f6c\u5316\u4e3a\u53ef\u5904\u7406\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u9ad8\u6548\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u57fa\u4e8e\u771f\u5b9e\u62d3\u6251\u548c\u6570\u636e\uff0c\u663e\u793a\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u8d85\u8fc780%\uff0c\u8ba1\u7b97\u6548\u7387\u663e\u8457\u63d0\u9ad8\uff0c\u4e14\u51c6\u786e\u6027\u4e0d\u53d7\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347DFL\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u63d0\u4f9b\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u6848\u3002"}}
{"id": "2504.12215", "pdf": "https://arxiv.org/pdf/2504.12215", "abs": "https://arxiv.org/abs/2504.12215", "authors": ["Ilkin Sevgi Isler", "David Mohaisen", "Curtis Lisle", "Damla Turgut", "Ulas Bagci"], "title": "Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware Post-Processing", "categories": ["cs.CV", "cs.AI"], "comment": "6 pages, 2 figures, to appear in IEEE ADSCA 2025", "summary": "Reliable tumor segmentation in thoracic computed tomography (CT) remains\nchallenging due to boundary ambiguity, class imbalance, and anatomical\nvariability. We propose an uncertainty-guided, coarse-to-fine segmentation\nframework that combines full-volume tumor localization with refined\nregion-of-interest (ROI) segmentation, enhanced by anatomically aware\npost-processing. The first-stage model generates a coarse prediction, followed\nby anatomically informed filtering based on lung overlap, proximity to lung\nsurfaces, and component size. The resulting ROIs are segmented by a\nsecond-stage model trained with uncertainty-aware loss functions to improve\naccuracy and boundary calibration in ambiguous regions. Experiments on private\nand public datasets demonstrate improvements in Dice and Hausdorff scores, with\nfewer false positives and enhanced spatial interpretability. These results\nhighlight the value of combining uncertainty modeling and anatomical priors in\ncascaded segmentation pipelines for robust and clinically meaningful tumor\ndelineation. On the Orlando dataset, our framework improved Swin UNETR Dice\nfrom 0.4690 to 0.6447. Reduction in spurious components was strongly correlated\nwith segmentation gains, underscoring the value of anatomically informed\npost-processing.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u7684\u7c97\u5230\u7ec6\u5206\u5272\u6846\u67b6\uff0c\u7528\u4e8eCT\u626b\u63cf\u4e2d\u7684\u80bf\u7624\u5206\u5272\uff0c\u901a\u8fc7\u6574\u5408\u89e3\u5256\u5b66\u5148\u9a8c\u548c\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u80bf\u7624\u5206\u5272\u4e2d\u7684\u8fb9\u754c\u6a21\u7cca\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u89e3\u5256\u53d8\u5f02\u6027\u7b49\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u751f\u6210\u7c97\u7565\u9884\u6d4b\u5e76\u8fdb\u884c\u57fa\u4e8e\u80ba\u91cd\u53e0\u3001\u63a5\u8fd1\u80ba\u8868\u9762\u548c\u7ec4\u4ef6\u5927\u5c0f\u7684\u89e3\u5256\u5b66\u8fc7\u6ee4\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u635f\u5931\u51fd\u6570\u8bad\u7ec3\u6a21\u578b\u4ee5\u6539\u8fdb\u6a21\u7cca\u533a\u57df\u7684\u51c6\u786e\u6027\u548c\u8fb9\u754c\u6821\u51c6\u3002", "result": "\u5728Orlando\u6570\u636e\u96c6\u4e0a\uff0c\u5c06Swin UNETR\u7684Dice\u5206\u6570\u4ece0.4690\u63d0\u9ad8\u52300.6447\uff0c\u6539\u5584Hausdorff\u5206\u6570\uff0c\u51cf\u5c11\u5047\u9633\u6027\uff0c\u5e76\u589e\u5f3a\u7a7a\u95f4\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u7ed3\u5408\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u548c\u89e3\u5256\u5b66\u5148\u9a8c\u53ef\u63d0\u5347\u7ea7\u8054\u5206\u5272\u7ba1\u9053\u7684\u9c81\u68d2\u6027\u548c\u4e34\u5e8a\u610f\u4e49\uff0c\u7528\u4e8e\u80bf\u7624\u63cf\u7ed8\u3002"}}
{"id": "2504.12167", "pdf": "https://arxiv.org/pdf/2504.12167", "abs": "https://arxiv.org/abs/2504.12167", "authors": ["Yuan Luo", "Rudolf Hoffmann", "Yan Xia", "Olaf Wysocki", "Benedikt Schwab", "Thomas H. Kolbe", "Daniel Cremers"], "title": "RADLER: Radar Object Detection Leveraging Semantic 3D City Models and Self-Supervised Radar-Image Learning", "categories": ["cs.CV", "cs.LG"], "comment": "The paper accepted for CVPRW '25 (PBVS 2025 - the Perception Beyond\n  the Visible Spectrum)", "summary": "Semantic 3D city models are worldwide easy-accessible, providing accurate,\nobject-oriented, and semantic-rich 3D priors. To date, their potential to\nmitigate the noise impact on radar object detection remains under-explored. In\nthis paper, we first introduce a unique dataset, RadarCity, comprising 54K\nsynchronized radar-image pairs and semantic 3D city models. Moreover, we\npropose a novel neural network, RADLER, leveraging the effectiveness of\ncontrastive self-supervised learning (SSL) and semantic 3D city models to\nenhance radar object detection of pedestrians, cyclists, and cars.\nSpecifically, we first obtain the robust radar features via a SSL network in\nthe radar-image pretext task. We then use a simple yet effective feature fusion\nstrategy to incorporate semantic-depth features from semantic 3D city models.\nHaving prior 3D information as guidance, RADLER obtains more fine-grained\ndetails to enhance radar object detection. We extensively evaluate RADLER on\nthe collected RadarCity dataset and demonstrate average improvements of 5.46%\nin mean avarage precision (mAP) and 3.51% in mean avarage recall (mAR) over\nprevious radar object detection methods. We believe this work will foster\nfurther research on semantic-guided and map-supported radar object detection.\nOur project page is publicly available\nathttps://gpp-communication.github.io/RADLER .", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165RadarCity\u6570\u636e\u96c6\u548cRADLER\u795e\u7ecf\u7f51\u7edc\uff0c\u4f7f\u7528\u5bf9\u6bd4\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u8bed\u4e493D\u57ce\u5e02\u6a21\u578b\u63d0\u5347\u96f7\u8fbe\u7269\u4f53\u68c0\u6d4b\u3002", "motivation": "\u8bed\u4e493D\u57ce\u5e02\u6a21\u578b\u6613\u83b7\u53d6\u4e14\u4fe1\u606f\u4e30\u5bcc\uff0c\u4f46\u5c1a\u672a\u5145\u5206\u7528\u4e8e\u51cf\u5c11\u96f7\u8fbe\u68c0\u6d4b\u4e2d\u7684\u566a\u58f0\u5f71\u54cd\u3002", "method": "\u63d0\u51faRADLER\u7f51\u7edc\uff0c\u901a\u8fc7\u5bf9\u6bd4\u81ea\u76d1\u7763\u5b66\u4e60\u83b7\u53d6\u96f7\u8fbe\u7279\u5f81\uff0c\u5e76\u878d\u5408\u8bed\u4e493D\u57ce\u5e02\u6a21\u578b\u7684\u8bed\u4e49\u6df1\u5ea6\u7279\u5f81\u3002", "result": "\u5728RadarCity\u6570\u636e\u96c6\u4e0a\uff0cmAP\u5e73\u5747\u63d0\u53475.46%\uff0cmAR\u5e73\u5747\u63d0\u53473.51%\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c06\u63a8\u52a8\u8bed\u4e49\u5f15\u5bfc\u548c\u5730\u56fe\u652f\u6301\u7684\u96f7\u8fbe\u7269\u4f53\u68c0\u6d4b\u7814\u7a76\u3002"}}
{"id": "2504.12256", "pdf": "https://arxiv.org/pdf/2504.12256", "abs": "https://arxiv.org/abs/2504.12256", "authors": ["Andreas Plesner", "Turlan Kuzhagaliyev", "Roger Wattenhofer"], "title": "FLIP Reasoning Challenge", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Published at First Workshop on Open Science for Foundation Models at\n  ICLR 2025", "summary": "Over the past years, advances in artificial intelligence (AI) have\ndemonstrated how AI can solve many perception and generation tasks, such as\nimage classification and text writing, yet reasoning remains a challenge. This\npaper introduces the FLIP dataset, a benchmark for evaluating AI reasoning\ncapabilities based on human verification tasks on the Idena blockchain. FLIP\nchallenges present users with two orderings of 4 images, requiring them to\nidentify the logically coherent one. By emphasizing sequential reasoning,\nvisual storytelling, and common sense, FLIP provides a unique testbed for\nmultimodal AI systems. Our experiments evaluate state-of-the-art models,\nleveraging both vision-language models (VLMs) and large language models (LLMs).\nResults reveal that even the best open-sourced and closed-sourced models\nachieve maximum accuracies of 75.5% and 77.9%, respectively, in zero-shot\nsettings, compared to human performance of 95.3%. Captioning models aid\nreasoning models by providing text descriptions of images, yielding better\nresults than when using the raw images directly, 69.6% vs. 75.2% for Gemini 1.5\nPro. Combining the predictions from 15 models in an ensemble increases the\naccuracy to 85.2%. These findings highlight the limitations of existing\nreasoning models and the need for robust multimodal benchmarks like FLIP. The\nfull codebase and dataset will be available at\nhttps://github.com/aplesner/FLIP-Reasoning-Challenge.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165FLIP\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u5728\u56fe\u50cf\u6392\u5e8f\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u51c6\u786e\u7387\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\uff0c\u5e76\u901a\u8fc7\u5b57\u5e55\u548c\u96c6\u6210\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\u3002", "motivation": "AI\u5728\u611f\u77e5\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u8fdb\u6b65\u663e\u8457\uff0c\u4f46\u63a8\u7406\u80fd\u529b\u4ecd\u8584\u5f31\uff0c\u56e0\u6b64\u9700\u8981\u57fa\u4e8e\u4eba\u7c7b\u9a8c\u8bc1\u4efb\u52a1\u7684\u57fa\u51c6\u5982FLIP\u6765\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528FLIP\u6570\u636e\u96c6\uff0c\u57fa\u4e8eIdena\u533a\u5757\u94fe\u7684\u4efb\u52a1\uff0c\u8bc4\u4f30VLMs\u548cLLMs\u5728\u8bc6\u522b\u56fe\u50cf\u903b\u8f91\u987a\u5e8f\u65b9\u9762\u7684\u6027\u80fd\uff0c\u5e76\u6d4b\u8bd5\u5b57\u5e55\u6a21\u578b\u548c\u6a21\u578b\u96c6\u6210\u65b9\u6cd5\u3002", "result": "\u6700\u5148\u8fdb\u6a21\u578b\u96f6\u6837\u672c\u51c6\u786e\u7387\u6700\u9ad877.9%\uff0c\u4eba\u7c7b\u4e3a95.3%\uff1b\u5b57\u5e55\u6a21\u578b\u63d0\u5347\u51c6\u786e\u7387\u81f375.2%\uff0c\u96c6\u621015\u4e2a\u6a21\u578b\u8fbe85.2%\u3002", "conclusion": "\u63ed\u793a\u73b0\u6709\u6a21\u578b\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u9700\u8981\u50cfFLIP\u8fd9\u6837\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6765\u63a8\u52a8AI\u63a8\u7406\u53d1\u5c55\u3002"}}
{"id": "2504.12175", "pdf": "https://arxiv.org/pdf/2504.12175", "abs": "https://arxiv.org/abs/2504.12175", "authors": ["Yuling Jiao", "Yanming Lai", "Defeng Sun", "Yang Wang", "Bokai Yan"], "title": "Approximation Bounds for Transformer Networks with Application to Regression", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We explore the approximation capabilities of Transformer networks for\nH\\\"older and Sobolev functions, and apply these results to address\nnonparametric regression estimation with dependent observations. First, we\nestablish novel upper bounds for standard Transformer networks approximating\nsequence-to-sequence mappings whose component functions are H\\\"older continuous\nwith smoothness index $\\gamma \\in (0,1]$. To achieve an approximation error\n$\\varepsilon$ under the $L^p$-norm for $p \\in [1, \\infty]$, it suffices to use\na fixed-depth Transformer network whose total number of parameters scales as\n$\\varepsilon^{-d_x n / \\gamma}$. This result not only extends existing findings\nto include the case $p = \\infty$, but also matches the best known upper bounds\non number of parameters previously obtained for fixed-depth FNNs and RNNs.\nSimilar bounds are also derived for Sobolev functions. Second, we derive\nexplicit convergence rates for the nonparametric regression problem under\nvarious $\\beta$-mixing data assumptions, which allow the dependence between\nobservations to weaken over time. Our bounds on the sample complexity impose no\nconstraints on weight magnitudes. Lastly, we propose a novel proof strategy to\nestablish approximation bounds, inspired by the Kolmogorov-Arnold\nrepresentation theorem. We show that if the self-attention layer in a\nTransformer can perform column averaging, the network can approximate\nsequence-to-sequence H\\\"older functions, offering new insights into the\ninterpretability of self-attention mechanisms.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8Transformer\u7f51\u7edc\u5bf9H\u00f6lder\u548cSobolev\u51fd\u6570\u7684\u903c\u8fd1\u80fd\u529b\uff0c\u5e76\u5e94\u7528\u4e8e\u975e\u53c2\u6570\u56de\u5f52\u4f30\u8ba1\uff0c\u5efa\u7acb\u4e86\u903c\u8fd1\u8bef\u5dee\u4e0a\u754c\u548c\u6536\u655b\u7387\u3002", "motivation": "\u63a2\u7d22Transformer\u5728\u51fd\u6570\u903c\u8fd1\u548c\u5904\u7406\u4f9d\u8d56\u89c2\u6d4b\u56de\u5f52\u4e2d\u7684\u80fd\u529b\u3002", "method": "\u5efa\u7acb\u903c\u8fd1\u4e0a\u754c\u3001\u63a8\u5bfc\u56de\u5f52\u6536\u655b\u7387\uff0c\u5e76\u4f7f\u7528Kolmogorov-Arnold\u8868\u793a\u5b9a\u7406\u7684\u8bc1\u660e\u7b56\u7565\u3002", "result": "Transformer\u53c2\u6570\u89c4\u6a21\u4e3a\u03b5^{-d_x n / \u03b3}\uff0c\u9002\u7528\u4e8e\u4e0d\u540cp\u503c\uff0c\u5e76\u7ed9\u51fa\u65e0\u6743\u91cd\u7ea6\u675f\u7684\u6536\u655b\u7387\u548cself-attention\u89e3\u91ca\u3002", "conclusion": "\u589e\u5f3a\u4e86\u5bf9Transformer\u903c\u8fd1\u80fd\u529b\u548cself-attention\u673a\u5236\u7684\u7406\u89e3\u3002"}}
{"id": "2504.12186", "pdf": "https://arxiv.org/pdf/2504.12186", "abs": "https://arxiv.org/abs/2504.12186", "authors": ["Alejandro Newell", "Peiyun Hu", "Lahav Lipson", "Stephan R. Richter", "Vladlen Koltun"], "title": "CoMotion: Concurrent Multi-person 3D Motion", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at ICLR 2025, for code and weights go to\n  https://github.com/apple/ml-comotion", "summary": "We introduce an approach for detecting and tracking detailed 3D poses of\nmultiple people from a single monocular camera stream. Our system maintains\ntemporally coherent predictions in crowded scenes filled with difficult poses\nand occlusions. Our model performs both strong per-frame detection and a\nlearned pose update to track people from frame to frame. Rather than match\ndetections across time, poses are updated directly from a new input image,\nwhich enables online tracking through occlusion. We train on numerous image and\nvideo datasets leveraging pseudo-labeled annotations to produce a model that\nmatches state-of-the-art systems in 3D pose estimation accuracy while being\nfaster and more accurate in tracking multiple people through time. Code and\nweights are provided at https://github.com/apple/ml-comotion", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u4ece\u5355\u76ee\u6444\u50cf\u5934\u6d41\u4e2d\u68c0\u6d4b\u548c\u8ddf\u8e2a\u591a\u4e2a\u4eba\u7684\u8be6\u7ec63D\u59ff\u52bf\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u62e5\u6324\u573a\u666f\u4e2d\u5904\u7406\u56f0\u96be\u59ff\u52bf\u548c\u906e\u6321\u3002", "motivation": "\u4e3a\u4e86\u5728\u62e5\u6324\u4e14\u6709\u906e\u6321\u7684\u573a\u666f\u4e2d\u7ef4\u6301\u65f6\u95f4\u8fde\u8d2f\u7684\u591a\u4eba3D\u59ff\u52bf\u9884\u6d4b\uff0c\u63d0\u9ad8\u8ddf\u8e2a\u9c81\u68d2\u6027\u3002", "method": "\u6a21\u578b\u7ed3\u5408\u5f3a\u6709\u529b\u7684\u6bcf\u5e27\u68c0\u6d4b\u548c\u5b66\u4e60\u59ff\u52bf\u66f4\u65b0\uff0c\u76f4\u63a5\u4ece\u65b0\u8f93\u5165\u56fe\u50cf\u66f4\u65b0\u59ff\u52bf\uff0c\u800c\u975e\u8de8\u65f6\u95f4\u5339\u914d\u68c0\u6d4b\u3002", "result": "\u6a21\u578b\u57283D\u59ff\u52bf\u4f30\u8ba1\u51c6\u786e\u6027\u4e0a\u5339\u914d\u6700\u5148\u8fdb\u7cfb\u7edf\uff0c\u540c\u65f6\u5728\u591a\u4eba\u8ddf\u8e2a\u4e2d\u66f4\u5feb\u66f4\u51c6\u786e\uff0c\u5e76\u63d0\u4f9b\u4e86\u4ee3\u7801\u548c\u6743\u91cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6539\u8fdb\u4e86\u591a\u4eba3D\u59ff\u52bf\u8ddf\u8e2a\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5728\u7ebf\u5904\u7406\u906e\u6321\u65f6\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2504.12268", "pdf": "https://arxiv.org/pdf/2504.12268", "abs": "https://arxiv.org/abs/2504.12268", "authors": ["Stefan Abi-Karam", "Cong Hao"], "title": "HLS-Eval: A Benchmark and Framework for Evaluating LLMs on High-Level Synthesis Design Tasks", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "The rapid scaling of large language model (LLM) training and inference has\ndriven their adoption in semiconductor design across academia and industry.\nWhile most prior work evaluates LLMs on hardware description language (HDL)\ntasks, particularly Verilog, designers are increasingly using high-level\nsynthesis (HLS) to build domain-specific accelerators and complex hardware\nsystems. However, benchmarks and tooling to comprehensively evaluate LLMs for\nHLS design tasks remain scarce.\n  To address this, we introduce HLS-Eval, the first complete benchmark and\nevaluation framework for LLM-driven HLS design. HLS-Eval targets two core\ntasks: (1) generating HLS code from natural language descriptions, and (2)\nperforming HLS-specific code edits to optimize performance and hardware\nefficiency. The benchmark includes 94 unique designs drawn from standard HLS\nbenchmarks and novel sources. Each case is prepared via a semi-automated flow\nthat produces a natural language description and a paired testbench for\nC-simulation and synthesis validation, ensuring each task is \"LLM-ready.\"\n  Beyond the benchmark, HLS-Eval offers a modular Python framework for\nautomated, parallel evaluation of both local and hosted LLMs. It includes a\nparallel evaluation engine, direct HLS tool integration, and abstractions for\nto support different LLM interaction paradigms, enabling rapid prototyping of\nnew benchmarks, tasks, and LLM methods.\n  We demonstrate HLS-Eval through baseline evaluations of open-source LLMs on\nVitis HLS, measuring outputs across four key metrics - parseability,\ncompilability, runnability, and synthesizability - reflecting the iterative HLS\ndesign cycle. We also report pass@k metrics, establishing clear baselines and\nreusable infrastructure for the broader LLM-for-hardware community.\n  All benchmarks, framework code, and results are open-sourced at\nhttps://github.com/stefanpie/hls-eval.", "AI": {"tldr": "\u5f15\u5165HLS-Eval\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u9ad8\u9636\u7efc\u5408\uff08HLS\uff09\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5305\u62ec\u4ee3\u7801\u751f\u6210\u548c\u4f18\u5316\u3002", "motivation": "LLM\u5728\u534a\u5bfc\u4f53\u8bbe\u8ba1\u4e2d\u5feb\u901f\u5e94\u7528\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9HLS\u4efb\u52a1\u7684\u5168\u9762\u57fa\u51c6\u548c\u5de5\u5177\u3002", "method": "\u5f00\u53d1HLS-Eval\u57fa\u51c6\u548cPython\u6846\u67b6\uff0c\u5305\u542b94\u4e2a\u8bbe\u8ba1\uff0c\u652f\u6301\u81ea\u52a8\u5316\u8bc4\u4f30\u548cHLS\u5de5\u5177\u96c6\u6210\u3002", "result": "\u8fdb\u884c\u4e86\u57fa\u7ebf\u8bc4\u4f30\uff0c\u6d4b\u91cf\u89e3\u6790\u6027\u3001\u53ef\u7f16\u8bd1\u6027\u7b49\u6307\u6807\uff0c\u5e76\u5f00\u6e90\u4e86\u6240\u6709\u5185\u5bb9\u3002", "conclusion": "\u4e3aLLM\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u53ef\u91cd\u7528\u57fa\u7840\u8bbe\u65bd\uff0c\u5efa\u7acb\u6e05\u6670\u57fa\u51c6\u3002"}}
{"id": "2504.12284", "pdf": "https://arxiv.org/pdf/2504.12284", "abs": "https://arxiv.org/abs/2504.12284", "authors": ["Aditya Prakash", "Benjamin Lundell", "Dmitry Andreychuk", "David Forsyth", "Saurabh Gupta", "Harpreet Sawhney"], "title": "How Do I Do That? Synthesizing 3D Hand Motion and Contacts for Everyday Interactions", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "CVPR 2025, Project page:\n  https://ap229997.github.io/projects/latentact", "summary": "We tackle the novel problem of predicting 3D hand motion and contact maps (or\nInteraction Trajectories) given a single RGB view, action text, and a 3D\ncontact point on the object as input. Our approach consists of (1) Interaction\nCodebook: a VQVAE model to learn a latent codebook of hand poses and contact\npoints, effectively tokenizing interaction trajectories, (2) Interaction\nPredictor: a transformer-decoder module to predict the interaction trajectory\nfrom test time inputs by using an indexer module to retrieve a latent\naffordance from the learned codebook. To train our model, we develop a data\nengine that extracts 3D hand poses and contact trajectories from the diverse\nHoloAssist dataset. We evaluate our model on a benchmark that is 2.5-10X larger\nthan existing works, in terms of diversity of objects and interactions\nobserved, and test for generalization of the model across object categories,\naction categories, tasks, and scenes. Experimental results show the\neffectiveness of our approach over transformer & diffusion baselines across all\nsettings.", "AI": {"tldr": "\u672c\u8bba\u6587\u89e3\u51b3\u4ece\u5355RGB\u89c6\u56fe\u3001\u52a8\u4f5c\u6587\u672c\u548c3D\u63a5\u89e6\u70b9\u9884\u6d4b3D\u624b\u90e8\u8fd0\u52a8\u548c\u63a5\u89e6\u56fe\u7684\u65b0\u95ee\u9898\uff0c\u4f7f\u7528VQVAE\u548cTransformer\u6a21\u578b\u3002", "motivation": "\u52a8\u673a\u662f\u5904\u7406\u4e00\u4e2a\u65b0\u9896\u7684\u9884\u6d4b\u624b\u90e8\u4ea4\u4e92\u8f68\u8ff9\u95ee\u9898\uff0c\u4ee5\u63d0\u5347\u4eba\u673a\u4ea4\u4e92\u6216\u865a\u62df\u73b0\u5b9e\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528VQVAE\u5b66\u4e60\u4ea4\u4e92\u4ee3\u7801\u672c\u548cTransformer\u89e3\u7801\u5668\u9884\u6d4b\u4ea4\u4e92\u8f68\u8ff9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u624b\u90e8\u4ea4\u4e92\u9884\u6d4b\u95ee\u9898\uff0c\u5e76\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u51c6\u3002"}}
{"id": "2504.12189", "pdf": "https://arxiv.org/pdf/2504.12189", "abs": "https://arxiv.org/abs/2504.12189", "authors": ["Kiljae Lee", "Yuan Zhang"], "title": "Leave-One-Out Stable Conformal Prediction", "categories": ["stat.ML", "cs.LG"], "comment": "Accepted at ICLR 2025", "summary": "Conformal prediction (CP) is an important tool for distribution-free\npredictive uncertainty quantification. Yet, a major challenge is to balance\ncomputational efficiency and prediction accuracy, particularly for multiple\npredictions. We propose Leave-One-Out Stable Conformal Prediction (LOO-StabCP),\na novel method to speed up full conformal using algorithmic stability without\nsample splitting. By leveraging leave-one-out stability, our method is much\nfaster in handling a large number of prediction requests compared to existing\nmethod RO-StabCP based on replace-one stability. We derived stability bounds\nfor several popular machine learning tools: regularized loss minimization (RLM)\nand stochastic gradient descent (SGD), as well as kernel method, neural\nnetworks and bagging. Our method is theoretically justified and demonstrates\nsuperior numerical performance on synthetic and real-world data. We applied our\nmethod to a screening problem, where its effective exploitation of training\ndata led to improved test power compared to state-of-the-art method based on\nsplit conformal.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLOO-StabCP\u65b9\u6cd5\uff0c\u65e8\u5728\u52a0\u901f\u5171\u5f62\u9884\u6d4b\uff0c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5171\u5f62\u9884\u6d4b\u4e2d\u8ba1\u7b97\u6548\u7387\u4e0e\u9884\u6d4b\u51c6\u786e\u6027\u7684\u5e73\u8861\u6311\u6218\uff0c\u7279\u522b\u662f\u9488\u5bf9\u591a\u4e2a\u9884\u6d4b\u8bf7\u6c42\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eleave-one-out\u7a33\u5b9a\u6027\u7684LOO-StabCP\u65b9\u6cd5\uff0c\u4e0d\u4f9d\u8d56\u6837\u672c\u5206\u5272\uff1b\u4e3aRLM\u3001SGD\u3001\u6838\u65b9\u6cd5\u3001\u795e\u7ecf\u7f51\u7edc\u548cbagging\u5bfc\u51fa\u4e86\u7a33\u5b9a\u6027\u754c\u3002", "result": "\u65b9\u6cd5\u7406\u8bba\u4e0a\u5f97\u5230\u8bc1\u660e\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\uff1b\u5728\u7b5b\u9009\u95ee\u9898\u4e2d\uff0c\u6d4b\u8bd5\u529f\u7387\u4f18\u4e8e\u57fa\u4e8e\u5206\u5272\u5171\u5f62\u7684state-of-the-art\u65b9\u6cd5\u3002", "conclusion": "LOO-StabCP\u65b9\u6cd5\u6709\u6548\u5229\u7528\u8bad\u7ec3\u6570\u636e\uff0c\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4f18\u52bf\u3002"}}
{"id": "2504.12292", "pdf": "https://arxiv.org/pdf/2504.12292", "abs": "https://arxiv.org/abs/2504.12292", "authors": ["Liam Schoneveld", "Zhe Chen", "Davide Davoli", "Jiapeng Tang", "Saimon Terazawa", "Ko Nishino", "Matthias Nie\u00dfner"], "title": "SHeaP: Self-Supervised Head Geometry Predictor Learned via 2D Gaussians", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "For video demonstrations and additional materials please see\n  https://nlml.github.io/sheap/", "summary": "Accurate, real-time 3D reconstruction of human heads from monocular images\nand videos underlies numerous visual applications. As 3D ground truth data is\nhard to come by at scale, previous methods have sought to learn from abundant\n2D videos in a self-supervised manner. Typically, this involves the use of\ndifferentiable mesh rendering, which is effective but faces limitations. To\nimprove on this, we propose SHeaP (Self-supervised Head Geometry Predictor\nLearned via 2D Gaussians). Given a source image, we predict a 3DMM mesh and a\nset of Gaussians that are rigged to this mesh. We then reanimate this rigged\nhead avatar to match a target frame, and backpropagate photometric losses to\nboth the 3DMM and Gaussian prediction networks. We find that using Gaussians\nfor rendering substantially improves the effectiveness of this self-supervised\napproach. Training solely on 2D data, our method surpasses existing\nself-supervised approaches in geometric evaluations on the NoW benchmark for\nneutral faces and a new benchmark for non-neutral expressions. Our method also\nproduces highly expressive meshes, outperforming state-of-the-art in emotion\nclassification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSHeaP\u65b9\u6cd5\uff0c\u4f7f\u75282D\u9ad8\u65af\u51fd\u6570\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6765\u63d0\u5347\u4ece\u5355\u76ee\u56fe\u50cf\u4e2d\u91cd\u5efa3D\u4eba\u5934\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u7531\u4e8e3D\u771f\u5b9e\u6570\u636e\u7a00\u7f3a\u4e14\u73b0\u6709\u53ef\u5fae\u6e32\u67d3\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u6539\u8fdb\u81ea\u76d1\u7763\u5b66\u4e60\u4ece2D\u89c6\u9891\u4e2d\u5b66\u4e60\u7684\u65b9\u6cd5\u3002", "method": "\u9884\u6d4b3DMM\u7f51\u683c\u548c\u7ed1\u5b9a\u5230\u7f51\u683c\u76842D\u9ad8\u65af\u51fd\u6570\uff0c\u7136\u540e\u901a\u8fc7\u518d\u73b0\u52a8\u753b\u5339\u914d\u76ee\u6807\u5e27\u5e76\u53cd\u5411\u4f20\u64ad\u5149\u5ea6\u635f\u5931\u6765\u4f18\u5316\u3002", "result": "\u5728NoW\u57fa\u51c6\u548c\u65b0\u7684\u975e\u4e2d\u6027\u8868\u60c5\u57fa\u51c6\u4e0a\u8d85\u8d8a\u73b0\u6709\u81ea\u76d1\u7763\u65b9\u6cd5\uff0c\u5728\u51e0\u4f55\u8bc4\u4f30\u548c\u60c5\u611f\u5206\u7c7b\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u4f7f\u7528\u9ad8\u65af\u51fd\u6570\u6e32\u67d3\u663e\u8457\u63d0\u9ad8\u4e86\u81ea\u76d1\u77633D\u4eba\u5934\u91cd\u5efa\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u8868\u73b0\u529b\u3002"}}
{"id": "2504.12216", "pdf": "https://arxiv.org/pdf/2504.12216", "abs": "https://arxiv.org/abs/2504.12216", "authors": ["Siyan Zhao", "Devaansh Gupta", "Qinqing Zheng", "Aditya Grover"], "title": "d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning", "categories": ["cs.CL", "cs.LG"], "comment": "25 pages, project page at https://dllm-reasoning.github.io/", "summary": "Recent large language models (LLMs) have demonstrated strong reasoning\ncapabilities that benefits from online reinforcement learning (RL). These\ncapabilities have primarily been demonstrated within the left-to-right\nautoregressive (AR) generation paradigm. In contrast, non-autoregressive\nparadigms based on diffusion generate text in a coarse-to-fine manner. Although\nrecent diffusion-based large language models (dLLMs) have achieved competitive\nlanguage modeling performance compared to their AR counterparts, it remains\nunclear if dLLMs can also leverage recent advances in LLM reasoning. To this\nend, we propose d1, a framework to adapt pre-trained masked dLLMs into\nreasoning models via a combination of supervised finetuning (SFT) and RL.\nSpecifically, we develop and extend techniques to improve reasoning in\npretrained dLLMs: (a) we utilize a masked SFT technique to distill knowledge\nand instill self-improvement behavior directly from existing datasets, and (b)\nwe introduce a novel critic-free, policy-gradient based RL algorithm called\ndiffu-GRPO. Through empirical studies, we investigate the performance of\ndifferent post-training recipes on multiple mathematical and logical reasoning\nbenchmarks. We find that d1 yields the best performance and significantly\nimproves performance of a state-of-the-art dLLM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fad1\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u65b0\u578b\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u63d0\u5347\u6269\u6563\u578bLLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u663e\u8457\u6539\u5584\u3002", "motivation": "\u63a2\u8ba8\u57fa\u4e8e\u6269\u6563\u7684LLM\u662f\u5426\u80fd\u5229\u7528\u73b0\u6709\u63a8\u7406\u8fdb\u5c55\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u8fdb\u5c55\u4e3b\u8981\u5728\u81ea\u56de\u5f52\u6a21\u578b\u4e0a\u3002", "method": "\u63d0\u51fad1\u6846\u67b6\uff0c\u7ed3\u5408\u63a9\u7801\u76d1\u7763\u5fae\u8c03\u548cdiffu-GRPO\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u5728\u6570\u5b66\u548c\u903b\u8f91\u63a8\u7406\u57fa\u51c6\u4e0a\uff0cd1\u6846\u67b6\u8868\u73b0\u6700\u4f73\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u6700\u5148\u8fdbdLLM\u7684\u6027\u80fd\u3002", "conclusion": "\u8bc1\u660ed1\u6846\u67b6\u6709\u6548\uff0c\u5c55\u793a\u4e86\u975e\u81ea\u56de\u5f52\u8303\u5f0f\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2504.12249", "pdf": "https://arxiv.org/pdf/2504.12249", "abs": "https://arxiv.org/abs/2504.12249", "authors": ["Zhijin He", "Alan B. McMillan"], "title": "Comparative Evaluation of Radiomics and Deep Learning Models for Disease Detection in Chest Radiography", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "The application of artificial intelligence (AI) in medical imaging has\nrevolutionized diagnostic practices, enabling advanced analysis and\ninterpretation of radiological data. This study presents a comprehensive\nevaluation of radiomics-based and deep learning-based approaches for disease\ndetection in chest radiography, focusing on COVID-19, lung opacity, and viral\npneumonia. While deep learning models, particularly convolutional neural\nnetworks (CNNs) and vision transformers (ViTs), learn directly from image data,\nradiomics-based models extract and analyze quantitative features, potentially\nproviding advantages in data-limited scenarios. This study systematically\ncompares the diagnostic accuracy and robustness of various AI models, including\nDecision Trees, Gradient Boosting, Random Forests, Support Vector Machines\n(SVM), and Multi-Layer Perceptrons (MLP) for radiomics, against\nstate-of-the-art computer vision deep learning architectures. Performance\nmetrics across varying sample sizes reveal insights into each model's efficacy,\nhighlighting the contexts in which specific AI approaches may offer enhanced\ndiagnostic capabilities. The results aim to inform the integration of AI-driven\ndiagnostic tools in clinical practice, particularly in automated and\nhigh-throughput environments where timely, reliable diagnosis is critical. This\ncomparative study addresses an essential gap, establishing guidance for the\nselection of AI models based on clinical and operational needs.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u653e\u5c04\u7ec4\u5b66\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u80f8\u90e8X\u5149\u68c0\u6d4bCOVID-19\u3001\u80ba\u4e0d\u900f\u660e\u548c\u75c5\u6bd2\u6027\u80ba\u708e\u4e2d\u7684\u8bca\u65ad\u6027\u80fd\u3002", "motivation": "AI\u5728\u533b\u7597\u6210\u50cf\u4e2d\u7684\u5e94\u7528\u9769\u547d\u6027\uff0c\u9700\u8981\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u4ee5\u5728\u6570\u636e\u6709\u9650\u573a\u666f\u4e0b\u63d0\u5347\u8bca\u65ad\u51c6\u786e\u6027\uff0c\u5e76\u6307\u5bfc\u4e34\u5e8a\u5b9e\u8df5\u3002", "method": "\u7cfb\u7edf\u6bd4\u8f83\u653e\u5c04\u7ec4\u5b66\u6a21\u578b\uff08\u5982\u51b3\u7b56\u6811\u3001\u68af\u5ea6\u63d0\u5347\u3001\u968f\u673a\u68ee\u6797\u3001SVM\u3001MLP\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5982CNN\u3001ViT\uff09\u7684\u8bca\u65ad\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5728\u4e0d\u540c\u6837\u672c\u5927\u5c0f\u4e0b\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u7ed3\u679c\u63ed\u793a\u4e86\u5404\u6a21\u578b\u7684\u6548\u80fd\u548c\u9002\u7528\u60c5\u5883\uff0c\u7a81\u51fa\u4e86\u7279\u5b9aAI\u65b9\u6cd5\u5728\u67d0\u4e9b\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u4f18\u52bf\u3002", "conclusion": "\u7814\u7a76\u586b\u8865\u4e86AI\u6a21\u578b\u9009\u62e9\u6307\u5bfc\u7684\u7a7a\u767d\uff0c\u4fc3\u8fdbAI\u5728\u81ea\u52a8\u5316\u3001\u9ad8\u901a\u91cf\u4e34\u5e8a\u8bca\u65ad\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2504.12272", "pdf": "https://arxiv.org/pdf/2504.12272", "abs": "https://arxiv.org/abs/2504.12272", "authors": ["Kong Ka Hing", "Mehran Behjati"], "title": "Edge Intelligence for Wildlife Conservation: Real-Time Hornbill Call Classification Using TinyML", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "This is a preprint version of a paper accepted and published in\n  Springer Lecture Notes in Networks and Systems. The final version is\n  available at https://doi.org/10.1007/978-981-96-3949-6_40", "summary": "Hornbills, an iconic species of Malaysia's biodiversity, face threats from\nhabi-tat loss, poaching, and environmental changes, necessitating accurate and\nreal-time population monitoring that is traditionally challenging and re-source\nintensive. The emergence of Tiny Machine Learning (TinyML) offers a chance to\ntransform wildlife monitoring by enabling efficient, real-time da-ta analysis\ndirectly on edge devices. Addressing the challenge of wildlife conservation,\nthis research paper explores the pivotal role of machine learn-ing,\nspecifically TinyML, in the classification and monitoring of hornbill calls in\nMalaysia. Leveraging audio data from the Xeno-canto database, the study aims to\ndevelop a speech recognition system capable of identifying and classifying\nhornbill vocalizations. The proposed methodology involves pre-processing the\naudio data, extracting features using Mel-Frequency Energy (MFE), and deploying\nthe model on an Arduino Nano 33 BLE, which is adept at edge computing. The\nresearch encompasses foundational work, in-cluding a comprehensive\nintroduction, literature review, and methodology. The model is trained using\nEdge Impulse and validated through real-world tests, achieving high accuracy in\nhornbill species identification. The project underscores the potential of\nTinyML for environmental monitoring and its broader application in ecological\nconservation efforts, contributing to both the field of TinyML and wildlife\nconservation.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528TinyML\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5206\u7c7b\u9a6c\u6765\u897f\u4e9a\u7280\u9e1f\u53eb\u58f0\uff0c\u5b9e\u73b0\u9ad8\u6548\u5b9e\u65f6\u91ce\u751f\u52a8\u7269\u76d1\u6d4b\u3002", "motivation": "\u7280\u9e1f\u9762\u4e34\u6816\u606f\u5730\u4e27\u5931\u3001\u5077\u730e\u548c\u73af\u5883\u53d8\u5316\u5a01\u80c1\uff0c\u4f20\u7edf\u76d1\u6d4b\u8d44\u6e90\u5bc6\u96c6\uff0cTinyML\u63d0\u4f9b\u9ad8\u6548\u5b9e\u65f6\u5206\u6790\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u97f3\u9891\u6570\u636e\u9884\u5904\u7406\u3001\u63d0\u53d6Mel-Frequency Energy\u7279\u5f81\u3001\u5728Arduino Nano 33 BLE\u4e0a\u90e8\u7f72\u6a21\u578b\uff0c\u4f7f\u7528Edge Impulse\u8bad\u7ec3\u548c\u9a8c\u8bc1\u3002", "result": "\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7280\u9e1f\u7269\u79cd\u8bc6\u522b\u3002", "conclusion": "\u5f3a\u8c03TinyML\u5728\u73af\u5883\u76d1\u6d4b\u548c\u751f\u6001\u4fdd\u62a4\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3aTinyML\u548c\u91ce\u751f\u52a8\u7269\u4fdd\u62a4\u9886\u57df\u8d21\u732e\u3002"}}
{"id": "2504.12279", "pdf": "https://arxiv.org/pdf/2504.12279", "abs": "https://arxiv.org/abs/2504.12279", "authors": ["Mikhail Osipov"], "title": "Dysarthria Normalization via Local Lie Group Transformations for Robust ASR", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "comment": "Preprint. 11 pages, 3 figures, 2 tables, 8 appendices. Code and data\n  available upon request", "summary": "We present a geometry-driven method for normalizing dysarthric speech using\nlocal Lie group transformations of spectrograms. Time, frequency, and amplitude\ndistortions are modeled as smooth, invertible deformations, parameterized by\nscalar fields and applied via exponential maps. A neural network is trained to\ninfer these fields from synthetic distortions of typical speech-without using\nany pathological data. At test time, the model applies an approximate inverse\nto real dysarthric inputs. Despite zero-shot generalization, we observe\nsubstantial ASR gains, including up to 16 percentage points WER reduction on\nchallenging TORGO samples, with no degradation on clean speech. This work\nintroduces a principled, interpretable approach for robust speech recognition\nunder motor speech disorders", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51e0\u4f55\u7684\u8c31\u56fe\u53d8\u6362\u65b9\u6cd5\uff0c\u7528\u4e8e\u89c4\u8303\u5316\u6784\u97f3\u969c\u788d\u8bed\u97f3\uff0c\u5b9e\u73b0\u96f6\u6837\u672c\u6cdb\u5316\u5e76\u663e\u8457\u6539\u5584\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u5904\u7406\u6784\u97f3\u969c\u788d\u5bfc\u81f4\u7684\u8bed\u97f3\u7578\u53d8\uff0c\u63d0\u9ad8\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u5728\u8fd0\u52a8\u6027\u8a00\u8bed\u969c\u788d\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u4f7f\u7528\u5c40\u90e8\u674e\u7fa4\u53d8\u6362\u5efa\u6a21\u8c31\u56fe\u7684\u65f6\u95f4\u3001\u9891\u7387\u548c\u5e45\u5ea6\u7578\u53d8\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u4ece\u5408\u6210\u7578\u53d8\u6570\u636e\u4e2d\u63a8\u65ad\u53c2\u6570\uff0c\u5e76\u5e94\u7528\u9006\u53d8\u6362\u89c4\u8303\u5316\u771f\u5b9e\u8f93\u5165\u3002", "result": "\u5728TORGO\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe16\u4e2a\u767e\u5206\u70b9\u7684\u8bcd\u9519\u8bef\u7387\u51cf\u5c11\uff0c\u540c\u65f6\u5728\u5e72\u51c0\u8bed\u97f3\u4e0a\u65e0\u6027\u80fd\u4e0b\u964d\uff0c\u5c55\u793a\u4e86\u96f6\u6837\u672c\u6cdb\u5316\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5f15\u5165\u4e86\u4e00\u79cd\u539f\u5219\u6027\u5f3a\u3001\u53ef\u89e3\u91ca\u7684\u9014\u5f84\uff0c\u63d0\u5347\u4e86\u5728\u8fd0\u52a8\u6027\u8a00\u8bed\u969c\u788d\u4e0b\u7684\u8bed\u97f3\u8bc6\u522b\u9c81\u68d2\u6027\u3002"}}
{"id": "2504.12285", "pdf": "https://arxiv.org/pdf/2504.12285", "abs": "https://arxiv.org/abs/2504.12285", "authors": ["Shuming Ma", "Hongyu Wang", "Shaohan Huang", "Xingxing Zhang", "Ying Hu", "Ting Song", "Yan Xia", "Furu Wei"], "title": "BitNet b1.58 2B4T Technical Report", "categories": ["cs.CL", "cs.LG"], "comment": "Work in progress", "summary": "We introduce BitNet b1.58 2B4T, the first open-source, native 1-bit Large\nLanguage Model (LLM) at the 2-billion parameter scale. Trained on a corpus of 4\ntrillion tokens, the model has been rigorously evaluated across benchmarks\ncovering language understanding, mathematical reasoning, coding proficiency,\nand conversational ability. Our results demonstrate that BitNet b1.58 2B4T\nachieves performance on par with leading open-weight, full-precision LLMs of\nsimilar size, while offering significant advantages in computational\nefficiency, including substantially reduced memory footprint, energy\nconsumption, and decoding latency. To facilitate further research and adoption,\nthe model weights are released via Hugging Face along with open-source\ninference implementations for both GPU and CPU architectures.", "AI": {"tldr": "\u672c\u8bba\u6587\u5f15\u5165\u4e86\u9996\u4e2a\u5f00\u6e90\u76841\u4f4dLLM BitNet b1.58 2B4T\uff0c\u5b83\u5728\u6027\u80fd\u4e0a\u4e0e\u7c7b\u4f3c\u89c4\u6a21\u7684\u5168\u7cbe\u5ea6LLM\u76f8\u5f53\uff0c\u4f46\u5177\u6709\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u52a8\u673a\u662f\u5f00\u53d1\u9ad8\u6548\u7684LLM\uff0c\u4ee5\u51cf\u5c11\u5185\u5b58\u5360\u7528\u3001\u80fd\u6e90\u6d88\u8017\u548c\u89e3\u7801\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u57284\u4e07\u4ebf\u4e2atoken\u7684\u8bed\u6599\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u8bed\u8a00\u7406\u89e3\u3001\u6570\u5b66\u63a8\u7406\u3001\u7f16\u7801\u80fd\u529b\u548c\u5bf9\u8bdd\u80fd\u529b\u7b49\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u4e0e\u9886\u5148\u7684\u5f00\u6e90\u5168\u7cbe\u5ea6LLM\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u5360\u7528\u3001\u80fd\u6e90\u6d88\u8017\u548c\u89e3\u7801\u5ef6\u8fdf\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u6a21\u578b\u6743\u91cd\u901a\u8fc7Hugging Face\u5f00\u6e90\uff0c\u5e76\u63d0\u4f9bGPU\u548cCPU\u7684\u63a8\u7406\u5b9e\u73b0\uff0c\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u91c7\u7528\u3002"}}
